#coding=utf8
import json, uuid, sys, os, re, logging
from typing import List, Union, Optional, Tuple, Any, Dict
import fitz, pymupdf # PyMuPDF
from utils.airqa_utils import AIRQA_DIR, get_airqa_paper_uuid, download_paper_pdf, get_relative_path
from .common_functions import is_valid_uuid, call_llm


logger = logging.getLogger(__name__)
handler = logging.StreamHandler(sys.stdout)
formatter = logging.Formatter(
    fmt='[%(asctime)s][%(filename)s - %(lineno)d][%(levelname)s]: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)


def infer_paper_title_from_pdf(
        pdf_path: str,
        first_lines: Optional[int] = None,
        model: str = 'gpt-4o',
        temperature: float = 0.0 # Use more deterministic decoding with temperature=0.0
    ) -> str:
    """ Use a language model to infer the title of a paper from the top `first_lines` lines of the first page in a PDF.
    """
    doc = fitz.open(pdf_path)
    first_page = doc[0]
    if first_lines is not None:
        first_page_text = '\n'.join(first_page.get_text().split('\n')[:first_lines])
        first_lines = f"the top {first_lines} lines of the first page"
    else:
        first_page_text = first_page.get_text()
        first_lines = "the first page"
    doc.close()

    # Call the language model to infer the title
    template = f"""You are an expert in academic papers. Your task is to identify the raw title of a research paper based on the extracted text from the first page. The provided text is from {first_lines} in the PDF file, extracted using PyMuPDF. Please ensure the following:\n1. Directly return the title without adding any extra context, explanations, or formatting.\n2. Do not modify the raw titleâ€”retain its original capitalization and punctuation exactly as presented.\n3. If the title spans multiple lines, concatenate them into a single line and return it.\n4. If you are certain that the provided text does not contain the paper's title, respond only with "title not found".\n\nHere is the extracted text:\n\n{first_page_text}\n\nYour response is:
"""
    title = call_llm(template, model=model, temperature=temperature).strip()
    if title.startswith("title not found"):
        logger.error(f"Paper title is not found in {first_lines} of the PDF {pdf_path}.")
        return None
    return title


def extract_metadata_from_scholar_api(title: str, api_tool: str = 'google-scholar') -> Dict[str, Any]:
    """ Extract metadata of a paper from Scholar APIs.
    @param:
        title: str, the title of the paper
        api_tool: str, the Scholar API tool to use, chosen from ['google-scholar', 'semantic-scholar', 'dblp']
    """
    assert api_tool in ['google-scholar', 'semantic-scholar', 'dblp'], f"Invalid Scholar API tool: {api_tool}."
    if api_tool == 'google-scholar':
        pass
    elif api_tool == 'semantic-scholar':
        pass
    elif api_tool == 'dblp':
        pass
    else:
        raise ValueError(f"Invalid Scholar API tool: {api_tool}.")


def get_ai_research_metadata(
        pdf_path: str,
        metadata_path: str = os.path.join(AIRQA_DIR, 'uuid2papers.json'),
        tmp_dir: str = os.path.join(AIRQA_DIR, 'uncategorized'),
        model: str = 'gpt-4o',
        temperature: float = 0.0,
        api_tool: str = 'google-scholar'
    ) -> Dict[str, Any]:
    """ Given input pdf_path, return the metadata of the paper.
    @param:
        pdf_path: str, we support the following inputs:
            - the local path to the PDF file, ending with '.pdf' (if already in {uuid}.pdf format, directly use the uuid)
            - the PDF URL to download the file, e.g., https://arxiv.org/pdf/2108.12212.pdf
            - the uuid of the paper (pre-fetch metadata of relevant papers)
            - the title of the paper (use scholar API calls to get the metadata)
        metadata_path: str, used to get the metadata of the given paper uuid
        tmp_dir: str, the folder to temporarily save the downloaded PDF file
        model and temperature: str, float, the language model and temperature for title inference
        api_tool: str, the Scholar API tool to use, chosen from ['google-scholar', 'semantic-scholar', 'dblp']
    @return: metadata dict
        {
            "uuid": "0a02b881-d0b1-59c6-a23e-1feb3bdf4c24", // UUID generated by `get_airqa_paper_uuid`
            "title": "Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models",
            "conference_full": "Annual Meeting of the Association for Computational Linguistics (2024)", // full title of the conference
            "conference": "ACL", // conference abbreviation
            "year": 2024, // conference year, or which year is this paper published
            "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", // volume title
            "bibtex": "...", // bibtex citation text
            "authors": ["Zhengxin Zhang", "Dan Zhao", "Xupeng Miao", ...], // authors list
            "num_pages": 36, // int value
            "pdf_url": "https://aclanthology.org/2024.acl-long.1.pdf", // URL to download the PDF, should end with .pdf
            "pdf_path": "data/dataset/airqa/papers/acl2024/ab14a93a-c5ee-5d60-8713-8b38bd501140.pdf", // local path to save the PDF, rename it with the UUID
            "abstract": "..." // paper abstract text
        }
    """
    if not os.path.exists(metadata_path):
        metadata_dict = {}
    with open(metadata_path, 'r', encoding='utf-8') as inf:
        metadata_dict = json.load(inf)

    # pdf_path: "/path/to/paper/397f31e7-2b9f-5795-a843-e29ea6b28e7a.pdf" -> "397f31e7-2b9f-5795-a843-e29ea6b28e7a"
    if pdf_path.endswith('.pdf') and is_valid_uuid(os.path.basename(pdf_path).split('.')[0]):
        pdf_path = os.path.basename(pdf_path).split('.')[0] # extract the uuid of the paper from the filename

    if is_valid_uuid(pdf_path): # is valid paper uuid?
        # [Preferred]: for published conference papers, pre-fetch metadata of all papers
        metadata = metadata_dict.get(pdf_path, {})
        if metadata == {}:
            raise ValueError(f"Metadata for paper UUID {pdf_path} not found in {metadata_path}.")
    else:
        if pdf_path.endswith('.pdf'): # local file path or remote URL
            pdf_path = pdf_path.strip()
            if pdf_path.startswith('http'): # remote URL, download to local path under `tmp_dir` with the same filename
                output_path = os.path.join(tmp_dir, os.path.basename(pdf_path))
                output_path = download_paper_pdf(pdf_path, output_path)
                if output_path is None:
                    raise ValueError(f"Failed to download the PDF file from {pdf_path}.")
                pdf_path = output_path
            # use LLM to infer the paper title from the first page (we assume the first page MUST contain the title)
            title = infer_paper_title_from_pdf(pdf_path, first_lines=20, model=model, temperature=temperature)
            if title is None:
                raise ValueError(f"Failed to infer the paper title from the first page of the PDF {pdf_path}.")
            logger.info(f"Inferred paper title for {pdf_path} is: {title}")
        else: title = pdf_path

        # use scholar API to get the metadata of the paper
        metadata = extract_metadata_from_scholar_api(title, api_tool=api_tool)
        if not metadata:
            raise ValueError(f"Failed to extract metadata from the Scholar API {api_tool} for the paper with title: {title}.")

        # metadata already exists, just skip
        if metadata["uuid"] in metadata_dict:
            logger.warning(f"Metadata for paper UUID {metadata['uuid']} already exists in {metadata_path}.")
            return metadata_dict[metadata['uuid']]

        pdf_path_renamed = metadata['pdf_path']
        if pdf_path.endswith('.pdf'): # already downloaded the PDF file, rename/move it
            os.rename(pdf_path, pdf_path_renamed)
        else: # not downloaded yet
            if not download_paper_pdf(metadata['pdf_url'], pdf_path_renamed):
                raise ValueError(f"Failed to download the PDF file from {metadata['pdf_url']} into {pdf_path_renamed}.")
        metadata['pdf_path'] = get_relative_path(pdf_path_renamed)

        # new entry added, serialize it
        with open(metadata_path, 'w', encoding='utf8') as of:
            json.dump(metadata_dict, of, indent=4, ensure_ascii=False)
    return metadata