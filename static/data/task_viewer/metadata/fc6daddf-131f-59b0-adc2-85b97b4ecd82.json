{
    "uuid": "fc6daddf-131f-59b0-adc2-85b97b4ecd82",
    "title": "Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{kasa-etal-2024-exploring,\n    title = \"Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques\",\n    author = \"Kasa, Siva Rajesh  and\n      Goel, Aniket  and\n      Gupta, Karan  and\n      Roychowdhury, Sumegh  and\n      Priyatam, Pattisapu  and\n      Bhanushali, Anish  and\n      Srinivasa Murthy, Prasanna\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.320\",\n    doi = \"10.18653/v1/2024.findings-acl.320\",\n    pages = \"5390--5404\",\n    abstract = \"Ordinal Classification (OC) is a widely encountered challenge in Natural Language Processing (NLP), with applications in various domains such as sentiment analysis, rating prediction, and more. Previous approaches to tackle OC have primarily focused on modifying existing or creating novel loss functions that explicitly account for the ordinal nature of labels. However, with the advent of Pre-trained Language Models (PLMs), it became possible to tackle ordinality through the implicit semantics of the labels as well. This paper provides a comprehensive theoretical and empirical examination of both these approaches. Furthermore, we also offer strategic recommendations regarding the most effective approach to adopt based on specific settings.\",\n}\n",
    "authors": [
        "Siva Rajesh Kasa",
        "Aniket Goel",
        "Karan Gupta",
        "Sumegh Roychowdhury",
        "Pattisapu Priyatam",
        "Anish Bhanushali",
        "Prasanna Srinivasa Murthy"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.320.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/fc6daddf-131f-59b0-adc2-85b97b4ecd82.pdf",
    "abstract": "Ordinal Classification (OC) is a widely encountered challenge in Natural Language Processing (NLP), with applications in various domains such as sentiment analysis, rating prediction, and more. Previous approaches to tackle OC have primarily focused on modifying existing or creating novel loss functions that explicitly account for the ordinal nature of labels. However, with the advent of Pre-trained Language Models (PLMs), it became possible to tackle ordinality through the implicit semantics of the labels as well. This paper provides a comprehensive theoretical and empirical examination of both these approaches. Furthermore, we also offer strategic recommendations regarding the most effective approach to adopt based on specific settings.",
    "num_pages": 15,
    "tldr": "Comparison of explicit and implicit techniques for ordinal text classification.",
    "tags": [
        "Ordinal Classification",
        "Natural Language Processing",
        "Pre-trained Language Models",
        "Loss Functions",
        "Sentiment Analysis"
    ]
}