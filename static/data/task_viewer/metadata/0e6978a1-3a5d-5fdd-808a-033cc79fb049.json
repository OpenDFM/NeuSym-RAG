{
    "uuid": "0e6978a1-3a5d-5fdd-808a-033cc79fb049",
    "title": "Interpretable Automatic Fine-grained Inconsistency Detection in Text Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{chan-etal-2023-interpretable,\n    title = \"Interpretable Automatic Fine-grained Inconsistency Detection in Text Summarization\",\n    author = \"Chan, Hou Pong  and\n      Zeng, Qi  and\n      Ji, Heng\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.402\",\n    doi = \"10.18653/v1/2023.findings-acl.402\",\n    pages = \"6433--6444\",\n    abstract = \"Existing factual consistency evaluation approaches for text summarization provide binary predictions and limited insights into the weakness of summarization systems. Therefore, we propose the task of fine-grained inconsistency detection, the goal of which is to predict the fine-grained types of factual errors in a summary. Motivated by how humans inspect factual inconsistency in summaries, we propose an interpretable fine-grained inconsistency detection model, FineGrainFact, which explicitly represents the facts in the documents and summaries with semantic frames extracted by semantic role labeling, and highlights the related semantic frames to predict inconsistency. The highlighted semantic frames help verify predicted error types and correct inconsistent summaries. Experiment results demonstrate that our model outperforms strong baselines and provides evidence to support or refute the summary.\",\n}\n",
    "authors": [
        "Hou Pong Chan",
        "Qi Zeng",
        "Heng Ji"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.402.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0e6978a1-3a5d-5fdd-808a-033cc79fb049.pdf",
    "abstract": "Existing factual consistency evaluation approaches for text summarization provide binary predictions and limited insights into the weakness of summarization systems. Therefore, we propose the task of fine-grained inconsistency detection, the goal of which is to predict the fine-grained types of factual errors in a summary. Motivated by how humans inspect factual inconsistency in summaries, we propose an interpretable fine-grained inconsistency detection model, FineGrainFact, which explicitly represents the facts in the documents and summaries with semantic frames extracted by semantic role labeling, and highlights the related semantic frames to predict inconsistency. The highlighted semantic frames help verify predicted error types and correct inconsistent summaries. Experiment results demonstrate that our model outperforms strong baselines and provides evidence to support or refute the summary.",
    "num_pages": 12,
    "tldr": "FineGrainFact detects and interprets fine-grained factual errors in summaries.",
    "tags": [
        "text summarization",
        "factual consistency",
        "inconsistency detection",
        "semantic role labeling",
        "interpretable models"
    ]
}