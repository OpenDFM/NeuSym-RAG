{
    "uuid": "32a52b98-370b-5bc4-87ab-5193405b723b",
    "title": "On the Multi-turn Instruction Following for Conversational Web Agents",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{deng-etal-2024-multi,\n    title = \"On the Multi-turn Instruction Following for Conversational Web Agents\",\n    author = \"Deng, Yang  and\n      Zhang, Xuan  and\n      Zhang, Wenxuan  and\n      Yuan, Yifei  and\n      Ng, See-Kiong  and\n      Chua, Tat-Seng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.477\",\n    doi = \"10.18653/v1/2024.acl-long.477\",\n    pages = \"8795--8812\",\n    abstract = \"Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to effectively engage with sequential user instructions in real-world scenarios has not been fully explored. In this work, we introduce a new task of Conversational Web Navigation, which necessitates sophisticated interactions that span multiple turns with both the users and the environment, supported by a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To tackle the limited context length of LLMs and the context-dependency issue of the conversational tasks, we further propose a novel framework, named self-reflective memory-augmented planning (Self-MAP), which employs memory utilization and self-reflection techniques. Extensive experiments are conducted to benchmark the MT-Mind2Web dataset, and validate the effectiveness of the proposed method.\",\n}\n",
    "authors": [
        "Yang Deng",
        "Xuan Zhang",
        "Wenxuan Zhang",
        "Yifei Yuan",
        "See-Kiong Ng",
        "Tat-Seng Chua"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.477.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/32a52b98-370b-5bc4-87ab-5193405b723b.pdf",
    "abstract": "Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to effectively engage with sequential user instructions in real-world scenarios has not been fully explored. In this work, we introduce a new task of Conversational Web Navigation, which necessitates sophisticated interactions that span multiple turns with both the users and the environment, supported by a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To tackle the limited context length of LLMs and the context-dependency issue of the conversational tasks, we further propose a novel framework, named self-reflective memory-augmented planning (Self-MAP), which employs memory utilization and self-reflection techniques. Extensive experiments are conducted to benchmark the MT-Mind2Web dataset, and validate the effectiveness of the proposed method.",
    "num_pages": 18,
    "tldr": "New framework enhances multi-turn web navigation with memory and self-reflection.",
    "tags": [
        "Conversational Web Navigation",
        "Large Language Models",
        "Multi-Turn Interactions",
        "Self-Reflective Memory",
        "Web Agents"
    ]
}