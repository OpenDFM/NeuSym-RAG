{
    "uuid": "c50df058-1617-58f1-9b89-c397fcdceb6f",
    "title": "FEVER: a large-scale dataset for Fact Extraction and VERification",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "James Thorne",
        "Andreas Vlachos",
        "Christos Christodoulopoulos",
        "Arpit Mittal"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.05355v3",
    "pdf_path": "data/dataset/airqa/papers/arxiv2018/c50df058-1617-58f1-9b89-c397fcdceb6f.pdf",
    "bibtex": "@misc{thorne2018feveralargescaledatasetfor,\n    title = {FEVER: a large-scale dataset for Fact Extraction and VERification},\n    author = {James Thorne and Andreas Vlachos and Christos Christodoulopoulos and Arpit Mittal},\n    year = {2018},\n    eprint = {1803.05355},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1803.05355},\n}",
    "abstract": "In this paper we introduce a new publicly available dataset for verification\nagainst textual sources, FEVER: Fact Extraction and VERification. It consists\nof 185,445 claims generated by altering sentences extracted from Wikipedia and\nsubsequently verified without knowledge of the sentence they were derived from.\nThe claims are classified as Supported, Refuted or NotEnoughInfo by annotators\nachieving 0.6841 in Fleiss $\\kappa$. For the first two classes, the annotators\nalso recorded the sentence(s) forming the necessary evidence for their\njudgment. To characterize the challenge of the dataset presented, we develop a\npipeline approach and compare it to suitably designed oracles. The best\naccuracy we achieve on labeling a claim accompanied by the correct evidence is\n31.87%, while if we ignore the evidence we achieve 50.91%. Thus we believe that\nFEVER is a challenging testbed that will help stimulate progress on claim\nverification against textual sources.",
    "num_pages": 20,
    "tldr": "FEVER dataset aids fact-checking research with 185,445 claims from Wikipedia.",
    "tags": [
        "Fact Verification",
        "Textual Sources",
        "Dataset",
        "Machine Learning",
        "Claim Classification"
    ]
}