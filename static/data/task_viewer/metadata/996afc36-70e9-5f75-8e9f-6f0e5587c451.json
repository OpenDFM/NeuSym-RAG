{
    "uuid": "996afc36-70e9-5f75-8e9f-6f0e5587c451",
    "title": "HuCurl: Human-induced Curriculum Discovery",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{elgaar-amiri-2023-hucurl,\n    title = \"{H}u{C}url: Human-induced Curriculum Discovery\",\n    author = \"Elgaar, Mohamed  and\n      Amiri, Hadi\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.104\",\n    doi = \"10.18653/v1/2023.acl-long.104\",\n    pages = \"1862--1877\",\n    abstract = \"We introduce the problem of curriculum discovery and describe a curriculum learning framework capable of discovering effective curricula in a curriculum space based on prior knowledge about sample difficulty. Using annotation entropy and loss as measures of difficulty, we show that (i): the top-performing discovered curricula for a given model and dataset are often non-monotonic as apposed to monotonic curricula in existing literature, (ii): the prevailing easy-to-hard or hard-to-easy transition curricula are often at the risk of underperforming, and (iii): the curricula discovered for smaller datasets and models perform well on larger datasets and models respectively. The proposed framework encompasses some of the existing curriculum learning approaches and can discover curricula that outperform them across several NLP tasks.\",\n}\n",
    "authors": [
        "Mohamed Elgaar",
        "Hadi Amiri"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.104.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/996afc36-70e9-5f75-8e9f-6f0e5587c451.pdf",
    "abstract": "We introduce the problem of curriculum discovery and describe a curriculum learning framework capable of discovering effective curricula in a curriculum space based on prior knowledge about sample difficulty. Using annotation entropy and loss as measures of difficulty, we show that (i): the top-performing discovered curricula for a given model and dataset are often non-monotonic as apposed to monotonic curricula in existing literature, (ii): the prevailing easy-to-hard or hard-to-easy transition curricula are often at the risk of underperforming, and (iii): the curricula discovered for smaller datasets and models perform well on larger datasets and models respectively. The proposed framework encompasses some of the existing curriculum learning approaches and can discover curricula that outperform them across several NLP tasks.",
    "num_pages": 16,
    "tldr": "HuCurl discovers effective non-monotonic curricula for improved NLP performance.",
    "tags": [
        "curriculum learning",
        "curriculum discovery",
        "non-monotonic curricula",
        "annotation entropy",
        "NLP tasks"
    ]
}