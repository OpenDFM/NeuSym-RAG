{
    "uuid": "0ef0a82a-0e86-5c1b-87b1-36e05e15bd76",
    "title": "Predicting the Quality of Revisions in Argumentative Writing",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
    "bibtex": "@inproceedings{liu-etal-2023-predicting,\n    title = \"Predicting the Quality of Revisions in Argumentative Writing\",\n    author = \"Liu, Zhexiong  and\n      Litman, Diane  and\n      Wang, Elaine  and\n      Matsumura, Lindsay  and\n      Correnti, Richard\",\n    editor = {Kochmar, Ekaterina  and\n      Burstein, Jill  and\n      Horbach, Andrea  and\n      Laarmann-Quante, Ronja  and\n      Madnani, Nitin  and\n      Tack, Ana{\\\"\\i}s  and\n      Yaneva, Victoria  and\n      Yuan, Zheng  and\n      Zesch, Torsten},\n    booktitle = \"Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bea-1.24\",\n    doi = \"10.18653/v1/2023.bea-1.24\",\n    pages = \"275--287\",\n    abstract = \"The ability to revise in response to feedback is critical to students{'} writing success. In the case of argument writing in specific, identifying whether an argument revision (AR) is successful or not is a complex problem because AR quality is dependent on the overall content of an argument. For example, adding the same evidence sentence could strengthen or weaken existing claims in different argument contexts (ACs). To address this issue we developed Chain-of-Thought prompts to facilitate ChatGPT-generated ACs for AR quality predictions. The experiments on two corpora, our annotated elementary essays and existing college essays benchmark, demonstrate the superiority of the proposed ACs over baselines.\",\n}\n",
    "authors": [
        "Zhexiong Liu",
        "Diane Litman",
        "Elaine Wang",
        "Lindsay Matsumura",
        "Richard Correnti"
    ],
    "pdf_url": "https://aclanthology.org/2023.bea-1.24.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0ef0a82a-0e86-5c1b-87b1-36e05e15bd76.pdf",
    "abstract": "The ability to revise in response to feedback is critical to studentsâ€™ writing success. In the case of argument writing in specific, identifying whether an argument revision (AR) is successful or not is a complex problem because AR quality is dependent on the overall content of an argument. For example, adding the same evidence sentence could strengthen or weaken existing claims in different argument contexts (ACs). To address this issue we developed Chain-of-Thought prompts to facilitate ChatGPT-generated ACs for AR quality predictions. The experiments on two corpora, our annotated elementary essays and existing college essays benchmark, demonstrate the superiority of the proposed ACs over baselines.",
    "num_pages": 13,
    "tldr": "Predicting revision quality in arguments using ChatGPT-generated contexts.",
    "tags": [
        "argumentative writing",
        "revision quality",
        "Chain-of-Thought prompts",
        "ChatGPT",
        "educational assessment"
    ]
}