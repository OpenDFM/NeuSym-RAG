{
    "uuid": "a6c04981-3a2d-5c78-acd2-66485765e32e",
    "title": "T.M. Scanlon at SemEval-2023 Task 4: Leveraging Pretrained Language Models for Human Value Argument Mining with Contrastive Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{molazadeh-oskuee-etal-2023-scanlon,\n    title = \"{T}.{M}. Scanlon at {S}em{E}val-2023 Task 4: Leveraging Pretrained Language Models for Human Value Argument Mining with Contrastive Learning\",\n    author = \"Molazadeh Oskuee, Milad  and\n      Rahgouy, Mostafa  and\n      Babaei Giglou, Hamed  and\n      D Seals, Cheryl\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.82\",\n    doi = \"10.18653/v1/2023.semeval-1.82\",\n    pages = \"603--608\",\n    abstract = \"Human values are of great concern to social sciences which refer to when people have different beliefs and priorities of what is generally worth striving for and how to do so. This paper presents an approach for human value argument mining using contrastive learning to leverage the isotropy of language models. We fine-tuned DeBERTa-Large in a multi-label classification fashion and achieved an F1 score of 49{\\%} for the task, resulting in a rank of 11. Our proposed model provides a valuable tool for analyzing arguments related to human values and highlights the significance of leveraging the isotropy of large language models for identifying human values.\",\n}\n",
    "authors": [
        "Milad Molazadeh Oskuee",
        "Mostafa Rahgouy",
        "Hamed Babaei Giglou",
        "Cheryl D Seals"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.82.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a6c04981-3a2d-5c78-acd2-66485765e32e.pdf",
    "abstract": "Human values are of great concern to social sciences which refer to when people have different beliefs and priorities of what is generally worth striving for and how to do so. This paper presents an approach for human value argument mining using contrastive learning to leverage the isotropy of language models. We fine-tuned DeBERTa-Large in a multi-label classification fashion and achieved an F1 score of 49% for the task, resulting in a rank of 11. Our proposed model provides a valuable tool for analyzing arguments related to human values and highlights the significance of leveraging the isotropy of large language models for identifying human values.",
    "num_pages": 6,
    "tldr": "Using contrastive learning with DeBERTa-Large for human value argument mining.",
    "tags": [
        "human values",
        "argument mining",
        "contrastive learning",
        "DeBERTa-Large",
        "language models"
    ]
}