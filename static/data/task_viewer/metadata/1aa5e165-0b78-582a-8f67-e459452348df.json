{
    "uuid": "1aa5e165-0b78-582a-8f67-e459452348df",
    "title": "CNLP-NITS at SemEval-2023 Task 10: Online sexism prediction, PREDHATE!",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{vetagiri-etal-2023-cnlp,\n    title = \"{CNLP}-{NITS} at {S}em{E}val-2023 Task 10: Online sexism prediction, {PREDHATE}!\",\n    author = \"Vetagiri, Advaitha  and\n      Adhikary, Prottay  and\n      Pakray, Partha  and\n      Das, Amitava\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.113\",\n    doi = \"10.18653/v1/2023.semeval-1.113\",\n    pages = \"815--822\",\n    abstract = \"Online sexism is a rising issue that threatens women{'}s safety, fosters hostile situations, and upholds social inequities. We describe a task SemEval-2023 Task 10 for creating English-language models that can precisely identify and categorize sexist content on internet forums and social platforms like Gab and Reddit as well to provide an explainability in order to address this problem. The problem is divided into three hierarchically organized subtasks: binary sexism detection, sexism by category, and sexism by fine-grained vector. The dataset consists of 20,000 labelled entries. For Task A, pertained models like Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM), which is called CNN-BiLSTM and Generative Pretrained Transformer 2 (GPT-2) models were used, as well as the GPT-2 model for Task B and C, and have provided experimental configurations. According to our findings, the GPT-2 model performs better than the CNN-BiLSTM model for Task A, while GPT-2 is highly accurate for Tasks B and C on the training, validation and testing splits of the training data provided in the task. Our proposed models allow researchers to create more precise and understandable models for identifying and categorizing sexist content in online forums, thereby empowering users and moderators.\",\n}\n",
    "authors": [
        "Advaitha Vetagiri",
        "Prottay Adhikary",
        "Partha Pakray",
        "Amitava Das"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.113.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/1aa5e165-0b78-582a-8f67-e459452348df.pdf",
    "abstract": "Online sexism is a rising issue that threatens womenâ€™s safety, fosters hostile situations, and upholds social inequities. We describe a task SemEval-2023 Task 10 for creating English-language models that can precisely identify and categorize sexist content on internet forums and social platforms like Gab and Reddit as well to provide an explainability in order to address this problem. The problem is divided into three hierarchically organized subtasks: binary sexism detection, sexism by category, and sexism by fine-grained vector. The dataset consists of 20,000 labelled entries. For Task A, pertained models like Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM), which is called CNN-BiLSTM and Generative Pretrained Transformer 2 (GPT-2) models were used, as well as the GPT-2 model for Task B and C, and have provided experimental configurations. According to our findings, the GPT-2 model performs better than the CNN-BiLSTM model for Task A, while GPT-2 is highly accurate for Tasks B and C on the training, validation and testing splits of the training data provided in the task. Our proposed models allow researchers to create more precise and understandable models for identifying and categorizing sexist content in online forums, thereby empowering users and moderators.",
    "num_pages": 8,
    "tldr": "GPT-2 excels in detecting and categorizing online sexism in SemEval-2023 Task 10.",
    "tags": [
        "online sexism detection",
        "SemEval-2023",
        "GPT-2",
        "CNN-BiLSTM",
        "social media analysis"
    ]
}