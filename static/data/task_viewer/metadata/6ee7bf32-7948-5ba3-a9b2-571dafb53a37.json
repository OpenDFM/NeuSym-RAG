{
    "uuid": "6ee7bf32-7948-5ba3-a9b2-571dafb53a37",
    "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Di Jin",
        "Eileen Pan",
        "Nassim Oufattole",
        "Wei-Hung Weng",
        "Hanyi Fang",
        "Peter Szolovits"
    ],
    "pdf_url": "http://arxiv.org/pdf/2009.13081v1",
    "pdf_path": "data/dataset/airqa/papers/arxiv2020/6ee7bf32-7948-5ba3-a9b2-571dafb53a37.pdf",
    "bibtex": "@misc{jin2020whatdiseasedoesthispatient,\n    title = {What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams},\n    author = {Di Jin and Eileen Pan and Nassim Oufattole and Wei-Hung Weng and Hanyi Fang and Peter Szolovits},\n    year = {2020},\n    eprint = {2009.13081},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2009.13081},\n}",
    "abstract": "Open domain question answering (OpenQA) tasks have been recently attracting\nmore and more attention from the natural language processing (NLP) community.\nIn this work, we present the first free-form multiple-choice OpenQA dataset for\nsolving medical problems, MedQA, collected from the professional medical board\nexams. It covers three languages: English, simplified Chinese, and traditional\nChinese, and contains 12,723, 34,251, and 14,123 questions for the three\nlanguages, respectively. We implement both rule-based and popular neural\nmethods by sequentially combining a document retriever and a machine\ncomprehension model. Through experiments, we find that even the current best\nmethod can only achieve 36.7\\%, 42.0\\%, and 70.1\\% of test accuracy on the\nEnglish, traditional Chinese, and simplified Chinese questions, respectively.\nWe expect MedQA to present great challenges to existing OpenQA systems and hope\nthat it can serve as a platform to promote much stronger OpenQA models from the\nNLP community in the future.",
    "num_pages": 12,
    "tldr": "MedQA: A challenging OpenQA dataset from medical exams in English and Chinese.",
    "tags": [
        "Open Domain Question Answering",
        "Medical Exams Dataset",
        "Multilingual NLP",
        "Machine Comprehension",
        "Natural Language Processing Challenges"
    ]
}