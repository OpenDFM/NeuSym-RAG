{
    "uuid": "3c3b3cfc-e4f2-52b9-899a-2f9cac25dafc",
    "title": "SantaCoder: don't reach for the stars!",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Loubna Ben Allal",
        "Raymond Li",
        "Denis Kocetkov",
        "Chenghao Mou",
        "Christopher Akiki",
        "Carlos Munoz Ferrandis",
        "Niklas Muennighoff",
        "Mayank Mishra",
        "Alex Gu",
        "Manan Dey",
        "Logesh Kumar Umapathi",
        "Carolyn Jane Anderson",
        "Yangtian Zi",
        "Joel Lamy Poirier",
        "Hailey Schoelkopf",
        "Sergey Troshin",
        "Dmitry Abulkhanov",
        "Manuel Romero",
        "Michael Lappert",
        "Francesco De Toni",
        "Bernardo García del Río",
        "Qian Liu",
        "Shamik Bose",
        "Urvashi Bhattacharyya",
        "Terry Yue Zhuo",
        "Ian Yu",
        "Paulo Villegas",
        "Marco Zocca",
        "Sourab Mangrulkar",
        "David Lansky",
        "Huu Nguyen",
        "Danish Contractor",
        "Luis Villa",
        "Jia Li",
        "Dzmitry Bahdanau",
        "Yacine Jernite",
        "Sean Hughes",
        "Daniel Fried",
        "Arjun Guha",
        "Harm de Vries",
        "Leandro von Werra"
    ],
    "pdf_url": "http://arxiv.org/pdf/2301.03988v2",
    "pdf_path": "data/dataset/airqa/papers/arxiv2023/3c3b3cfc-e4f2-52b9-899a-2f9cac25dafc.pdf",
    "bibtex": "@misc{allal2023santacoderdontreachforthe,\n    title = {SantaCoder: don't reach for the stars!},\n    author = {Loubna Ben Allal and Raymond Li and Denis Kocetkov and Chenghao Mou and Christopher Akiki and Carlos Munoz Ferrandis and Niklas Muennighoff and Mayank Mishra and Alex Gu and Manan Dey and Logesh Kumar Umapathi and Carolyn Jane Anderson and Yangtian Zi and Joel Lamy Poirier and Hailey Schoelkopf and Sergey Troshin and Dmitry Abulkhanov and Manuel Romero and Michael Lappert and Francesco De Toni and Bernardo García del Río and Qian Liu and Shamik Bose and Urvashi Bhattacharyya and Terry Yue Zhuo and Ian Yu and Paulo Villegas and Marco Zocca and Sourab Mangrulkar and David Lansky and Huu Nguyen and Danish Contractor and Luis Villa and Jia Li and Dzmitry Bahdanau and Yacine Jernite and Sean Hughes and Daniel Fried and Arjun Guha and Harm de Vries and Leandro von Werra},\n    year = {2023},\n    eprint = {2301.03988},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.SE},\n    url = {http://arxiv.org/abs/2301.03988},\n}",
    "abstract": "The BigCode project is an open-scientific collaboration working on the\nresponsible development of large language models for code. This tech report\ndescribes the progress of the collaboration until December 2022, outlining the\ncurrent state of the Personally Identifiable Information (PII) redaction\npipeline, the experiments conducted to de-risk the model architecture, and the\nexperiments investigating better preprocessing methods for the training data.\nWe train 1.1B parameter models on the Java, JavaScript, and Python subsets of\nThe Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find\nthat more aggressive filtering of near-duplicates can further boost performance\nand, surprisingly, that selecting files from repositories with 5+ GitHub stars\ndeteriorates performance significantly. Our best model outperforms previous\nopen-source multilingual code generation models (InCoder-6.7B and\nCodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java,\nJavaScript, and Python portions of MultiPL-E, despite being a substantially\nsmaller model. All models are released under an OpenRAIL license at\nhttps://hf.co/bigcode.",
    "num_pages": 22,
    "tldr": "SantaCoder project improves code generation by filtering near-duplicates, not stars.",
    "tags": [
        "BigCode project",
        "language models",
        "code generation",
        "PII redaction",
        "model performance"
    ]
}