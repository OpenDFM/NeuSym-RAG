{
    "uuid": "13a0c782-cda2-55db-b796-550f810c68c8",
    "title": "Quantifying Generalizations: Exploring the Divide Between Human and LLMs’ Sensitivity to Quantification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{collacciani-etal-2024-quantifying,\n    title = \"Quantifying Generalizations: Exploring the Divide Between Human and {LLM}s{'} Sensitivity to Quantification\",\n    author = \"Collacciani, Claudia  and\n      Rambelli, Giulia  and\n      Bolognesi, Marianna\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.636\",\n    doi = \"10.18653/v1/2024.acl-long.636\",\n    pages = \"11811--11822\",\n    abstract = \"Generics are expressions used to communicate abstractions about categories. While conveying general truths (e.g., {``}Birds fly{''}), generics have the interesting property to admit exceptions (e.g., penguins do not fly). Statements of this type help us organizing our knowledge of the world, and form the basis of how we express it (Hampton, 2012; Leslie, 2014).This study investigates how Large Language Models (LLMs) interpret generics, drawing upon psycholinguistic experimental methodologies. Understanding how LLMs interpret generic statements serves not only as a measure of their ability to abstract but also arguably plays a role in their encoding of stereotypes. Given that generics interpretation necessitates a comparison with explicitly quantified sentences, we explored i.) whether LLMs can correctly associate a quantifier with the generic structure, and ii.) whether the presence of a generic sentence as context influences the outcomes of quantifiers. We evaluated LLMs using both Surprisal distributions and prompting techniques.The findings indicate that models do not exhibit a strong sensitivity to quantification. Nevertheless, they seem to encode a meaning linked with the generic structure, which leads them to adjust their answers accordingly when a generalization is provided as context.\",\n}\n",
    "authors": [
        "Claudia Collacciani",
        "Giulia Rambelli",
        "Marianna Bolognesi"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.636.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/13a0c782-cda2-55db-b796-550f810c68c8.pdf",
    "abstract": "Generics are expressions used to communicate abstractions about categories. While conveying general truths (e.g., “Birds fly”), generics have the interesting property to admit exceptions (e.g., penguins do not fly). Statements of this type help us organizing our knowledge of the world, and form the basis of how we express it (Hampton, 2012; Leslie, 2014).This study investigates how Large Language Models (LLMs) interpret generics, drawing upon psycholinguistic experimental methodologies. Understanding how LLMs interpret generic statements serves not only as a measure of their ability to abstract but also arguably plays a role in their encoding of stereotypes. Given that generics interpretation necessitates a comparison with explicitly quantified sentences, we explored i.) whether LLMs can correctly associate a quantifier with the generic structure, and ii.) whether the presence of a generic sentence as context influences the outcomes of quantifiers. We evaluated LLMs using both Surprisal distributions and prompting techniques.The findings indicate that models do not exhibit a strong sensitivity to quantification. Nevertheless, they seem to encode a meaning linked with the generic structure, which leads them to adjust their answers accordingly when a generalization is provided as context.",
    "num_pages": 12,
    "tldr": "LLMs struggle with quantification but encode meaning from generic structures.",
    "tags": [
        "Generics",
        "Quantification",
        "Large Language Models",
        "Psycholinguistics",
        "Stereotypes"
    ]
}