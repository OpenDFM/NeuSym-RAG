{
    "uuid": "8689853d-6fd5-5394-86e4-f836490e237c",
    "title": "Puzzle Solving using Reasoning of Large Language Models: A Survey",
    "conference_full": "The 2024 Conference on Empirical Methods in Natural Language Processing",
    "conference": "EMNLP",
    "year": 2024,
    "volume": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    "bibtex": "@inproceedings{giadikiaroglou-etal-2024-puzzle,\n    title = \"Puzzle Solving using Reasoning of Large Language Models: A Survey\",\n    author = \"Giadikiaroglou, Panagiotis  and\n      Lymperaiou, Maria  and\n      Filandrianos, Giorgos  and\n      Stamou, Giorgos\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.646\",\n    doi = \"10.18653/v1/2024.emnlp-main.646\",\n    pages = \"11574--11591\",\n    abstract = \"Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in AI, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy{---}dividing puzzles into rule-based and rule-less categories{---}to critically assess LLMs through various methodologies, including prompting techniques, neuro-symbolic approaches, and fine-tuning. Through a critical review of relevant datasets and benchmarks, we assess LLMs{'} performance, identifying significant challenges in complex puzzle scenarios. Our findings highlight the disparity between LLM capabilities and human-like reasoning, particularly in those requiring advanced logical inference. The survey underscores the necessity for novel strategies and richer datasets to advance LLMs{'} puzzle-solving proficiency and contribute to AI{'}s logical reasoning and creative problem-solving advancements.\",\n}\n",
    "authors": [
        "Panagiotis Giadikiaroglou",
        "Maria Lymperaiou",
        "Giorgos Filandrianos",
        "Giorgos Stamou"
    ],
    "pdf_url": "https://aclanthology.org/2024.emnlp-main.646.pdf",
    "pdf_path": "data/dataset/airqa/papers/emnlp2024/8689853d-6fd5-5394-86e4-f836490e237c.pdf",
    "num_pages": 18,
    "abstract": "Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in AI, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy—dividing puzzles into rule-based and rule-less categories—to critically assess LLMs through various methodologies, including prompting techniques, neuro-symbolic approaches, and fine-tuning. Through a critical review of relevant datasets and benchmarks, we assess LLMs’ performance, identifying significant challenges in complex puzzle scenarios. Our findings highlight the disparity between LLM capabilities and human-like reasoning, particularly in those requiring advanced logical inference. The survey underscores the necessity for novel strategies and richer datasets to advance LLMs’ puzzle-solving proficiency and contribute to AI’s logical reasoning and creative problem-solving advancements.",
    "tldr": "Surveying LLMs' puzzle-solving abilities reveals key insights and challenges.",
    "tags": [
        "Large Language Models",
        "Puzzle Solving",
        "AI Reasoning",
        "Taxonomy",
        "Logical Inference"
    ]
}