{
    "uuid": "0d7108da-de5c-5e4c-9865-7c4141672767",
    "title": "Agent Planning with World Knowledge Model",
    "conference_full": "Conference on Neural Information Processing Systems",
    "conference": "NeurIPS",
    "year": 2024,
    "volume": "NeurIPS 2024 poster",
    "bibtex": "@inproceedings{\nqiao2024agent,\ntitle={Agent Planning with World Knowledge Model},\nauthor={Shuofei Qiao and Runnan Fang and Ningyu Zhang and Yuqi Zhu and Xiang Chen and Shumin Deng and Yong Jiang and Pengjun Xie and Fei Huang and Huajun Chen},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=j6kJSS9O6I}\n}",
    "authors": [
        "Shuofei Qiao",
        "Runnan Fang",
        "Ningyu Zhang",
        "Yuqi Zhu",
        "Xiang Chen",
        "Shumin Deng",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen"
    ],
    "pdf_url": "https://openreview.net/pdf/f7a356cde46106ef3f622466166ad2984ce70670.pdf",
    "pdf_path": "data/dataset/airqa/papers/neurips2024/0d7108da-de5c-5e4c-9865-7c4141672767.pdf",
    "num_pages": 29,
    "abstract": "Recent endeavors towards directly using large language models (LLMs) as agent models to execute interactive planning tasks have shown commendable results. Despite their achievements, however, they still struggle with brainless trial-and-error in global planning and generating hallucinatory actions in local planning due to their poor understanding of the \"real\" physical world. Imitating humans' mental world knowledge model which provides global prior knowledge before the task and maintains local dynamic knowledge during the task, in this paper, we introduce parametric World Knowledge Model (WKM) to facilitate agent planning. Concretely, we steer the agent model to self-synthesize knowledge from both expert and sampled trajectories. Then we develop WKM, providing prior task knowledge to guide the global planning and dynamic state knowledge to assist the local planning. Experimental results on three real-world simulated datasets with Mistral-7B, Gemma-7B, and Llama-3-8B demonstrate that our method can achieve superior performance compared to various strong baselines. Besides, we analyze to illustrate that our WKM can effectively alleviate the blind trial-and-error and hallucinatory action issues, providing strong support for the agent's understanding of the world. Other interesting findings include: 1) our instance-level task knowledge can generalize better to unseen tasks, 2) weak WKM can guide strong agent model planning, and 3) unified WKM training has promising potential for further development.",
    "tldr": "We introduce parametric World Knowledge Model (WKM) which provides global prior task knowledge and local dynamic state knowledge to facilitate agent planning.",
    "tags": [
        "world knowledge model",
        "agent planning",
        "large language models"
    ]
}