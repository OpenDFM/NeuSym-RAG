{
    "uuid": "10e37be8-8c9f-590c-b94f-e6bea03794f2",
    "title": "Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{jiang-etal-2024-leveraging,\n    title = \"Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling\",\n    author = \"Jiang, Hang  and\n      Zhang, Xiajie  and\n      Mahari, Robert  and\n      Kessler, Daniel  and\n      Ma, Eric  and\n      August, Tal  and\n      Li, Irene  and\n      Pentland, Alex  and\n      Kim, Yoon  and\n      Roy, Deb  and\n      Kabbara, Jad\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.388\",\n    doi = \"10.18653/v1/2024.acl-long.388\",\n    pages = \"7194--7219\",\n    abstract = \"Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of large language models (LLMs) in legal education to help non-experts learn intricate legal concepts through storytelling, an effective pedagogical tool in conveying complex and abstract concepts. We also introduce a new dataset LegalStories, which consists of 294 complex legal doctrines, each accompanied by a story and a set of multiple-choice questions generated by LLMs. To construct the dataset, we experiment with various LLMs to generate legal stories explaining these concepts. Furthermore, we use an expert-in-the-loop approach to iteratively design multiple-choice questions. Then, we evaluate the effectiveness of storytelling with LLMs through randomized controlled trials (RCTs) with legal novices on 10 samples from the dataset. We find that LLM-generated stories enhance comprehension of legal concepts and interest in law among non-native speakers compared to only definitions. Moreover, stories consistently help participants relate legal concepts to their lives. Finally, we find that learning with stories shows a higher retention rate for non-native speakers in the follow-up assessment. Our work has strong implications for using LLMs in promoting teaching and learning in the legal field and beyond.\",\n}\n",
    "authors": [
        "Hang Jiang",
        "Xiajie Zhang",
        "Robert Mahari",
        "Daniel Kessler",
        "Eric Ma",
        "Tal August",
        "Irene Li",
        "Alex Pentland",
        "Yoon Kim",
        "Deb Roy",
        "Jad Kabbara"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.388.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/10e37be8-8c9f-590c-b94f-e6bea03794f2.pdf",
    "abstract": "Making legal knowledge accessible to non-experts is crucial for enhancing general legal literacy and encouraging civic participation in democracy. However, legal documents are often challenging to understand for people without legal backgrounds. In this paper, we present a novel application of large language models (LLMs) in legal education to help non-experts learn intricate legal concepts through storytelling, an effective pedagogical tool in conveying complex and abstract concepts. We also introduce a new dataset LegalStories, which consists of 294 complex legal doctrines, each accompanied by a story and a set of multiple-choice questions generated by LLMs. To construct the dataset, we experiment with various LLMs to generate legal stories explaining these concepts. Furthermore, we use an expert-in-the-loop approach to iteratively design multiple-choice questions. Then, we evaluate the effectiveness of storytelling with LLMs through randomized controlled trials (RCTs) with legal novices on 10 samples from the dataset. We find that LLM-generated stories enhance comprehension of legal concepts and interest in law among non-native speakers compared to only definitions. Moreover, stories consistently help participants relate legal concepts to their lives. Finally, we find that learning with stories shows a higher retention rate for non-native speakers in the follow-up assessment. Our work has strong implications for using LLMs in promoting teaching and learning in the legal field and beyond.",
    "num_pages": 26,
    "tldr": "LLMs enhance legal learning via storytelling, improving comprehension and retention.",
    "tags": [
        "large language models",
        "legal education",
        "storytelling",
        "legal literacy",
        "dataset creation"
    ]
}