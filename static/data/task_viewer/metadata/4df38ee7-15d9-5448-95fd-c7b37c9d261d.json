{
    "uuid": "4df38ee7-15d9-5448-95fd-c7b37c9d261d",
    "title": "Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS",
    "conference_full": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "conference": "icassp",
    "year": 2024,
    "volume": "ICASSP session SLP: Speech & Language Processing",
    "bibtex": "@inproceedings{DBLP:conf/icassp/YangSDM0P024,\n  author       = {Yifan Yang and\n                  Feiyu Shen and\n                  Chenpeng Du and\n                  Ziyang Ma and\n                  Kai Yu and\n                  Daniel Povey and\n                  Xie Chen},\n  title        = {Towards Universal Speech Discrete Tokens: {A} Case Study for {ASR}\n                  and {TTS}},\n  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,\n                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},\n  pages        = {10401--10405},\n  publisher    = {{IEEE}},\n  year         = {2024},\n  url          = {https://doi.org/10.1109/ICASSP48485.2024.10447751},\n  doi          = {10.1109/ICASSP48485.2024.10447751},\n  timestamp    = {Tue, 06 Aug 2024 14:48:06 +0200},\n  biburl       = {https://dblp.org/rec/conf/icassp/YangSDM0P024.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}",
    "authors": [
        "Yifan Yang",
        "Feiyu Shen",
        "Chenpeng Du",
        "Ziyang Ma",
        "Kai Yu",
        "Daniel Povey",
        "Xie Chen"
    ],
    "pdf_url": "https://doi.org/10.1109/ICASSP48485.2024.10447751",
    "pdf_path": "data/dataset/airqa/papers/icassp2024/4df38ee7-15d9-5448-95fd-c7b37c9d261d.pdf",
    "num_pages": 5,
    "abstract": "Self-supervised learning (SSL) proficiency in speech-related tasks has driven research into utilizing discrete tokens for speech tasks like recognition and translation, which offer lower storage requirements and great potential to employ natural language processing techniques. However, these studies, mainly single-task focused, faced challenges like overfitting and performance degradation in speech recognition tasks, often at the cost of sacrificing performance in multi-task scenarios. This study presents a comprehensive comparison and optimization of discrete tokens generated by various leading SSL models in speech recognition and synthesis tasks. We aim to explore the universality of speech discrete tokens across multiple speech tasks. Experimental results demonstrate that discrete tokens achieve comparable results against systems trained on FBank features in speech recognition tasks and outperform mel-spectrogram features in speech synthesis in subjective and objective metrics. These findings suggest that universal discrete tokens have enormous potential in various speech-related tasks. Our work is open-source and publicly available at https://github.com/k2-fsa/icefall.",
    "tldr": "Universal discrete tokens enhance ASR and TTS performance, offering significant potential.",
    "tags": [
        "speech recognition",
        "speech synthesis",
        "discrete tokens",
        "self-supervised learning",
        "multi-task learning"
    ]
}