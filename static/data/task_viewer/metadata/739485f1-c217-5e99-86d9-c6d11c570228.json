{
    "uuid": "739485f1-c217-5e99-86d9-c6d11c570228",
    "title": "Measuring the Measuring Tools: An Automatic Evaluation of Semantic Metrics for Text Corpora",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "George Kour",
        "Samuel Ackerman",
        "Orna Raz",
        "Eitan Farchi",
        "Boaz Carmeli",
        "Ateret Anaby-Tavor"
    ],
    "pdf_url": "http://arxiv.org/pdf/2211.16259v1",
    "pdf_path": "data/dataset/airqa/papers/arxiv2022/739485f1-c217-5e99-86d9-c6d11c570228.pdf",
    "bibtex": "@misc{kour2022measuringthemeasuringtoolsan,\n    title = {Measuring the Measuring Tools: An Automatic Evaluation of Semantic Metrics for Text Corpora},\n    author = {George Kour and Samuel Ackerman and Orna Raz and Eitan Farchi and Boaz Carmeli and Ateret Anaby-Tavor},\n    year = {2022},\n    eprint = {2211.16259},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2211.16259},\n}",
    "abstract": "The ability to compare the semantic similarity between text corpora is\nimportant in a variety of natural language processing applications. However,\nstandard methods for evaluating these metrics have yet to be established. We\npropose a set of automatic and interpretable measures for assessing the\ncharacteristics of corpus-level semantic similarity metrics, allowing sensible\ncomparison of their behavior. We demonstrate the effectiveness of our\nevaluation measures in capturing fundamental characteristics by evaluating them\non a collection of classical and state-of-the-art metrics. Our measures\nrevealed that recently-developed metrics are becoming better in identifying\nsemantic distributional mismatch while classical metrics are more sensitive to\nperturbations in the surface text levels.",
    "num_pages": 12,
    "tldr": "Automatic evaluation of corpus-level semantic similarity metrics is proposed and tested.",
    "tags": [
        "semantic similarity",
        "text corpora",
        "evaluation metrics",
        "natural language processing",
        "corpus-level analysis"
    ]
}