{
    "uuid": "5a2b95c1-12d6-5b77-82a1-ee24180d27ae",
    "title": "In-context Examples Selection for Machine Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{agrawal-etal-2023-context,\n    title = \"In-context Examples Selection for Machine Translation\",\n    author = \"Agrawal, Sweta  and\n      Zhou, Chunting  and\n      Lewis, Mike  and\n      Zettlemoyer, Luke  and\n      Ghazvininejad, Marjan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.564\",\n    doi = \"10.18653/v1/2023.findings-acl.564\",\n    pages = \"8857--8873\",\n    abstract = \"Large-scale generative models show an impressive ability to perform a wide range of Natural Language Processing (NLP) tasks using in-context learning, where a few examples are used to describe a task to the model. For Machine Translation (MT), these examples are typically randomly sampled from the development dataset with a similar distribution as the evaluation set. However, it is unclear how the choice of these in context examples and their ordering impacts the output translation quality. In this work, we aim to understand the properties of good in-context examples for MT in both in-domain and out-of-domain settings. We show that the translation quality and the domain of the in-context examples matter and that 1-shot noisy unrelated examples can have a catastrophic impact on output quality. While concatenating multiple random examples reduces the effect of noise, a single good prompt optimized to maximize translation quality on the development dataset can elicit learned information from the pre-trained language model. Adding similar examples based on an n-gram overlap with the test source significantly and consistently improves the translation quality of the outputs, outperforming a strong kNN-MT baseline in 2 out of 4 out-of-domain datasets.\",\n}\n",
    "authors": [
        "Sweta Agrawal",
        "Chunting Zhou",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Marjan Ghazvininejad"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.564.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/5a2b95c1-12d6-5b77-82a1-ee24180d27ae.pdf",
    "abstract": "Large-scale generative models show an impressive ability to perform a wide range of Natural Language Processing (NLP) tasks using in-context learning, where a few examples are used to describe a task to the model. For Machine Translation (MT), these examples are typically randomly sampled from the development dataset with a similar distribution as the evaluation set. However, it is unclear how the choice of these in context examples and their ordering impacts the output translation quality. In this work, we aim to understand the properties of good in-context examples for MT in both in-domain and out-of-domain settings. We show that the translation quality and the domain of the in-context examples matter and that 1-shot noisy unrelated examples can have a catastrophic impact on output quality. While concatenating multiple random examples reduces the effect of noise, a single good prompt optimized to maximize translation quality on the development dataset can elicit learned information from the pre-trained language model. Adding similar examples based on an n-gram overlap with the test source significantly and consistently improves the translation quality of the outputs, outperforming a strong kNN-MT baseline in 2 out of 4 out-of-domain datasets.",
    "num_pages": 17,
    "tldr": "Optimizing in-context examples enhances machine translation quality.",
    "tags": [
        "Machine Translation",
        "In-context Learning",
        "Example Selection",
        "Translation Quality",
        "Domain Adaptation"
    ]
}