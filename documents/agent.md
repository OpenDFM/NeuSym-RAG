# Agent Baselines


## Folder Structure

<details><summary>ğŸ‘‡ğŸ» Click to preview the <code>agents</code> module</summary>

```txt
agents/
â”œâ”€â”€ envs/
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ actions/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ action.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ actions.json
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ calculate_expr.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ classic_retrieve.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ error_action.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ generate_answer.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ observation.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ retrieve_from_database.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ retrieve_from_vectorstore.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ view_image.py
â”‚Â Â  â”œâ”€â”€ classic_env.py
â”‚Â Â  â”œâ”€â”€ env_base.py
â”‚Â Â  â”œâ”€â”€ graph_env.py
â”‚Â Â  â”œâ”€â”€ hybrid_env.py
â”‚Â Â  â”œâ”€â”€ neural_env.py
â”‚Â Â  â””â”€â”€ symbolic_env.py
â”œâ”€â”€ frameworks/
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ agent_base.py
â”‚Â Â  â”œâ”€â”€ classic_rag_agent.py
â”‚Â Â  â”œâ”€â”€ iterative_classic_rag_agent.py
â”‚Â Â  â”œâ”€â”€ iterative_neu_rag_agent.py
â”‚Â Â  â”œâ”€â”€ iterative_sym_rag_agent.py
â”‚Â Â  â”œâ”€â”€ neusym_rag_agent.py
â”‚Â Â  â”œâ”€â”€ trivial_baseline.py
â”‚Â Â  â”œâ”€â”€ two_stage_hybrid_rag_agent.py
â”‚Â Â  â”œâ”€â”€ two_stage_neu_rag_agent.py
â”‚Â Â  â””â”€â”€ two_stage_sym_rag_agent.py
â”œâ”€â”€ models/
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ llm_base.py
â”‚Â Â  â”œâ”€â”€ llm_cache.py
â”‚Â Â  â”œâ”€â”€ llm_gpt.py
â”‚Â Â  â””â”€â”€ llm_vllm.py
â””â”€â”€ prompts/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ agent_prompt.py
    â”œâ”€â”€ hint_prompt.py
    â”œâ”€â”€ schema_prompt.py
    â”œâ”€â”€ system_prompt.py
    â””â”€â”€ task_prompt.py
```

</details>

The entire `agents` package can be splitted into 4 sub-modules:
- ğŸŒ `envs`: responsible for `gym`-like environments and action/observation space management (e.g., action specification, action parsing, serialization to messages, and execution upon the backend)
- ğŸ“­ `models`: responsible for calling LLMs. We implement the unified interface for both closed-source ([`GPTClient`](../agents/models/llm_gpt.py)) and open-source LLMs ([`VLLMClient`](../agents/models/llm_vllm.py)), along with a SQLite cache ([`Sqlite3CacheProvider`](../agents/models/llm_cache.py)) to store historical responses
- ğŸ“œ `prompts`: responsible for different prompt templates, e.g., system, agent, task, schema and hint prompts.
- â›©ï¸ `frameworks`: responsible for different agentic frameworks. Each baseline method inherits from the base `AgentBase` class and implements the `interact` function.


## Overview of Agent Baselines

<p align="center">
  <img src="../assets/agent_baselines.png" alt="Agent Baselines" width="95%">
  <br>
  <em>The Comparison of Different Agent Baselines</em>
</p>

Here is the checklist of all different agent baselines:

| method name                    | neural | symbolic | multi-view | multi-turn | agent method |
|:------------------------------ |:----:|:----:|:----:|:----:|:----|
| Trivial: question only         | âŒ | âŒ | âŒ | âŒ | [`trivial_question_only`](../scripts/trivial_question_only_baseline.py) |
| Trivial: title + abstract      | âŒ | âŒ | âŒ | âŒ | [`trivial_title_with_abstract`](../scripts/trivial_title_with_abstract_baseline.py) |
| Trivial: full-text with cutoff | âŒ | âŒ | âŒ | âŒ | [`trivial_full_text_with_cutoff`](../scripts/trivial_full_text_with_cutoff_baseline.py) |
| Classic-RAG                    | âœ… | âŒ | âŒ | âŒ | [`classic_rag`](../scripts/classic_rag_baseline.py) |
| Iterative Classic-RAG          | âœ… | âŒ | âŒ | âœ… | [`iterative_classic_rag`](../scripts/iterative_classic_rag_baseline.py) |
| Two-stage Neu-RAG              | âœ… | âŒ | âœ… | âŒ | [`two_stage_neu_rag`](../scripts/two_stage_neu_rag_baseline.py) |
| Iterative Neu-RAG              | âœ… | âŒ | âœ… | âœ… | [`iterative_neu_rag`](../scripts/iterative_neu_rag_baseline.py) |
| Two-stage Sym-RAG              | âŒ | âœ… | âœ… | âŒ | [`two_stage_sym_rag`](../scripts/two_stage_sym_rag_baseline.py) |
| Iterative Sym-RAG              | âŒ | âœ… | âœ… | âœ… | [`iterative_sym_rag`](../scripts/iterative_sym_rag_baseline.py) |
| Two-stage Graph-RAG            | âœ… | âŒ | âœ… | âŒ | [`two_stage_graph_rag`](../scripts/two_stage_graph_rag_baseline.py) |
| Iterative Graph-RAG            | âœ… | âŒ | âœ… | âœ… | [`iterative_graph_rag`](../scripts/iterative_graph_rag_baseline.py) |
| Two-stage Hybrid-RAG           | âœ… | âœ… | âœ… | âŒ | [`two_stage_hybrid_rag`](../scripts/two_stage_hybrid_rag_baseline.py) |
| **NeuSym-RAG**                 | âœ… | âœ… | âœ… | âœ… | [`neusym_rag`](../scripts/hybrid_neural_symbolic_rag.py) |

> **â—ï¸ Note:** Code for Two-stage Graph-RAG and Iterative Graph-RAG are preparing.


## Usage

- All dataset and database/vectorstore names are:

    | Dataset    | Dataset Name  | Database Name       | Vectorstore Name    |
    |:----------:|:-------------:|:-------------------:|:-------------------:|
    | AirQA-Real | `airqa`       | `ai_research`       | `ai_research`       |
    | M3SciQA    | `m3sciqa`     | `emnlp_papers`      | `emnlp_papers`      |
    | SciDQA     | `scidqa`      | `openreview_papers` | `openreview_papers` |

- We take the dataset `airqa` and database/vectorstore `ai_research` as an example:
    - Before running, please set the environment variable `OPENAI_API_KEY` to your OpenAI API key
    - If you want to use open-source LLMs (e.g., `â€‘â€‘llm qwen2.5-vl-72b-instruct`) launched with vLLM, please set the environment variable like:

        ```sh
        export VLLM_API_KEY="EMPTY"
        export VLLM_BASE_URL="http://localhost:8000/v1/"
        # export VLLM_EMBED_BASE_URL="http://localhost:8001/v1/" # for Graph-RAG methods
        ```

    - For other agent baselines, please use the corresponding [agent method](#overview-of-agent-baselines)

```sh
# NeuSym-RAG framework
python scripts/hybrid_neural_symbolic_rag.py --dataset airqa --test_data test_data_553.jsonl \
    --database ai_research --vectorstore ai_research --agent_method neusym_rag \
    --llm gpt-4o-mini --max_turn 20 # ... optional arguments, see below

# Other agent baseline methods
agent_method=classic_rag # trivial_question_only, iterative_neu_rag, two_stage_hybrid_rag, etc.
python scripts/${agent_method}_baseline.py --dataset airqa --test_data test_data_553.jsonl \
    --database ai_research --vectorstore ai_research --agent_method ${agent_method} \
    --llm gpt-4o-mini # ... optional arguments, see below
```

> **â—ï¸ NOTE:** For `two_stage_graph_rag` and `iterative_graph_rag`, the main body is the invocation of the official [GraphRAG](https://microsoft.github.io/graphrag/) script. Currently, we only support that the LLM (`--llm`) and embedding model (`--graphrag_embed`)  are both models from the OpenAI API base, or both from the vLLM API. If local servers are used, please also set the environment variable `VLLM_EMBED_BASE_URL` (e.g., `VLLM_EMBED_BASE_URL="http://localhost:8001/v1/"`) to the launched embedding server.
> **â­ï¸ TIP:** For different datasets, we set the default graphrag root to `data/graph/${dataset}/`. This folder can be changed by modifying the function `get_graphrag_root` in [`utils/config.py`](../utils/config.py).


## Optional Arguments

For all arguments below, they apply to all agent baselines (see [`utils/hyperparam_utils.py`](../utils/hyperparam_utils.py)).

### Input / Output Arguments

| Argument             | Default Value | Description               |
|:---------------------|:--------------|:--------------------------|
| `â€‘â€‘test_data`        | test_data.jsonl | The test data file in `.jsonl` format.      |
| `â€‘â€‘result_dir`       | results/        | Which folder to record the log and results. |
| `â€‘â€‘database_path`    | data/database/${database}.duckdb          | Specify the DuckDB path of the `.duckdb` file. |
| `â€‘â€‘vectorstore_path` | data/vectorstore/${vectorstore}.db        | Specify the Milvus VS path of the `.db` file if the launch_method is `standalone`. |
| `â€‘â€‘launch_method`    | standalone                                | How to launch the Milvus vectorstore. Choices: `['standalone', 'docker']` |
| `â€‘â€‘docker_uri`       | 127.0.0.1:19530                           | The URI of the Milvus server if the launch_method is `docker`. |


### Method Arguments

| Argument              | Default Value | Description |
|:----------------------|:--------------|:------------|
| `â€‘â€‘cutoff`            | 5             | The maximum number of tokens (x 1000) for input text context. For agent method `trivial_title_with_abstract` and `trivial_full_text_with_cutoff`. |
| `â€‘â€‘collection_name`   | text_sentence_transformers_all_minilm_l6_v2 | The collection name of the Milvus vectorstore. By default, use sentence-transformers/all-MiniLM-L6-v2. For agent method `classic_rag` and `iterative_classic_rag`. |
| `â€‘â€‘table_name`        | chunks        | The table name (which chunking view) to retrieve. For agent method `classic_rag` and `iterative_classic_rag`. |
| `â€‘â€‘column_name`       | text_content  | The column name (which chunking view) to retrieve. For agent method `classic_rag` and `iterative_classic_rag`. |
| `â€‘â€‘limit`             | 4             | The number of chunks to retrieve from the VS. Only used for agent method `classic_rag`. |
| `â€‘â€‘graphrag_method`   | local         | The retrieval method for agent method `two_stage_graph_rag` and `iterative_graph_rag`. Choices: `['local', 'global']`. |
| `--graphrag_embed`    | text-embedding-3-small | The embedding model name for Graph-RAG methods `two_stage_graph_rag` and `iterative_graph_rag`. |


### Prompt Arguments

| Argument              | Default Value | Description |
|:----------------------|:--------------|:------------|
| `â€‘â€‘action_format`     | markdown      | The format of the serialized action. Choices: `['json', 'markdown', 'xml', 'yaml']` |
| `â€‘â€‘output_format`     | json          | The format of the output observation. Choices: `['markdown', 'json', 'html', 'string']`. It will affect the [`RetrieveFromDatabase`](../agents/envs/actions/retrieve_from_database.py) and [`RetrieveFromVectorstore`](../agents/envs/actions/retrieve_from_vectorstore.py) actions. |
| `â€‘â€‘db_format`         | create_sql    | How to serialize the database schema. Choices: `['create_sql', 'detailed_json']`. |
| `â€‘â€‘vs_format`         | detailed_json | How to serialize the vectorstore schema. Currently, only `detailed_json` is supported. |
| `â€‘â€‘interact_protocol` | react         | How to extract the action text from raw LLM responses. Choices: `['react', 'code_block']`. Currently, this field is fixed. For Iterative Classic-RAG/Neu-RAG/Sym-RAG and NeuSym-RAG, it must be `react`, while `code_block` for the others. |
| `â€‘â€‘window_size`      | 5             | The history trajectory size of the sliding window for iterative agent methods. |
| `â€‘â€‘max_turn`         | 20            | The maximum number of turns in the interaction. |


### LLM Arguments

| Argument              | Default Value | Description |
|:----------------------|:--------------|:------------|
| `â€‘â€‘llm`               | gpt-4o-mini   | The LLM model name to use.  |
| `â€‘â€‘temperature`       | 0.7           | The temperature of the LLM. |
| `â€‘â€‘top_p`             | 0.95          | The top-p of the LLM.       |
| `â€‘â€‘max_tokens`        | 1500          | The maximum number of tokens to generate each turn. |
| `â€‘â€‘image_limit`      | 10            | The maximum number of images which can be inserted into messages. For non-VLLMs, set it to $0$. |
| `â€‘â€‘length_limit`     | 32            | The maximum number of tokens (x 1000, prompt + completion).           |
