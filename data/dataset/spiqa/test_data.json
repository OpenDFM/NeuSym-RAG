{"uuid": "562b0130-4810-51eb-a6c0-f682e3ccb107", "question": "Which dataset contains the most interactions (events) in the training set and how much larger is it compared to the dataset with the least interactions in the training set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset contains the most interactions (events) in the training set and how much larger is it compared to the dataset with the least interactions in the training set?", "reference_answer": "The VIDXL dataset contains the most interactions (events) in the training set with 69,312,698 events. This is roughly 7.7 times larger than the RSC15 dataset, which has the least interactions (9,011,321) in the training set. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8e9f49ed-32b5-5d9d-9a34-8584e5bbbf9d", "question": "How does the Average Relative Error (ARE) of node queries change as the width increases for different configurations of GSS and TCM?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the Average Relative Error (ARE) of node queries change as the width increases for different configurations of GSS and TCM?", "reference_answer": "The ARE of node queries generally decreases as the width increases for all configurations of GSS and TCM. However, there are some fluctuations in the ARE for some configurations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d106f09e-09bc-5fc7-9d6b-81c33797fa82", "question": "What systems are tested?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["68a65c06-f867-5dc7-887d-126231ab9db5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13695/4-Table1-1.png", "data/dataset/spiqa/images/1909.13695/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13695/1-Figure1-1.png", "data/dataset/spiqa/images/1909.13695/4-Table2-1.png", "data/dataset/spiqa/images/1909.13695/4-Table1-1.png", "data/dataset/spiqa/images/1909.13695/4-Figure2-1.png", "data/dataset/spiqa/images/1909.13695/5-Table4-1.png", "data/dataset/spiqa/images/1909.13695/5-Table3-1.png", "data/dataset/spiqa/images/1909.13695/6-Table5-1.png", "data/dataset/spiqa/images/1909.13695/6-Figure3-1.png", "data/dataset/spiqa/images/1909.13695/6-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What systems are tested?", "reference_answer": "BULATS i-vector/PLDA\nBULATS x-vector/PLDA\nVoxCeleb x-vector/PLDA\nPLDA adaptation (X1)\n Extractor fine-tuning (X2) ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "60cb011b-e97d-5d75-8cf9-bc760e1e5951", "question": "What does an \"affine classifier\" mean?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4bc68d1d-c421-567f-a14a-076cb7acca37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure3-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure6-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does an \"affine classifier\" mean?", "reference_answer": "The affine classifier is the classifier in the form of an affine function. The general form that is used in the paper is the function f: R^n -> R^m, where f(x) = W^T * x + B, for the given matrix and vector W and B."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "cbd5353d-c4ca-5729-b854-c6051f43e537", "question": "What kind of information do the HMMs learn that the LSTMs don't?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["87a9e03f-09ae-5bb4-bc24-68595340bd33"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1606.05320/4-Figure2-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1606.05320/2-Figure1-1.png", "data/dataset/spiqa/images/1606.05320/3-Table1-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure2-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What kind of information do the HMMs learn that the LSTMs don't?", "reference_answer": "The HMM can identify punctuation or pick up on vowels.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "db9b3638-1f9b-552b-b3c0-99b467359762", "question": "Between WSN and ALOQ, which method is the most efficient in terms of runtime for both F-SRE1 and F-SRE2?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Between WSN and ALOQ, which method is the most efficient in terms of runtime for both F-SRE1 and F-SRE2?", "reference_answer": "ALOQ is significantly more efficient than WSN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b57e57e8-a33a-548e-8137-2cb779d0ac16", "question": "How much is proposed model better than baselines in performed experiments?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["173e78a6-fe2d-557c-b85c-20332b46d0c3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.09484/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.09484/2-Figure1-1.png", "data/dataset/spiqa/images/1909.09484/4-Figure2-1.png", "data/dataset/spiqa/images/1909.09484/6-Table1-1.png", "data/dataset/spiqa/images/1909.09484/7-Table2-1.png", "data/dataset/spiqa/images/1909.09484/8-Table3-1.png", "data/dataset/spiqa/images/1909.09484/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much is proposed model better than baselines in performed experiments?", "reference_answer": "most of the models have similar performance on BPRA: DSTC2 (+0.0015), Maluuba (+0.0729)\nGDP achieves the best performance in APRA: DSTC2 (+0.2893), Maluuba (+0.2896)\nGDP significantly outperforms the baselines on BLEU: DSTC2 (+0.0791), Maluuba (+0.0492)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0daa3283-eb47-54c1-8523-6a2440c44ad4", "question": "What is the role of the Leaky Unit in the SYNONYMNET model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the Leaky Unit in the SYNONYMNET model?", "reference_answer": "The Leaky Unit helps to aggregate the context information from different sources and allows the model to learn the relationships between entities and their contexts."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b17745a4-8a66-5040-8d06-2b0b303a6f41", "question": "Can SCRF be used to pretrain the model?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["cb1cdc71-ce9a-5344-ac1c-eb19c69b6af8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.06378/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.06378/3-Figure1-1.png", "data/dataset/spiqa/images/1702.06378/3-Table1-1.png", "data/dataset/spiqa/images/1702.06378/4-Figure2-1.png", "data/dataset/spiqa/images/1702.06378/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Can SCRF be used to pretrain the model?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7d18e2d8-95f1-5bfc-98b3-16651f7db143", "question": "Which retrieval system was used for baselines?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["291d1fdb-d1eb-5734-9b4d-629d03ced08a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.03904/8-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.03904/2-Figure1-1.png", "data/dataset/spiqa/images/1707.03904/5-Figure2-1.png", "data/dataset/spiqa/images/1707.03904/6-Table1-1.png", "data/dataset/spiqa/images/1707.03904/7-Figure3-1.png", "data/dataset/spiqa/images/1707.03904/8-Figure4-1.png", "data/dataset/spiqa/images/1707.03904/9-Table2-1.png", "data/dataset/spiqa/images/1707.03904/9-Table3-1.png", "data/dataset/spiqa/images/1707.03904/11-Table4-1.png", "data/dataset/spiqa/images/1707.03904/11-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which retrieval system was used for baselines?", "reference_answer": "The dataset comes with a ranked set of relevant documents. Hence the baselines do not use a retrieval system.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9535a3cd-504f-5567-a527-dcdff7f2e2e2", "question": "What is the meaning of \"using graph structures explicitly\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5c0777ae-e2aa-52ca-b4d3-5f54a4fcbd7e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/17-Table4-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/18-Table5-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/18-Table6-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/19-Table7-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/19-Table8-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/2-Figure1-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/21-Figure5-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/4-Figure2-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/6-Table1-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/7-Table2-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/8-Table3-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/9-Figure3-1.png", "data/dataset/spiqa/images/ea0e4a9778e33b7f8e7b3246d63071330950995a/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the meaning of \"using graph structures explicitly\"?", "reference_answer": "The meaning of using graph structures explicitly is to explicity incorporate structural information into the self-attention.\nThe reason is that both P3 and P7 state the main contribution of SAT with paraphrasing.\nP3 indicates that to consider graph structure explicitly is a main idea of SAT, and P7 emphasizes it as to incorporate structural information in the self-attention."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "75e831a1-1d69-5a6e-b999-2fda9ac1e7b2", "question": "Which model performed best on the SNLI test set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e12c7d24-8cfc-57b1-b048-9a36c5251d57"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table3-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table4-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table5-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table6-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed best on the SNLI test set?", "reference_answer": "The Transfer + MTSA model performed best on the SNLI test set with an accuracy of 86.9%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0527bb02-a04f-591a-9e6b-7b1603507ba8", "question": "Could you tell me more about the metrics used for performance evaluation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6361988e-3e4f-5f83-8fe0-d397f71d596c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.05474/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.05474/3-Table1-1.png", "data/dataset/spiqa/images/1906.05474/4-Table2-1.png", "data/dataset/spiqa/images/1906.05474/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Could you tell me more about the metrics used for performance evaluation?", "reference_answer": "BLUE utilizes different metrics for each of the tasks: Pearson correlation coefficient, F-1 scores, micro-averaging, and accuracy", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "345d05a9-5cf9-5db5-b2c1-cc9be149f48a", "question": " What percentage of improvement in inference speed is obtained by the proposed method over the newest state-of-the-art methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["70ae29ea-ee7c-5f6d-9dcb-3e357e5633b6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.05969/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.05969/6-Table1-1.png", "data/dataset/spiqa/images/1908.05969/7-Table2-1.png", "data/dataset/spiqa/images/1908.05969/7-Figure1-1.png", "data/dataset/spiqa/images/1908.05969/8-Table3-1.png", "data/dataset/spiqa/images/1908.05969/8-Table4-1.png", "data/dataset/spiqa/images/1908.05969/9-Table5-1.png", "data/dataset/spiqa/images/1908.05969/9-Table7-1.png", "data/dataset/spiqa/images/1908.05969/9-Table8-1.png", "data/dataset/spiqa/images/1908.05969/9-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": " What percentage of improvement in inference speed is obtained by the proposed method over the newest state-of-the-art methods?", "reference_answer": "Across 4 datasets, the best performing proposed model (CNN) achieved an average of 363% improvement over the state of the art method (LR-CNN)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "77e02059-ccc0-5aa9-bc5a-a62ded953e96", "question": "What is the relationship between the table and the graph sketch in the figure?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the table and the graph sketch in the figure?", "reference_answer": "The table provides the mapping between the nodes in the original graph and their corresponding hash values, which are used to create the graph sketch."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4c91500f-4b12-5546-8aca-e12999b1ea2f", "question": "Is the dataset balanced between speakers of different L1s?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["20a6a8bb-4530-596f-bb20-a85794e4b4c7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.11346/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.11346/2-Table1-1.png", "data/dataset/spiqa/images/1804.11346/3-Figure1-1.png", "data/dataset/spiqa/images/1804.11346/3-Table2-1.png", "data/dataset/spiqa/images/1804.11346/3-Table3-1.png", "data/dataset/spiqa/images/1804.11346/4-Figure2-1.png", "data/dataset/spiqa/images/1804.11346/4-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the dataset balanced between speakers of different L1s?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e71d8f70-d70c-51fa-99f5-90013d761d62", "question": "Why did the authors chose to train YOLO using VGG-16 and not other neural network architecture ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why did the authors chose to train YOLO using VGG-16 and not other neural network architecture ?", "reference_answer": "In fact, the base YOLO model and Fast YOLO have used GoogLeNet-inspired architecture to VGG-16. The authors claim that they have trained it with VGG-16 and it had better accuracy, however, it was too slow to be real-time. The YOLO model is first pretrained on the ImageNet 1000-class competition dataset and later trained on training and validation data of the Pascal VOC 2007 dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7d790c79-74a1-5623-802f-eb55c09c2a38", "question": "Do the tweets come from a specific region?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["003f3652-c8da-5e68-b9cc-37dce4480ab1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.06927/3-Figure1-1.png", "data/dataset/spiqa/images/1912.06927/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.06927/2-Table1-1.png", "data/dataset/spiqa/images/1912.06927/3-Table2-1.png", "data/dataset/spiqa/images/1912.06927/3-Figure1-1.png", "data/dataset/spiqa/images/1912.06927/4-Figure2-1.png", "data/dataset/spiqa/images/1912.06927/4-Figure3-1.png", "data/dataset/spiqa/images/1912.06927/5-Table3-1.png", "data/dataset/spiqa/images/1912.06927/5-Table5-1.png", "data/dataset/spiqa/images/1912.06927/5-Table6-1.png", "data/dataset/spiqa/images/1912.06927/5-Table4-1.png", "data/dataset/spiqa/images/1912.06927/6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the tweets come from a specific region?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "96dcb2d8-dd71-50c6-b82f-be2982f3d0d7", "question": "On which dataset did the gRCC* algorithm achieve the largest relative improvement over the RCC algorithm, and by approximately how much did it improve?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "On which dataset did the gRCC* algorithm achieve the largest relative improvement over the RCC algorithm, and by approximately how much did it improve?", "reference_answer": "The gRCC* algorithm achieved the largest relative improvement over the RCC algorithm on the YTF dataset, with a relative improvement of approximately 31.9%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "aecb9506-78df-5844-b8ff-49318631a84b", "question": "What is the relationship between the decline probability of an expert and whether or not they have a \"friend\" who has already declined?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5ca3482f-83fe-54e5-acb1-1b4d1ecfa5b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Table1-1.png", "data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Figure2-1.png", "data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the decline probability of an expert and whether or not they have a \"friend\" who has already declined?", "reference_answer": "The decline probability of an expert is higher if they have a \"friend\" who has already declined."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5d8320e1-4af8-5d98-bef9-bf8c1018ad9f", "question": "Did ensemble schemes help in boosting peformance, by how much?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/4-Table3-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did ensemble schemes help in boosting peformance, by how much?", "reference_answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3cec34a0-a775-5eff-a8ce-32baf8fe9b44", "question": "What were the sizes of the test sets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5117e634-b3ba-554e-a128-afdab2e09dc4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.07464/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.07464/2-Figure1-1.png", "data/dataset/spiqa/images/1905.07464/3-Table1-1.png", "data/dataset/spiqa/images/1905.07464/3-Table2-1.png", "data/dataset/spiqa/images/1905.07464/5-Figure2-1.png", "data/dataset/spiqa/images/1905.07464/8-Table3-1.png", "data/dataset/spiqa/images/1905.07464/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What were the sizes of the test sets?", "reference_answer": "Test set 1 contained 57 drug labels and 8208 sentences and test set 2 contained 66 drug labels and 4224 sentences", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f1cbeacb-02ef-51b0-9a7c-aef6d060aab6", "question": "What are the three steps involved in compressed matrix factorization?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["31d46012-0f02-590b-bcb4-f7f19a18db4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure4-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three steps involved in compressed matrix factorization?", "reference_answer": "The three steps involved in compressed matrix factorization are: \n\n1. Compress the full data matrix M to obtain a compressed matrix M̃. \n2. Factorize M̃ to obtain matrices W̃ and H̃. \n3. Approximate the left factor of M via sparse recovery on each column of W̃."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "74da3eb7-9181-54d0-9781-b7b677708f1b", "question": "Which translation system performs the best and how does its performance compare to Google Translate (GT)? Is the comparison with GT completely fair? Explain your answer.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["72b0d1a9-3397-5940-bf4b-b5fdf8480554"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure3-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure4-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure5-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table1-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which translation system performs the best and how does its performance compare to Google Translate (GT)? Is the comparison with GT completely fair? Explain your answer.", "reference_answer": "According to Table 2, Moses achieves the highest BLEU scores among the listed translation systems (Moses, Nematus) across all language pairs. However, its performance still falls behind Google Translate (GT) in every case.\n\nThe comparison with GT might not be entirely fair because, as GT has the advantage of being trained on a significantly larger dataset. This suggests that GT's performance advantage might be partially due to its training data rather than solely its inherent capabilities."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "935208a8-9205-56e5-a430-77a9995447f5", "question": "What is the difference between the representation task and the learning-to-learn task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9104d00a-0d2b-565f-acc8-c4650cf151b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure6-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure7-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure2-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure8-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure12-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure9-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the representation task and the learning-to-learn task?", "reference_answer": "The representation task takes an appearance as input and outputs an RGB value, while the learning-to-learn task takes an image as input and outputs a DAM representation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1716d226-9a79-55b2-8a3d-31e92f2ba657", "question": "Does the paper show how each component of KERM can contribute to passage re-ranking performance quantitatively and qualitatively?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c2ce8e68-6fc4-5e1d-b409-ebb07c73d811"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table5-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table6-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table7-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/2-Figure1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/4-Figure2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/5-Figure3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/6-Figure4-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/8-Table1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does the paper show how each component of KERM can contribute to passage re-ranking performance quantitatively and qualitatively?", "reference_answer": "This work conducted ablation studies to investigate the contribution of each component in the performance of KERM. By testing different settings for the knowledge injector, this work found that performance decreases without knowledge interaction and also without knowledge propagation. By testing the model without global or local distillation, they also demonstrated that performance decreases without global distillation and efficiency decreases without either global or local distillation. These experiments demonstrate that each component of KERM contributes to passage re-ranking performance quantitatively."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8480ef51-16d2-51f4-a107-77a4a54bfcd4", "question": "What is the performance achieved on NarrativeQA?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["03783a9f-aefc-568a-94a9-d775185b2072"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.02262/8-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.02262/1-Figure1-1.png", "data/dataset/spiqa/images/1901.02262/2-Figure2-1.png", "data/dataset/spiqa/images/1901.02262/4-Figure3-1.png", "data/dataset/spiqa/images/1901.02262/5-Table1-1.png", "data/dataset/spiqa/images/1901.02262/6-Table2-1.png", "data/dataset/spiqa/images/1901.02262/6-Table3-1.png", "data/dataset/spiqa/images/1901.02262/6-Table4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure5-1.png", "data/dataset/spiqa/images/1901.02262/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the performance achieved on NarrativeQA?", "reference_answer": "Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, ROUGE-L: 59.87", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ba8fa9c8-59f6-5a80-ac53-591742bf3917", "question": "By how much does the proposed approach outperform CoVE?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c4860d9-c6fc-5c07-b4c7-dc9cd1aff233"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/5-Table1-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "By how much does the proposed approach outperform CoVE?", "reference_answer": "On IMDb, the proposed approach reduced the error by 43.9% when compared to CoVe but, on TREC-6, the approach did not improve performance significantly. The results are shown in Table 2."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c3505313-6b08-5ec8-acd7-3a0bfbe99e80", "question": "Which dataset has the highest AUC for all ripple set sizes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the highest AUC for all ripple set sizes?", "reference_answer": "MovieLens-1M"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "735b1549-7585-56a5-ab19-34a0ad763e79", "question": "Do they compare to other models appart from HAN?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["0ed2d55f-edc2-5373-bb0c-0b75929df9f1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.06006/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.06006/1-Figure1-1.png", "data/dataset/spiqa/images/1908.06006/2-Figure2-1.png", "data/dataset/spiqa/images/1908.06006/2-Figure3-1.png", "data/dataset/spiqa/images/1908.06006/6-Table1-1.png", "data/dataset/spiqa/images/1908.06006/6-Table2-1.png", "data/dataset/spiqa/images/1908.06006/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they compare to other models appart from HAN?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0423f55f-4294-556f-8173-a109882884e4", "question": "What datasets do they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["00beb125-0ab9-5d4c-b11c-5d2a4febd4d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.07820/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.07820/3-Figure1-1.png", "data/dataset/spiqa/images/2001.07820/3-Table1-1.png", "data/dataset/spiqa/images/2001.07820/4-Table2-1.png", "data/dataset/spiqa/images/2001.07820/5-Figure2-1.png", "data/dataset/spiqa/images/2001.07820/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What datasets do they use?", "reference_answer": "1 IMDB dataset and 2 Yelp datasets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "537243b1-5df2-5b64-9dbc-4fdd8bc9ed02", "question": "How does the proposed method preserve facial details and expression during face swapping?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed method preserve facial details and expression during face swapping?", "reference_answer": "The proposed method utilizes Light-CNN as both the source of the identity features and face verification loss. This allows the method to transfer the appearance of eyes, eyebrows, hairs, etc., while keeping other factors intact, e.g., head pose, shape of face, and facial expression."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fb6bb4d0-a5a3-518c-b866-c6018baab5be", "question": "What is the effect of adding DA to the baseline method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of adding DA to the baseline method?", "reference_answer": "Adding DA to the baseline method improves the PSNR and SSIM values, while slightly decreasing the LMD value."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ee8423ed-66f7-55df-9679-0c5c97b9d344", "question": "What rouge score do they achieve?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3e23a677-9f88-5a36-a751-7eaaca56c05f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.08345/7-Table4-1.png", "data/dataset/spiqa/images/1908.08345/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.08345/3-Figure1-1.png", "data/dataset/spiqa/images/1908.08345/5-Table1-1.png", "data/dataset/spiqa/images/1908.08345/6-Table2-1.png", "data/dataset/spiqa/images/1908.08345/7-Table4-1.png", "data/dataset/spiqa/images/1908.08345/7-Table3-1.png", "data/dataset/spiqa/images/1908.08345/8-Table5-1.png", "data/dataset/spiqa/images/1908.08345/8-Figure2-1.png", "data/dataset/spiqa/images/1908.08345/9-Figure3-1.png", "data/dataset/spiqa/images/1908.08345/9-Table7-1.png", "data/dataset/spiqa/images/1908.08345/9-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What rouge score do they achieve?", "reference_answer": "Highest scores for ROUGE-1, ROUGE-2 and ROUGE-L on CNN/DailyMail test set are 43.85, 20.34 and 39.90 respectively; on the XSum test set 38.81, 16.50 and 31.27 and on the NYT test set 49.02, 31.02 and 45.55", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "69aa3553-2712-5e52-a6c1-00e996732a24", "question": "How do the results of the baseline and the proposed method compare in terms of accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the results of the baseline and the proposed method compare in terms of accuracy?", "reference_answer": "The proposed method appears to be more accurate than the baseline method. The depth maps generated by the proposed method are more detailed and realistic than those generated by the baseline method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2ca7e65e-e420-5e7a-998b-7eafac37bfe5", "question": "Which constraint has the most significant impact on the FIT values for the CMS data set when the target rank is 15?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which constraint has the most significant impact on the FIT values for the CMS data set when the target rank is 15?", "reference_answer": "The smoothness constraint on $\\M{U_k}$ has the most significant impact on the FIT values for the CMS data set when the target rank is 15."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f4a72422-e1a4-5d71-959d-90a54c638f35", "question": "What are the CNN architectures that were explored in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the CNN architectures that were explored in this paper?", "reference_answer": "The paper uses AlexNet, CifarNet, and GoogLeNet with various numbers of parameters."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b768f644-5e48-5cca-bc2e-6622dab8379a", "question": "Can the methods of \"one-to-many augmentation\" like data augmentation and 3D face reconstruction effectively improve the performance of deep FR algorithms in terms of accuracy and diversity of training data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Can the methods of \"one-to-many augmentation\" like data augmentation and 3D face reconstruction effectively improve the performance of deep FR algorithms in terms of accuracy and diversity of training data?", "reference_answer": "In terms of accuracy, the paper mentions a set of work done on assembled multi-input networks that used \"one-to-many augmentation\" methods to expand their dataset and achieve better results compared to individual networks. In terms of diversity, all data augmentation, 3D face reconstruction, autoencoders, and especially GANs were found to be effective in generating faces in certain poses, angles, with different expressions, etc."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f9ba7b76-45bb-50c5-bf28-6c6519e35978", "question": "Which dataset has the most lane marking annotations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the most lane marking annotations?", "reference_answer": "BDD100K"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5d20f331-a37e-5cf3-b4ad-87cd97caa542", "question": "What is specific to gCAS cell?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["a1b87d72-fb6c-5cf0-b2fd-7e16ff1ab378"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11546/2-Figure1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11546/1-Table1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure2-1.png", "data/dataset/spiqa/images/1908.11546/3-Table5-1.png", "data/dataset/spiqa/images/1908.11546/3-Table4-1.png", "data/dataset/spiqa/images/1908.11546/3-Table3-1.png", "data/dataset/spiqa/images/1908.11546/3-Table2-1.png", "data/dataset/spiqa/images/1908.11546/4-Table6-1.png", "data/dataset/spiqa/images/1908.11546/4-Table7-1.png", "data/dataset/spiqa/images/1908.11546/5-Table8-1.png", "data/dataset/spiqa/images/1908.11546/5-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is specific to gCAS cell?", "reference_answer": "It has three sequentially connected units to output continue, act and slots generating multi-acts in a doble recurrent manner.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ff28a154-0c44-59d6-ab75-a10c15cc6681", "question": "How many times better performance is the model than the baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d85f50b2-fa24-5b35-9fdd-00222f679121"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/2-Figure1-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/4-Table1-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/4-Table2-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/5-Table3-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/5-Table4-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/6-Table5-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Figure2-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Table6-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Table7-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many times better performance is the model than the baseline?", "reference_answer": "almost same"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "34a412e8-1fee-5462-b392-037c4d75e259", "question": "How does the performance of the adaptive model compare to the fixed model with different values of α?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the adaptive model compare to the fixed model with different values of α?", "reference_answer": "The adaptive model consistently outperforms the fixed model for all values of α."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "70a456af-d994-5413-8a22-f63a6a21b60d", "question": "BLINK have two different versions, bi-encoding version and cross-encoding version. Is this true?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Figure2-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Table1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Table2-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table3-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "BLINK have two different versions, bi-encoding version and cross-encoding version. Is this true?", "reference_answer": "BLINK model is a two-stage method using two encoders: bi-encoder and cross-encoder. With the qualitative analysis, the authors compared the BLINK with its bi-encoding version which uses a bi-encoder for candidate ranking instead of a cross-encoder, and showed that the cross-encoding version utilizing context information better than the bi-encoding version. Therefore we can say that BLINK has two different versions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0efa0d8f-3284-5e56-b762-a9d9ac991060", "question": "How are edges aggregated in the graph sketch $G_h$?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How are edges aggregated in the graph sketch $G_h$?", "reference_answer": "Edges are aggregated by adding their weights together."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "327ccf6d-0944-5dff-9df3-eb33341290b4", "question": "Is the model tested against any baseline?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["5008cb98-355b-5856-a606-64c9db839023"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.05603/3-TableIV-1.png", "data/dataset/spiqa/images/1910.05603/3-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.05603/2-TableI-1.png", "data/dataset/spiqa/images/1910.05603/2-TableII-1.png", "data/dataset/spiqa/images/1910.05603/3-Figure1-1.png", "data/dataset/spiqa/images/1910.05603/3-TableIII-1.png", "data/dataset/spiqa/images/1910.05603/3-TableIV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the model tested against any baseline?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "76c36cbb-3e61-5c0c-a6f7-ab1f909ff787", "question": "Which method performs the best when trained with only 1% of the MNIST training data, and how much does data augmentation improve its performance in this scenario?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best when trained with only 1% of the MNIST training data, and how much does data augmentation improve its performance in this scenario?", "reference_answer": "When trained with only 1% of the MNIST training data, ITN (B-CNN) (w/ DA) performs the best with a testing error of 2.78%. Data augmentation further improves its performance by 0.4%, bringing the testing error down to 2.78% from 3.18% achieved by ITN (B-CNN) without data augmentation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b3fd6c20-b1a6-54dc-a6c1-a419e307b502", "question": "Which method achieved the highest F1 score on the Lobby dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1291db8d-1be8-551a-a360-7bedc5ef404a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure2-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table3-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table2-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table1-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the highest F1 score on the Lobby dataset?", "reference_answer": "Ours-supervised achieved the highest F1 score on the Lobby dataset with a score of 93.4."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "954950a8-8673-5b22-bff3-04fb2d46faee", "question": "Which of the following algorithms performs the best when trained via the CE?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the following algorithms performs the best when trained via the CE?", "reference_answer": "C&W-hc"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "299ea47a-67ba-50ed-a0a0-eeeade4f9731", "question": "What is the size of this dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["37a5f603-9e5f-5fa5-bdfd-9dc0318ef668"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.02027/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.02027/1-Figure1-1.png", "data/dataset/spiqa/images/1909.02027/3-Table1-1.png", "data/dataset/spiqa/images/1909.02027/4-Table2-1.png", "data/dataset/spiqa/images/1909.02027/4-Table3-1.png", "data/dataset/spiqa/images/1909.02027/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the size of this dataset?", "reference_answer": " 23,700 queries, including 22,500 in-scope queries covering 150 intents, which can be grouped into 10 general domains and 1,200 out-of-scope queries.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c597d6f8-16a4-5b96-b4bf-dad93ab35f85", "question": "How does the ACNN framework learn context-sensitive filters?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the ACNN framework learn context-sensitive filters?", "reference_answer": "The ACNN framework learns context-sensitive filters through two modules: the filter generation module and the adaptive convolution module. The filter generation module produces a set of filters conditioned on the input sentence, while the adaptive convolution module applies the generated filters to an input sentence. The two modules are jointly differentiable, and the overall architecture can be trained in an end-to-end manner."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5de1ca4d-e025-550c-8f18-93392a32faf6", "question": "By how much do they outperform BiLSTMs in Sentiment Analysis?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["46891329-d7bb-5ed0-8a96-0c1db898f0bf"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09786/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09786/3-Figure1-1.png", "data/dataset/spiqa/images/1811.09786/6-Table1-1.png", "data/dataset/spiqa/images/1811.09786/7-Table4-1.png", "data/dataset/spiqa/images/1811.09786/7-Table6-1.png", "data/dataset/spiqa/images/1811.09786/9-Table10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much do they outperform BiLSTMs in Sentiment Analysis?", "reference_answer": "Proposed RCRN outperforms ablative baselines BiLSTM by +2.9% and 3L-BiLSTM by +1.1% on average across 16 datasets.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ac85dcec-87f4-52b2-87af-d1a7460ee012", "question": "Why does flow estimation become less accurate near image boundaries?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why does flow estimation become less accurate near image boundaries?", "reference_answer": "Flow estimation becomes less accurate near image boundaries because there is less information available to estimate the flow. This is because the pixels at the boundaries are only surrounded by pixels on one side, whereas pixels in the interior of the image are surrounded by pixels on all sides."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "23a98e60-306a-5f41-980c-cbd7ebfbccc8", "question": "By how much is performance improved with multimodality?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c92a0375-1113-5ab2-8a03-db0cfac6b0ed"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13714/2-Table1-1.png", "data/dataset/spiqa/images/1909.13714/2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13714/2-Table1-1.png", "data/dataset/spiqa/images/1909.13714/2-Table2-1.png", "data/dataset/spiqa/images/1909.13714/3-Table3-1.png", "data/dataset/spiqa/images/1909.13714/3-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much is performance improved with multimodality?", "reference_answer": "F1 score increased from 0.89 to 0.92", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6860619e-68ae-576a-91c6-019154d57cb1", "question": "Which correction method resulted in the best performance in terms of nDCG@10 and ERR@10, and how does it compare to not using any correction method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["43e9c887-125b-5503-b988-b6cac3e4aa71"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table3-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table2-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table1-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which correction method resulted in the best performance in terms of nDCG@10 and ERR@10, and how does it compare to not using any correction method?", "reference_answer": "The DNN trained with DLA achieved the best performance in terms of both nDCG@10 (0.421) and ERR@10 (0.582). Compared to not using any correction method (NoCorrect), DLA shows a significant improvement in both metrics, with nDCG@10 being higher by 0.063 and ERR@10 being higher by 0.082."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "49c31ffe-cfc2-529c-a49a-e31a81d54157", "question": "Is the segmented training data 2d or 3d ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is the segmented training data 2d or 3d ?", "reference_answer": "V-Net is trained on the 3D MRI prostate volumes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "826ac639-d112-5b84-b5b2-5fd0c6b8b0ff", "question": "How many natural language explanations are human-written?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6bdd1d89-2a09-591a-a1d4-4dacee0a3091"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.03744/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.03744/2-Figure1-1.png", "data/dataset/spiqa/images/2004.03744/2-Figure2-1.png", "data/dataset/spiqa/images/2004.03744/4-Table1-1.png", "data/dataset/spiqa/images/2004.03744/5-Figure3-1.png", "data/dataset/spiqa/images/2004.03744/5-Figure4-1.png", "data/dataset/spiqa/images/2004.03744/6-Table2-1.png", "data/dataset/spiqa/images/2004.03744/6-Figure5-1.png", "data/dataset/spiqa/images/2004.03744/7-Figure6-1.png", "data/dataset/spiqa/images/2004.03744/7-Figure7-1.png", "data/dataset/spiqa/images/2004.03744/8-Figure8-1.png", "data/dataset/spiqa/images/2004.03744/8-Table3-1.png", "data/dataset/spiqa/images/2004.03744/8-Figure9-1.png", "data/dataset/spiqa/images/2004.03744/8-Figure10-1.png", "data/dataset/spiqa/images/2004.03744/9-Figure11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many natural language explanations are human-written?", "reference_answer": "Totally 6980 validation and test image-sentence pairs have been corrected.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9426a424-44fc-5d65-b7ac-0c00c6108be9", "question": "They propose StarGAN to overcome a limitation of high computational complexity of current image-to-image translation models. Is it true?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6b94108c-7ba9-5d71-959f-889739e9041f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/2-Figure2-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/3-Figure3-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/5-Figure4-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/6-Figure5-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/7-Figure6-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/7-Table1-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/7-Table2-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/8-Figure7-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "They propose StarGAN to overcome a limitation of high computational complexity of current image-to-image translation models. Is it true?", "reference_answer": "It is false. There is no evidence that the motivation of StarGAN was made in order to overcome a limitation of high computational complexity, even it achieved that."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "be249d94-567d-5ae6-8f18-ebc81c5dc0f8", "question": "Which method achieves the lowest error rate on ILSVRC at 1/4 of the total cost?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ed9d843d-3ea3-5d22-89db-e8dff591f7ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure3-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure1-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure4-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure5-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the lowest error rate on ILSVRC at 1/4 of the total cost?", "reference_answer": "MSDNNet38"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e00feba5-ce06-530a-826c-795c49fce839", "question": "What are the three types of sentences that the annotators are asked to write?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ab8d017f-8645-5337-aa84-f52783391b99"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table4-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Figure1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table5-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table2-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three types of sentences that the annotators are asked to write?", "reference_answer": "The three types of sentences are: \n1. A sentence that is definitely correct about the situation or event in the line.\n2. A sentence that might be correct about the situation or event in the line.\n3. A sentence that is definitely incorrect about the situation or event in the line."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "538385cf-f77e-5c22-a9ad-b938b698c27e", "question": "By how much do they improve the accuracy of inferences over state-of-the-art methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9b137394-bf1f-5368-adc9-cd1f6165f76d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.08824/7-Table6-1.png", "data/dataset/spiqa/images/1909.08824/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.08824/1-Figure1-1.png", "data/dataset/spiqa/images/1909.08824/2-Table1-1.png", "data/dataset/spiqa/images/1909.08824/2-Table2-1.png", "data/dataset/spiqa/images/1909.08824/3-Figure2-1.png", "data/dataset/spiqa/images/1909.08824/3-Figure3-1.png", "data/dataset/spiqa/images/1909.08824/4-Figure4-1.png", "data/dataset/spiqa/images/1909.08824/6-Table3-1.png", "data/dataset/spiqa/images/1909.08824/6-Table4-1.png", "data/dataset/spiqa/images/1909.08824/6-Table5-1.png", "data/dataset/spiqa/images/1909.08824/7-Table6-1.png", "data/dataset/spiqa/images/1909.08824/7-Table7-1.png", "data/dataset/spiqa/images/1909.08824/7-Table9-1.png", "data/dataset/spiqa/images/1909.08824/7-Table8-1.png", "data/dataset/spiqa/images/1909.08824/8-Table10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much do they improve the accuracy of inferences over state-of-the-art methods?", "reference_answer": "ON Event2Mind, the accuracy of proposed method is improved by  absolute BLUE  2.9,  10.87, 1.79 for xIntent, xReact and oReact respectively.\nOn Atomic dataset, the accuracy of proposed method is improved by  absolute BLUE 3.95.   4.11, 4.49 for xIntent, xReact and oReact.respectively.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "51210c28-f9bf-561a-b6cc-b8c988ddd185", "question": "What is the definition of a non-negative tensor?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e0369791-b574-5ff8-aaeb-89c221d8f857"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table4-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the definition of a non-negative tensor?", "reference_answer": "A non-negative tensor is a tensor whose elements are all non-negative real numbers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b5109981-23d6-53a6-bdf9-6f7298fd70c6", "question": "Which lossless compression scheme achieved the highest compression gain in the example shown in Figure 1?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which lossless compression scheme achieved the highest compression gain in the example shown in Figure 1?", "reference_answer": "The proposed scheme achieved the highest compression gain."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f687014d-03ef-5610-b096-8f6bbae6c2da", "question": "How is the quality of singing voice measured?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9cf7109a-fd48-5204-a06a-f3625a1359ae"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.01852/3-Table2-1.png", "data/dataset/spiqa/images/1912.01852/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.01852/2-Figure2-1.png", "data/dataset/spiqa/images/1912.01852/2-Figure1-1.png", "data/dataset/spiqa/images/1912.01852/3-Table1-1.png", "data/dataset/spiqa/images/1912.01852/3-Table2-1.png", "data/dataset/spiqa/images/1912.01852/4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How is the quality of singing voice measured?", "reference_answer": "Automatic: Normalized cross correlation (NCC)\nManual: Mean Opinion Score (MOS)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e196c9b0-b001-5ea4-a607-d03b058ddae6", "question": "How does the performance of lane marking detection change with different thresholds (τ) for direction, continuity, and category?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of lane marking detection change with different thresholds (τ) for direction, continuity, and category?", "reference_answer": "As the threshold (τ) increases, the ODS-F scores for direction, continuity, and category generally increase as well. This indicates that the model performs better in detecting lane markings with higher thresholds, meaning it can tolerate larger deviations from the ground truth annotations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d506fe24-a5ab-56a5-9d34-9f938bbe5351", "question": "Which weather condition has the highest classification accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which weather condition has the highest classification accuracy?", "reference_answer": "Clear weather."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a7bfe260-c915-55fc-9a57-a203c7332b68", "question": "Can't we use parallelization with RNN layers approach with any possible way?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/13-Figure3-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/14-Figure4-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/15-Figure5-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/3-Figure1-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/4-Figure2-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/6-Table1-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/8-Table2-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/9-Table3-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Can't we use parallelization with RNN layers approach with any possible way?", "reference_answer": "Because hidden state of each input position depends on previous hidden state therefore RNN can not be parallelized. Whereas Transformer due to attention layers are highly parallel."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5dba0efc-cbc5-51ac-923b-e9c2804b0bf8", "question": "The authors claims that the LSTM networks systems allow the flow of information across many layers without attenuation, is that true?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0931f3d2-f642-5062-8737-af4d1805c275"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/3-Figure1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/5-Table3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/7-Figure3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/8-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The authors claims that the LSTM networks systems allow the flow of information across many layers without attenuation, is that true?", "reference_answer": "Inspired by LSTM, the authors designed an information highway that adaptively passes information back, which is effective when there are many layers, so LSTM is also effective for many layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "4e89eb3c-b03f-5092-a6c8-ce2ea8eae8a4", "question": "What is the purpose of the blank space labeled Z'5?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f51e9f68-1547-5a42-8e74-fbfbfcb7f509"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure5-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure3-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure4-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Table1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the blank space labeled Z'5?", "reference_answer": "The blank space labeled Z'5 is used to complete the allocation of the original pieces."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e43da0e0-9ac1-55b6-9d55-05a407e5f861", "question": "What do they mean by answer styles?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["03783a9f-aefc-568a-94a9-d775185b2072"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.02262/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.02262/1-Figure1-1.png", "data/dataset/spiqa/images/1901.02262/2-Figure2-1.png", "data/dataset/spiqa/images/1901.02262/4-Figure3-1.png", "data/dataset/spiqa/images/1901.02262/5-Table1-1.png", "data/dataset/spiqa/images/1901.02262/6-Table2-1.png", "data/dataset/spiqa/images/1901.02262/6-Table3-1.png", "data/dataset/spiqa/images/1901.02262/6-Table4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure5-1.png", "data/dataset/spiqa/images/1901.02262/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What do they mean by answer styles?", "reference_answer": "well-formed sentences vs concise answers", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "eef74249-d387-595a-8654-3e1a2ac489e2", "question": "What type of parameter would be considered a 'good' initial parameter?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6297fbcc-4cda-5e1d-b3ab-9036a2192dcd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/12-Figure6-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/12-Table3-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/13-Figure7-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/2-Figure1-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/6-Figure2-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/6-Figure3-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/7-Table1-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What type of parameter would be considered a 'good' initial parameter?", "reference_answer": "A good initial parameter is a parameter that gives good performance in many tasks even with a little fine-tuning of the parameter. This means that the loss function defined in many tasks is sensitive, and this sensitive loss leads to good updates."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e914871d-64cc-5ce4-8337-899e47e9258a", "question": "Why is the optimal threshold chosen to be at the right margin of the region around the mode of the histogram?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e91f7cea-06b5-5326-88d0-de2c234edf4d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table1-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table5-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table6-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why is the optimal threshold chosen to be at the right margin of the region around the mode of the histogram?", "reference_answer": "The region around the mode of the histogram mostly contains noise. Therefore, the optimal threshold is chosen to be at the right margin of this region to avoid including too much noise in the thresholded image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0e1c0032-68e0-5fc1-a97a-b43134480232", "question": "How does the IPA label data after interacting with users?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6afd317a-0848-5d04-a59e-f04ede10e164"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.02284/5-Table2-1.png", "data/dataset/spiqa/images/2001.02284/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.02284/5-Table1-1.png", "data/dataset/spiqa/images/2001.02284/5-Table2-1.png", "data/dataset/spiqa/images/2001.02284/6-Table3-1.png", "data/dataset/spiqa/images/2001.02284/7-Table4-1.png", "data/dataset/spiqa/images/2001.02284/7-Table5-1.png", "data/dataset/spiqa/images/2001.02284/7-Table6-1.png", "data/dataset/spiqa/images/2001.02284/9-Table10-1.png", "data/dataset/spiqa/images/2001.02284/9-Table11-1.png", "data/dataset/spiqa/images/2001.02284/9-Table8-1.png", "data/dataset/spiqa/images/2001.02284/10-Figure1-1.png", "data/dataset/spiqa/images/2001.02284/12-Table17-1.png", "data/dataset/spiqa/images/2001.02284/12-Table18-1.png", "data/dataset/spiqa/images/2001.02284/13-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How does the IPA label data after interacting with users?", "reference_answer": "It defined a sequence labeling task to extract custom entities from user input and label the next action (out of 13  custom actions defined).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d0850e37-2534-565f-94f8-b6ef96172bf4", "question": "Which step in the methodology resulted in the largest decrease in the size of the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0423e038-405f-5171-a89b-75e3079e5aa6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which step in the methodology resulted in the largest decrease in the size of the dataset?", "reference_answer": "Step 4, Reason disambiguation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c51ebbcb-07b8-55c0-87b0-590287befc56", "question": "Why does the Semantic self-supervision model perform better on ReferIt (mask) compared to ReferIt (bbox), and how does this relate to the difference in performance between Visual Genome and Flickr30k datasets? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why does the Semantic self-supervision model perform better on ReferIt (mask) compared to ReferIt (bbox), and how does this relate to the difference in performance between Visual Genome and Flickr30k datasets? ", "reference_answer": "The Semantic self-supervision model performs better on ReferIt (mask) compared to ReferIt (bbox) because mask-based annotations are considered more precise and accurate for measuring localization performance than bounding boxes. Masks tightly encompass the specific region referred to by the phrase, whereas bounding boxes can include extraneous areas. \n\nThis relates to the difference in performance between Visual Genome and Flickr30k because both Visual Genome and ReferIt (mask) contain phrases that refer to very specific regions or non-salient objects. Precise localization is crucial for achieving high accuracy on these datasets. Flickr30k, on the other hand, annotates all bounding boxes referring to a phrase, leading to potentially less precise localization requirements and generally higher performance across methods. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e758040b-08d9-5e26-9163-df6d3a021082", "question": "which algorithm was the highest performer?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e2ee9294-e24c-5a6e-a4e9-15d0ab035817"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.04042/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.04042/2-Table1-1.png", "data/dataset/spiqa/images/1908.04042/4-Figure1-1.png", "data/dataset/spiqa/images/1908.04042/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "which algorithm was the highest performer?", "reference_answer": "A hybrid model consisting of best performing popularity-based approach with the best similarity-based approach", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f0cb74b5-b85e-5023-8e8d-9c9c582f29de", "question": "how did the authors translate the reviews to other languages?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["fffd3285-1bba-5935-a5b9-c4e567574c61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1806.04511/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1806.04511/2-Figure1-1.png", "data/dataset/spiqa/images/1806.04511/3-Table2-1.png", "data/dataset/spiqa/images/1806.04511/3-Figure2-1.png", "data/dataset/spiqa/images/1806.04511/3-Table3-1.png", "data/dataset/spiqa/images/1806.04511/3-Table1-1.png", "data/dataset/spiqa/images/1806.04511/3-Table4-1.png", "data/dataset/spiqa/images/1806.04511/4-Figure3-1.png", "data/dataset/spiqa/images/1806.04511/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "how did the authors translate the reviews to other languages?", "reference_answer": "Using Google translation API.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6b7bb647-a003-5003-bae6-2b84d3ace3d7", "question": "What are the languages used to test the model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["50f0c6bf-6a60-5e48-8fa7-3307a612d2ae"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.12642/6-Table3-1.png", "data/dataset/spiqa/images/1909.12642/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.12642/3-Table1-1.png", "data/dataset/spiqa/images/1909.12642/5-Figure1-1.png", "data/dataset/spiqa/images/1909.12642/6-Table2-1.png", "data/dataset/spiqa/images/1909.12642/6-Table3-1.png", "data/dataset/spiqa/images/1909.12642/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the languages used to test the model?", "reference_answer": "Hindi, English and German (German task won)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0bcb5235-3f82-5a46-893f-c3be739e1c82", "question": "what genres do they songs fall under?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["2bdb9835-9557-59b0-bec9-ba2f3e4ad00f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.05377/3-Figure1-1.png", "data/dataset/spiqa/images/2003.05377/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.05377/3-Figure1-1.png", "data/dataset/spiqa/images/2003.05377/3-Table1-1.png", "data/dataset/spiqa/images/2003.05377/4-Figure2-1.png", "data/dataset/spiqa/images/2003.05377/5-Figure3-1.png", "data/dataset/spiqa/images/2003.05377/5-Table2-1.png", "data/dataset/spiqa/images/2003.05377/6-Table3-1.png", "data/dataset/spiqa/images/2003.05377/6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what genres do they songs fall under?", "reference_answer": "Gospel, Sertanejo, MPB, Forró, Pagode, Rock, Samba, Pop, Axé, Funk-carioca, Infantil, Velha-guarda, Bossa-nova and Jovem-guarda", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "baee5b49-6db0-51c9-ae5b-dfc958de4125", "question": "How strong was the correlation between exercise and diabetes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["a5aa33b6-dd50-53f7-9cea-027d1b53f2fd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.07916/6-Figure2-1.png", "data/dataset/spiqa/images/1709.07916/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.07916/3-Figure1-1.png", "data/dataset/spiqa/images/1709.07916/5-Table1-1.png", "data/dataset/spiqa/images/1709.07916/6-Table2-1.png", "data/dataset/spiqa/images/1709.07916/6-Figure2-1.png", "data/dataset/spiqa/images/1709.07916/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How strong was the correlation between exercise and diabetes?", "reference_answer": "weak correlation with p-value of 0.08", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f8798be8-2f12-5c92-9ce3-5cf09a821256", "question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "reference_answer": "3%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5a51c904-d89b-5a84-b113-2586b226fbbc", "question": "In this sentence, do the current target state and all source states mean hidden states of the encoder?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f124ba10-c318-5d52-ab9a-3be90aca000a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/3-Figure2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/1-Figure1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/3-Figure2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/4-Figure3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/5-Figure4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure5-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Table3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "In this sentence, do the current target state and all source states mean hidden states of the encoder?", "reference_answer": "A possible answer is yes as a global attention model considers all the hidden states of the encoder when deriving the context. However, it's not clear which sentence the questioner refers to and the question needs more elaboration."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "17252c9f-c21b-53b0-8716-ddb8db15b2de", "question": "What features are used to represent the salience and relative authority of entities?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["999456fd-dfa1-55ae-9b0b-c37de34db04a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10344/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10344/1-Figure1-1.png", "data/dataset/spiqa/images/1703.10344/2-Figure2-1.png", "data/dataset/spiqa/images/1703.10344/4-Table1-1.png", "data/dataset/spiqa/images/1703.10344/6-Table2-1.png", "data/dataset/spiqa/images/1703.10344/7-Figure3-1.png", "data/dataset/spiqa/images/1703.10344/7-Table3-1.png", "data/dataset/spiqa/images/1703.10344/8-Table4-1.png", "data/dataset/spiqa/images/1703.10344/8-Table5-1.png", "data/dataset/spiqa/images/1703.10344/9-Figure4-1.png", "data/dataset/spiqa/images/1703.10344/9-Figure5-1.png", "data/dataset/spiqa/images/1703.10344/10-Figure6-1.png", "data/dataset/spiqa/images/1703.10344/10-Figure7-1.png", "data/dataset/spiqa/images/1703.10344/11-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What features are used to represent the salience and relative authority of entities?", "reference_answer": "Salience features positional features, occurrence frequency and the internal POS structure of the entity and the sentence it occurs in.\nThe relative authority of entity features:   comparative relevance of the news article to the different entities occurring in it.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a4fd0e63-4bbd-5cd6-858c-70c69437c5ed", "question": " How many negative samples are there in the training set of the CNSE dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3883ee7d-6df2-5037-93dc-13b5b7ad891a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table1-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table2-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " How many negative samples are there in the training set of the CNSE dataset?", "reference_answer": "There are approximately 9,719 negative samples in the training set of the CNSE dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d8a8b148-c9b0-5fa4-a954-e254abf81bb5", "question": "What is the role of the task-irrelevant data in ZDDA?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["86d109ac-bfba-5548-a67e-8dfd401e8f3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table7-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table6-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table5-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table9-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table2-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table8-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the task-irrelevant data in ZDDA?", "reference_answer": "The task-irrelevant data is used to simulate the RGB representation using the gray scale image. This allows ZDDA to learn a joint network that can be used to classify digits in both the gray scale and RGB domains."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a4135fa2-c4a0-5b5a-b4d8-eaa77d9de746", "question": "Is the increase in receptive field of the features being computed in subsequent network layers due to the downsampling mentioned by the authors, or is it the result of subsequent convolutions as the network goes deeper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is the increase in receptive field of the features being computed in subsequent network layers due to the downsampling mentioned by the authors, or is it the result of subsequent convolutions as the network goes deeper?", "reference_answer": "The increase in receptive field of the features being computed in subsequent network layers is the result of convolutions layers as the network goes deeper?"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "407288af-70d4-5fab-b072-34007f234b72", "question": "How big is their model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["b3660386-f4d7-5741-b850-4bb8ae33b70f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.09314/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.09314/3-Figure1-1.png", "data/dataset/spiqa/images/1902.09314/5-Table1-1.png", "data/dataset/spiqa/images/1902.09314/6-Table2-1.png", "data/dataset/spiqa/images/1902.09314/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is their model?", "reference_answer": "Proposed model has 1.16 million parameters and 11.04 MB.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "818d5d96-5c2f-5a90-b14e-c7e6422db053", "question": "What is the difference in performance between the interpretable system (e.g. vectors and cosine distance) and LSTM with ELMo system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d4032873-7bd5-568a-becd-291c7a61f3b0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.10810/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.10810/3-Table1-1.png", "data/dataset/spiqa/images/1905.10810/3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the difference in performance between the interpretable system (e.g. vectors and cosine distance) and LSTM with ELMo system?", "reference_answer": "Accuracy of best interpretible system was 0.3945 while accuracy of LSTM-ELMo net was 0.6818.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ea9d67b9-cc3d-5673-94b7-44313348bde7", "question": "Which dataset performs best when used alone for training a 3D body keypoint prediction model, and how does its performance compare to models trained on combined datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset performs best when used alone for training a 3D body keypoint prediction model, and how does its performance compare to models trained on combined datasets?", "reference_answer": "HUMBI performs best when used alone for training, with an average AUC of 0.399. While this is lower than the average AUC of models trained on combined datasets (0.433 for H36M+HUMBI and 0.413 for MI3D+HUMBI), HUMBI still achieves the highest score among the individual datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "aa74ee7d-5ad2-51f9-8042-84d65b92e3f8", "question": "What two components are included in their proposed framework?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e7ab2bd6-80e8-5501-93b7-0c331087b6ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04815/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04815/2-Figure1-1.png", "data/dataset/spiqa/images/1706.04815/5-Figure2-1.png", "data/dataset/spiqa/images/1706.04815/7-Figure3-1.png", "data/dataset/spiqa/images/1706.04815/9-Table2-1.png", "data/dataset/spiqa/images/1706.04815/9-Table3-1.png", "data/dataset/spiqa/images/1706.04815/10-Table4-1.png", "data/dataset/spiqa/images/1706.04815/10-Table5-1.png", "data/dataset/spiqa/images/1706.04815/11-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What two components are included in their proposed framework?", "reference_answer": "evidence extraction and answer synthesis", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "690b2bc0-b3ce-565e-8611-de8cacc1ff6d", "question": "What is the relationship between the Bernoulli parameter and the image?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the Bernoulli parameter and the image?", "reference_answer": "The Bernoulli parameter is a measure of the probability of a pixel being foreground or background. The higher the Bernoulli parameter, the more likely the pixel is to be foreground. This is reflected in the images, where the pixels with higher Bernoulli parameters are more likely to be part of the person's silhouette."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5a125a78-a745-5ac7-bfaa-d365f769f06b", "question": "What are some of the specific challenges that FR models face in real-world applications and how have researchers attempted to address these challenges through the design of specialized algorithms?\t", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are some of the specific challenges that FR models face in real-world applications and how have researchers attempted to address these challenges through the design of specialized algorithms?\t", "reference_answer": "Cross-pose FR is still a challenging problem for existing algorithms and over 10% decrease in accuracy was observed in frontal-frontal to frontal-profile verification. Techniques like DREAM and PIM were employed to perform frontalization in the deep face and learn pose-invariant representations. Cross-age FR is also a natural problem as facial appearance changes over time. There were attempts to synthesize images from the same age group with a generative probabilistic model and conditional GANs were used to generate an identity-preserved face with a target age. Further, local manifold adaptation (LMA) and pyramidal adversarial discriminator approaches were tried to deal with the imperfect preservation of identities of GAN-synthesized images. Alternatively, decomposing the identity and age from each other was another direction. Latent identity analysis (LIA) and decomposing in a spherical coordinate system are some methods from that direction. Lastly, CNN fine-tuning, siamese deep network, feature extraction, and deep learning with CNN were some of the notable approaches. Makeup FR is another real-world problem that needs a solution, as makeup can drastically change the appearance of the subject. Bi-level adversarial network (BLAN) was used to generate non makeup images from makeup images. Fine-tuning the triplet network with a small makeup dataset was another try. In particular, facial disguise is a big issue for FR as people can either want to hide their identity or impersonate another one. Identity hiding increases intra-class variation, while impersonation decreases inter-class distinction. Using DCNN and finding the transformation matrix with PCA for face disguise, fine-tuning models with disguised faces, hard example mining, and learning the representation of images in colors, shapes, and textures are some of the attempts to solve the issue. NIR-VIS FR is needed to match the NIS images, (near-infrared spectrum) that usually come from surveillance contexts to VIS (visible light spectrum) images, as most of the available datasets contain VIS images. Transferring from VIS to NIR with fine-tuning, transforming NIR images to VIS with CNN, using the siamese network for each VIS and NIR respectively, dividing the network into NIR, VIS, and NIR-VIS layers to learn modality-invariant features, embedding cross-spectral face hallucination and discriminative features, and low-rank relevance and cross-modal ranking are some of the methods that were used to solve the issue. Low-resolution FR needs addressing, although deep models are mostly robust to such cases. Mapping low and high-resolution faces into the same space with CNN, using face semantic information and local structural constraints to restore the shape and detail of the images are notable approaches in this direction. Photo-sketch FR can help find suspects effectively. Approaches usually either use transfer learning to directly match photos to sketches or perform image-to-image translation (image to sketch or sketch to an image). For the first type, training with images of faces and fine-tuning with sketches is one of the attempts. For the second type, branched fully convolution network (BFCN) and lately, GAN architectures were used to translate the image to sketch or vice versa. In many real-world scenarios low-shot FR is needed where only a few data points are available. Researchers tried to either synthesize more data or learn more meaningful features. 3D models, GANs, data augmentation, hybrid classifiers, and normalization are some of the attempts that were found useful. Using not only a single image but a set of data as the smallest unit matches many of the biometric scenarios. There are 2 types of methods in set/template-based FR, either processing all the data in the set separately to find the matching score by combining the individual scores with a certain function or doing feature pooling which generates a single representation of the set and compares only them. Additionally, a deep heterogeneous feature fusion network and actor-critic reinforcement learning are some of the alternative attempts to deal with sets/templates. Video FR is also a complex problem consisting of combining the data across frames and handling individual frames with blur, pose variations, and occlusions. A neural aggregation network (NAN), combining metric and adversarial learning is some of the attempts to aggregate the frames. To deal with bad frames: deep reinforcement learning, learning blur-robust representations, and reconstruction of frames with CNN was tried. 3D FR is underdeveloped due to a lack of good datasets. Despite attempts to enlarge such datasets with 3D reconstruction from 2D images, using 2D CNN, and using 3-channel inputs, the direction is still open for exploration. Partial Face Recognition is emerging in several real-world scenarios where a decision should be made with only a part of the face available. Dividing the aligned image into multi-scale patches and Dynamic Feature Matching (DFM) are some of the approaches for Partial FR. Applying FR in mobile devices is an important problem that needs a solution under stricter conditions. Deep models like MobiFace and the multi-batch method are some of the work in this direction. However, the light networks and compressing methods as in image classification still need exploration in the FR context. Face Anti-attack systems are needed to defend from face spoofing, adversarial perturbations, etc. For face spoofing, ensuring face-like depth with two-stream CNN, classification with CNN, and LSTM for sequences of frames were tried to resolve the issue. In terms of adversarial perturbation, detecting abnormal layers of the network to increase the robustness of the model was an idea. However, the attack methods evolve as well, thus continued work in this direction is necessary. Highly biased FR datasets impose fairness issues on FR models. Thus, debiasing attempts are made by unbalanced training, attribute removal, and domain adaptation. Unbalanced training, for example, RL-RBN,  tries to remove the bias of the model by regularization (i.e adjusting the objective function). The attribute-removal method tries to learn attribute-invariant representations by removing demographic information. Lastly, domain adaptation attempts to learn domain-invariant representations to avoid any domain bias."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5df38f0b-63ee-5742-aacb-4d077421fc3c", "question": "What is the relationship between compression factor and reconstruction error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["31d46012-0f02-590b-bcb4-f7f19a18db4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure4-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between compression factor and reconstruction error?", "reference_answer": "The reconstruction error increases as the compression factor increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3d772cc8-d67c-5e05-a0d0-126951a7979c", "question": "What is increase in percentage of humor contained in headlines generated with TitleStylist method (w.r.t. baselines)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3f09576c-0a21-5d2c-ae00-4df708d405e2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.01980/8-Table4-1.png", "data/dataset/spiqa/images/2004.01980/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.01980/1-Figure1-1.png", "data/dataset/spiqa/images/2004.01980/3-Figure2-1.png", "data/dataset/spiqa/images/2004.01980/3-Figure3-1.png", "data/dataset/spiqa/images/2004.01980/5-Table1-1.png", "data/dataset/spiqa/images/2004.01980/7-Table2-1.png", "data/dataset/spiqa/images/2004.01980/8-Table3-1.png", "data/dataset/spiqa/images/2004.01980/8-Table4-1.png", "data/dataset/spiqa/images/2004.01980/9-Table5-1.png", "data/dataset/spiqa/images/2004.01980/9-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is increase in percentage of humor contained in headlines generated with TitleStylist method (w.r.t. baselines)?", "reference_answer": "Humor in headlines (TitleStylist vs Multitask baseline):\nRelevance: +6.53% (5.87 vs 5.51)\nAttraction: +3.72% (8.93 vs 8.61)\nFluency: 1,98% (9.29 vs 9.11)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5a0b1054-abe2-5366-85ed-f68c9fbc7619", "question": "What are the three constraints imposed by COPA on PARAFAC2 model factors?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three constraints imposed by COPA on PARAFAC2 model factors?", "reference_answer": "Non-negativity, smoothness, and sparsity."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1b22d360-5c3f-5db6-9a19-11f1bac1abe6", "question": "The authors claims that the  performance increase with the number of attention module, is that true, knowing that they tried only m = {1,2,3,4} ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0dce7274-5a43-574c-b6c5-81c384e94d2a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/7-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/2-Figure1-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/4-Figure2-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/5-Figure3-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/5-Table1-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/5-Table2-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/6-Figure4-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/6-Table3-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/7-Table4-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/7-Table5-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/7-Table6-1.png", "data/dataset/spiqa/images/77d30cf9a34fb6b50979c6a68863099da9a060ad/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The authors claims that the  performance increase with the number of attention module, is that true, knowing that they tried only m = {1,2,3,4} ?", "reference_answer": "It seems true as they also tried m = 5 and 6 and performance still improved, as seen in Table 6."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c0b8f75b-2d7b-558e-b45e-c798f50bcf35", "question": "Which 7 Indian languages do they experiment with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de3148dd-ff01-5fd2-b6fa-9438245883a3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01664/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01664/2-Figure1-1.png", "data/dataset/spiqa/images/2002.01664/3-Table1-1.png", "data/dataset/spiqa/images/2002.01664/4-Table4-1.png", "data/dataset/spiqa/images/2002.01664/4-Table2-1.png", "data/dataset/spiqa/images/2002.01664/4-Figure2-1.png", "data/dataset/spiqa/images/2002.01664/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which 7 Indian languages do they experiment with?", "reference_answer": "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1a50a588-8f6d-57c2-8738-13ab9dd36151", "question": "Based on the table, which attack method is the most efficient in terms of time taken to craft an adversarial example, and how much faster is it compared to the slowest method for the same objective function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the table, which attack method is the most efficient in terms of time taken to craft an adversarial example, and how much faster is it compared to the slowest method for the same objective function?", "reference_answer": "The FGSM attack is the most efficient, requiring approximately 1.9 milliseconds to craft an adversarial example with the CE objective function. This is roughly **55,000 times faster** than the slowest method, C&W-wb, which takes about 700 seconds for the same objective function."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2f64d617-3fbb-5119-95fc-34c63a32264f", "question": "Are the tweets location-specific?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["c5834f1a-8517-54ba-ae9c-b877b7e2e178"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.04315/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.04315/2-Table2-1.png", "data/dataset/spiqa/images/2004.04315/2-Table1-1.png", "data/dataset/spiqa/images/2004.04315/2-Table3-1.png", "data/dataset/spiqa/images/2004.04315/3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the tweets location-specific?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "489583e2-e843-5da9-989d-898498cff5a9", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["f8c69bd7-ee40-55f3-9f5c-4e49f6cde607"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.09369/2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.09369/2-Table1-1.png", "data/dataset/spiqa/images/1907.09369/2-Table2-1.png", "data/dataset/spiqa/images/1907.09369/3-Figure1-1.png", "data/dataset/spiqa/images/1907.09369/3-Table3-1.png", "data/dataset/spiqa/images/1907.09369/4-Table5-1.png", "data/dataset/spiqa/images/1907.09369/4-Table4-1.png", "data/dataset/spiqa/images/1907.09369/5-Table6-1.png", "data/dataset/spiqa/images/1907.09369/5-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e57d8832-a37a-537b-a37d-771287be69af", "question": "Explain the rationale behind using five deformable cost volumes with different hyperparameter settings in Devon's relation module.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Explain the rationale behind using five deformable cost volumes with different hyperparameter settings in Devon's relation module.", "reference_answer": "The five deformable cost volumes in Devon's relation module are designed to capture multi-scale motion by combining dense correspondences near the image center with sparser correspondences in the periphery. This is achieved by using different neighborhood sizes (k) and dilation rates (r) for each cost volume, as shown in Table 1. Smaller neighborhood sizes and dilation rates result in denser correspondences, focusing on finer details and small displacements, while larger values capture broader context and larger motions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ac85d6d6-e103-56fb-bdf9-d3e794f4953d", "question": "Which model performs best on the Ubuntu dataset for text lengths between 60 and 90 words?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d62d3025-a1b0-5616-84f5-5ea256c9ac90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table3-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table2-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table1-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table4-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table5-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table6-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best on the Ubuntu dataset for text lengths between 60 and 90 words?", "reference_answer": "KEHNN"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "09393b79-9726-5bd3-a5d4-84e499dc2d96", "question": "Is this a span-based (extractive) QA task?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["aceed5df-08df-5a31-8fd4-8447541bb4db"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00361/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00361/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00361/5-Figure2-1.png", "data/dataset/spiqa/images/1909.00361/6-Table1-1.png", "data/dataset/spiqa/images/1909.00361/7-Table2-1.png", "data/dataset/spiqa/images/1909.00361/7-Table3-1.png", "data/dataset/spiqa/images/1909.00361/8-Table4-1.png", "data/dataset/spiqa/images/1909.00361/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is this a span-based (extractive) QA task?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "530bb16d-b11b-5bd0-8d7d-7eb6b0e3d8f4", "question": "How do they combine a deep learning model with a knowledge base?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["836657b7-d657-5f24-a0b2-9463d99e8e3a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.10503/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.10503/2-Table1-1.png", "data/dataset/spiqa/images/1904.10503/2-Figure1-1.png", "data/dataset/spiqa/images/1904.10503/4-Figure2-1.png", "data/dataset/spiqa/images/1904.10503/5-Figure3-1.png", "data/dataset/spiqa/images/1904.10503/5-Table2-1.png", "data/dataset/spiqa/images/1904.10503/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they combine a deep learning model with a knowledge base?", "reference_answer": "Entities from a deep learning model are linked to the related entities from a knowledge base by a lookup.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "be1d43d6-95c3-5394-8cfb-7fe6159f02f8", "question": "Which of the two scenes, Drop or Staris, requires more computation time for rendering?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the two scenes, Drop or Staris, requires more computation time for rendering?", "reference_answer": "Staris"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3d077ee9-9cd1-5105-906e-3dbb0f18e6ce", "question": "Do they do quantitative quality analysis of learned embeddings?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["c33e99c3-502a-5b26-ae37-4cc75a515479"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.11768/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.11768/2-Table1-1.png", "data/dataset/spiqa/images/1910.11768/3-Figure1-1.png", "data/dataset/spiqa/images/1910.11768/4-Table2-1.png", "data/dataset/spiqa/images/1910.11768/4-Table3-1.png", "data/dataset/spiqa/images/1910.11768/6-Table4-1.png", "data/dataset/spiqa/images/1910.11768/6-Table5-1.png", "data/dataset/spiqa/images/1910.11768/6-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they do quantitative quality analysis of learned embeddings?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "51bb32a5-e0fe-59db-a6b3-418dd509b4e8", "question": "Explain how the answering procedure works.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2f3b7633-fa54-55d7-8802-08f611b754d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure6-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure9-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure10-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Explain how the answering procedure works.", "reference_answer": "The answering procedure follows the question graph, searching for a valid assignment in the image. At each step, the handled node is set and objects (extracted using Mask R-CNN) are examined according to the node’s requirements (utilizing corresponding visual estimators). If successful, a new node is set (according to a DFS traversal) and the function is called again to handle the unassigned subgraph."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "eb5b8d4f-03d1-5722-ae02-731e6b048cbf", "question": "How do they measure which words are under-translated by NMT models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["64509992-cc22-5ab1-8576-ce25b4ecb4df"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00326/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00326/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00326/5-Figure2-1.png", "data/dataset/spiqa/images/1909.00326/6-Figure3-1.png", "data/dataset/spiqa/images/1909.00326/6-Figure4-1.png", "data/dataset/spiqa/images/1909.00326/7-Table1-1.png", "data/dataset/spiqa/images/1909.00326/7-Table2-1.png", "data/dataset/spiqa/images/1909.00326/8-Table3-1.png", "data/dataset/spiqa/images/1909.00326/8-Table4-1.png", "data/dataset/spiqa/images/1909.00326/11-Table5-1.png", "data/dataset/spiqa/images/1909.00326/11-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they measure which words are under-translated by NMT models?", "reference_answer": "They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "36315e65-dde2-5f66-bf34-e61a927f783e", "question": "Which model and configuration achieves the best performance on the Chinese-English translation task, and how much improvement does it offer compared to the baseline RNNSearch model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7e050ffe-a1b2-5ec1-a6cd-9641ced929b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table3-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table1-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model and configuration achieves the best performance on the Chinese-English translation task, and how much improvement does it offer compared to the baseline RNNSearch model?", "reference_answer": "The Transformer+BR-CSGAN model with λ=0.8 achieves the best performance on the Chinese-English translation task with an average BLEU score of 42.61. This represents an improvement of 0.81 BLEU points compared to the baseline RNNSearch model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "49f88df3-2c63-58aa-8d4f-fb0385b7b60d", "question": "Which of the two models, LSTw/oAR or LST-Skip, seems to perform better in predicting electricity consumption?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the two models, LSTw/oAR or LST-Skip, seems to perform better in predicting electricity consumption?", "reference_answer": "LST-Skip seems to perform better in predicting electricity consumption."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9f65dc9e-2484-5d04-9af2-104fe3d5f7f1", "question": "What is the role of the attribute vector $z$ in the Conditional CycleGAN network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the attribute vector $z$ in the Conditional CycleGAN network?", "reference_answer": "The attribute vector $z$ provides additional information about the desired attributes of the generated high-resolution face image $\\hat{X}$. This information is used by the generator networks $G_{X \\to Y}$ and $G_{Y \\to X}$ to generate images that are more consistent with the desired attributes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "15b36cc3-6141-5afe-9a46-ce8834b4b1ad", "question": "Which system, CCA or SMT, generally performs better when the caption is of low quality (average rank less than 3)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which system, CCA or SMT, generally performs better when the caption is of low quality (average rank less than 3)?", "reference_answer": "It is difficult to definitively say which system performs better for low-quality captions based solely on the provided data. However, we can observe some trends:\n\n1. When the SMT average rank is below 3, the CCA average rank is also lower (1.64 vs. 1.77).\n2. When the SMT average rank is 3 or higher, the CCA average rank is significantly higher (3.54 vs. 3.46).\n\nThis suggests that CCA might perform relatively better for low-quality captions, but more data and analysis are needed for a conclusive answer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3fbe05df-2ef8-56da-b000-774eb4ded3cd", "question": "What baseline models do they compare against?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8cf8c9a4-2645-5510-afcd-537ff05bd1ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.02257/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.02257/4-Figure1-1.png", "data/dataset/spiqa/images/1901.02257/7-Table2-1.png", "data/dataset/spiqa/images/1901.02257/8-Table3-1.png", "data/dataset/spiqa/images/1901.02257/9-Figure2-1.png", "data/dataset/spiqa/images/1901.02257/10-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What baseline models do they compare against?", "reference_answer": "SLQA, Rusalka, HMA Model (single), TriAN (single), jiangnan (ensemble), MITRE (ensemble), TriAN (ensemble), HMA Model (ensemble)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b3c994e4-7b53-582d-9b8e-fc8f6f94e87a", "question": "How does the test accuracy of the different models vary with the hyperparameter λ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["296788f8-16bc-55ff-9d9a-9fdf5ff3b0e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table4-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the test accuracy of the different models vary with the hyperparameter λ?", "reference_answer": "The test accuracy of all models decreases as λ increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ec540c47-6dbe-5091-a150-d9fff7c32ff4", "question": "How can we solve the chllenges of image segmentation ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d1c1e345-b84d-5866-8475-acfaa66dadf9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Figure6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/2-Figure2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/1-Figure1-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/2-Figure2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/4-Figure3-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Figure4-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Table1-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Figure5-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Table2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/7-Table3-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Figure6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table4-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table5-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/9-Figure7-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/9-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How can we solve the chllenges of image segmentation ?", "reference_answer": "In this paper, It is shown that a surprisingly simple, flexible, and fast system can surpass prior state-of-the-art instance segmentation results. We use object detection to denote detection via bounding boxes, not masks, and semantic segmentation to denote per-pixel classification without differentiating instances. Given this, one might expect a complex method to be required to achieve good results."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8e2623c1-695f-510c-ac8b-660b66067ce3", "question": "How much better does this baseline neural model do?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9163d4a8-27ac-56ab-98a7-8f20ff0d480b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.07471/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.07471/3-Table1-1.png", "data/dataset/spiqa/images/1905.07471/3-Figure1-1.png", "data/dataset/spiqa/images/1905.07471/4-Figure2-1.png", "data/dataset/spiqa/images/1905.07471/4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much better does this baseline neural model do?", "reference_answer": "The model outperforms at every point in the\nimplicit-tuples PR curve reaching almost 0.8 in recall", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "67b90c7d-266b-5738-807a-76d2a720525a", "question": "What is the role of the Joint Attention Module in the model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the Joint Attention Module in the model?", "reference_answer": "The Joint Attention Module takes the embedded image and phrase features as input and uses them to induce a parameterization for spatial attention. This spatial attention map is then used by the decoder to predict the common concept."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c91e1b8c-ab67-5d65-9eae-3819493f4a4e", "question": "Is the G-BERT model useful beyond the task considered?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4069edd1-4397-5037-ae8c-f479b600e46e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.00346/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.00346/1-Figure1-1.png", "data/dataset/spiqa/images/1906.00346/3-Figure2-1.png", "data/dataset/spiqa/images/1906.00346/3-Table1-1.png", "data/dataset/spiqa/images/1906.00346/5-Table2-1.png", "data/dataset/spiqa/images/1906.00346/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the G-BERT model useful beyond the task considered?", "reference_answer": "There is nothing specific about the approach that depends on medical recommendations. The approach combines graph data and text data into a single embedding.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "eb346db4-c82a-5ae9-a785-61e382cde3a2", "question": "How does the selection rate affect the expected outcome and institution utilities for different decision rules?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a7193e4-6411-5e3e-9b02-09ce82c0f1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the selection rate affect the expected outcome and institution utilities for different decision rules?", "reference_answer": "The selection rate has a different effect on the expected outcome and institution utilities for different decision rules. For example, the maximum expected outcome is achieved at a higher selection rate for the MaxUtil rule than for the EqOpt rule."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "41847bf9-e640-5190-bc7a-e442d5f546cf", "question": "Which type of grounding appears to be most beneficial for the MRPC task, and how does its performance compare to the baseline model (ST-LN)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1d4aae8d-be49-5bef-88ce-e6d9a04354e4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table1-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table2-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table3-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table4-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table5-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which type of grounding appears to be most beneficial for the MRPC task, and how does its performance compare to the baseline model (ST-LN)?", "reference_answer": "GroundSent-Cap appears to be most beneficial for the MRPC task, achieving an accuracy of 72.9/82.2 compared to the baseline model ST-LN's 69.6/81.2."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ff73ee7d-8d41-52dd-9853-d6c326fc7072", "question": "Which method performs best at all noise levels?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best at all noise levels?", "reference_answer": "ChoiceNet."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e7170832-3195-5e2c-aff4-ddb2b1fb5fe6", "question": "What was their perplexity score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9a7d9614-47fb-58de-aa73-a1f9f9a0227a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.10254/3-Table2-1.png", "data/dataset/spiqa/images/1810.10254/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.10254/2-Figure1-1.png", "data/dataset/spiqa/images/1810.10254/3-Table3-1.png", "data/dataset/spiqa/images/1810.10254/3-Table1-1.png", "data/dataset/spiqa/images/1810.10254/3-Table2-1.png", "data/dataset/spiqa/images/1810.10254/4-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was their perplexity score?", "reference_answer": "Perplexity score 142.84 on dev and 138.91 on test", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ca62d463-e6e4-567a-b6a5-0cef124aa48f", "question": "Where does the data come from?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["37a5f603-9e5f-5fa5-bdfd-9dc0318ef668"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.02027/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.02027/1-Figure1-1.png", "data/dataset/spiqa/images/1909.02027/3-Table1-1.png", "data/dataset/spiqa/images/1909.02027/4-Table2-1.png", "data/dataset/spiqa/images/1909.02027/4-Table3-1.png", "data/dataset/spiqa/images/1909.02027/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Where does the data come from?", "reference_answer": "crowsourcing platform", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "18be1b08-69c3-53fe-8e60-f831b5112eca", "question": "What is the relationship between the element-hash value pairs and the signature size?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the element-hash value pairs and the signature size?", "reference_answer": "The element-hash value pairs are the elements of the signature, and the signature size is the number of element-hash value pairs in the signature."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "69623691-5e88-5510-91bf-85f1fcb19e1f", "question": "What is the role of the Higher Level Policy in the framework?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f16a3bd9-b17e-5e49-a098-482dcced698c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure9-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure4-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure5-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure6-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure7-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table2-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure8-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the Higher Level Policy in the framework?", "reference_answer": "The Higher Level Policy sets constraints for the next sub-trajectory and provides information about the previous stage to the Lower Level Policy."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "84a825c7-900f-5702-bc2b-7f0189018306", "question": "Which model performs best on the SNLI dataset, and how much does grounding contribute to its performance compared to the baseline STb-1024 model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1d4aae8d-be49-5bef-88ce-e6d9a04354e4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table1-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table2-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table3-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table4-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table5-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best on the SNLI dataset, and how much does grounding contribute to its performance compared to the baseline STb-1024 model?", "reference_answer": "The GroundSent-Both model performs best on the SNLI dataset, achieving an accuracy of 72.0%. Grounding contributes to an improvement of 4.7% compared to the baseline STb-1024 model, which achieves 67.3%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "116097d7-6762-5c2c-8c3e-8c97ca7c0de8", "question": "Which method performs best on the PaSC dataset for the handheld testing scenario (PaSC2), and how does its performance compare to other methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5ce6798c-a395-5175-8b83-6e7fa08c4245"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure1-1.png", "data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure2-1.png", "data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best on the PaSC dataset for the handheld testing scenario (PaSC2), and how does its performance compare to other methods?", "reference_answer": "The method that performs best on the PaSC dataset for the handheld testing scenario (PaSC2) is SPDNet, with an accuracy of 72.83%. This performance is slightly higher than GrNet-2Blocks (72.76%) and significantly higher than other methods like VGGDeepFace (68.24%) and DeepO2P (60.14%)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b8ac75d0-a1f6-5ac1-b58e-3ce0712ab14f", "question": "Which estimator has the smallest bias and best MSE performance in the case of fully observed confounders?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["af9d16f1-fea7-5ffd-8fce-8a0430f9324e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure3-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure5-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table2-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table5-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure8-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure1-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table1-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table4-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure7-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure6-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table3-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure4-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which estimator has the smallest bias and best MSE performance in the case of fully observed confounders?", "reference_answer": "The Entropy Balancing (EB) and Covariate Control (CC) estimators."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d4b2ee8b-6c3c-5548-ba27-7fcfb34749ae", "question": "How did the authors leverage the CNN architectures designed for color images and to transfer CNN parameters pre-trained on ImageNet to be able to use it on the medical dataset ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How did the authors leverage the CNN architectures designed for color images and to transfer CNN parameters pre-trained on ImageNet to be able to use it on the medical dataset ?", "reference_answer": "The authors transformed every gray-scale axial CT image using the three CT windows of lung window range [-1400, -200HU], high-attenuation range [-160, 240HU], and low-attenuation range [-1400; -950HU], then encoded the transformed images into RGB images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d0171e74-7920-50e3-a1b7-c7f64d661d90", "question": "What are the different types of layers in the LSTNet model and how are they connected?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the different types of layers in the LSTNet model and how are they connected?", "reference_answer": "The LSTNet model has four main types of layers:\n\n1. Convolutional layer: This layer extracts local dependency patterns from the input data. \n2. Recurrent and recurrent-skip layer: These layers capture long-term dependencies in the data. \n3. Fully connected and element-wise sum output layer: This layer combines the outputs from the convolutional and recurrent layers to produce the final prediction.\n4. Autoregressive layer: This layer provides a linear bypass to the non-linear neural network part of the model. \n\nThe convolutional layer receives the input data and passes its output to the recurrent and recurrent-skip layers. These layers then pass their output to the fully connected and element-wise sum output layer. The autoregressive layer receives the input data directly and its output is also fed into the fully connected and element-wise sum output layer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ea16a110-5868-5c4e-ab54-b75767b91525", "question": "How does the performance of the learned policy compare to the production baseline for CAT2 queries in terms of relevance and efficiency?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5236776a-47d8-5fdc-9606-592245a5a1ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure1-1.png", "data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure2-1.png", "data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the learned policy compare to the production baseline for CAT2 queries in terms of relevance and efficiency?", "reference_answer": "For CAT2 queries, the learned policy shows a slight improvement in relevance (NCG) for the weighted set and a significant reduction in index blocks accessed for both weighted and unweighted sets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cb5ff6aa-4693-5944-9ad2-05abc2c2340e", "question": "Does the new objective perform better than the original objective bert is trained on?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["40843903-571a-5d54-9bfb-a3be8e0c346a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06705/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06705/5-Figure1-1.png", "data/dataset/spiqa/images/1812.06705/5-Table1-1.png", "data/dataset/spiqa/images/1812.06705/7-Table2-1.png", "data/dataset/spiqa/images/1812.06705/7-Table3-1.png", "data/dataset/spiqa/images/1812.06705/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the new objective perform better than the original objective bert is trained on?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "18f7029d-cc9c-5d86-bc81-b6b9abacc377", "question": "Based on Table 1, which dataset has the largest vocabulary size and how does this compare to the average number of words per document in that dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on Table 1, which dataset has the largest vocabulary size and how does this compare to the average number of words per document in that dataset?", "reference_answer": "The Yelp P. dataset has the largest vocabulary size with 25,709 unique words. This is significantly larger than the average number of words per document in the dataset, which is 138."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b4549a2a-e3ae-54a8-a0f8-75499e0cd049", "question": "What other sentence embeddings methods are evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c76b968a-995a-5109-a4eb-f329fa710f26"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.10084/4-Table1-1.png", "data/dataset/spiqa/images/1908.10084/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.10084/3-Figure1-1.png", "data/dataset/spiqa/images/1908.10084/3-Figure2-1.png", "data/dataset/spiqa/images/1908.10084/4-Table1-1.png", "data/dataset/spiqa/images/1908.10084/5-Table2-1.png", "data/dataset/spiqa/images/1908.10084/6-Table4-1.png", "data/dataset/spiqa/images/1908.10084/6-Table3-1.png", "data/dataset/spiqa/images/1908.10084/7-Table5-1.png", "data/dataset/spiqa/images/1908.10084/7-Table6-1.png", "data/dataset/spiqa/images/1908.10084/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What other sentence embeddings methods are evaluated?", "reference_answer": "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8c40740a-caea-52d0-a955-237a312cf0d4", "question": "Do the hashtag and SemEval datasets contain only English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["dfab3446-3a68-54cd-9b0c-af1f9ef95a4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.00790/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.00790/1-Table1-1.png", "data/dataset/spiqa/images/1906.00790/3-Table2-1.png", "data/dataset/spiqa/images/1906.00790/4-Figure1-1.png", "data/dataset/spiqa/images/1906.00790/5-Table3-1.png", "data/dataset/spiqa/images/1906.00790/6-Table4-1.png", "data/dataset/spiqa/images/1906.00790/6-Table5-1.png", "data/dataset/spiqa/images/1906.00790/7-Table6-1.png", "data/dataset/spiqa/images/1906.00790/7-Table7-1.png", "data/dataset/spiqa/images/1906.00790/8-Figure2-1.png", "data/dataset/spiqa/images/1906.00790/8-Figure3-1.png", "data/dataset/spiqa/images/1906.00790/9-Table9-1.png", "data/dataset/spiqa/images/1906.00790/9-Table10-1.png", "data/dataset/spiqa/images/1906.00790/12-Table11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the hashtag and SemEval datasets contain only English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "65f07ba3-cc1c-5ade-834e-e69114709d51", "question": "Is audio data per language balanced in dataset?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["1f015aa6-1af9-5556-bb95-77ef359be599"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.06670/3-Table1-1.png", "data/dataset/spiqa/images/1912.06670/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.06670/2-Figure1-1.png", "data/dataset/spiqa/images/1912.06670/2-Figure3-1.png", "data/dataset/spiqa/images/1912.06670/2-Figure2-1.png", "data/dataset/spiqa/images/1912.06670/3-Table1-1.png", "data/dataset/spiqa/images/1912.06670/4-Table2-1.png", "data/dataset/spiqa/images/1912.06670/4-Table3-1.png", "data/dataset/spiqa/images/1912.06670/4-Figure4-1.png", "data/dataset/spiqa/images/1912.06670/5-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is audio data per language balanced in dataset?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bd9dea5c-3ef3-5aca-834d-487dc9790602", "question": "Which method requires the fewest observations to spot an action in a video with 2.5% action coverage?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6437feca-e73b-5ddd-a3f2-d94ef3737017"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure2-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure1-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure3-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure4-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure5-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method requires the fewest observations to spot an action in a video with 2.5% action coverage?", "reference_answer": "Action Search"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a6a7a544-f417-5751-b07f-2c9f442d7ee2", "question": "Which are the sequence model architectures this method can be transferred across?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["70ae29ea-ee7c-5f6d-9dcb-3e357e5633b6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.05969/9-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.05969/6-Table1-1.png", "data/dataset/spiqa/images/1908.05969/7-Table2-1.png", "data/dataset/spiqa/images/1908.05969/7-Figure1-1.png", "data/dataset/spiqa/images/1908.05969/8-Table3-1.png", "data/dataset/spiqa/images/1908.05969/8-Table4-1.png", "data/dataset/spiqa/images/1908.05969/9-Table5-1.png", "data/dataset/spiqa/images/1908.05969/9-Table7-1.png", "data/dataset/spiqa/images/1908.05969/9-Table8-1.png", "data/dataset/spiqa/images/1908.05969/9-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which are the sequence model architectures this method can be transferred across?", "reference_answer": "The sequence model architectures which this method is transferred to are: LSTM and Transformer-based models", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bc692288-d7b4-5213-ae9b-a95cb36ffbf1", "question": "What approach performs better in experiments global latent or sequence of fine-grained latent variables?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7ee273d1-3cff-57ad-a2ce-dffc33298d34"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.12738/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.12738/3-Figure1-1.png", "data/dataset/spiqa/images/2003.12738/4-Figure2-1.png", "data/dataset/spiqa/images/2003.12738/7-Table1-1.png", "data/dataset/spiqa/images/2003.12738/8-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What approach performs better in experiments global latent or sequence of fine-grained latent variables?", "reference_answer": "PPL: SVT\nDiversity: GVT\nEmbeddings Similarity: SVT\nHuman Evaluation: SVT", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "17c0e5d4-518e-565c-bb08-8c752b3f6dbc", "question": "How long is the dataset for each step of hierarchy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f9d26857-e887-5526-8b66-e0f9cecda38e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.09666/3-Table2-1.png", "data/dataset/spiqa/images/1902.09666/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.09666/2-Table1-1.png", "data/dataset/spiqa/images/1902.09666/3-Table2-1.png", "data/dataset/spiqa/images/1902.09666/4-Table3-1.png", "data/dataset/spiqa/images/1902.09666/5-Table4-1.png", "data/dataset/spiqa/images/1902.09666/5-Table5-1.png", "data/dataset/spiqa/images/1902.09666/5-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How long is the dataset for each step of hierarchy?", "reference_answer": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e460e411-a977-51d9-81b2-3d99d2dea39a", "question": "How does GBI compare to A* in terms of reducing disagreement rate on the SRL-100 network's failure set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does GBI compare to A* in terms of reducing disagreement rate on the SRL-100 network's failure set?", "reference_answer": "GBI is more effective than A* in reducing the disagreement rate on the SRL-100 network's failure set. After applying GBI, the average disagreement rate drops to 24.92%, while A* only reduces it to 33.91%. This represents an 19.93% greater reduction in disagreement rate when using GBI compared to A*."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d451b6bd-4f33-5f11-9286-0fb1d78f3d2e", "question": "What is their system's absolute accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["72250259-7097-560b-adbd-18551626f2e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.01010/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.01010/1-Figure1-1.png", "data/dataset/spiqa/images/1901.01010/3-Figure2-1.png", "data/dataset/spiqa/images/1901.01010/4-Table1-1.png", "data/dataset/spiqa/images/1901.01010/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is their system's absolute accuracy?", "reference_answer": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "588dfd8c-e6f6-5814-bc56-719480295d4e", "question": "What are the approaches that led to improved accuracy with lesser parameters for NASNets compared to Inception, ResNet and PolyNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["acb67ddd-a0d1-56d4-871c-f5f79ed59efb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/12-Figure8-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure9-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/2-Figure1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Figure5-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the approaches that led to improved accuracy with lesser parameters for NASNets compared to Inception, ResNet and PolyNet?", "reference_answer": "Ensembling multiple inferences across multiple model instances and image crops led to improved accuracy with lesser parameters for NASNets compared to Inception, ResNet and PolyNet."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "4b0d9f7e-805b-510f-a6a6-fb34e860d10e", "question": "What is the difference in response time between CoAP and HTTP for a response size of 50 KiB?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference in response time between CoAP and HTTP for a response size of 50 KiB?", "reference_answer": "The difference in response time between CoAP and HTTP for a response size of 50 KiB is approximately 20 seconds."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "43e26638-1cb6-5ab2-a919-16569f3aa381", "question": "What is their f1 score and recall?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["43d86e1b-d8b3-55d5-a16f-bcdcfd2657fd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.11402/3-Table2-1.png", "data/dataset/spiqa/images/2002.11402/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.11402/2-Table1-1.png", "data/dataset/spiqa/images/2002.11402/3-Table2-1.png", "data/dataset/spiqa/images/2002.11402/3-Table3-1.png", "data/dataset/spiqa/images/2002.11402/3-Figure1-1.png", "data/dataset/spiqa/images/2002.11402/6-Table4-1.png", "data/dataset/spiqa/images/2002.11402/6-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is their f1 score and recall?", "reference_answer": "F1 score and Recall are 68.66, 80.08 with Traditional NERs as reference and 59.56, 69.76 with Wikipedia titles as reference.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e22b0d56-7119-5355-9a52-52469855898e", "question": "Which policy learning method achieved the lowest regret in Ex. 2?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7caa596c-f93b-5f04-aa2f-3e61d9379cbf"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.07384v2/1705.07384v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.07384v2/1705.07384v2-Figure2-1.png", "data/dataset/spiqa/images/1705.07384v2/1705.07384v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which policy learning method achieved the lowest regret in Ex. 2?", "reference_answer": "The DR-SVM method achieved the lowest regret in Ex. 2, with a regret of 0.18."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3c2e5402-74e0-5a5f-9456-c096a23b4a26", "question": "did they compare with other evaluation metrics?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["20d493ab-9e92-5bda-8a20-7f67e3b93b94"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.01910/7-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.01910/2-Figure1-1.png", "data/dataset/spiqa/images/1906.01910/4-Figure2-1.png", "data/dataset/spiqa/images/1906.01910/4-Figure3-1.png", "data/dataset/spiqa/images/1906.01910/5-Figure4-1.png", "data/dataset/spiqa/images/1906.01910/7-Figure5-1.png", "data/dataset/spiqa/images/1906.01910/7-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "did they compare with other evaluation metrics?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f12c1f7e-b0a9-512d-b051-5297638d95c3", "question": "Which baselines did they compare against?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9b317efd-a981-5ed6-8252-048914d85be5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.02286/6-Table1-1.png", "data/dataset/spiqa/images/1809.02286/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.02286/3-Figure1-1.png", "data/dataset/spiqa/images/1809.02286/4-Figure2-1.png", "data/dataset/spiqa/images/1809.02286/6-Table1-1.png", "data/dataset/spiqa/images/1809.02286/6-Table2-1.png", "data/dataset/spiqa/images/1809.02286/7-Figure4-1.png", "data/dataset/spiqa/images/1809.02286/7-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which baselines did they compare against?", "reference_answer": "Sentence classification baselines: RNTN (Socher et al. 2013), AdaMC-RNTN (Dong et al. 2014), TE-RNTN (Qian et al. 2015), TBCNN (Mou et al. 2015), Tree-LSTM (Tai, Socher, and Manning 2015), AdaHT-LSTM-CM (Liu, Qiu, and Huang 2017), DC-TreeLSTM (Liu, Qiu, and Huang 2017), TE-LSTM (Huang, Qian, and Zhu 2017), BiConTree (Teng and Zhang 2017), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), TreeNet (Cheng et al. 2018), CNN (Kim 2014), AdaSent (Zhao, Lu, and Poupart 2015), LSTM-CNN (Zhou et al. 2016), byte-mLSTM (Radford, Jozefowicz, and Sutskever 2017), BCN + Char + CoVe (McCann et al. 2017), BCN + Char + ELMo (Peters et al. 2018). \nStanford Natural Language Inference baselines: Latent Syntax Tree-LSTM (Yogatama et al. 2017), Tree-based CNN (Mou et al. 2016), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), NSE (Munkhdalai and Yu 2017), Reinforced Self- Attention Network (Shen et al. 2018), Residual stacked encoders: (Nie and Bansal 2017), BiLSTM with generalized pooling (Chen, Ling, and Zhu 2018).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c1c8600b-8606-5639-b05c-da2812d4a5df", "question": "How does the performance of our RGB-to-Depth transfer compare to Yosinski et al. [90] in terms of top-1 accuracy on DPI-T when all layers are fine-tuned?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of our RGB-to-Depth transfer compare to Yosinski et al. [90] in terms of top-1 accuracy on DPI-T when all layers are fine-tuned?", "reference_answer": "The proposed RGB-to-Depth transfer performs slightly better than Yosinski et al. [90] in terms of top-1 accuracy on DPI-T when all layers are fine-tuned."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ae622020-8659-5c75-8f98-fe65897697e4", "question": "Do they evaluate on NER data sets?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["b50bcfa6-2c71-5841-a236-8565f44ecdb1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00170/7-Table6-1.png", "data/dataset/spiqa/images/1909.00170/7-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00170/2-Table1-1.png", "data/dataset/spiqa/images/1909.00170/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00170/4-Figure2-1.png", "data/dataset/spiqa/images/1909.00170/5-Table2-1.png", "data/dataset/spiqa/images/1909.00170/5-Table3-1.png", "data/dataset/spiqa/images/1909.00170/6-Table4-1.png", "data/dataset/spiqa/images/1909.00170/6-Table5-1.png", "data/dataset/spiqa/images/1909.00170/7-Table6-1.png", "data/dataset/spiqa/images/1909.00170/7-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they evaluate on NER data sets?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4343b2e5-c08c-5c1a-bcac-dab55f8c939d", "question": "What is the percentage of categories that can generate at least 10 recommendations using the section-count-based method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e23d7484-ec68-5c65-bb90-6d11b1d325a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Table1-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure5-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the percentage of categories that can generate at least 10 recommendations using the section-count-based method?", "reference_answer": "Around 68%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3566d1ce-85c8-5681-9fda-9bb991470183", "question": "Do they conduct any human evaluation?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["5a50572f-39a1-5cc3-9a01-d9be6a8478df"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.10408/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.10408/2-Figure1-1.png", "data/dataset/spiqa/images/1910.10408/2-Figure2-1.png", "data/dataset/spiqa/images/1910.10408/4-Figure3-1.png", "data/dataset/spiqa/images/1910.10408/4-Table1-1.png", "data/dataset/spiqa/images/1910.10408/4-Table2-1.png", "data/dataset/spiqa/images/1910.10408/5-Table3-1.png", "data/dataset/spiqa/images/1910.10408/6-Table4-1.png", "data/dataset/spiqa/images/1910.10408/6-Table5-1.png", "data/dataset/spiqa/images/1910.10408/7-Table6-1.png", "data/dataset/spiqa/images/1910.10408/7-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they conduct any human evaluation?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "355051a8-46c1-59b5-a6bc-8ec40e243385", "question": "Which training data configuration resulted in the lowest prediction error for both UP-3D and HUMBI test sets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which training data configuration resulted in the lowest prediction error for both UP-3D and HUMBI test sets?", "reference_answer": "Training with UP-3D + HUMBI resulted in the lowest prediction error for both UP-3D and HUMBI test sets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0a79a16e-d22b-531f-85d4-7629c9c2b335", "question": "Which method has the lowest average misclassification error for the cubechips image pair?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the lowest average misclassification error for the cubechips image pair?", "reference_answer": "Multi-X"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2b51c6c6-18cc-55be-94d9-2ad09d22e6b6", "question": "Which model performs better on the MultiNLI dataset when considering the percentage of individual labels that match the author's label?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ab8d017f-8645-5337-aa84-f52783391b99"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table4-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Figure1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table5-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table2-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs better on the MultiNLI dataset when considering the percentage of individual labels that match the author's label?", "reference_answer": "SNLI performs better than MultiNLI when considering the percentage of individual labels that match the author's label. SNLI has a score of 85.8%, while MultiNLI has a score of 85.2%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a0db484e-1305-5a98-9fb8-fe6b148954df", "question": "Which model performs best in terms of Mean F-measure on the DUT-OMRON dataset when trained on the MB dataset? How does the FLoss variant of this model compare to its base version?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best in terms of Mean F-measure on the DUT-OMRON dataset when trained on the MB dataset? How does the FLoss variant of this model compare to its base version?", "reference_answer": "The DSS+FLoss model performs best in terms of Mean F-measure on the DUT-OMRON dataset when trained on the MB dataset, achieving a score of 0.755.\n\nThe FLoss variant of the DSS model shows a clear improvement over the base DSS model, with a Mean F-measure increase from 0.738 to 0.755."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "465074f5-85b9-533e-a856-269302bba6d4", "question": "What characteristics did MobileNet showed better performance when compared to other models.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What characteristics did MobileNet showed better performance when compared to other models.", "reference_answer": "MobileNets showed better performance at reducing model size, computational complexity and latency while maintaining comparable accuracy when compared with the other models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7618e947-b578-57a3-9664-e93d9bca58b9", "question": "Which model performs the best at SNR=0dB?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c1f08f3f-172c-5a71-8dc0-c149805df7ce"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.05776v2/1803.05776v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.05776v2/1803.05776v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best at SNR=0dB?", "reference_answer": "GPG-K"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "068f5940-37f5-5bbf-8feb-3d6e07588e2b", "question": "The Daily Mail part of the dataset is approximately 2x larger than the CNN section of the dataset. True or false?  ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The Daily Mail part of the dataset is approximately 2x larger than the CNN section of the dataset. True or false?  ", "reference_answer": "True. The ratio of number of articles from CNN and DailyMail is 1:2.36. Similarly, the ratio of queries from these datasets is given by 380,298:879,450 = 1:2.31. Since 2.31 and 2.36 both round down to 2, the statement is true, approximately."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ae753c7c-c585-5535-b890-50443f54ca55", "question": "What is the performance of their model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4fb65934-36b7-53d9-81bf-8ff67eb535e8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.03261/6-TableII-1.png", "data/dataset/spiqa/images/1705.03261/6-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.03261/2-TableI-1.png", "data/dataset/spiqa/images/1705.03261/2-Figure1-1.png", "data/dataset/spiqa/images/1705.03261/3-Figure2-1.png", "data/dataset/spiqa/images/1705.03261/4-Figure3-1.png", "data/dataset/spiqa/images/1705.03261/5-Figure4-1.png", "data/dataset/spiqa/images/1705.03261/5-Figure5-1.png", "data/dataset/spiqa/images/1705.03261/6-TableII-1.png", "data/dataset/spiqa/images/1705.03261/6-Figure6-1.png", "data/dataset/spiqa/images/1705.03261/6-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the performance of their model?", "reference_answer": "Answer with content missing: (Table II) Proposed model has F1 score of  0.7220.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2cd3cbd6-6bc2-5387-834b-3473fcc8e689", "question": "Which are the metrics used by authors to compare the performance of the models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Which are the metrics used by authors to compare the performance of the models?", "reference_answer": "They use FID as our default metric for overall sample quality comparisons as it captures both diversity and fidelity and has been the de facto standard metric for state-of-the-art generative modeling work. Moreover, they use Precision or IS to measure fidelity, and Recall to measure diversity or distribution coverage. In Table 4, they report FID, sFID, IS, Precision, and Recall as metrics."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c2e134d1-5995-594e-afe7-6a672f5c8a94", "question": "Which combination of method and dataset achieved the highest Recall@20 score, and how much higher was it compared to the original GRU4Rec model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which combination of method and dataset achieved the highest Recall@20 score, and how much higher was it compared to the original GRU4Rec model?", "reference_answer": "The highest Recall@20 score was achieved by the GRU4Rec with additional samples and BPR-max loss function on the RSC15 dataset. This score was 42.37% higher than the Recall@20 score of the original GRU4Rec model on the same dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a35b2a54-45b3-5386-8f52-9c0be0335d19", "question": "How does the advertising system select the best items to show to the user?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f16a3bd9-b17e-5e49-a098-482dcced698c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure9-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure4-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure5-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure6-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure7-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table2-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure8-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the advertising system select the best items to show to the user?", "reference_answer": "The advertising system selects the best items to show to the user by first generating a candidate set of items from the recommender system. This candidate set is then shuffled and sorted by their score, which is determined by the network. The network takes into account the features of the items and the scoring factors, which are likely based on the user's past behavior and preferences."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "61b9fc28-7ef5-57f4-b374-5d29724e911f", "question": "Do they use the same distance metric for both the SimCluster and K-means algorithm?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["f1cc63e0-5d23-51ed-90a0-2799b7bcd7d8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.10609/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.10609/2-Figure1-1.png", "data/dataset/spiqa/images/1710.10609/3-Figure2-1.png", "data/dataset/spiqa/images/1710.10609/5-Figure3-1.png", "data/dataset/spiqa/images/1710.10609/6-Table1-1.png", "data/dataset/spiqa/images/1710.10609/7-Figure4-1.png", "data/dataset/spiqa/images/1710.10609/7-Figure5-1.png", "data/dataset/spiqa/images/1710.10609/8-Table2-1.png", "data/dataset/spiqa/images/1710.10609/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they use the same distance metric for both the SimCluster and K-means algorithm?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d054f7e6-e527-57e5-9a6d-bfb248fb09a3", "question": "What protocol has a higher radio duty cycle in the first 7 hours of the trial?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What protocol has a higher radio duty cycle in the first 7 hours of the trial?", "reference_answer": "TCP"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2ceb76e3-98c8-5b28-be9f-c50df74d37ab", "question": "What is the difference between the Jaccard similarity and the containment similarity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the Jaccard similarity and the containment similarity?", "reference_answer": "The Jaccard similarity measures the overlap between two sets, while the containment similarity measures how much one set is contained within another set."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6e98eed8-b5a5-5eea-bffa-7c9f221f16aa", "question": "Which category of objects has the highest total number of annotations, and is there evidence that this category might be more challenging to annotate accurately?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which category of objects has the highest total number of annotations, and is there evidence that this category might be more challenging to annotate accurately?", "reference_answer": "The category with the highest total number of annotations is \"Masks,\" with 129K annotations. There is evidence that this category might be more challenging to annotate accurately because it also has the highest number of annotations in the \"Occluded\" subcategory, indicating that a large portion of these objects are partially hidden in the images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "40f8a217-3380-5ac6-a829-f124efd4a0f3", "question": "How does the Mean-Shift algorithm perform in the presence of outliers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the Mean-Shift algorithm perform in the presence of outliers?", "reference_answer": "The Mean-Shift algorithm is robust to outliers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9e9ad101-358f-55f2-961b-d9b8e49d68f5", "question": "From the left graph of Figure 1, we observe that even the deepest highway network has same/worse performance than the plain network, so what are the benefits of using the highway networks with deeper layers ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["0931f3d2-f642-5062-8737-af4d1805c275"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/3-Figure1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/8-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/3-Figure1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/5-Table3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/7-Figure3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/8-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "From the left graph of Figure 1, we observe that even the deepest highway network has same/worse performance than the plain network, so what are the benefits of using the highway networks with deeper layers ?", "reference_answer": "Although highway networks do not perform well at best, they do not break down significantly when stacked deeply. Also, there is freedom in setting the number of depths, and it can be learned well with vanilla SGD. In addition, meaningful outputs come out from all layers and information can be handed over dynamically."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "bda9bcfa-074d-5d3b-9e6c-d5d54cc1cb18", "question": "How does the author show the mitigation of interference?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does the author show the mitigation of interference?", "reference_answer": "Use interference ratio."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "179671e2-677b-5b27-a4d1-4123233ab96a", "question": "What is meant by \"linear sweep\" in hyperparameter space?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["96d9113e-0b25-5b72-bf1a-4d570cb7496b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Figure3-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/7-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/3-Figure1-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/5-Figure2-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/7-Figure4-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/8-Figure5-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Figure3-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is meant by \"linear sweep\" in hyperparameter space?", "reference_answer": "linear sweep can be seen as a regular increment in the values of some regularization hyperparameter (from leftmost where there is no regularization to rightmost where strong regularization occur ) to see the variation of their effects on the corresponding activations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e097e5f1-e451-51cd-b1de-bd26714a722d", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3c3110e0-bdfd-5e3f-97ba-8cff862e1ea9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.00667/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.00667/3-Figure1-1.png", "data/dataset/spiqa/images/1912.00667/4-Figure2-1.png", "data/dataset/spiqa/images/1912.00667/5-Table1-1.png", "data/dataset/spiqa/images/1912.00667/6-Table2-1.png", "data/dataset/spiqa/images/1912.00667/6-Figure3-1.png", "data/dataset/spiqa/images/1912.00667/7-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "dc203223-d556-546a-85c6-4befedc9bbb9", "question": "Which dataset has the largest number of clinical visits per patient?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the largest number of clinical visits per patient?", "reference_answer": "CMS"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f0df1c2e-15e2-59fb-968a-04de3870ab01", "question": "Which of the three methods, LiteFlowNet, PWC-Net, or Devon, most accurately predicts the motion of the small object in the scene?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the three methods, LiteFlowNet, PWC-Net, or Devon, most accurately predicts the motion of the small object in the scene?", "reference_answer": "Devon."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "bbce50ad-9463-569d-8e40-20be3d5676a0", "question": "Which datasets are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["acde2923-a403-5f4c-a39e-0298b5491253"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.08960/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.08960/1-Figure1-1.png", "data/dataset/spiqa/images/1912.08960/3-Table1-1.png", "data/dataset/spiqa/images/1912.08960/4-Figure2-1.png", "data/dataset/spiqa/images/1912.08960/5-Figure3-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure4-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure6-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which datasets are used?", "reference_answer": "Existential (OneShape, MultiShapes), Spacial (TwoShapes, Multishapes), Quantification (Count, Ratio) datasets are generated from ShapeWorldICE", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "118800c0-d83c-54d7-a81c-6ef35687ba97", "question": "What are the metrics used to compare the performance between YOLO & DPM/RCNN?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the metrics used to compare the performance between YOLO & DPM/RCNN?", "reference_answer": "Different approaches to evaluating object detection models are presented in the paper where they mostly use mean average precision (mAP) and frames per second (fps) for accuracy and speed respectively. Qualitatively, the YOLO's errors are compared to R-CNN, and mAP on different classes of objects is shown. Moreover, YOLO was shown to boost the performance of R-CNN, and better generalize for new domains."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d8b5f105-1ef5-5963-a230-818e9b282f3a", "question": "how small of a dataset did they train on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52401b8c-9c2c-5db5-8107-cbfc6855f629"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07090/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07090/4-Table1-1.png", "data/dataset/spiqa/images/1703.07090/5-Figure1-1.png", "data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png", "data/dataset/spiqa/images/1703.07090/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "how small of a dataset did they train on?", "reference_answer": "23085 hours of data", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1a9f88b3-fec7-52ee-a83c-389ded05ead9", "question": "Why is KG Modularization needed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why is KG Modularization needed?", "reference_answer": "KG modularization is crucial for maintaining the intrinsic knowledge of each individual KG. As the selection and alignment of an appropriate KG has been shown to have a significant impact on downstream tasks, it is important that the model is able to learn the subtle differences between each KG without any interference from other KGs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ecd376bc-7bae-5d0e-8691-cb4aa9bd2e85", "question": "For the images used for visualization in the paper, were they selected randomly or picked by the authors?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["96d9113e-0b25-5b72-bf1a-4d570cb7496b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Figure3-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/7-Figure4-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/8-Figure5-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/3-Figure1-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/5-Figure2-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/7-Figure4-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/8-Figure5-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Figure3-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "For the images used for visualization in the paper, were they selected randomly or picked by the authors?", "reference_answer": "Authors best practices were to combine effects of different ways of regularization to produce interpretable images. They first search randomly through 300 different combinations of  hyperparameters, then they pick the best four sets of hyperparameters that are compliments to each other and then these sets would be used to visualize preferred images for different classes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f99662ac-ecd5-5d49-959a-1d11b5d008ff", "question": "Beyond correctness, why did the authors not evaluate the actual quality, meaning, or usefulness of the generated instructions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f992c4ad-ce9f-584d-b09e-80bcdf9589b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Table2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/22-Table10-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/23-Table11-1.png"], "reference_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/1-Figure1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/14-Figure8-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table5-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/16-Table6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/19-Figure9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/2-Figure2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/22-Table10-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/23-Table11-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/4-Table1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Table2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/7-Figure6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Beyond correctness, why did the authors not evaluate the actual quality, meaning, or usefulness of the generated instructions?", "reference_answer": "One reason to explain why the authors did not perform more comprehensive quality evaluation of the generated outputs is the difficulty in judging the output of the model. Some tasks cannot be quickly verified by the average human (one example the authors provide for this is converting first-order logic into natural language - a task that only experts with the appropriate domain knowledge can perform). However, despite this challenge, the authors do perform some analysis to gauge the overall quality of the generated samples. They randomly select 200 instructions, and for each sample they examine the quality of one instance within each instruction. Doing this evaluation reveals that their approach performs much better than a vanilla GPT3 (i.e. a bare-bones GPT3 with nothing else)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2e9837a4-8feb-5bf2-bdb6-d12ff0c75fd8", "question": "So this paper turns unstructured text inputs to parameters that GNNs can read?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["69b78f59-d9a5-5dd8-94d4-05602ac28fb3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.00756/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.00756/2-Figure1-1.png", "data/dataset/spiqa/images/1902.00756/4-Figure2-1.png", "data/dataset/spiqa/images/1902.00756/6-Table1-1.png", "data/dataset/spiqa/images/1902.00756/6-Table2-1.png", "data/dataset/spiqa/images/1902.00756/7-Table3-1.png", "data/dataset/spiqa/images/1902.00756/7-Figure3-1.png", "data/dataset/spiqa/images/1902.00756/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "So this paper turns unstructured text inputs to parameters that GNNs can read?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5180832b-d03e-59c6-a61f-e9fe242f2209", "question": "Which estimator achieves the highest accuracy on the CLEVR validation set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2f3b7633-fa54-55d7-8802-08f611b754d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure6-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure9-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure10-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which estimator achieves the highest accuracy on the CLEVR validation set?", "reference_answer": "Size estimator."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d0da32c5-4a87-5c11-bac5-31a9b994249a", "question": "How does the proposed method compare to the method in~\\cite{kim2017learning}?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed method compare to the method in~\\cite{kim2017learning}?", "reference_answer": "The proposed method produces more realistic and natural-looking images than the method in~\\cite{kim2017learning}."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8d07df0e-a430-5f05-b994-0de664ed65f0", "question": "How accurate is the aspect based sentiment classifier trained only using the XR loss?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3dae5fd3-3062-58cd-9fd7-b1b01d71b45d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00430/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00430/5-Figure1-1.png", "data/dataset/spiqa/images/1909.00430/5-Figure2-1.png", "data/dataset/spiqa/images/1909.00430/7-Table1-1.png", "data/dataset/spiqa/images/1909.00430/9-Figure3-1.png", "data/dataset/spiqa/images/1909.00430/9-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How accurate is the aspect based sentiment classifier trained only using the XR loss?", "reference_answer": "BiLSTM-XR-Dev Estimation accuracy is 83.31 for SemEval-15 and 87.68 for SemEval-16.\nBiLSTM-XR accuracy is 83.31 for SemEval-15 and 88.12 for SemEval-16.\n", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d03a0427-8c82-5c81-9bfb-deb3ef11f471", "question": "IS the graph representation supervised?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["4069edd1-4397-5037-ae8c-f479b600e46e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.00346/3-Figure2-1.png", "data/dataset/spiqa/images/1906.00346/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.00346/1-Figure1-1.png", "data/dataset/spiqa/images/1906.00346/3-Figure2-1.png", "data/dataset/spiqa/images/1906.00346/3-Table1-1.png", "data/dataset/spiqa/images/1906.00346/5-Table2-1.png", "data/dataset/spiqa/images/1906.00346/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "IS the graph representation supervised?", "reference_answer": "The graph representation appears to be semi-supervised. It is included in the learning pipeline for the medical recommendation, where the attention model is learned. (There is some additional evidence that is unavailable in parsed text)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4a8478cc-2131-5b38-921f-3ac4e86aa43f", "question": "What is the difference between the `inc_i(p)` and `inc_i'(p)` operations in the Grow-only Counter data type?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the `inc_i(p)` and `inc_i'(p)` operations in the Grow-only Counter data type?", "reference_answer": "The `inc_i(p)` operation increments the value associated with the key `i` in the counter `p`, while the `inc_i'(p)` operation increments the value associated with the key `i` in the counter `p` only if the key `i` is not already present in the counter."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3e2ba024-a10b-5114-a433-53f04aa363d2", "question": "To obtain the final compact descriptor of the image, why did the authors use PCA instead of other compression algorithms?.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c804ee67-1926-5ef9-b327-509f4405fea3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/7-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/1-Figure1-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure2-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure3-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/5-Figure4-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/7-Figure5-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/8-Figure6-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "To obtain the final compact descriptor of the image, why did the authors use PCA instead of other compression algorithms?.", "reference_answer": "Maybe authors found that PCA is  computationally less expensive and much memory and time saving in experiments than other methods. PCA is used to reduce the dimensions of the descriptor to 4096 learnt on the training set, which is discovered experimentally to help in achieving state-of-the-art results on the challenging Tokyo 24/7 dataset as comparisons show that the lower dimensional fVLAD performs similarly to the full size vector."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "be651020-a8da-50f5-a823-36fb5e586c15", "question": "By how much does the new parser outperform the current state-of-the-art?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["78370cda-efca-5256-8e6f-8f13b2b5695c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.09340/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.09340/2-Figure1-1.png", "data/dataset/spiqa/images/1710.09340/2-Figure2-1.png", "data/dataset/spiqa/images/1710.09340/2-Figure3-1.png", "data/dataset/spiqa/images/1710.09340/3-Figure4-1.png", "data/dataset/spiqa/images/1710.09340/4-Table2-1.png", "data/dataset/spiqa/images/1710.09340/4-Table1-1.png", "data/dataset/spiqa/images/1710.09340/5-Table3-1.png", "data/dataset/spiqa/images/1710.09340/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much does the new parser outperform the current state-of-the-art?", "reference_answer": "Proposed method achieves 94.5 UAS and 92.4 LAS  compared to 94.3 and 92.2 of best state-of-the -art greedy based parser. Best state-of-the art parser overall achieves 95.8 UAS and 94.6 LAS.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ae78de40-096a-5824-b52b-dfdd24f63832", "question": "Which natural language(s) are studied in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["17498990-dabf-546a-905e-9c3a0757dc47"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.11563/5-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.11563/4-Table1-1.png", "data/dataset/spiqa/images/2003.11563/5-Figure1-1.png", "data/dataset/spiqa/images/2003.11563/5-Table2-1.png", "data/dataset/spiqa/images/2003.11563/6-Table3-1.png", "data/dataset/spiqa/images/2003.11563/7-Figure2-1.png", "data/dataset/spiqa/images/2003.11563/8-Table4-1.png", "data/dataset/spiqa/images/2003.11563/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which natural language(s) are studied in this paper?", "reference_answer": "English", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "450f9679-39f8-5905-b01e-152a40fc7d56", "question": "Why can’t we use sampling based solutions instead of this algorithm in case of large datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a324a22-6bd2-5602-84bc-07231c819440"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/5f5dc5b9a2ba710937e2c413b37b053cd673df02/8-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/5f5dc5b9a2ba710937e2c413b37b053cd673df02/10-Figure4-1.png", "data/dataset/spiqa/images/5f5dc5b9a2ba710937e2c413b37b053cd673df02/2-Figure1-1.png", "data/dataset/spiqa/images/5f5dc5b9a2ba710937e2c413b37b053cd673df02/7-Figure2-1.png", "data/dataset/spiqa/images/5f5dc5b9a2ba710937e2c413b37b053cd673df02/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why can’t we use sampling based solutions instead of this algorithm in case of large datasets?", "reference_answer": "It is hard to use sampling based solutions because batch optimization with so much data is too expensive. If you want to inference in almost any model with continuous latent variables and/or parameters, sampling based solution is not applicable. For very low-dimensional latent space it is possible to estimate the marginal likelihood of the learned generative models using an MCMC estimator which is one of sampling based solution. But we need to deal with high dimensional data and the AEVB algorithm is useful."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ba6746d7-4deb-5221-9265-a303a4a49162", "question": "Which sampling strategy for random matrices in CDAN+E leads to the highest average accuracy across all domain adaptation tasks on Office-31? How does this compare to the performance of CDAN+E variants that use random sampling?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["08eae607-b68b-5938-842d-52805a218768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table5-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table4-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table1-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which sampling strategy for random matrices in CDAN+E leads to the highest average accuracy across all domain adaptation tasks on Office-31? How does this compare to the performance of CDAN+E variants that use random sampling?", "reference_answer": "The table shows that CDAN+E (w/o random sampling) achieves the highest average accuracy of 87.7% across all domain adaptation tasks. This is slightly higher than the performance of CDAN+E with uniform sampling (87.0%) and Gaussian sampling (86.4%)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "757518ff-504f-5bfb-a1bd-da4608f96c2b", "question": "What is the activation function for a ShuffleNet Unit?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the activation function for a ShuffleNet Unit?", "reference_answer": "The use of activation functions in the ShuffleNet unit happens only after the first 1x1 group convolution and the last concatenation of shortcut and residual paths, following the suggestions of referenced papers [3, 9, 40]. And the only non-linear activation function that is used is ReLU."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5405efe3-4e5a-53b5-a8f0-d7cac4c02dfe", "question": "Which image representation results in the sharpest and highest-quality samples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which image representation results in the sharpest and highest-quality samples?", "reference_answer": "DCT and wavelet representations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2d659038-55fc-5af9-883b-bdb54411d6df", "question": "What is the relationship between the Similarity Ratio and AUC Increasing?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["77db890f-c739-5abc-a1af-4cdaee857323"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the Similarity Ratio and AUC Increasing?", "reference_answer": "There is a positive linear relationship between the Similarity Ratio and AUC Increasing."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6ff2a31d-0507-5402-af2a-439e942791c5", "question": "Based on the table, how does the training process handle large vocabulary sizes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the table, how does the training process handle large vocabulary sizes?", "reference_answer": "The training process uses several techniques to handle large vocabulary sizes. These include:\n\n1. **Token-based batching:** Instead of grouping sentences of similar lengths together, the training process batches together a fixed number of tokens (5120 tokens per batch). This approach ensures that the model sees a consistent amount of vocabulary regardless of sentence length variation.\n2. **Shared embedding:** This technique maps both source and target words to the same embedding space, effectively reducing the memory footprint needed to store word representations. \n3. **Positional encoding:** This method injects information about the position of words in a sentence into the model, helping it better understand long-range dependencies within the text. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1056017e-d0c7-5d84-9c7a-a601ded9b444", "question": "How much transcribed data is available for for Ainu language?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5dc3e445-b600-510c-adf9-439c8a1b5413"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.06675/2-Table1-1.png", "data/dataset/spiqa/images/2002.06675/2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.06675/2-Table1-1.png", "data/dataset/spiqa/images/2002.06675/2-Table2-1.png", "data/dataset/spiqa/images/2002.06675/3-Figure1-1.png", "data/dataset/spiqa/images/2002.06675/4-Table3-1.png", "data/dataset/spiqa/images/2002.06675/4-Figure2-1.png", "data/dataset/spiqa/images/2002.06675/5-Table4-1.png", "data/dataset/spiqa/images/2002.06675/6-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much transcribed data is available for for Ainu language?", "reference_answer": "Transcribed data is available for duration of 38h 54m 38s for 8 speakers.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9622a020-437c-5d54-82ed-f667b16eb49f", "question": "What BERT models are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["308cff71-46a0-50ee-9116-6a1056686328"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.06264/5-Table7-1.png", "data/dataset/spiqa/images/1908.06264/5-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.06264/1-Table1-1.png", "data/dataset/spiqa/images/1908.06264/3-Figure1-1.png", "data/dataset/spiqa/images/1908.06264/4-Table2-1.png", "data/dataset/spiqa/images/1908.06264/4-Table4-1.png", "data/dataset/spiqa/images/1908.06264/4-Table5-1.png", "data/dataset/spiqa/images/1908.06264/4-Table3-1.png", "data/dataset/spiqa/images/1908.06264/5-Table6-1.png", "data/dataset/spiqa/images/1908.06264/5-Table7-1.png", "data/dataset/spiqa/images/1908.06264/6-Table8-1.png", "data/dataset/spiqa/images/1908.06264/6-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What BERT models are used?", "reference_answer": "BERT-base, BERT-large, BERT-uncased, BERT-cased", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a917f245-1106-5d9a-a819-630e81491d9d", "question": "What is the prediction accuracy of the model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["afbb8b00-13c9-5004-8370-ccd58e96b392"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.10806/7-Table1-1.png", "data/dataset/spiqa/images/1912.10806/8-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.10806/3-Figure1-1.png", "data/dataset/spiqa/images/1912.10806/3-Figure2-1.png", "data/dataset/spiqa/images/1912.10806/4-Figure3-1.png", "data/dataset/spiqa/images/1912.10806/5-Figure4-1.png", "data/dataset/spiqa/images/1912.10806/7-Figure5-1.png", "data/dataset/spiqa/images/1912.10806/7-Figure6-1.png", "data/dataset/spiqa/images/1912.10806/7-Table1-1.png", "data/dataset/spiqa/images/1912.10806/8-Table2-1.png", "data/dataset/spiqa/images/1912.10806/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the prediction accuracy of the model?", "reference_answer": "mean prediction accuracy 0.99582651\nS&P 500 Accuracy 0.99582651", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b3fc8a04-43b3-5698-8687-68a9208d5077", "question": "How big is the performance difference between this method and the baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["12fcf772-8e31-55cb-80d6-362ceccc500a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.00330/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.00330/2-Figure1-1.png", "data/dataset/spiqa/images/1902.00330/3-Figure2-1.png", "data/dataset/spiqa/images/1902.00330/4-Figure3-1.png", "data/dataset/spiqa/images/1902.00330/6-Table1-1.png", "data/dataset/spiqa/images/1902.00330/6-Table2-1.png", "data/dataset/spiqa/images/1902.00330/7-Table3-1.png", "data/dataset/spiqa/images/1902.00330/7-Figure4-1.png", "data/dataset/spiqa/images/1902.00330/7-Table4-1.png", "data/dataset/spiqa/images/1902.00330/8-Figure5-1.png", "data/dataset/spiqa/images/1902.00330/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is the performance difference between this method and the baseline?", "reference_answer": "Comparing with the highest performing baseline: 1.3 points on ACE2004 dataset, 0.6 points on CWEB dataset, and 0.86 points in the average of all scores.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1878b115-7bdd-5a76-ac09-6655510acf8b", "question": "Why does the proposed method outperform the baselines for the action \"<person, move toward (home), walkway>\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f290ed70-eb81-598b-aa2d-1920fc19428f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Table1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure3-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure9-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure10-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why does the proposed method outperform the baselines for the action \"<person, move toward (home), walkway>\"?", "reference_answer": "The proposed method outperforms the baselines for the action \"<person, move toward (home), walkway>\" because it is better at modeling moving directions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "323e844b-5377-5b29-b753-0b57628c0d68", "question": "Which soft-selection approaches are evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["d87ee1cb-c52a-519b-b88a-66a01044d1b5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.11297/1-Figure1-1.png", "data/dataset/spiqa/images/1909.11297/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.11297/1-Figure1-1.png", "data/dataset/spiqa/images/1909.11297/3-Figure2-1.png", "data/dataset/spiqa/images/1909.11297/5-Table1-1.png", "data/dataset/spiqa/images/1909.11297/6-Table2-1.png", "data/dataset/spiqa/images/1909.11297/7-Table5-1.png", "data/dataset/spiqa/images/1909.11297/7-Table3-1.png", "data/dataset/spiqa/images/1909.11297/7-Table4-1.png", "data/dataset/spiqa/images/1909.11297/8-Figure3-1.png", "data/dataset/spiqa/images/1909.11297/8-Table6-1.png", "data/dataset/spiqa/images/1909.11297/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which soft-selection approaches are evaluated?", "reference_answer": "LSTM and BERT ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2ed706d6-4d2a-50ab-b7b9-84fc01af95fd", "question": "How does the level of quantization affect the output of the soft edge detector?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the level of quantization affect the output of the soft edge detector?", "reference_answer": "As the quantization level $k$ is decreased, the cardinality of colors co-located with edges decreases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9ab6073e-eff7-5084-b5cc-86f543535052", "question": "How they evaluate quality of generated output?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8bbc0579-9f29-57e3-be5b-a472771c9421"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.03350/9-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.03350/4-Table1-1.png", "data/dataset/spiqa/images/1911.03350/7-Table2-1.png", "data/dataset/spiqa/images/1911.03350/7-Table3-1.png", "data/dataset/spiqa/images/1911.03350/8-Figure1-1.png", "data/dataset/spiqa/images/1911.03350/9-Table4-1.png", "data/dataset/spiqa/images/1911.03350/9-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How they evaluate quality of generated output?", "reference_answer": "Through human evaluation where they are asked to evaluate the generated output on a likert scale.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d9e47137-c39b-5a2c-b0be-455d8abc2f83", "question": "What is the purpose of the singular value decomposition step in the CCA algorithm?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the singular value decomposition step in the CCA algorithm?", "reference_answer": "The singular value decomposition step is used to find the projection matrices U and V."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "001f43fe-dfbd-5b80-9617-126a1634459c", "question": "What role does the low-resolution input play in the identity-guided face generation process?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What role does the low-resolution input play in the identity-guided face generation process?", "reference_answer": "The low-resolution input provides an overall shape constraint for the generated high-resolution image. The head pose and facial expression of the generated high-res images adopt those in the low-res inputs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "24921b1c-703a-5f14-b596-5d1f7eaa8cd2", "question": "Should their approach be applied only when dealing with incomplete data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["b0f8cb4c-5420-5ada-b490-7aed7819cfd1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.00137/14-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png", "data/dataset/spiqa/images/2001.00137/8-Table1-1.png", "data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/9-Table3-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png", "data/dataset/spiqa/images/2001.00137/11-Figure2-1.png", "data/dataset/spiqa/images/2001.00137/12-Table5-1.png", "data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/15-Figure3-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure4-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Should their approach be applied only when dealing with incomplete data?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e9f58e0d-e94d-5849-a37d-18a3d2f3aaef", "question": "Which method generates the best moving objects?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method generates the best moving objects?", "reference_answer": "SDVI"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c1ea12fa-2be3-55d8-ab16-17fb674c3a8f", "question": "Are agglutinative languages used in the prediction of both prefixing and suffixing languages?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["c82c9933-a43a-5166-b9b6-4436ea2b748a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.05456/7-Table7-1.png", "data/dataset/spiqa/images/1910.05456/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.05456/1-Table1-1.png", "data/dataset/spiqa/images/1910.05456/4-Table2-1.png", "data/dataset/spiqa/images/1910.05456/5-Table3-1.png", "data/dataset/spiqa/images/1910.05456/5-Table4-1.png", "data/dataset/spiqa/images/1910.05456/6-Table5-1.png", "data/dataset/spiqa/images/1910.05456/7-Table7-1.png", "data/dataset/spiqa/images/1910.05456/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are agglutinative languages used in the prediction of both prefixing and suffixing languages?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1cabe1ca-6009-5406-bc98-81454b4fabc0", "question": "Which dataset benefited more from the Pairwise Confusion (PC) optimization method: ImageNet-Dogs or ImageNet-Random?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["296788f8-16bc-55ff-9d9a-9fdf5ff3b0e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table4-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset benefited more from the Pairwise Confusion (PC) optimization method: ImageNet-Dogs or ImageNet-Random?", "reference_answer": "ImageNet-Dogs benefited more from the PC optimization method compared to ImageNet-Random."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "08a85b79-1cc8-55bf-a744-c2455b67716c", "question": "Where do the authors source their labelled dataset from? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Where do the authors source their labelled dataset from? ", "reference_answer": "The source of the labelled dataset in the paper is two news websites, namely, CNN and Daily News. The authors created the dataset of approximately one million data points from ~93k CNN and ~220k Daily Mail online news articles."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "16eb7b75-3d22-5a11-bb19-581397a6e715", "question": "What were the various hyperparameter used in 'grid search'?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What were the various hyperparameter used in 'grid search'?", "reference_answer": "Hyperparameters are Batch Size 16, Epoch 50, Kernel Size 3 x 3, Optimizer Adam, Dropout Rate 0.3, Pooling Size 2 x 2, Activation Function ReLU."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "1b3bf1b8-ffbd-5ced-b23d-11f7d303b78a", "question": "What are the three main modules of a face recognition system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the three main modules of a face recognition system?", "reference_answer": "The 3 main modules are: face detection, facial landmark detector, and FR module."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0d081494-cd3e-50b7-9395-929abba1ede2", "question": "What models other than standalone BERT is new model compared to?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bf3287bb-7899-53e8-81f6-f59e7425acd3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.07181/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.07181/5-Figure1-1.png", "data/dataset/spiqa/images/1910.07181/7-Table1-1.png", "data/dataset/spiqa/images/1910.07181/7-Table2-1.png", "data/dataset/spiqa/images/1910.07181/8-Table3-1.png", "data/dataset/spiqa/images/1910.07181/9-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What models other than standalone BERT is new model compared to?", "reference_answer": "Only Bert base and Bert large are compared to proposed approach.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8298febd-2596-5979-beba-ffbf2cc44e21", "question": "How does joint training with the object detection set affect instance segmentation performance, and what is the likely reason for this effect?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does joint training with the object detection set affect instance segmentation performance, and what is the likely reason for this effect?", "reference_answer": "Joint training with the object detection set improves instance segmentation performance significantly. This is evidenced by the increase in AP, AP50, and AP75 metrics in Table 1 when comparing \"Inst-Seg\" and \"Inst-Seg + Det\" rows.\n\nThe passage explains that this improvement is likely due to the richer diversity of images and object examples in the detection set. This allows the instance segmentation model to learn better object appearance features and localization."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "af300ee9-49f1-57e9-8331-3c309d286923", "question": "What are the likely problems authors would have encountered if they did not use batch normalization and dropout during training?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7edfe29a-5f05-5124-91f5-9d8a99732918"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/13-Figure7-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/14-Figure8-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/4-Table1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Figure4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the likely problems authors would have encountered if they did not use batch normalization and dropout during training?", "reference_answer": "Since there is no evidential information about the effect of batch normalization and dropout, this question cannot be answered and requires external knowledges."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ecbbfc72-b006-5be7-a8ef-6a1cc7419fbd", "question": "Do they use a crowdsourcing platform for annotation?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["9dad9e4b-a3a3-53f7-8306-add047241bb4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.05310/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.05310/3-Table1-1.png", "data/dataset/spiqa/images/1612.05310/7-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they use a crowdsourcing platform for annotation?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a987122a-d4d3-5a28-bba7-bb73c074d179", "question": "what dataset was used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["82c6dc69-cf50-5a75-9149-2372efec282e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.09589/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.09589/1-Figure1-1.png", "data/dataset/spiqa/images/1710.09589/2-Table1-1.png", "data/dataset/spiqa/images/1710.09589/2-Figure2-1.png", "data/dataset/spiqa/images/1710.09589/4-Table3-1.png", "data/dataset/spiqa/images/1710.09589/4-Table2-1.png", "data/dataset/spiqa/images/1710.09589/5-Table5-1.png", "data/dataset/spiqa/images/1710.09589/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what dataset was used?", "reference_answer": "The dataset from a joint ADAPT-Microsoft project", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8f6578c6-4865-5a57-a82d-440acaae78dc", "question": "What is the role of the 3D ConvNet in the distance-based place discretization process?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f290ed70-eb81-598b-aa2d-1920fc19428f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Table1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure3-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure9-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure10-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the 3D ConvNet in the distance-based place discretization process?", "reference_answer": "The 3D ConvNet is used to extract features from the input images. These features are then used to generate place-based feature descriptions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "20126745-1df8-5880-9097-14ed20452d38", "question": "What is the state of the art system mentioned?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b591d28d-1b45-592d-bc1c-fee816597535"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.07245/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.07245/2-Table1-1.png", "data/dataset/spiqa/images/1908.07245/3-Table2-1.png", "data/dataset/spiqa/images/1908.07245/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the state of the art system mentioned?", "reference_answer": "Two knowledge-based systems,\ntwo traditional word expert supervised systems, six recent neural-based systems, and one BERT feature-based system.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "912d1109-5428-574b-aed5-f8aef237eef2", "question": "What is the role of the GRU in the Deep Listwise Context Model (DLCM)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4211b30e-5e8d-5449-8335-9f14cfeb4b9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table5-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the GRU in the Deep Listwise Context Model (DLCM)?", "reference_answer": "The GRU is used to process the ranked list of documents provided by a global ranking function."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b91c30b9-9193-5177-a649-befbae8cfca5", "question": "Which model performs best on tasks T3 and T3-OOV in terms of per-dialog accuracy, and how does its performance differ between the two test sets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best on tasks T3 and T3-OOV in terms of per-dialog accuracy, and how does its performance differ between the two test sets?", "reference_answer": "The proposed system model (BOSSNET) performs best on both tasks T3 and T3-OOV in terms of per-dialog accuracy. However, its performance is significantly higher on the T3-OOV test set (95.7%) compared to the non-OOV T3 test set (95.2%)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8219a835-5c17-5844-90f9-1aeeedbde499", "question": "What is the difference between the representation module and the learning-to-learn module?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9104d00a-0d2b-565f-acc8-c4650cf151b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure6-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure7-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure2-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure8-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure12-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure9-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the representation module and the learning-to-learn module?", "reference_answer": "The representation module takes an input image and outputs a feature representation. The learning-to-learn module takes a set of features and learns how to segment the image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ce53d786-6bf2-5c0b-8d89-72ab2e21c696", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["999456fd-dfa1-55ae-9b0b-c37de34db04a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10344/1-Figure1-1.png", "data/dataset/spiqa/images/1703.10344/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10344/1-Figure1-1.png", "data/dataset/spiqa/images/1703.10344/2-Figure2-1.png", "data/dataset/spiqa/images/1703.10344/4-Table1-1.png", "data/dataset/spiqa/images/1703.10344/6-Table2-1.png", "data/dataset/spiqa/images/1703.10344/7-Figure3-1.png", "data/dataset/spiqa/images/1703.10344/7-Table3-1.png", "data/dataset/spiqa/images/1703.10344/8-Table4-1.png", "data/dataset/spiqa/images/1703.10344/8-Table5-1.png", "data/dataset/spiqa/images/1703.10344/9-Figure4-1.png", "data/dataset/spiqa/images/1703.10344/9-Figure5-1.png", "data/dataset/spiqa/images/1703.10344/10-Figure6-1.png", "data/dataset/spiqa/images/1703.10344/10-Figure7-1.png", "data/dataset/spiqa/images/1703.10344/11-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c357c082-f90c-5d93-8832-875423099b55", "question": "What accuracy does the proposed system achieve?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c4efe9a-9220-55d0-add7-651e7176d6b1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.05147/6-Table3-1.png", "data/dataset/spiqa/images/1801.05147/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.05147/3-Figure1-1.png", "data/dataset/spiqa/images/1801.05147/5-Table1-1.png", "data/dataset/spiqa/images/1801.05147/6-Table2-1.png", "data/dataset/spiqa/images/1801.05147/6-Table3-1.png", "data/dataset/spiqa/images/1801.05147/7-Figure3-1.png", "data/dataset/spiqa/images/1801.05147/7-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What accuracy does the proposed system achieve?", "reference_answer": "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e1cf0299-12ed-572b-819e-b67b47be8c1a", "question": "How well do the proposed model in this paper and the model in Dai and Lee (2015) generalize to documents of varying lengths?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c4860d9-c6fc-5c07-b4c7-dc9cd1aff233"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/5-Table1-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/5-Table1-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How well do the proposed model in this paper and the model in Dai and Lee (2015) generalize to documents of varying lengths?", "reference_answer": "This work’s method was evaluated in six widely-studied datasets which varied in document length and experimental results demonstrated that the method outperformed existing approaches in all of these datasets. This indicates that this work’s method generalizes to documents of varying lengths. Also compared to Dai and Le, this method achieved a lower error rate on IMDb showing that it also generalizes better to document lengths reflective of the real world."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "3cc26bc5-a35f-5ea5-9b18-9b483e909105", "question": "Do the authors also analyze transformer-based architectures?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["20582e13-6076-541f-aaa9-6d5552860a7e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1806.04330/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1806.04330/3-Table1-1.png", "data/dataset/spiqa/images/1806.04330/3-Figure1-1.png", "data/dataset/spiqa/images/1806.04330/5-Figure2-1.png", "data/dataset/spiqa/images/1806.04330/6-Table2-1.png", "data/dataset/spiqa/images/1806.04330/8-Table3-1.png", "data/dataset/spiqa/images/1806.04330/8-Table4-1.png", "data/dataset/spiqa/images/1806.04330/9-Figure3-1.png", "data/dataset/spiqa/images/1806.04330/9-Table5-1.png", "data/dataset/spiqa/images/1806.04330/10-Figure4-1.png", "data/dataset/spiqa/images/1806.04330/10-Table6-1.png", "data/dataset/spiqa/images/1806.04330/10-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors also analyze transformer-based architectures?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "874af927-9362-505c-86e0-7986d5041a9c", "question": "Which policy resulted in the highest average cost?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which policy resulted in the highest average cost?", "reference_answer": "MAP Policy"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b711c964-104c-59e1-b089-8423291c5e87", "question": "Which method has the highest T-Diff on average for the Vid4 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the highest T-Diff on average for the Vid4 dataset?", "reference_answer": "TecoGAN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "185cf688-6c6b-5546-8f88-36e6c9b0825a", "question": "Can you explain why the authors claim that their S-ACNN model with a single filter is \"much more expressive\" than the basic S-CNN model, even though it doesn't achieve the best overall performance on either dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Can you explain why the authors claim that their S-ACNN model with a single filter is \"much more expressive\" than the basic S-CNN model, even though it doesn't achieve the best overall performance on either dataset?", "reference_answer": "The authors claim that S-ACNN is more expressive than S-CNN because, despite having only one filter, it significantly outperforms S-CNN on both datasets. This suggests that the filter-generation module in ACNN allows for greater flexibility and adaptability, enabling the model to better capture the specific features of each sentence."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "02656b3e-235e-5711-945d-ca1b6337bc3f", "question": "Which model has the lowest Top-1 validation error on ImageNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model has the lowest Top-1 validation error on ImageNet?", "reference_answer": "ResNet-101 from the reference paper reports top-1 validation error of 23.60 which is lower than ResNet-101 reevaluated (26.41) and DMRNet (23.66)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ce58db79-5657-51f0-a68f-b68cfcf355f3", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["0f7367dd-eb06-55e5-b2dc-f2f390723368"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1807.07279/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1807.07279/4-Figure1-1.png", "data/dataset/spiqa/images/1807.07279/5-TableI-1.png", "data/dataset/spiqa/images/1807.07279/5-TableII-1.png", "data/dataset/spiqa/images/1807.07279/6-TableIII-1.png", "data/dataset/spiqa/images/1807.07279/7-Figure2-1.png", "data/dataset/spiqa/images/1807.07279/8-Figure3-1.png", "data/dataset/spiqa/images/1807.07279/8-TableIV-1.png", "data/dataset/spiqa/images/1807.07279/8-TableV-1.png", "data/dataset/spiqa/images/1807.07279/9-TableVI-1.png", "data/dataset/spiqa/images/1807.07279/9-TableVII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "def0953d-d574-56ba-9a7a-b95e940bc4fc", "question": "Are the rules dataset specific?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["59c70e8f-54d9-5dd8-91fe-c8f8e8726bf3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.05438/6-Table5-1.png", "data/dataset/spiqa/images/1909.05438/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.05438/3-Figure1-1.png", "data/dataset/spiqa/images/1909.05438/4-Table1-1.png", "data/dataset/spiqa/images/1909.05438/4-Table2-1.png", "data/dataset/spiqa/images/1909.05438/5-Table3-1.png", "data/dataset/spiqa/images/1909.05438/5-Figure2-1.png", "data/dataset/spiqa/images/1909.05438/6-Table4-1.png", "data/dataset/spiqa/images/1909.05438/6-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the rules dataset specific?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "64b3ac64-7745-5091-8dc6-daad69f7ce7d", "question": "What are the two types of attention mechanisms used in the Reinforced Mnemonic Reader architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e31707d3-f5f4-5c59-86a2-af24ff7cfed7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the two types of attention mechanisms used in the Reinforced Mnemonic Reader architecture?", "reference_answer": "The two types of attention mechanisms are reattention and self-attention."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c29d7aa9-4578-5839-aa70-57156bb37f19", "question": "What are the results achieved from the introduced method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d39b404b-d98e-57ef-8292-573db9c9444b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.03430/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.03430/2-Figure2-1.png", "data/dataset/spiqa/images/1808.03430/2-Figure1-1.png", "data/dataset/spiqa/images/1808.03430/3-Table1-1.png", "data/dataset/spiqa/images/1808.03430/4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the results achieved from the introduced method?", "reference_answer": "Their model resulted in values of 0.476, 0.672 and 0.893 for recall at position 1,2 and 5 respectively in 10 candidates.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b210d05c-1f3b-5272-bdd7-a585437f75c1", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["eca36618-8e25-5ad7-a22b-5e71fbb4c6eb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.10551/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.10551/5-Figure1-1.png", "data/dataset/spiqa/images/1906.10551/5-Table1-1.png", "data/dataset/spiqa/images/1906.10551/6-Table2-1.png", "data/dataset/spiqa/images/1906.10551/7-Table3-1.png", "data/dataset/spiqa/images/1906.10551/7-Table4-1.png", "data/dataset/spiqa/images/1906.10551/8-Figure2-1.png", "data/dataset/spiqa/images/1906.10551/8-Table5-1.png", "data/dataset/spiqa/images/1906.10551/8-Table6-1.png", "data/dataset/spiqa/images/1906.10551/10-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "21678329-87bc-5b35-bce2-5478985c14ca", "question": "How does the appearance of the sphere differ between the re-synthesis using DAMs and the reference image?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9104d00a-0d2b-565f-acc8-c4650cf151b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure6-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure7-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure2-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure8-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure12-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure9-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the appearance of the sphere differ between the re-synthesis using DAMs and the reference image?", "reference_answer": "The sphere in the re-synthesis using DAMs appears to have a more even and consistent surface texture than the reference image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1b59417c-b638-5544-9ff8-4dfa4558b6b7", "question": "Does the paper report macro F1?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["464c4041-96c7-5006-b564-02de05e9b455"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.07723/8-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.07723/3-Figure1-1.png", "data/dataset/spiqa/images/2003.07723/3-Table1-1.png", "data/dataset/spiqa/images/2003.07723/4-Table2-1.png", "data/dataset/spiqa/images/2003.07723/4-Table3-1.png", "data/dataset/spiqa/images/2003.07723/4-Table4-1.png", "data/dataset/spiqa/images/2003.07723/5-Figure2-1.png", "data/dataset/spiqa/images/2003.07723/6-Figure3-1.png", "data/dataset/spiqa/images/2003.07723/7-Table5-1.png", "data/dataset/spiqa/images/2003.07723/7-Figure4-1.png", "data/dataset/spiqa/images/2003.07723/8-Table6-1.png", "data/dataset/spiqa/images/2003.07723/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the paper report macro F1?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "84bb76ed-68f8-505b-89a9-78b29c021433", "question": "Why does the proposed dataset have a lower number of persons per image compared to the Cityscapes dataset, even though it has a much higher total number of pedestrians?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why does the proposed dataset have a lower number of persons per image compared to the Cityscapes dataset, even though it has a much higher total number of pedestrians?", "reference_answer": "The proposed dataset contains non-city scenes like highways, which typically have fewer pedestrians per image compared to cityscapes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "95930142-0a94-5c56-8332-0764a9c407d9", "question": "Do any of the evaluations show that adversarial learning improves performance in at least two different language families?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["486d658e-836b-57c3-a40a-ccfb3658a6a9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00153/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00153/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00153/3-Figure2-1.png", "data/dataset/spiqa/images/1909.00153/4-Table1-1.png", "data/dataset/spiqa/images/1909.00153/5-Table2-1.png", "data/dataset/spiqa/images/1909.00153/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do any of the evaluations show that adversarial learning improves performance in at least two different language families?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "78701351-9002-5523-b903-2ebfb21ac067", "question": "Do they use a neural model for their task?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["468ae5f7-7eec-5984-a75d-dfe60f8a3e1a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.06878/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.06878/2-Figure1-1.png", "data/dataset/spiqa/images/1707.06878/4-Figure2-1.png", "data/dataset/spiqa/images/1707.06878/4-Figure3-1.png", "data/dataset/spiqa/images/1707.06878/5-Table1-1.png", "data/dataset/spiqa/images/1707.06878/5-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they use a neural model for their task?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b50a74af-d817-5ded-8c9c-7985b3082f7d", "question": "What are the state-of-the-art systems?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4e8cbd3b-5a2f-5823-a2af-ad17af1e1e3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.12569/6-TableIV-1.png", "data/dataset/spiqa/images/1911.12569/5-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.12569/3-Figure1-1.png", "data/dataset/spiqa/images/1911.12569/5-TableI-1.png", "data/dataset/spiqa/images/1911.12569/5-TableII-1.png", "data/dataset/spiqa/images/1911.12569/5-TableIII-1.png", "data/dataset/spiqa/images/1911.12569/5-Figure2-1.png", "data/dataset/spiqa/images/1911.12569/6-TableIV-1.png", "data/dataset/spiqa/images/1911.12569/7-TableXI-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the state-of-the-art systems?", "reference_answer": "For sentiment analysis UWB, INF-UFRGS-OPINION-MINING, LitisMind, pkudblab and SVM + n-grams + sentiment and for emotion analysis MaxEnt, SVM, LSTM, BiLSTM and CNN", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "91dcc2f7-2305-528a-9408-f4f5d47ba25c", "question": "How does CNN model learns to ignore areas that appear in both healthy and diseased lungs?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does CNN model learns to ignore areas that appear in both healthy and diseased lungs?", "reference_answer": "The model learns very small weights in the filters for such areas."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5f64b47c-f78b-5e74-97a2-b644d8b9a653", "question": "What are the tasks that this method has shown improvements?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dd606563-ea62-59fb-bcf1-442e965645dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.08780/8-Table4-1.png", "data/dataset/spiqa/images/1808.08780/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.08780/5-Table1-1.png", "data/dataset/spiqa/images/1808.08780/6-Table2-1.png", "data/dataset/spiqa/images/1808.08780/6-Figure1-1.png", "data/dataset/spiqa/images/1808.08780/7-Table3-1.png", "data/dataset/spiqa/images/1808.08780/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the tasks that this method has shown improvements?", "reference_answer": "bilingual dictionary induction, monolingual and cross-lingual word similarity, and cross-lingual hypernym discovery", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3fc37ccd-5421-5583-9313-ef495f532095", "question": "Which method performs the best when there is a high fraction of corrupted samples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["031a172b-3552-5f74-bbeb-ea0f4bed4c91"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1606.07384v2/1606.07384v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1606.07384v2/1606.07384v2-Figure1-1.png", "data/dataset/spiqa/images/1606.07384v2/1606.07384v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best when there is a high fraction of corrupted samples?", "reference_answer": "RANSAC"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0b59a6e7-6a6b-55ac-80e9-8026cea4737f", "question": "How does the training time of the different losses change as the number of additional samples increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the training time of the different losses change as the number of additional samples increases?", "reference_answer": "The training time of all losses increases as the number of additional samples increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b8c4570f-c1b9-5cbd-b15e-c86bf07ae2aa", "question": "How does the PP loss improve the temporal coherence of the video sequence?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the PP loss improve the temporal coherence of the video sequence?", "reference_answer": "The PP loss constrains the output sequence to be symmetric by reducing the L2 distance between corresponding frames in the forward and backward passes. This helps to reduce drifting artifacts and improve temporal coherence."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "86062871-17f0-5347-85d8-a333d2578fcc", "question": "What is the relationship between the input space and the output space in CCA inference?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the input space and the output space in CCA inference?", "reference_answer": "The input space and the output space are related by a cosine similarity measure."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cd4f25f0-77c5-5d35-b343-2bbc59fbf1c8", "question": "How does the graph diameter change with increasing average degree for different methods and datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the graph diameter change with increasing average degree for different methods and datasets?", "reference_answer": "The graph diameter generally decreases with increasing average degree for all methods and datasets. However, the rate of decrease and the final diameter value vary depending on the method and dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "318a9f6a-e492-5bfa-85ed-1884fdb67182", "question": "How does the performance of GeoCUTS compare to the Grid method in identifying highly mobile clusters when the number of clusters is increased from approximately 25 to 50?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of GeoCUTS compare to the Grid method in identifying highly mobile clusters when the number of clusters is increased from approximately 25 to 50?", "reference_answer": "GeoCUTS consistently outperforms the Grid method in identifying highly mobile clusters, regardless of the number of clusters. However, the performance of both methods decreases as the number of clusters increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7492610f-0c98-591d-9c2b-00561d78af41", "question": "What is improvement in accuracy for short Jokes in relation other types of jokes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27719854-566e-5b77-8c88-e07d5570e4c9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00252/4-Table4-1.png", "data/dataset/spiqa/images/1909.00252/3-Table2-1.png", "data/dataset/spiqa/images/1909.00252/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00252/2-Table1-1.png", "data/dataset/spiqa/images/1909.00252/3-Table2-1.png", "data/dataset/spiqa/images/1909.00252/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00252/4-Table3-1.png", "data/dataset/spiqa/images/1909.00252/4-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is improvement in accuracy for short Jokes in relation other types of jokes?", "reference_answer": "It had the highest accuracy comparing to all datasets 0.986% and It had the highest improvement comparing to previous methods on the same dataset by 8%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6d911370-a84d-5ba3-9fc5-af154fdb56dd", "question": "Do the authors do manual evaluation?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["74be74fe-95b5-578d-8a58-68d5bcdf15ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.02815/5-Figure2-1.png", "data/dataset/spiqa/images/1904.02815/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.02815/2-Figure1-1.png", "data/dataset/spiqa/images/1904.02815/3-Table1-1.png", "data/dataset/spiqa/images/1904.02815/4-Table2-1.png", "data/dataset/spiqa/images/1904.02815/5-Figure2-1.png", "data/dataset/spiqa/images/1904.02815/5-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors do manual evaluation?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "80042a5d-c09d-5aea-8328-66d2aadbad31", "question": "Do adversarial examples generated with the 2-keyword constraint maintain a similar syntactic structure to the original sentences?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4979a3cd-d95a-5e60-a12e-08263adccd51"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table4-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table5-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table6-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table7-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table8-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table9-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table1-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table2-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Do adversarial examples generated with the 2-keyword constraint maintain a similar syntactic structure to the original sentences?", "reference_answer": "No, adversarial examples generated with the 2-keyword constraint deviate significantly from the original syntactic structure."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d27280ae-964c-58d7-9502-938dbf28cae5", "question": "What is the containment similarity of Q in X1?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the containment similarity of Q in X1?", "reference_answer": "0.67"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b5778695-985b-5dd3-b561-b44eeea72c17", "question": "Do experiment results show consistent significant improvement of new approach over traditional CNN and RNN models?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["dcc2ddd3-6715-5903-99ec-11d46ac92b7a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.05960/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.05960/4-Figure2-1.png", "data/dataset/spiqa/images/1911.05960/4-Figure1-1.png", "data/dataset/spiqa/images/1911.05960/6-Table1-1.png", "data/dataset/spiqa/images/1911.05960/6-Table2-1.png", "data/dataset/spiqa/images/1911.05960/7-Figure3-1.png", "data/dataset/spiqa/images/1911.05960/7-Figure4-1.png", "data/dataset/spiqa/images/1911.05960/8-Table3-1.png", "data/dataset/spiqa/images/1911.05960/8-Table5-1.png", "data/dataset/spiqa/images/1911.05960/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do experiment results show consistent significant improvement of new approach over traditional CNN and RNN models?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d9d105c1-697d-5c87-a9e8-8c3eeec5b72c", "question": "Look Figure 4.  Give your one observation by comparing (a) and (b), or pretrained and non-pretrained. Reason them.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["74ebae64-5177-5968-9a94-6626f9954498"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/5-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/12-Table4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/12-Table5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.3-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/14-FigureA.5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/14-Table6-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/2-Table1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/4-Figure2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/4-Figure3-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/5-Figure4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/6-Figure5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Figure6-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Figure7-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Table2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Look Figure 4.  Give your one observation by comparing (a) and (b), or pretrained and non-pretrained. Reason them.", "reference_answer": "pretrained LMs can perfectly learn the tasks with many fewer labeled examples, compared to the non-pretrained models in both tasks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "73c1869d-0193-5003-8173-df8734624098", "question": "Which model achieved the best overall performance in terms of ranking relevant tags for users?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6251b737-ea9f-5728-a709-63edee304768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Figure1-1.png", "data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Table1-1.png", "data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model achieved the best overall performance in terms of ranking relevant tags for users?", "reference_answer": "HDMF achieved the best overall performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "78b29a5d-e750-5a4c-94b8-56e02a3508b6", "question": "Which method performed the best on the GRID dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performed the best on the GRID dataset?", "reference_answer": "AMIE (Ours)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ccb45b74-4132-53d5-9694-389aa53d20bc", "question": "Which method achieves the highest Top-1 accuracy on the CUB-200-2011 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["296788f8-16bc-55ff-9d9a-9fdf5ff3b0e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table4-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the highest Top-1 accuracy on the CUB-200-2011 dataset?", "reference_answer": "PC-DenseNet-161"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d0804d2d-72c1-50d2-a0b0-db5f7525e709", "question": "Which 5 languages appear most frequently in AA paper titles?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["083c588e-cadb-585b-985f-70949e59e35d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.03562/10-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.03562/2-Figure1-1.png", "data/dataset/spiqa/images/1911.03562/3-Figure2-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure3-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure4-1.png", "data/dataset/spiqa/images/1911.03562/6-Figure5-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure6-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure7-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure8-1.png", "data/dataset/spiqa/images/1911.03562/8-Figure9-1.png", "data/dataset/spiqa/images/1911.03562/9-Figure10-1.png", "data/dataset/spiqa/images/1911.03562/10-Figure11-1.png", "data/dataset/spiqa/images/1911.03562/12-Figure12-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure13-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure14-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure15-1.png", "data/dataset/spiqa/images/1911.03562/15-Figure16-1.png", "data/dataset/spiqa/images/1911.03562/16-Figure17-1.png", "data/dataset/spiqa/images/1911.03562/17-Figure18-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure19-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure20-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure21-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure22-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure23-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure24-1.png", "data/dataset/spiqa/images/1911.03562/20-Figure25-1.png", "data/dataset/spiqa/images/1911.03562/21-Figure26-1.png", "data/dataset/spiqa/images/1911.03562/22-Figure27-1.png", "data/dataset/spiqa/images/1911.03562/23-Figure28-1.png", "data/dataset/spiqa/images/1911.03562/24-Figure29-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure30-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure31-1.png", "data/dataset/spiqa/images/1911.03562/28-Figure32-1.png", "data/dataset/spiqa/images/1911.03562/29-Figure33-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which 5 languages appear most frequently in AA paper titles?", "reference_answer": "English, Chinese, French, Japanese and Arabic", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1728aff5-174b-56d2-8815-f048f66f74dc", "question": "How many uniue words are in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7f8efd0e-5d39-59ac-b90a-0be783c17b7e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.12579/8-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.12579/4-Table1-1.png", "data/dataset/spiqa/images/1911.12579/5-Figure1-1.png", "data/dataset/spiqa/images/1911.12579/8-Table2-1.png", "data/dataset/spiqa/images/1911.12579/9-Figure2-1.png", "data/dataset/spiqa/images/1911.12579/10-Table3-1.png", "data/dataset/spiqa/images/1911.12579/11-Table4-1.png", "data/dataset/spiqa/images/1911.12579/12-Figure3-1.png", "data/dataset/spiqa/images/1911.12579/12-Table5-1.png", "data/dataset/spiqa/images/1911.12579/14-Table6-1.png", "data/dataset/spiqa/images/1911.12579/15-Table7-1.png", "data/dataset/spiqa/images/1911.12579/15-Table8-1.png", "data/dataset/spiqa/images/1911.12579/16-Table9-1.png", "data/dataset/spiqa/images/1911.12579/17-Figure4-1.png", "data/dataset/spiqa/images/1911.12579/17-Figure5-1.png", "data/dataset/spiqa/images/1911.12579/17-Figure6-1.png", "data/dataset/spiqa/images/1911.12579/18-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many uniue words are in the dataset?", "reference_answer": "908456 unique words are available in collected corpus.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ccb24ab3-34eb-567d-9e47-d8a88a84bef1", "question": "How does the proposed attribute-guided face generation method compare to conventional face super-resolution methods in terms of identity preservation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed attribute-guided face generation method compare to conventional face super-resolution methods in terms of identity preservation?", "reference_answer": "The proposed attribute-guided face generation method preserves the identity of the person in the high-resolution result, while conventional face super-resolution methods do not necessarily guarantee this."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "23e9bbf3-44ca-5c8a-aa3e-ca3db66a446a", "question": "Which eight NER tasks did they evaluate on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1c2e0a2c-3c92-53ff-9439-639ebdded4d7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.03354/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.03354/2-Table1-1.png", "data/dataset/spiqa/images/2004.03354/3-Table2-1.png", "data/dataset/spiqa/images/2004.03354/4-Figure1-1.png", "data/dataset/spiqa/images/2004.03354/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which eight NER tasks did they evaluate on?", "reference_answer": "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bb432a34-5b4e-584b-ab04-8d92960fb047", "question": "Why does the proposed FLoss method perform better than the balanced cross-entropy loss, even though both methods aim to address the data imbalance problem in salient object detection?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why does the proposed FLoss method perform better than the balanced cross-entropy loss, even though both methods aim to address the data imbalance problem in salient object detection?", "reference_answer": "The FLoss method performs better than the balanced cross-entropy loss because it can automatically adjust to data imbalance using the F-measure criterion, while the balanced cross-entropy loss relies on pre-defined weights for positive and negative samples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fb9ff9eb-33e1-5bbf-a7c8-be50ddfa3c3e", "question": "Is this approach compared to some baseline?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["f7771a2b-2d25-5607-9cb4-81a171865925"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.10869/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.10869/2-Figure1-1.png", "data/dataset/spiqa/images/1910.10869/2-Table1-1.png", "data/dataset/spiqa/images/1910.10869/3-Figure2-1.png", "data/dataset/spiqa/images/1910.10869/4-Figure3-1.png", "data/dataset/spiqa/images/1910.10869/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is this approach compared to some baseline?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8818142a-1c07-5ee8-9536-3ca815e37771", "question": "What is the accuracy of the model for the six languages tested?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e9f86328-afc3-5d9e-81a2-0c543538dc03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13362/6-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13362/2-Figure1-1.png", "data/dataset/spiqa/images/1909.13362/3-Figure2-1.png", "data/dataset/spiqa/images/1909.13362/5-TableI-1.png", "data/dataset/spiqa/images/1909.13362/5-TableII-1.png", "data/dataset/spiqa/images/1909.13362/6-TableIII-1.png", "data/dataset/spiqa/images/1909.13362/6-TableIV-1.png", "data/dataset/spiqa/images/1909.13362/7-TableV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the accuracy of the model for the six languages tested?", "reference_answer": "Authors report their best models have following accuracy: English CELEX (98.5%), Dutch CELEX (99.47%), Festival (99.990%), OpenLexique (100%), IIT-Guwahat (95.4%), E-Hitz (99.83%)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7817fc8b-aa1b-5b4a-802c-ab53c66f1899", "question": "How could restricting self attention to some window with size r be useful with long term dependencies?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/13-Figure3-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/14-Figure4-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/15-Figure5-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/3-Figure1-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/4-Figure2-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/6-Table1-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/8-Table2-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/9-Table3-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How could restricting self attention to some window with size r be useful with long term dependencies?", "reference_answer": "Restricting self attention to some window with size r does improve computational performance but its effect on long term dependencies have not been explored in the paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8a604b8a-306a-5d40-959f-9e94962716be", "question": "What is the accuracy of the proposed technique?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9203802d-bcbc-53a4-ac86-4001b26cfe57"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05572/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05572/3-Figure1-1.png", "data/dataset/spiqa/images/1704.05572/4-Table2-1.png", "data/dataset/spiqa/images/1704.05572/4-Table1-1.png", "data/dataset/spiqa/images/1704.05572/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the accuracy of the proposed technique?", "reference_answer": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "35ae4b17-50e0-56e9-8312-d173768fa839", "question": "How does the shape of the negative log-likelihood (NLL) and probability density functions change as the value of α increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the shape of the negative log-likelihood (NLL) and probability density functions change as the value of α increases?", "reference_answer": " As the value of α increases, the NLL functions become more peaked and the probability density functions become more concentrated around the mean."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fcc617c8-fe88-58e0-bf77-d8aff6d284c1", "question": "How did the authors showed that the methods performed worse on the data coming from the second clinical center? Using which metrics ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6b7a7cc4-8550-5ec3-a2bf-f86ba6f4acef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/14-Figure13-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/13-Table3-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/14-Table5-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/12-Table2-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/13-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/10-Table1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/11-Figure10-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/11-Figure11-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/12-Table2-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/13-Table3-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/13-Table4-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/14-Figure13-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/14-Table5-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/15-Figure14-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/17-TableB.1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/17-TableC.1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/2-Figure1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/4-Figure2-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/5-Figure3-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/5-Figure4-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/6-Figure5-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/8-Figure6-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/8-Figure7-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/8-Figure8-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How did the authors showed that the methods performed worse on the data coming from the second clinical center? Using which metrics ?", "reference_answer": "Through Tables 2 to 5, the authors have shown that the performance of DeepMedic in terms of DSC, precision, sensitivity, ASSD, and Haussdorf for the BRATS and ISLES test datasets are worse than the performance of DeepMedic when trained with the BRATS and ISLES training datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "283924b3-bf42-5bd7-8e66-e445db618c74", "question": "Which model performs best on the SelQA dataset and how does it compare to the baseline CNN model reported in Jurczyk et al. (2016)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best on the SelQA dataset and how does it compare to the baseline CNN model reported in Jurczyk et al. (2016)?", "reference_answer": "The AdaQA (two-way) + att. model achieves the best performance on the SelQA dataset with a MAP score of 0.9021 and an MRR score of 0.9103. Compared to the baseline CNN model from Jurczyk et al. (2016) which has a MAP score of 0.8320 and an MRR score of 0.8420, the AdaQA (two-way) + att. model demonstrates a significant improvement in both metrics."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6c043b33-c60c-557b-bdf4-fd89b7dbb68d", "question": "Which method has the highest overall accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2f3b7633-fa54-55d7-8802-08f611b754d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure6-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure9-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure10-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the highest overall accuracy?", "reference_answer": "UnCoRd-VG-E"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5b4871dc-f2d4-5469-b556-d75e59cc5fd1", "question": "Is it more beneficial to use ConvNet+CN with or without Mixup when the corruption probability is 80%? Explain your reasoning.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Is it more beneficial to use ConvNet+CN with or without Mixup when the corruption probability is 80%? Explain your reasoning.", "reference_answer": "ConvNet+CN with Mixup achieves a higher accuracy (75.4%) than ConvNet+CN without Mixup (65.2%) when the corruption probability is 80%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9b3c7ef0-fb67-5d03-ab05-e84f26e077fb", "question": "How much is the BLEU score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["430bf567-c67b-554a-b865-ca96e054ca1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00110/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00110/3-Figure1-1.png", "data/dataset/spiqa/images/1707.00110/4-Figure2-1.png", "data/dataset/spiqa/images/1707.00110/4-Table1-1.png", "data/dataset/spiqa/images/1707.00110/5-Figure3-1.png", "data/dataset/spiqa/images/1707.00110/6-Figure4-1.png", "data/dataset/spiqa/images/1707.00110/6-Table2-1.png", "data/dataset/spiqa/images/1707.00110/6-Table3-1.png", "data/dataset/spiqa/images/1707.00110/7-Figure5-1.png", "data/dataset/spiqa/images/1707.00110/8-Figure6-1.png", "data/dataset/spiqa/images/1707.00110/8-Figure7-1.png", "data/dataset/spiqa/images/1707.00110/8-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much is the BLEU score?", "reference_answer": "Ranges from 44.22 to 100.00 depending on K and the sequence length.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3cbd845f-c502-5087-9cf7-799c4ff795fd", "question": "What is the upper bound on the query complexity for finding an ε-perfect allocation with minimum cuts for 3 or more players?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4713fdd0-d414-5267-9d4e-3c4e85657fe4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure5-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure6-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure4-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table2-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure2-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table1-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure3-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure8-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure1-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the upper bound on the query complexity for finding an ε-perfect allocation with minimum cuts for 3 or more players?", "reference_answer": "O(n^3 / ε)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "53e0260d-7644-5e00-8eaa-25dabb558ec3", "question": "How big is the dataset used in this work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["61981692-50f7-5118-9cc5-d34611414f01"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.06592/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.06592/3-Figure1-1.png", "data/dataset/spiqa/images/1910.06592/4-Table1-1.png", "data/dataset/spiqa/images/1910.06592/5-Figure3-1.png", "data/dataset/spiqa/images/1910.06592/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is the dataset used in this work?", "reference_answer": "Total dataset size: 171 account (522967 tweets)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "601b021a-4468-5060-a3d3-7a7c3b71ac60", "question": "How much gain does the model achieve with pretraining MVCNN?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b8957afb-5f88-5b99-a834-c98345f07fd2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.04513/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.04513/3-Figure1-1.png", "data/dataset/spiqa/images/1603.04513/7-Table1-1.png", "data/dataset/spiqa/images/1603.04513/7-Table2-1.png", "data/dataset/spiqa/images/1603.04513/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much gain does the model achieve with pretraining MVCNN?", "reference_answer": "0.8 points on Binary; 0.7 points on Fine-Grained; 0.6 points on Senti140; 0.7 points on Subj", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c2407cf8-446f-505e-8bd8-ebba3a4dfad7", "question": "What is the goal behind using a single model SR approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["98008c07-575a-5ae0-a403-5a072d976ae0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/1-Figure1-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/3-Figure2-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/4-Table1-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/5-Figure3-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/6-Figure5-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/6-Table2-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/7-Figure6-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/7-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the goal behind using a single model SR approach?", "reference_answer": "Existing methods are only trained for a single scale, so adapting them to other scales requires retraining. However, this would be impractical, so having a single model that accepts multiple scales would fix the problem."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ad9830c3-289b-56e2-914b-d2d762b29032", "question": "Is the model presented in the paper state of the art?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8d6a2c23-82b0-5e7d-828e-456f2670106a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.04553/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.04553/3-Table1-1.png", "data/dataset/spiqa/images/1603.04553/3-Table2-1.png", "data/dataset/spiqa/images/1603.04553/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the model presented in the paper state of the art?", "reference_answer": "No, supervised models perform better for this task.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "484517b3-c17b-570d-b459-4e9d8678be5b", "question": "What metrics are used to compare the performance of ULMFiT against existing approaches?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c4860d9-c6fc-5c07-b4c7-dc9cd1aff233"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/5-Table1-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What metrics are used to compare the performance of ULMFiT against existing approaches?", "reference_answer": "For consistency, the authors reported all results as error rates where lower is better."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c160940d-fda1-5061-89d3-cfba21c0448f", "question": "Which algorithm has the highest percentage of switched instances?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ffd62601-2bd0-5ace-ac7f-d4fb321dcc10"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure1-1.png", "data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure3-1.png", "data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm has the highest percentage of switched instances?", "reference_answer": "US-HC-MQ"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "af5a4311-9283-568d-89a7-cb91918468ba", "question": " \n\nWhat is the difference between the original and pre-processed SMD Navigate data? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " \n\nWhat is the difference between the original and pre-processed SMD Navigate data? ", "reference_answer": " \n\nThe pre-processed SMD Navigate data combines all the properties (such as distance, address) of a point of interest (POI) into a single subject with the object being \"poi\". The original data had separate entries for each property. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "34e33f8e-8621-54ae-b23b-ded2f3ece926", "question": "How big is the dataset used in this work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["61981692-50f7-5118-9cc5-d34611414f01"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.06592/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.06592/3-Figure1-1.png", "data/dataset/spiqa/images/1910.06592/4-Table1-1.png", "data/dataset/spiqa/images/1910.06592/5-Figure3-1.png", "data/dataset/spiqa/images/1910.06592/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is the dataset used in this work?", "reference_answer": "212 accounts", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "53a2cc99-300f-52e2-9667-36300f733412", "question": "Which model performed best on the IMDB dataset for classifying documents with categorical labels, and how much better did it perform compared to the SLDA model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed best on the IMDB dataset for classifying documents with categorical labels, and how much better did it perform compared to the SLDA model?", "reference_answer": "Both the SCHOLAR (covariates) and Logistic Regression models achieved the highest accuracy of 0.87 on the IMDB dataset. This represents a 0.23 improvement over the SLDA model, which achieved an accuracy of 0.64."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "734530c3-a995-557c-9215-2a38cf860824", "question": "Is it valid to presume a bad medical wikipedia article should not contain much domain-specific jargon?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["5ae43791-c10b-5f90-9d86-6de92667f1f5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.01987/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.01987/4-Figure1-1.png", "data/dataset/spiqa/images/1603.01987/4-Figure2-1.png", "data/dataset/spiqa/images/1603.01987/6-Table1-1.png", "data/dataset/spiqa/images/1603.01987/7-Figure3-1.png", "data/dataset/spiqa/images/1603.01987/8-Table2-1.png", "data/dataset/spiqa/images/1603.01987/10-Table3-1.png", "data/dataset/spiqa/images/1603.01987/11-Figure4-1.png", "data/dataset/spiqa/images/1603.01987/12-Table4-1.png", "data/dataset/spiqa/images/1603.01987/13-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is it valid to presume a bad medical wikipedia article should not contain much domain-specific jargon?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0e514133-2bf0-5c21-b067-68eec91257e7", "question": "Which loss type performs best when the concept batch size is 5k?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which loss type performs best when the concept batch size is 5k?", "reference_answer": "Independent and common concept"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "de2b1ee6-3cf2-53de-878c-1c05c97c39db", "question": "What is a depthwise separable convolution means?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is a depthwise separable convolution means?", "reference_answer": "Depthwise separable convolution is made up of two layers: depthwise convolutions and pointwise convolutions where depthwise convolutions apply a single filter per each input channel and a Pointwise convolution creates a linear combination of the output of the depthwise layer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "dd81fcc1-770c-5b63-8f99-2aa0201e9083", "question": "Which type of word has the greatest difference in frequency of occurrence between MultiNLI and SNLI?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ab8d017f-8645-5337-aa84-f52783391b99"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table4-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Figure1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table5-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table2-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which type of word has the greatest difference in frequency of occurrence between MultiNLI and SNLI?", "reference_answer": "Negation (PTB)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "eaf16a7e-377d-5a3c-81ea-7b03db6c5811", "question": "How can we check if the model suffers from mode collapse?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db57be6f-8829-5091-b1d9-ef653aa08e83"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/8-Figure7-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/2-Figure2-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/11-Figure10-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/12-Figure11-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/13-Figure12-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/14-Figure13-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/15-Figure14-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/15-Figure15-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/16-Figure16-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/16-Figure17-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/2-Figure2-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/3-Figure3-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/4-Figure4-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/6-Figure5-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/6-Figure6-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table1-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table2-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table3-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table4-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/8-Figure7-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/8-Figure8-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How can we check if the model suffers from mode collapse?", "reference_answer": "[If all input images map to the same output image and the optimization fails to make progress, then the model is suffering from “mode collapse”. For example, the paper evaluates its method with the cycle loss in only one direction: GAN + forward cycle loss, or GAN + backward cycle loss (in Equation 2) and finds that it often incurs training instability and causes mode collapse, especially for the direction of the mapping that was removed.]"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "daeea112-c6e2-55a5-8c63-eed05d2a011e", "question": "Did the authors try stacking multiple convolutional layers?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["2287765e-006c-57a2-ace2-6bb971359e5f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.02121/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.02121/2-Table1-1.png", "data/dataset/spiqa/images/1712.02121/3-Table2-1.png", "data/dataset/spiqa/images/1712.02121/3-Figure1-1.png", "data/dataset/spiqa/images/1712.02121/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did the authors try stacking multiple convolutional layers?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3551eda4-6760-507e-8c11-5df5bbdee1b4", "question": "What evaluation metric do they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9f9c1350-3ff8-59e5-a69a-c1f9b7437cc7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1604.05372/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1604.05372/4-Table1-1.png", "data/dataset/spiqa/images/1604.05372/5-Table2-1.png", "data/dataset/spiqa/images/1604.05372/6-Figure1-1.png", "data/dataset/spiqa/images/1604.05372/6-Figure2-1.png", "data/dataset/spiqa/images/1604.05372/7-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What evaluation metric do they use?", "reference_answer": "Accuracy", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bd0bae53-acfd-5d31-a167-a61f21d73efe", "question": "Which genre in the SRL-NW network has the lowest failure rate and how does its inference time compare to other genres within the same network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which genre in the SRL-NW network has the lowest failure rate and how does its inference time compare to other genres within the same network?", "reference_answer": "The PT genre within the SRL-NW network has the lowest failure rate at 10.01%. Its inference time is also the lowest across all genres in the SRL-NW network for all three inference procedures (Viterbi, GBI, and A*)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c88d474b-0615-5a55-af68-3239234db00c", "question": "What is the performance of the model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["0faafe1c-fa8e-5766-8078-51df2fec2ae9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00124/5-Figure2-1.png", "data/dataset/spiqa/images/1909.00124/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00124/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00124/4-Table1-1.png", "data/dataset/spiqa/images/1909.00124/5-Table2-1.png", "data/dataset/spiqa/images/1909.00124/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the performance of the model?", "reference_answer": "Experiment 1: ACC around 0.5 with 50% noise rate in worst case - clearly higher than baselines for all noise rates\nExperiment 2: ACC on real noisy datasets: 0.7 on Movie, 0.79 on Laptop, 0.86 on Restaurant (clearly higher than baselines in almost all cases)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d4d7bbaa-91b6-5705-830b-53553b6859fc", "question": "How is performance measured?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4d7e1725-aef7-52fb-80c4-1ffb2c659ff8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.06941/7-Figure3-1.png", "data/dataset/spiqa/images/1904.06941/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.06941/3-Figure1-1.png", "data/dataset/spiqa/images/1904.06941/4-Figure2-1.png", "data/dataset/spiqa/images/1904.06941/7-Figure3-1.png", "data/dataset/spiqa/images/1904.06941/7-Table1-1.png", "data/dataset/spiqa/images/1904.06941/9-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How is performance measured?", "reference_answer": "they use ROC curves and cross-validation", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9a45b4e4-ae76-51ba-b92e-bc881244f0ff", "question": "Which dataset would you expect to be the most challenging for a model trained on MSRA-B to perform well on, and why?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset would you expect to be the most challenging for a model trained on MSRA-B to perform well on, and why?", "reference_answer": "The DUT-OMRON dataset is likely the most challenging for a model trained on MSRA-B."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "48ef248e-3fc4-5ede-92fb-6db47099381c", "question": "Which four languages do they experiment with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d6e070f6-a12e-5e97-bf62-c0f54d4702d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.07996/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.07996/2-Table1-1.png", "data/dataset/spiqa/images/2003.07996/2-Table2-1.png", "data/dataset/spiqa/images/2003.07996/3-Table3-1.png", "data/dataset/spiqa/images/2003.07996/3-Table4-1.png", "data/dataset/spiqa/images/2003.07996/4-Figure1-1.png", "data/dataset/spiqa/images/2003.07996/4-Figure2-1.png", "data/dataset/spiqa/images/2003.07996/5-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which four languages do they experiment with?", "reference_answer": "German, English, Italian, Chinese", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "96beded9-0604-5291-a92b-554a203ae228", "question": "Which models were compared?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["906a1415-0b8a-531a-97e8-96878b6c2642"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.09774/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.09774/3-Table1-1.png", "data/dataset/spiqa/images/1810.09774/4-Table2-1.png", "data/dataset/spiqa/images/1810.09774/5-Table3-1.png", "data/dataset/spiqa/images/1810.09774/6-Table4-1.png", "data/dataset/spiqa/images/1810.09774/9-Table5-1.png", "data/dataset/spiqa/images/1810.09774/10-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which models were compared?", "reference_answer": "BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and BERT", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a3158645-d5e5-5f9c-a0a3-e829f2b9a4e2", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["3bb937a0-4a80-51d3-84fd-f9e14eb336f7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1610.00879/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1610.00879/2-Figure1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table2-1.png", "data/dataset/spiqa/images/1610.00879/4-Table4-1.png", "data/dataset/spiqa/images/1610.00879/4-Table3-1.png", "data/dataset/spiqa/images/1610.00879/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d872b68b-8f1c-50e1-97d3-41e42087706e", "question": "What datasets are used for training/testing models? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a1b87d72-fb6c-5cf0-b2fd-7e16ff1ab378"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11546/3-Table4-1.png", "data/dataset/spiqa/images/1908.11546/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11546/1-Table1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure2-1.png", "data/dataset/spiqa/images/1908.11546/3-Table5-1.png", "data/dataset/spiqa/images/1908.11546/3-Table4-1.png", "data/dataset/spiqa/images/1908.11546/3-Table3-1.png", "data/dataset/spiqa/images/1908.11546/3-Table2-1.png", "data/dataset/spiqa/images/1908.11546/4-Table6-1.png", "data/dataset/spiqa/images/1908.11546/4-Table7-1.png", "data/dataset/spiqa/images/1908.11546/5-Table8-1.png", "data/dataset/spiqa/images/1908.11546/5-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What datasets are used for training/testing models? ", "reference_answer": "Microsoft Research dataset containing movie, taxi and restaurant domains.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b4f2c36f-b60d-5cfd-8f90-04b0fe806e2f", "question": "Do they evaluate only on English?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["9efa25a9-b0bd-58c6-b41d-81bcb6cd3ba6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.09795/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.09795/3-Table1-1.png", "data/dataset/spiqa/images/1809.09795/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they evaluate only on English?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b17b1218-6495-5fca-8a62-17b545b2286f", "question": "Which task-oriented dialog system performs the best when the percentage of unseen information in the KB is high?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which task-oriented dialog system performs the best when the percentage of unseen information in the KB is high?", "reference_answer": "BoSsNet"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b72ba852-15f0-579d-ac96-9324c4562b27", "question": "How does the accuracy of the model change as the value of c increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the accuracy of the model change as the value of c increases?", "reference_answer": "The accuracy of the model decreases as the value of c increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0549f03b-798e-5472-a32f-5c724a20354d", "question": "Explain the difference between the features \"TF-IDF\" and \"BM25\".", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["43e9c887-125b-5503-b988-b6cac3e4aa71"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table3-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table2-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table1-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Explain the difference between the features \"TF-IDF\" and \"BM25\".", "reference_answer": "Both TF-IDF and BM25 are features used to estimate the relevance of a document to a query. However, they differ in their underlying calculations.\n\nTF-IDF: This feature represents the average product of term frequency (TF) and inverse document frequency (IDF) for each query term within different document sections (URL, title, content, and whole document). TF measures how often a term appears in a specific document section, while IDF measures how important that term is across the entire document collection.\n\nBM25: This feature utilizes the BM25 ranking function, which is a probabilistic model that considers term frequency, document length, and average document length to estimate relevance. While it also considers term frequency like TF-IDF, it incorporates additional factors to improve the weighting scheme."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8b2e0f16-df97-54b3-933d-3175942a2998", "question": "Does sharing the first convolutional layer and the last fully connected layer improve the accuracy of the merge-and-run mapping?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Does sharing the first convolutional layer and the last fully connected layer improve the accuracy of the merge-and-run mapping?", "reference_answer": "Yes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f55223cb-bb08-5470-b071-c3af72c36858", "question": "What is the range of values for the shape parameter α?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the range of values for the shape parameter α?", "reference_answer": "The range of values for the shape parameter α is from 0 to 2."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "bc8ecc62-4efa-5d40-9969-d0bda64cc3e6", "question": "Which method performed best according to the P@1 metric for the QA-Expert task, and how much better did it perform compared to the average P@1 score of the D2V method? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5ca3482f-83fe-54e5-acb1-1b4d1ecfa5b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Table1-1.png", "data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Figure2-1.png", "data/dataset/spiqa/images/1611.04363v2/1611.04363v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performed best according to the P@1 metric for the QA-Expert task, and how much better did it perform compared to the average P@1 score of the D2V method? ", "reference_answer": "The WeakFG method achieved the highest P@1 score for the QA-Expert task with a score of 52.8. This is 23.2% higher than the average P@1 score of the D2V method, which was 29.6. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4733daaf-a8f7-5c00-afd1-dd461249823b", "question": "How does the performance of SPIRAL-DTW-kMeans compare to k-Shape and CLDS?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ac630ef5-d68e-5774-9cf6-4edd657f3310"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Table1-1.png", "data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure1-1.png", "data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of SPIRAL-DTW-kMeans compare to k-Shape and CLDS?", "reference_answer": "SPIRAL-DTW-kMeans performs better than k-Shape and CLDS on most datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d8d99d86-e689-5825-af94-2a60f40509ac", "question": "How big is seed lexicon used for training?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is seed lexicon used for training?", "reference_answer": "30 words", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "acd540b0-7de1-5b7b-bc1b-70c6c0eb4c75", "question": "What baselines did they consider?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4712486a-c8e6-5346-88a5-b322dacec591"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01202/6-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01202/1-Figure1-1.png", "data/dataset/spiqa/images/1809.01202/4-Table1-1.png", "data/dataset/spiqa/images/1809.01202/4-Table2-1.png", "data/dataset/spiqa/images/1809.01202/5-Figure2-1.png", "data/dataset/spiqa/images/1809.01202/6-Table5-1.png", "data/dataset/spiqa/images/1809.01202/6-Table3-1.png", "data/dataset/spiqa/images/1809.01202/6-Table4-1.png", "data/dataset/spiqa/images/1809.01202/7-Table6-1.png", "data/dataset/spiqa/images/1809.01202/7-Table7-1.png", "data/dataset/spiqa/images/1809.01202/8-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What baselines did they consider?", "reference_answer": "Linear SVM, RBF SVM, and Random Forest", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d5cf6f04-9f32-5382-b066-c13066ae0c3d", "question": "Which model is the most effective at connecting digits with larger distances?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model is the most effective at connecting digits with larger distances?", "reference_answer": "The log model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "09e94d8b-dd27-59ef-acb1-b37db7d4f4cb", "question": "What are the differences between the results of the three methods, LiteFlowNet, PWC-Net, and Devon, compared to the ground truth?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the differences between the results of the three methods, LiteFlowNet, PWC-Net, and Devon, compared to the ground truth?", "reference_answer": "LiteFlowNet, PWC-Net, and Devon all produce results that are similar to the ground truth, but there are some subtle differences. For example, LiteFlowNet tends to overestimate the motion of the small object, while PWC-Net and Devon tend to underestimate it. Additionally, all three methods produce some artifacts around the edges of the moving object."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f7ae862e-6906-5f9f-82a2-24044373a7fb", "question": "What is an \"answer style\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["03783a9f-aefc-568a-94a9-d775185b2072"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.02262/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.02262/1-Figure1-1.png", "data/dataset/spiqa/images/1901.02262/2-Figure2-1.png", "data/dataset/spiqa/images/1901.02262/4-Figure3-1.png", "data/dataset/spiqa/images/1901.02262/5-Table1-1.png", "data/dataset/spiqa/images/1901.02262/6-Table2-1.png", "data/dataset/spiqa/images/1901.02262/6-Table3-1.png", "data/dataset/spiqa/images/1901.02262/6-Table4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure5-1.png", "data/dataset/spiqa/images/1901.02262/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is an \"answer style\"?", "reference_answer": "well-formed sentences vs concise answers", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "cafc49b8-8224-53d8-8d69-dbc4b7889226", "question": "what dataset statistics are provided?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1476648e-0d55-550f-8e3c-ecc0dafb09a1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.05223/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.05223/1-Figure1-1.png", "data/dataset/spiqa/images/1803.05223/3-Table1-1.png", "data/dataset/spiqa/images/1803.05223/4-Figure2-1.png", "data/dataset/spiqa/images/1803.05223/4-Figure3-1.png", "data/dataset/spiqa/images/1803.05223/6-Figure4-1.png", "data/dataset/spiqa/images/1803.05223/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what dataset statistics are provided?", "reference_answer": "More than 2,100 texts were paired with 15 questions each, resulting in a total number of approx. 32,000 annotated questions. 13% of the questions are not answerable.  Out of the answerable questions, 10,160 could be answered from the text directly (text-based) and 3,914 questions required the use of commonsense knowledge (script-based).  The final dataset comprises 13,939 questions, 3,827 of which require commonsense knowledge (i.e. 27.4%).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "14aa9dd5-aea5-5ef0-8b68-53045e03d475", "question": "How does explicitly modeling meaning-preserving invariances impact the generation of paraphrases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e81915ee-6436-5660-8f3e-a8d93e4e8f32"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Figure1-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table3-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table2-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does explicitly modeling meaning-preserving invariances impact the generation of paraphrases?", "reference_answer": "Explicitly modeling meaning-preserving invariances leads to the generation of better paraphrases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7acafe2b-5f7e-59e7-a1d6-8d9a12dfff49", "question": "What is the relationship between the color of the points and the motion of the object?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the color of the points and the motion of the object?", "reference_answer": "The color of the points indicates the motion that the Multi-X algorithm assigned to each point."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "65920008-f4de-547c-be35-576d90ba0e3c", "question": "what are the three methods presented in the paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5ec710cc-1af9-5fad-b178-1dd186e6651f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.08976/2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.08976/1-Table1-1.png", "data/dataset/spiqa/images/1911.08976/2-Table2-1.png", "data/dataset/spiqa/images/1911.08976/4-Figure1-1.png", "data/dataset/spiqa/images/1911.08976/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what are the three methods presented in the paper?", "reference_answer": "Optimized TF-IDF, iterated TF-IDF, BERT re-ranking.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1b4f26cd-6711-5fd4-8e25-510d4514424f", "question": "What will be the effect in performance if group numbers for convolution is increased? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What will be the effect in performance if group numbers for convolution is increased? ", "reference_answer": "For ShuffleNet, having more than 1 group seems to show consistently better results for all complexities. As the model gets smaller, the performance gain seems to increase more as the number of groups increases. However, for larger models, a too large number of groups led to saturation or a drop in classification error, possibly due to reduced representative capabilities."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "178ab1b3-800f-55ea-a5b3-398c6aa3b071", "question": "Going deep through network layers makes it harder to remember shallower local information, wouldn't that make segmentation harder?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Going deep through network layers makes it harder to remember shallower local information, wouldn't that make segmentation harder?", "reference_answer": "Since non anatomy part has a much larger spatial support than the anatomy and As we move down the layers in a CNN the receptive field of the features increases therefore proposed CNN would work fine for the local information."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "87f57840-783c-57e7-8c37-e2e0178f1bc9", "question": "How well does their system perform on the development set of SRE?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["619cbcf0-5dc7-5b38-9ddc-919fc3996a53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.00514/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.00514/1-Table1-1.png", "data/dataset/spiqa/images/1611.00514/2-Figure1-1.png", "data/dataset/spiqa/images/1611.00514/3-Figure2-1.png", "data/dataset/spiqa/images/1611.00514/3-Figure3-1.png", "data/dataset/spiqa/images/1611.00514/5-Table2-1.png", "data/dataset/spiqa/images/1611.00514/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How well does their system perform on the development set of SRE?", "reference_answer": "EER 16.04, Cmindet 0.6012, Cdet 0.6107", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "db47b811-a3f5-5a77-8532-ef6c313e2bf2", "question": "How is the performance on the task evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c82c9933-a43a-5166-b9b6-4436ea2b748a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.05456/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.05456/1-Table1-1.png", "data/dataset/spiqa/images/1910.05456/4-Table2-1.png", "data/dataset/spiqa/images/1910.05456/5-Table3-1.png", "data/dataset/spiqa/images/1910.05456/5-Table4-1.png", "data/dataset/spiqa/images/1910.05456/6-Table5-1.png", "data/dataset/spiqa/images/1910.05456/7-Table7-1.png", "data/dataset/spiqa/images/1910.05456/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How is the performance on the task evaluated?", "reference_answer": "Comparison of test accuracies of neural network models on an inflection task and qualitative analysis of the errors", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7c97311a-05b2-5f3e-a28d-ecd94290b73c", "question": "What are the layers of depthwise separable convolution and discuss the function of each of them.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the layers of depthwise separable convolution and discuss the function of each of them.", "reference_answer": "Depthwise separable convolutions have two layers—depthwise and pointwise. Depthwise convolutions apply one filter per input channel (input depth). The depthwise layer output is linearly combined using pointwise convolution which is a 1\\times 1 convolution."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "9aef6c79-c1cf-5462-9303-d0bc3e8dd0c9", "question": "Which method performs best overall on VQA-2014val, and how does its performance compare to human performance on the same dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best overall on VQA-2014val, and how does its performance compare to human performance on the same dataset?", "reference_answer": "MLP-IQA achieves the highest overall accuracy (46.5%) among the machine learning methods tested on VQA-2014val. However, this performance still falls short of human performance, which reaches an accuracy of 85.5% on the same dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0b7c90e9-c1f5-5d30-9030-14b0b5f7e621", "question": "What is difference in peformance between proposed model and state-of-the art on other question types?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3b00efc6-7dc4-596c-9d4e-6847f1652175"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13375/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13375/6-Table1-1.png", "data/dataset/spiqa/images/1909.13375/6-Table2-1.png", "data/dataset/spiqa/images/1909.13375/6-Table3-1.png", "data/dataset/spiqa/images/1909.13375/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is difference in peformance between proposed model and state-of-the art on other question types?", "reference_answer": "For single-span questions, the proposed LARGE-SQUAD improve performance of the MTMSNlarge baseline for 2.1 EM and 1.55 F1.\nFor number type question,  MTMSNlarge baseline  have improvement over LARGE-SQUAD for 3,11  EM and  2,98 F1. \nFor date question,  LARGE-SQUAD have improvements in 2,02 EM but MTMSNlarge have improvement of 4,39 F1.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f0cd0d4e-0072-57a1-a5c4-10acb4e9480a", "question": " What are the limitations of the Zhou \\textit{et al.} and Chen \\textit{et al.} methods for generating talking-face videos, as compared to the method proposed in the paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " What are the limitations of the Zhou \\textit{et al.} and Chen \\textit{et al.} methods for generating talking-face videos, as compared to the method proposed in the paper?", "reference_answer": " The Zhou \\textit{et al.} method suffers from a \"zoom-in-and-out\" effect, while the Chen \\textit{et al.} method produces lip shapes that differ from the real ones."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8d0dd7b4-9f2f-587d-82ec-2bc60c467e01", "question": "Which method performs the best on the Branin function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best on the Branin function?", "reference_answer": "One Step ALOQ"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3e4afcf3-49be-54cd-8bb3-653dcc2fefe2", "question": "Which algorithm achieves the fastest processing time per frame and how much faster is it compared to the slowest algorithm listed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e91f7cea-06b5-5326-88d0-de2c234edf4d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table1-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table5-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table6-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm achieves the fastest processing time per frame and how much faster is it compared to the slowest algorithm listed?", "reference_answer": "Algorithm 12(SCDM with Geman-McLure) achieves the fastest processing time per frame at 0.103 seconds. This is approximately 100 times faster than the slowest algorithm, TTD_3WD, which takes 10.343 seconds per frame."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "86662ed4-3d0f-504a-93e3-1ef92708c096", "question": "How does HUMBI capture diverse appearance of human expressions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does HUMBI capture diverse appearance of human expressions?", "reference_answer": "HUMBI includes 772 distinctive subjects across gender, ethnicity, age, clothing style, and physical condition, which generates diverse appearance of human expressions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c964f1cf-7089-5681-8d63-4b4acde30dc8", "question": "What is the size of the new dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f9d26857-e887-5526-8b66-e0f9cecda38e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.09666/4-Table3-1.png", "data/dataset/spiqa/images/1902.09666/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.09666/2-Table1-1.png", "data/dataset/spiqa/images/1902.09666/3-Table2-1.png", "data/dataset/spiqa/images/1902.09666/4-Table3-1.png", "data/dataset/spiqa/images/1902.09666/5-Table4-1.png", "data/dataset/spiqa/images/1902.09666/5-Table5-1.png", "data/dataset/spiqa/images/1902.09666/5-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the size of the new dataset?", "reference_answer": "Dataset contains total of 14100 annotations.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a4b4e81e-f80e-54dd-b663-ec5b49817fee", "question": " What is the role of the warped triplets in the conditional VSR Ds,t?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " What is the role of the warped triplets in the conditional VSR Ds,t?", "reference_answer": " The warped triplets provide additional information about the motion and appearance of the scene, which helps the VSR Ds,t to generate more accurate and realistic results."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c01f3b50-57ff-54dd-b760-bb250c1aff84", "question": "What is the purpose of negative sampling?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of negative sampling?", "reference_answer": "Negative sampling is a technique used to reduce the number of negative examples that need to be considered during training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ddbe8af4-90a1-5138-a9a7-6393e246d0cc", "question": "How does the proposed model compare to the other models in terms of accuracy on the NIPS Abstracts dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["510d6fc0-d3e0-5dc1-8e0d-4d470f964287"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table4-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table3-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Figure2-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table5-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table1-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed model compare to the other models in terms of accuracy on the NIPS Abstracts dataset?", "reference_answer": "The proposed model has the highest accuracy on the NIPS Abstracts dataset, with an accuracy of 51.55."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4293df7c-9797-5ceb-bedb-2cd5bd02f7c4", "question": "What is new state-of-the-art performance on CoNLL-2009 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["98fc6c15-8779-5c22-8492-0514d955e3cd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.11204/8-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.11204/1-Figure1-1.png", "data/dataset/spiqa/images/1910.11204/3-Figure2-1.png", "data/dataset/spiqa/images/1910.11204/4-Figure3-1.png", "data/dataset/spiqa/images/1910.11204/5-Table1-1.png", "data/dataset/spiqa/images/1910.11204/5-Figure4-1.png", "data/dataset/spiqa/images/1910.11204/6-Table2-1.png", "data/dataset/spiqa/images/1910.11204/6-Table3-1.png", "data/dataset/spiqa/images/1910.11204/7-Table4-1.png", "data/dataset/spiqa/images/1910.11204/7-Table5-1.png", "data/dataset/spiqa/images/1910.11204/7-Table6-1.png", "data/dataset/spiqa/images/1910.11204/8-Table7-1.png", "data/dataset/spiqa/images/1910.11204/9-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is new state-of-the-art performance on CoNLL-2009 dataset?", "reference_answer": "In closed setting 84.22 F1 and in open 87.35 F1.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "249ca8d5-86e8-5f4a-af05-042859d08b0f", "question": "What does non-linguistic means?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["74ebae64-5177-5968-9a94-6626f9954498"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/2-Table1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/12-Table4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/12-Table5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.3-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/14-FigureA.5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/14-Table6-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/2-Table1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/4-Figure2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/4-Figure3-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/5-Figure4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/6-Figure5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Figure6-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Figure7-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Table2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does non-linguistic means?", "reference_answer": "Non-linguistic is something which is not related to linguistic information, and it includes the tasks such as quantitative computation and decimal operation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ebf2d850-6f04-5c4b-ac69-b349cb6e9b01", "question": "What is the purpose of the activation layer in a convolutional neural network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the activation layer in a convolutional neural network?", "reference_answer": "The activation layer applies a non-linear function to the output of the convolution layer. This allows the network to learn more complex features from the data."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2e19f7a7-0ec8-553d-a9ca-c4b0ee79ce65", "question": "Based on the table, which method performs best on the Sintel \"Final\" test set, and how does its performance compare to Devon (ft) on the same set? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the table, which method performs best on the Sintel \"Final\" test set, and how does its performance compare to Devon (ft) on the same set? ", "reference_answer": "PWC-Net (ft) performs best on the Sintel \"Final\" test set with an error of 5.04. Devon (ft) has a higher error of 6.35 on the same set. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cb721b3a-6174-5e9b-b16e-ea4ce68a5d69", "question": "What other tasks do they test their method on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ee4ce3f5-a8de-5a72-9097-2f8dabd95bf9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.03481/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.03481/3-Figure1-1.png", "data/dataset/spiqa/images/1605.03481/4-Table1-1.png", "data/dataset/spiqa/images/1605.03481/4-Table2-1.png", "data/dataset/spiqa/images/1605.03481/4-Table3-1.png", "data/dataset/spiqa/images/1605.03481/5-Figure2-1.png", "data/dataset/spiqa/images/1605.03481/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What other tasks do they test their method on?", "reference_answer": "None", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "51aba2e5-dd1f-5165-b228-a25a01b0c8e5", "question": "Which method is more efficient at utilizing space while maintaining high accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method is more efficient at utilizing space while maintaining high accuracy?", "reference_answer": "GB-KMV is more efficient at utilizing space while maintaining high accuracy."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f0fab5ed-4ccd-5183-942e-666ef2bc02ad", "question": "What is the difference between the \"median appearance\" and the \"view-specific appearance\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the \"median appearance\" and the \"view-specific appearance\"?", "reference_answer": "The median appearance is the average of all the multiview images, while the view-specific appearance is a single image that is rendered from a specific viewpoint."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1cd74372-3a39-5c68-a20e-5444b628c1ec", "question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "reference_answer": "An output layer for each task", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "956764f0-8f76-5962-b074-1d1f52d8398a", "question": "What is the degree of dimension reduction of the efficient aggregation method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abd3e4c5-927d-52de-9b64-24f038923cae"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.03342/19-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.03342/3-Table1-1.png", "data/dataset/spiqa/images/1702.03342/7-Figure1-1.png", "data/dataset/spiqa/images/1702.03342/9-Table2-1.png", "data/dataset/spiqa/images/1702.03342/14-Table3-1.png", "data/dataset/spiqa/images/1702.03342/15-Table4-1.png", "data/dataset/spiqa/images/1702.03342/16-Table5-1.png", "data/dataset/spiqa/images/1702.03342/17-Table6-1.png", "data/dataset/spiqa/images/1702.03342/18-Table7-1.png", "data/dataset/spiqa/images/1702.03342/19-Figure2-1.png", "data/dataset/spiqa/images/1702.03342/19-Table8-1.png", "data/dataset/spiqa/images/1702.03342/20-Figure3-1.png", "data/dataset/spiqa/images/1702.03342/20-Table9-1.png", "data/dataset/spiqa/images/1702.03342/21-Table10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the degree of dimension reduction of the efficient aggregation method?", "reference_answer": "The number of dimensions can be reduced by up to 212 times.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0cd9d824-0a21-5961-84a3-f8edeb1c973e", "question": "Which method achieves the highest overall accuracy on the validation set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2f3b7633-fa54-55d7-8802-08f611b754d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure6-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure9-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure10-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the highest overall accuracy on the validation set?", "reference_answer": "UnCoRd-None-B."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3df44a67-74fe-53fa-87b0-63808799b8a5", "question": "Which of the following methods has the best performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4211b30e-5e8d-5449-8335-9f14cfeb4b9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table5-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the following methods has the best performance?", "reference_answer": "LambdaMART"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6dd75ca6-32d6-572c-ae13-ee46fd7bc1b7", "question": "Which other approaches do they compare their model with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["836657b7-d657-5f24-a0b2-9463d99e8e3a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.10503/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.10503/2-Table1-1.png", "data/dataset/spiqa/images/1904.10503/2-Figure1-1.png", "data/dataset/spiqa/images/1904.10503/4-Figure2-1.png", "data/dataset/spiqa/images/1904.10503/5-Figure3-1.png", "data/dataset/spiqa/images/1904.10503/5-Table2-1.png", "data/dataset/spiqa/images/1904.10503/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which other approaches do they compare their model with?", "reference_answer": "They compare to Akbik et al. (2018) and Link et al. (2012).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4b71e5eb-1d87-5d74-b5c5-d17ab57c9347", "question": "What are the six classes of the data used for training ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the six classes of the data used for training ?", "reference_answer": "The six classes are healthy, emphysema, ground glass, fibrosis, micronodules, and consolidation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8709aa49-f598-573b-9958-58e6848d20b2", "question": "What experiments are proposed to test that upper layers produce context-specific embeddings?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ec4c774e-94db-5538-b588-a7a5eb319e9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00512/5-Figure1-1.png", "data/dataset/spiqa/images/1909.00512/6-Figure2-1.png", "data/dataset/spiqa/images/1909.00512/7-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00512/5-Figure1-1.png", "data/dataset/spiqa/images/1909.00512/6-Figure2-1.png", "data/dataset/spiqa/images/1909.00512/7-Figure3-1.png", "data/dataset/spiqa/images/1909.00512/8-Figure4-1.png", "data/dataset/spiqa/images/1909.00512/8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What experiments are proposed to test that upper layers produce context-specific embeddings?", "reference_answer": "They plot the average cosine similarity between uniformly random words increases exponentially from layers 8 through 12.  \nThey plot the average self-similarity of uniformly randomly sampled words in each layer of BERT, ELMo, and GPT-2 and shown that the higher layer produces more context-specific embeddings.\nThey plot that word representations in a sentence become more context-specific in upper layers, they drift away from one another.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e2c55033-dca3-5aac-b0eb-5c7033ee31ae", "question": "Is the model compared against a linear regression baseline?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["afbb8b00-13c9-5004-8370-ccd58e96b392"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.10806/7-Table1-1.png", "data/dataset/spiqa/images/1912.10806/7-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.10806/3-Figure1-1.png", "data/dataset/spiqa/images/1912.10806/3-Figure2-1.png", "data/dataset/spiqa/images/1912.10806/4-Figure3-1.png", "data/dataset/spiqa/images/1912.10806/5-Figure4-1.png", "data/dataset/spiqa/images/1912.10806/7-Figure5-1.png", "data/dataset/spiqa/images/1912.10806/7-Figure6-1.png", "data/dataset/spiqa/images/1912.10806/7-Table1-1.png", "data/dataset/spiqa/images/1912.10806/8-Table2-1.png", "data/dataset/spiqa/images/1912.10806/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the model compared against a linear regression baseline?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6e076ec3-c245-50bc-83c5-a068c567cfa4", "question": "How big is the difference in performance between proposed model and baselines?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["72afc0ee-2f4c-5c98-a504-5334dcdf2627"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.08293/6-Table3-1.png", "data/dataset/spiqa/images/1910.08293/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.08293/1-Figure1-1.png", "data/dataset/spiqa/images/1910.08293/3-Figure4-1.png", "data/dataset/spiqa/images/1910.08293/3-Figure2-1.png", "data/dataset/spiqa/images/1910.08293/3-Figure3-1.png", "data/dataset/spiqa/images/1910.08293/4-Figure5-1.png", "data/dataset/spiqa/images/1910.08293/5-Table1-1.png", "data/dataset/spiqa/images/1910.08293/6-Figure6-1.png", "data/dataset/spiqa/images/1910.08293/6-Table2-1.png", "data/dataset/spiqa/images/1910.08293/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is the difference in performance between proposed model and baselines?", "reference_answer": "Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f2047769-2e5b-56dc-8849-fc36226b0ba7", "question": "Which approach performs best on the development set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0423e038-405f-5171-a89b-75e3079e5aa6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which approach performs best on the development set?", "reference_answer": "Intra-warrant attention with context."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "486dd52b-be4f-5ddd-a498-17f24e706ea0", "question": "What kind of celebrities do they obtain tweets from?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3f9f74ab-d230-56d1-906b-3a9a8bd96612"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.04002/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.04002/2-Figure1-1.png", "data/dataset/spiqa/images/1909.04002/3-Table1-1.png", "data/dataset/spiqa/images/1909.04002/6-Figure2-1.png", "data/dataset/spiqa/images/1909.04002/6-Table2-1.png", "data/dataset/spiqa/images/1909.04002/7-Table3-1.png", "data/dataset/spiqa/images/1909.04002/8-Table4-1.png", "data/dataset/spiqa/images/1909.04002/8-Figure3-1.png", "data/dataset/spiqa/images/1909.04002/8-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What kind of celebrities do they obtain tweets from?", "reference_answer": "Celebrities from varioius domains - Acting, Music, Politics, Business, TV, Author, Sports, Modeling. ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e546e728-739e-5bc2-b080-4336b6ade732", "question": "How does the trade-off between fidelity and diversity vary with the Gradient Scale?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does the trade-off between fidelity and diversity vary with the Gradient Scale?", "reference_answer": "When using a scale of 1, we observed that the classifier assigned reasonable probabilities (around 50%) to the desired classes for the final samples, but these samples did not match the intended classes upon visual inspection. Scaling up the classifier gradients remedied this problem, and the class probabilities from the classifier increased to nearly 100%. Using a larger gradient scale focuses more on the modes of the classifier, which is potentially desirable for producing higher fidelity (but less diverse) samples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "13a62ad6-699d-5e0d-9190-e35e59ea2ebf", "question": "Which algorithm has the fastest runtime?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["df02179f-8e81-5fcd-aade-8be0722cd2f1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.02349v2/1805.02349v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.02349v2/1805.02349v2-Figure1-1.png", "data/dataset/spiqa/images/1805.02349v2/1805.02349v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm has the fastest runtime?", "reference_answer": "The algorithm proposed in this paper has the fastest runtime."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "814ab347-daba-533d-89fa-5f39e11936d8", "question": "What is the definition of intra-class variability?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["83b3e5d8-deaa-5589-a367-d37f3a29ce54"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/23-Figure19-1.png"], "reference_image": ["data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/1-Figure1-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/12-Figure5-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/12-Figure6-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/13-Figure7-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/13-Figure8-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/14-Figure10-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/14-Figure9-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/15-Figure11-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/15-Figure12-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/16-Figure13-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/16-Figure14-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/17-Figure15-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/17-Table4-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/18-Table5-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/18-Table6-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/20-Figure16-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/20-Figure17-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/21-Figure18-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/23-Figure19-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/24-Figure20-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/24-Figure21-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/25-Figure22-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/25-Figure23-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/26-Figure24-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/26-Figure25-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/27-Figure26-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/27-Figure27-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/3-Table1-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/4-Figure2-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/5-Figure3-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/7-Figure4-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/7-Table2-1.png", "data/dataset/spiqa/images/22aab110058ebbd198edb1f1e7b4f69fb13c0613/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the definition of intra-class variability?", "reference_answer": "intra-class variability here means images with multiple objects at a variety of scales."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c627246c-9a19-5d69-902c-9c63f4f75c65", "question": "How many rules had to be defined?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["59c70e8f-54d9-5dd8-91fe-c8f8e8726bf3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.05438/6-Table5-1.png", "data/dataset/spiqa/images/1909.05438/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.05438/3-Figure1-1.png", "data/dataset/spiqa/images/1909.05438/4-Table1-1.png", "data/dataset/spiqa/images/1909.05438/4-Table2-1.png", "data/dataset/spiqa/images/1909.05438/5-Table3-1.png", "data/dataset/spiqa/images/1909.05438/5-Figure2-1.png", "data/dataset/spiqa/images/1909.05438/6-Table4-1.png", "data/dataset/spiqa/images/1909.05438/6-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many rules had to be defined?", "reference_answer": "WikiSQL - 2 rules (SELECT, WHERE)\nSimpleQuestions - 1 rule\nSequentialQA - 3 rules (SELECT, WHERE, COPY)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e704ff15-2cff-58ea-a5de-c0cc0da61f3c", "question": "How can the attention mechanism connecting the bottom layer of the decoder to the top layer of the encoder contribute to improving parallelism?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How can the attention mechanism connecting the bottom layer of the decoder to the top layer of the encoder contribute to improving parallelism?", "reference_answer": "First we have to establish that LSTM layers reduces parallelism as each layer would have to wait until both forward and backward directions of the previous layer to finish. Then notice in Figure 1, the model architecture consists of 8 LSTM encoder layers (1 bi-directional and 7 uni-directional layers), and 8 decoder layers. During training the bottom bi-directional encoder layers compute in parallelism first, then the uni-directional encoder layers. So to retain retain and much possible parallelism during the decoder layers, the bottom layers of the decoder output only for obtaining the recurrent attention context which is sent directly to all the remaining decoder layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "9372b82c-a4f1-5545-a7d6-7c20a43285d9", "question": "How is the original ILD images were reconstructed ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How is the original ILD images were reconstructed ?", "reference_answer": "A process consisting of deconvolution, back-propagation with convolution, and un-pooling from the activation maps of the pooling units was used to reconstruct the original ILD images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0d212ca1-2213-56b3-82f2-3e95c8341783", "question": "How does the performance of VAGER+Voting compare to other VAGER variants in the 1-shot and 20-shot settings?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["77db890f-c739-5abc-a1af-4cdaee857323"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of VAGER+Voting compare to other VAGER variants in the 1-shot and 20-shot settings?", "reference_answer": "VAGER+Voting consistently outperforms all other VAGER variants in both 1-shot and 20-shot settings, achieving the highest AUC and F1 scores."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6a5206ec-1584-5051-bdce-7dacf068889f", "question": "What kind of features are used by the HMM models, and how interpretable are those?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["87a9e03f-09ae-5bb4-bc24-68595340bd33"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1606.05320/4-Figure2-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1606.05320/2-Figure1-1.png", "data/dataset/spiqa/images/1606.05320/3-Table1-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure2-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What kind of features are used by the HMM models, and how interpretable are those?", "reference_answer": "A continuous emission HMM uses the hidden states of a 2-layer LSTM as features and a discrete emission HMM uses data as features. \nThe interpretability of the model is shown in Figure 2. ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bbbf0b4b-3799-54ff-9ca5-6594d3f33bb4", "question": "What is the difference between the top-down and bottom-up compositional learning schemes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["be0ab42f-3812-52ff-8345-282868119291"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure4-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure5-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the top-down and bottom-up compositional learning schemes?", "reference_answer": "The top-down compositional learning scheme starts with a holistic object model and decomposes it into smaller parts, while the bottom-up compositional learning scheme starts with basic parts and composes them into a holistic object model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3f2bb16e-1ab1-5485-afd8-924591c2d4b0", "question": "Which generative model generates more accurate and realistic samples on the MNIST dataset, AC-GATN or ITN?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which generative model generates more accurate and realistic samples on the MNIST dataset, AC-GATN or ITN?", "reference_answer": "ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2ce9200c-ebaf-5fe0-857e-f66368a6d4fb", "question": "Which genre shows the **largest absolute improvement** in F1 score on the failure set after applying GBI for **both** syntactic parsing and SRL?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which genre shows the **largest absolute improvement** in F1 score on the failure set after applying GBI for **both** syntactic parsing and SRL?", "reference_answer": "Pivot Corpus (PT) shows the largest absolute improvement in F1 score on the failure set after applying GBI for both syntactic parsing and SRL."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7a124d00-ed83-5588-8af9-4b859b24b8e0", "question": "Does the dataset contain non-English reviews?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["2e62e09e-8367-5cdd-9f3b-5dc19d2f8147"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.11879/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.11879/2-Table1-1.png", "data/dataset/spiqa/images/1909.11879/2-Figure1-1.png", "data/dataset/spiqa/images/1909.11879/3-Table2-1.png", "data/dataset/spiqa/images/1909.11879/3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the dataset contain non-English reviews?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e51bcf84-c768-501c-9ece-7f9ee3726019", "question": "Is the dataset multilingual?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["0036b375-c6e0-51bf-b3f7-ab61d7edf0a4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.05873/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.05873/2-Figure1-1.png", "data/dataset/spiqa/images/1708.05873/2-Figure2-1.png", "data/dataset/spiqa/images/1708.05873/3-Figure3-1.png", "data/dataset/spiqa/images/1708.05873/4-Figure4-1.png", "data/dataset/spiqa/images/1708.05873/4-Figure5-1.png", "data/dataset/spiqa/images/1708.05873/4-Figure6-1.png", "data/dataset/spiqa/images/1708.05873/5-Figure7-1.png", "data/dataset/spiqa/images/1708.05873/5-Figure9-1.png", "data/dataset/spiqa/images/1708.05873/5-Figure8-1.png", "data/dataset/spiqa/images/1708.05873/6-Figure10-1.png", "data/dataset/spiqa/images/1708.05873/6-Figure11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the dataset multilingual?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9785be03-297a-511c-848f-b4f100fd9109", "question": "Is it true that this paper's learning process can be viewed as maximizing the sensitivity of the loss functions of new tasks with respect to the parameters?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6297fbcc-4cda-5e1d-b3ab-9036a2192dcd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/12-Figure6-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/12-Table3-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/13-Figure7-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/2-Figure1-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/6-Figure2-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/6-Figure3-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/7-Table1-1.png", "data/dataset/spiqa/images/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is it true that this paper's learning process can be viewed as maximizing the sensitivity of the loss functions of new tasks with respect to the parameters?", "reference_answer": "It is true. As many sentences mention, it can be seen as increasing the sensitivity of the loss function."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f00be6f2-fda0-54dc-a1c4-dbaa3f37b447", "question": "Can you estimate the percentage of entity pairs in the NYT training set that have a corresponding relational fact in the Knowledge Base (KB)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["427f53cc-34f9-53f5-bfe0-7803daa82b6c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table1-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure1-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure4-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure5-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure6-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure2-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure7-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table2-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table3-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Can you estimate the percentage of entity pairs in the NYT training set that have a corresponding relational fact in the Knowledge Base (KB)?", "reference_answer": "Approximately 6.66%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9982d0f7-8f19-5df7-82f3-2c6209dd0fef", "question": "what are the state of the art methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9090b98c-48cd-5ffb-a540-a003b287849e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1606.04631/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1606.04631/2-Figure1-1.png", "data/dataset/spiqa/images/1606.04631/4-Figure2-1.png", "data/dataset/spiqa/images/1606.04631/4-Table2-1.png", "data/dataset/spiqa/images/1606.04631/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what are the state of the art methods?", "reference_answer": "S2VT, RGB (VGG), RGB (VGG)+Flow (AlexNet), LSTM-E (VGG), LSTM-E (C3D) and Yao et al.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7dca63dd-5655-53ab-b3d5-f23e307d8d1b", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["0ee34a5c-803f-5218-b3fd-445e16391355"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.08079/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.08079/5-Figure1-1.png", "data/dataset/spiqa/images/1901.08079/7-Table1-1.png", "data/dataset/spiqa/images/1901.08079/7-Table2-1.png", "data/dataset/spiqa/images/1901.08079/8-Table3-1.png", "data/dataset/spiqa/images/1901.08079/8-Table4-1.png", "data/dataset/spiqa/images/1901.08079/10-Figure2-1.png", "data/dataset/spiqa/images/1901.08079/11-Figure3-1.png", "data/dataset/spiqa/images/1901.08079/12-Figure4-1.png", "data/dataset/spiqa/images/1901.08079/15-Table5-1.png", "data/dataset/spiqa/images/1901.08079/15-Table6-1.png", "data/dataset/spiqa/images/1901.08079/16-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "61c66286-07c8-5de7-95f3-79cd11e55cbb", "question": "What are the other loss functions experimented by the authors'? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d51a9214-fff1-52cb-8bbc-d55f87c0cd9c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/5-Figure3-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/6-Table1-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/7-Figure4-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/8-Table2-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Figure5-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Figure6-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Figure7-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the other loss functions experimented by the authors'? ", "reference_answer": "The main loss function used by authors is The Focal Loss. Besides this, the other loss functions experimented on are: 1) Hinge Loss 2) Dynamically scaled cross entropy loss 3) \\alpha-balanced CE loss 4) \\alpha-balanced variant of the focal loss 5) Huber loss 6) The CE loss"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "504985b6-0e59-5dc4-8fdd-d3fbc7a8e3f3", "question": "Is there a disadvantage to using low-precision arithmetic for inference, such as decreased inference accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is there a disadvantage to using low-precision arithmetic for inference, such as decreased inference accuracy?", "reference_answer": "Quantization models can perform slightly have lower results on neural network models, however in this paper authors performed some constraints during training so that's quantizable with minimal impact on the output of the model, the quantized model even performed slightly better than none-quantized training and they suggest it could be due to regularization roles those constraints had during training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "42781d1f-404d-5a57-8ac6-a9c86df7ddb6", "question": "What biases are found in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7f1b6849-af3b-55d3-bf59-5da71f8f5bcd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.06083/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.06083/1-Figure1-1.png", "data/dataset/spiqa/images/1605.06083/2-Figure2-1.png", "data/dataset/spiqa/images/1605.06083/3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What biases are found in the dataset?", "reference_answer": "Ethnic bias", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a38512f0-3aa8-528c-9651-1de1c7068e0f", "question": "How well do the approximate bounds of $\\theta$ predict sparsity in the \"spherical\" dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How well do the approximate bounds of $\\theta$ predict sparsity in the \"spherical\" dataset?", "reference_answer": "The approximate bounds of $\\theta$ are very effective at predicting sparsity in the \"spherical\" dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8aa829d2-4b1e-5a25-b863-9c36403edc2f", "question": "Which method is the fastest for computing a graph with a small average node degree?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method is the fastest for computing a graph with a small average node degree?", "reference_answer": "The proposed method in this paper (k=5) is the fastest for computing a graph with a small average node degree."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d0d8e0c7-89a7-52a5-94b1-241a04b0b7c8", "question": "What are the two auxiliary tasks that are used in the ESMM architecture for CVR modeling?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f2e1d9a7-fce3-5c7c-af44-2a80ea5a78dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table1-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure3-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the two auxiliary tasks that are used in the ESMM architecture for CVR modeling?", "reference_answer": "The two auxiliary tasks are CTR and CTCVR."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6799775c-c3a6-5a26-ad9a-98dff7ab38d8", "question": "How does the performance of the SIM saliency map change as the number of fixations increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2e451896-1a65-54a5-9d6c-886582d00353"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure7-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure1-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure4-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure6-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure5-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the SIM saliency map change as the number of fixations increases?", "reference_answer": "The performance of the SIM saliency map increases as the number of fixations increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5e904e4f-4139-5ff1-ac2d-cc53d5579552", "question": "What is the ratio of the total number of articles collected from CNN and Daily News?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the ratio of the total number of articles collected from CNN and Daily News?", "reference_answer": "Assuming “Daily News” here refers to “Daily Mail”, one of the websites the authors sourced the data from, the ratio of CNN:(Daily Mail) articles is approximately 93:220 or 1:2.36."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b513344a-74b7-5b71-b7a2-4c819a01e6a0", "question": "Is the dataset focused on a region?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["c5834f1a-8517-54ba-ae9c-b877b7e2e178"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.04315/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.04315/2-Table2-1.png", "data/dataset/spiqa/images/2004.04315/2-Table1-1.png", "data/dataset/spiqa/images/2004.04315/2-Table3-1.png", "data/dataset/spiqa/images/2004.04315/3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the dataset focused on a region?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5bc6d415-18f9-5219-8343-3a5aee4d8c2f", "question": "Does the performance necessarily drop when more control is desired?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["5adee5fd-41ca-5ba0-bc0d-2fa267698a6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.04453/7-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.04453/3-Figure1-1.png", "data/dataset/spiqa/images/1909.04453/6-Table2-1.png", "data/dataset/spiqa/images/1909.04453/7-Table4-1.png", "data/dataset/spiqa/images/1909.04453/7-Table5-1.png", "data/dataset/spiqa/images/1909.04453/7-Table3-1.png", "data/dataset/spiqa/images/1909.04453/8-Table6-1.png", "data/dataset/spiqa/images/1909.04453/8-Figure2-1.png", "data/dataset/spiqa/images/1909.04453/9-Figure3-1.png", "data/dataset/spiqa/images/1909.04453/13-Figure4-1.png", "data/dataset/spiqa/images/1909.04453/14-Figure5-1.png", "data/dataset/spiqa/images/1909.04453/15-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the performance necessarily drop when more control is desired?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b9226f8d-f48e-5778-ad4b-f945ebbf552a", "question": "What is the purpose of the skip connections in the proposed denoising network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0adb94de-50f5-51ff-8e1a-b2e3e72dcfd2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure5-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure2-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure4-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the skip connections in the proposed denoising network?", "reference_answer": "The skip connections are used to combine the features from the encoding and decoding modules at each scale. This helps to preserve the spatial information that is lost during the downsampling and upsampling operations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a021d784-ddc3-5bf0-a72b-947d8053920e", "question": "How did the authors find potential causes of cross-lingual transfer?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How did the authors find potential causes of cross-lingual transfer?", "reference_answer": "Authors do not discuss how they pointed to these potential causes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "9f2ad857-2426-53ed-a21b-f6b7ab87d2f6", "question": "Which method performs best in the 10 classes 1-shot multi-class classification problem?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["77db890f-c739-5abc-a1af-4cdaee857323"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best in the 10 classes 1-shot multi-class classification problem?", "reference_answer": "VAGER + Voting"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6eb2c6e8-5c48-5fcf-98da-375fbbc2b105", "question": "How much is performance hurt when using too small amount of layers in encoder?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a3bb4e84-5dea-50ce-92cc-e7dcb6c87275"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.06151/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.06151/3-Figure1-1.png", "data/dataset/spiqa/images/1908.06151/6-Table1-1.png", "data/dataset/spiqa/images/1908.06151/7-Table2-1.png", "data/dataset/spiqa/images/1908.06151/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much is performance hurt when using too small amount of layers in encoder?", "reference_answer": "comparing to the results from reducing the number of layers in the decoder, the BLEU score was 69.93 which is less than 1% in case of test2016 and in case of test2017 it was less by 0.2 %. In terms of TER it had higher score by 0.7 in case of test2016 and 0.1 in case of test2017. ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ed9b7dd3-82a6-596b-a012-34ab5501b3ca", "question": "Which method performed better on the MNIST dataset, ResNet-32 (CE) or ResNet-56 (RCE)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performed better on the MNIST dataset, ResNet-32 (CE) or ResNet-56 (RCE)?", "reference_answer": "ResNet-56 (RCE) performed better on the MNIST dataset with a classification error rate of 0.32% compared to ResNet-32 (CE) which had a classification error rate of 0.38%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ce922586-0bc9-5e32-9270-6c13d50aeab2", "question": "Which of the VSR models in the figure achieves the best balance of spatial detail and temporal coherence?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the VSR models in the figure achieves the best balance of spatial detail and temporal coherence?", "reference_answer": "TecoGAN"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6f5c0ac7-8c43-5160-b001-5e030c07b681", "question": "What is MSD prediction?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8a308def-6fbf-5fd4-9efa-22550987414d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01541/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01541/2-Table1-1.png", "data/dataset/spiqa/images/1809.01541/2-Figure1-1.png", "data/dataset/spiqa/images/1809.01541/3-Table2-1.png", "data/dataset/spiqa/images/1809.01541/4-Table3-1.png", "data/dataset/spiqa/images/1809.01541/5-Figure2-1.png", "data/dataset/spiqa/images/1809.01541/5-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is MSD prediction?", "reference_answer": "The task of predicting MSD tags: V, PST, V.PCTP, PASS.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d56d0fa1-4a6f-51f6-adb1-c9213ce466ee", "question": "What are the two place recognition benchmarks used by the authors?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c804ee67-1926-5ef9-b327-509f4405fea3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/7-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/1-Figure1-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure2-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure3-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/5-Figure4-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/7-Figure5-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/8-Figure6-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the two place recognition benchmarks used by the authors?", "reference_answer": "Pittsburgh(Pitts250k) and Tokyo 24/7 benchmarks"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ba2dc628-110d-574e-a472-bcdb5ee5251b", "question": "What is training method used for decreasing the gap between monolingual model and multilingual model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is training method used for decreasing the gap between monolingual model and multilingual model?", "reference_answer": "It is fine tuning."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "eefcf888-6904-581f-9fc3-c1e3901077c7", "question": "How does the training size of the Action Search model affect its performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6437feca-e73b-5ddd-a3f2-d94ef3737017"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure2-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure1-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure3-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure4-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure5-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the training size of the Action Search model affect its performance?", "reference_answer": "As the training size increases, the mAP and S score of the Action Search model also improve."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c8a8e2c9-ad78-5059-a499-c52b6c06f3a4", "question": "What is the difference between a deep residual network and a network built by stacking inception-like blocks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between a deep residual network and a network built by stacking inception-like blocks?", "reference_answer": "Deep residual networks have skip connections that allow the gradient to flow directly from one layer to another, while networks built by stacking inception-like blocks do not."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "042b70ee-d2a8-552c-b7d5-ecaac32ffb31", "question": "How many hops are there between the Hamilton and the Internet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How many hops are there between the Hamilton and the Internet?", "reference_answer": "5 hops"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "09f66452-d80b-5d08-be7b-0170f90d426c", "question": "How does the proposed method compare to icGAN in terms of generating images with different hair colors?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed method compare to icGAN in terms of generating images with different hair colors?", "reference_answer": "The proposed method is able to generate images with different hair colors more accurately than icGAN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e45acd8f-b1e8-5402-84bb-3b32d922cdfa", "question": "Do the authors claim that bigger datasets would improve the performance and expressiveness of reading comprehension models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Do the authors claim that bigger datasets would improve the performance and expressiveness of reading comprehension models?", "reference_answer": "Based on the information in this paper alone, it is unclear if a bigger dataset would improve the performance of reading comprehension models. While authors explain that a key contribution they make is the creation of a real-world, massive labelled reading comprehension dataset, it is unclear if such a dataset is essential to improve the performance of reading comprehension models - the authors pitch their dataset-building approach also as a way of evaluating performance of these models, which is different from the dataset itself leading to better performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f58fdc2f-a8c2-596a-a769-c109ae9bb3a2", "question": "Which model performs the best at predicting the delexicalised constituency tree of an example, and how much better does it perform compared to the baseline model in terms of unlabelled F1 score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e81915ee-6436-5660-8f3e-a8d93e4e8f32"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Figure1-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table3-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table2-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best at predicting the delexicalised constituency tree of an example, and how much better does it perform compared to the baseline model in terms of unlabelled F1 score?", "reference_answer": "The Text-to-parse model performs the best at predicting the delexicalised constituency tree, achieving an unlabelled F1 score of 87.5. This is significantly higher than the baseline Unconditional model, which achieves an unlabelled F1 score of 38.5. The Text-to-parse model therefore performs approximately 49 points better than the baseline."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7da62ee9-1675-5573-b6dc-a6c0c1008756", "question": "What is the effect of increasing the projection dimension d on the approximation error for sparse PCA and NMF?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["31d46012-0f02-590b-bcb4-f7f19a18db4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure4-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of increasing the projection dimension d on the approximation error for sparse PCA and NMF?", "reference_answer": "Increasing the projection dimension d decreases the approximation error for both sparse PCA and NMF."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f718c095-094d-55e3-a9ce-7a7f38d03635", "question": "Which steganography method achieves the best performance in terms of distortion for both cover and secret images when embedding 2 bits per channel?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8b9b8747-d8ff-5b20-b2aa-e1354d3a4068"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.08465v3/1805.08465v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.08465v3/1805.08465v3-Table1-1.png", "data/dataset/spiqa/images/1805.08465v3/1805.08465v3-Figure2-1.png", "data/dataset/spiqa/images/1805.08465v3/1805.08465v3-Figure1-1.png", "data/dataset/spiqa/images/1805.08465v3/1805.08465v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which steganography method achieves the best performance in terms of distortion for both cover and secret images when embedding 2 bits per channel?", "reference_answer": "The proposed method achieves the best performance for both cover and secret images when embedding 2 bits per channel."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5f49c6a6-aad3-5e09-a48d-af0117fa4471", "question": "What does the parameter network do to the initial surface?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What does the parameter network do to the initial surface?", "reference_answer": "The parameter network weights the initial surface, causing it to deform."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8c51ae75-64ac-5921-8ee4-561b7226515b", "question": "Have the candidates given their consent to have their videos used for the research?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["288ad37d-5b36-5886-a710-90f263f13689"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.11062/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.11062/3-Table1-1.png", "data/dataset/spiqa/images/1907.11062/3-Figure1-1.png", "data/dataset/spiqa/images/1907.11062/5-Table2-1.png", "data/dataset/spiqa/images/1907.11062/6-Table3-1.png", "data/dataset/spiqa/images/1907.11062/6-Table4-1.png", "data/dataset/spiqa/images/1907.11062/7-Figure2-1.png", "data/dataset/spiqa/images/1907.11062/7-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Have the candidates given their consent to have their videos used for the research?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8a775df7-42d3-54c3-b833-9565a2cd9955", "question": "Which method achieved the lowest testing error on the miniImageNet dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the lowest testing error on the miniImageNet dataset?", "reference_answer": "ITTN (ResNet-32) (w/ DA) achieved the lowest testing error on the miniImageNet dataset with an error rate of 29.65%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "14d5d368-901a-51ba-80ca-b574168f0723", "question": "How does the performance of gFGR change as the shape parameter α increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of gFGR change as the shape parameter α increases?", "reference_answer": "The performance of gFGR generally improves as the shape parameter α increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "88aff7fd-1ff5-5e86-9a95-800840def79e", "question": "What web and user-generated NER datasets are used for the analysis?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8ff5ae63-7e5c-5533-b882-8108dbc2e683"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.02877/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.02877/4-Table1-1.png", "data/dataset/spiqa/images/1701.02877/5-Table2-1.png", "data/dataset/spiqa/images/1701.02877/6-Table3-1.png", "data/dataset/spiqa/images/1701.02877/6-Table4-1.png", "data/dataset/spiqa/images/1701.02877/7-Table5-1.png", "data/dataset/spiqa/images/1701.02877/7-Table6-1.png", "data/dataset/spiqa/images/1701.02877/8-Table7-1.png", "data/dataset/spiqa/images/1701.02877/10-Table8-1.png", "data/dataset/spiqa/images/1701.02877/11-Table9-1.png", "data/dataset/spiqa/images/1701.02877/12-Figure1-1.png", "data/dataset/spiqa/images/1701.02877/13-Table10-1.png", "data/dataset/spiqa/images/1701.02877/13-Table11-1.png", "data/dataset/spiqa/images/1701.02877/14-Table12-1.png", "data/dataset/spiqa/images/1701.02877/15-Table13-1.png", "data/dataset/spiqa/images/1701.02877/17-Figure2-1.png", "data/dataset/spiqa/images/1701.02877/18-Table14-1.png", "data/dataset/spiqa/images/1701.02877/19-Table15-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What web and user-generated NER datasets are used for the analysis?", "reference_answer": "MUC, CoNLL, ACE, OntoNotes, MSM, Ritter, UMBC", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "977195e8-4a37-54aa-8d06-a42319136b96", "question": "Why it is possible to say that multiple group convolutional layers works efficiently without weakening representation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why it is possible to say that multiple group convolutional layers works efficiently without weakening representation?", "reference_answer": "It is clearly stated in the paper that having group convolutions is a trade-off between representative capability and the computational cost of the model. The ShuffleNet allows stacking multiple group convolutions with an appropriate number of groups because of channel shuffle and it is empirically shown in the paper. However, it is also noted that having too many groups might sometimes damage the performance. Thus, multiple group convolutions work efficiently only when the number of groups is chosen carefully and channel shuffle is used."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "564aec21-cfb9-5223-ad59-a400a7ecbe5e", "question": "Did they use a crowdsourcing platform for annotations?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["128f8965-e852-5f42-89f8-93d7461d0110"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.07960/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.07960/3-Figure1-1.png", "data/dataset/spiqa/images/1710.07960/6-Table1-1.png", "data/dataset/spiqa/images/1710.07960/7-Table2-1.png", "data/dataset/spiqa/images/1710.07960/7-Figure2-1.png", "data/dataset/spiqa/images/1710.07960/8-Table4-1.png", "data/dataset/spiqa/images/1710.07960/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did they use a crowdsourcing platform for annotations?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "523da714-2c61-5f63-b58e-c70e55625c51", "question": "Does the phrase \"data with larger spatial support than the typical size of the anatomy\" refer to feature maps with a larger number of channels than the input map at the deepest layer, or does it refer to something else?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does the phrase \"data with larger spatial support than the typical size of the anatomy\" refer to feature maps with a larger number of channels than the input map at the deepest layer, or does it refer to something else?", "reference_answer": "Yes the phrase refer to feature maps with a larger number of channels than the input map at the deepest layer. As we move deeper the network will capture more features.."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "bfcffb1e-956c-5880-95e5-be3052f84b14", "question": "Are the unobserved samples from the same distribution as the training data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["b65e121c-c271-5c07-ac83-6286d9b071d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.01001/6-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.01001/4-Table1-1.png", "data/dataset/spiqa/images/1811.01001/5-Figure1-1.png", "data/dataset/spiqa/images/1811.01001/6-Figure2-1.png", "data/dataset/spiqa/images/1811.01001/7-Figure3-1.png", "data/dataset/spiqa/images/1811.01001/8-Figure4-1.png", "data/dataset/spiqa/images/1811.01001/9-Figure5-1.png", "data/dataset/spiqa/images/1811.01001/10-Figure6-1.png", "data/dataset/spiqa/images/1811.01001/10-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the unobserved samples from the same distribution as the training data?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "45d5b22e-d3ae-5296-b596-7eee33c2fd5f", "question": "Which dataset has the highest average record length?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the highest average record length?", "reference_answer": "CaOpenData"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b2ae8e53-a218-505e-9915-30d15d448e38", "question": "Are the intent labels imbalanced in the dataset?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["a9e93e5d-9332-5bd6-8ef6-431c83a7801f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.10500/5-Table1-1.png", "data/dataset/spiqa/images/1904.10500/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.10500/4-Figure1-1.png", "data/dataset/spiqa/images/1904.10500/5-Table1-1.png", "data/dataset/spiqa/images/1904.10500/5-Table2-1.png", "data/dataset/spiqa/images/1904.10500/7-Figure2-1.png", "data/dataset/spiqa/images/1904.10500/8-Figure3-1.png", "data/dataset/spiqa/images/1904.10500/9-Figure4-1.png", "data/dataset/spiqa/images/1904.10500/10-Figure5-1.png", "data/dataset/spiqa/images/1904.10500/11-Figure6-1.png", "data/dataset/spiqa/images/1904.10500/12-Table3-1.png", "data/dataset/spiqa/images/1904.10500/13-Table4-1.png", "data/dataset/spiqa/images/1904.10500/13-Table5-1.png", "data/dataset/spiqa/images/1904.10500/14-Table6-1.png", "data/dataset/spiqa/images/1904.10500/14-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the intent labels imbalanced in the dataset?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c106037f-cd5b-50f4-9375-3bd24606a82c", "question": "Does this approach perform better in the multi-domain or single-domain setting?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b1a7d4b6-cf77-555c-a6bb-493f49a8cee0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00754/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00754/1-Table1-1.png", "data/dataset/spiqa/images/1909.00754/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00754/2-Figure2-1.png", "data/dataset/spiqa/images/1909.00754/3-Figure3-1.png", "data/dataset/spiqa/images/1909.00754/5-Figure4-1.png", "data/dataset/spiqa/images/1909.00754/6-Table2-1.png", "data/dataset/spiqa/images/1909.00754/7-Table3-1.png", "data/dataset/spiqa/images/1909.00754/7-Table4-1.png", "data/dataset/spiqa/images/1909.00754/7-Table5-1.png", "data/dataset/spiqa/images/1909.00754/9-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does this approach perform better in the multi-domain or single-domain setting?", "reference_answer": "single-domain setting", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a816d6bd-9214-591c-ba05-34bdb827cc69", "question": "Why cutout data augmentation improve NASNet-A model error rate?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["acb67ddd-a0d1-56d4-871c-f5f79ed59efb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/12-Figure8-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure9-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/2-Figure1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Figure5-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why cutout data augmentation improve NASNet-A model error rate?", "reference_answer": "From the above evidential paragraph, we can see that the cutout data augmentation achieves a state-of-the-art error rate of 2.40% which is better than the previous record. But, why it improves the performance cannot be answered in this paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7e67613c-8427-52c8-9a12-8815f3ca3c9a", "question": "For a given benchmarking algorithm, did the authors try different hyper-parameters?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8a4baa1a-b24d-5e20-b9a4-74bc77db60ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32/2-Figure1-1.png", "data/dataset/spiqa/images/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32/2-Table1-1.png", "data/dataset/spiqa/images/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32/3-Table2-1.png", "data/dataset/spiqa/images/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32/3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "For a given benchmarking algorithm, did the authors try different hyper-parameters?", "reference_answer": "Yes the author used hyper-parameter tuning."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7248ec86-9726-5b2b-b870-98a56dbe5f01", "question": "What is the McGurk effect?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["63173c63-7b32-5e64-9566-71db7170f6be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.01040/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.01040/2-Figure1-1.png", "data/dataset/spiqa/images/1906.01040/3-Table1-1.png", "data/dataset/spiqa/images/1906.01040/4-Table2-1.png", "data/dataset/spiqa/images/1906.01040/4-Table3-1.png", "data/dataset/spiqa/images/1906.01040/5-Figure2-1.png", "data/dataset/spiqa/images/1906.01040/6-Table4-1.png", "data/dataset/spiqa/images/1906.01040/6-Table5-1.png", "data/dataset/spiqa/images/1906.01040/6-Table6-1.png", "data/dataset/spiqa/images/1906.01040/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the McGurk effect?", "reference_answer": "When the perception of what we hear is influenced by what we see.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d2ed993a-3725-548b-bde3-57711f30af27", "question": "What are the inputs to the image generation network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["570e01d8-2c85-5e04-b7e5-aef3f43f49b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure1-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure6-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure8-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure7-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure13-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure2-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure3-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure9-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure4-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure12-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure11-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure10-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the inputs to the image generation network?", "reference_answer": "The inputs to the image generation network are the observed images (x) and a random noise vector (z)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f37d509b-cb87-582f-9627-3384b261aea6", "question": "Which technique was most effective at reducing memory consumption in both send and receive buffers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which technique was most effective at reducing memory consumption in both send and receive buffers?", "reference_answer": "The \"Resource Constraints\" challenge was addressed with two techniques: \"Zero-Copy Send\" and \"In-Place Reass.\" The first led to a 50% reduction in send buffer memory usage, while the second achieved a 38% reduction in receive buffer memory. Therefore, Zero-Copy Send was slightly more effective in reducing overall memory consumption."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1086d158-8ed0-54ae-ad8c-70751c5abd27", "question": "Which dataset has the shortest average sentence length?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0ef7a576-90fe-5b70-81db-8770ba622135"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table2-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Figure1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table4-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table3-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table7-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table8-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table6-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the shortest average sentence length?", "reference_answer": "Headlines."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2e5c35e7-fbd4-5bc5-9b48-c7f0c1f1df56", "question": "What were their results on the classification and regression tasks", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b087c1b5-e5d4-5448-88af-f3544e9681f5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.03187/6-Figure1-1.png", "data/dataset/spiqa/images/1907.03187/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.03187/5-Table1-1.png", "data/dataset/spiqa/images/1907.03187/6-Table2-1.png", "data/dataset/spiqa/images/1907.03187/6-Figure1-1.png", "data/dataset/spiqa/images/1907.03187/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What were their results on the classification and regression tasks", "reference_answer": "F1 score result of 0.8099", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6d65f670-97cb-543e-a1cf-99c962d54291", "question": "what linguistics features are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e03708f0-d6c8-5e2a-850d-02e88f174570"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01207/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01207/7-Figure1-1.png", "data/dataset/spiqa/images/2002.01207/8-Table1-1.png", "data/dataset/spiqa/images/2002.01207/9-Figure2-1.png", "data/dataset/spiqa/images/2002.01207/10-Table2-1.png", "data/dataset/spiqa/images/2002.01207/11-Table3-1.png", "data/dataset/spiqa/images/2002.01207/14-Figure3-1.png", "data/dataset/spiqa/images/2002.01207/15-Figure4-1.png", "data/dataset/spiqa/images/2002.01207/19-Table4-1.png", "data/dataset/spiqa/images/2002.01207/20-Table5-1.png", "data/dataset/spiqa/images/2002.01207/21-Table6-1.png", "data/dataset/spiqa/images/2002.01207/22-Table7-1.png", "data/dataset/spiqa/images/2002.01207/23-Table8-1.png", "data/dataset/spiqa/images/2002.01207/24-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what linguistics features are used?", "reference_answer": "POS, gender/number and stem POS", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "fe1c5b9f-69b5-50f1-91a4-747efb5d9616", "question": "Which type of adversarial example generation method results in images that are visually more similar to the original images?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which type of adversarial example generation method results in images that are visually more similar to the original images?", "reference_answer": "The CE method results in images that are visually more similar to the original images than the RCE method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2b637c89-7715-5818-92ca-e88e8ff501f1", "question": "What are the baselines that Masque is compared against?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["03783a9f-aefc-568a-94a9-d775185b2072"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.02262/8-Table5-1.png", "data/dataset/spiqa/images/1901.02262/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.02262/1-Figure1-1.png", "data/dataset/spiqa/images/1901.02262/2-Figure2-1.png", "data/dataset/spiqa/images/1901.02262/4-Figure3-1.png", "data/dataset/spiqa/images/1901.02262/5-Table1-1.png", "data/dataset/spiqa/images/1901.02262/6-Table2-1.png", "data/dataset/spiqa/images/1901.02262/6-Table3-1.png", "data/dataset/spiqa/images/1901.02262/6-Table4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure5-1.png", "data/dataset/spiqa/images/1901.02262/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the baselines that Masque is compared against?", "reference_answer": "BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Multi-PGNet, Selector+CCG, VNET, DECAPROP, MHPGM+NOIC, ConZNet, RMR+A2D", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "85f75440-6031-5fb2-9b4e-d405fd65b9bb", "question": "What is the correlation between the number of KGs and the performance when using zero-shot fusion?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the correlation between the number of KGs and the performance when using zero-shot fusion?", "reference_answer": "Zero-shot fusion obtains relative performance improvement across most of benchmark when more KGs are utilized for training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7d5085a1-54fd-5322-8c85-075b47ab6728", "question": "What does an \"adversarial perturbation\" mean?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4bc68d1d-c421-567f-a14a-076cb7acca37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure3-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure6-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does an \"adversarial perturbation\" mean?", "reference_answer": "Adversarial perturbation is a small and unnoticeable change to the data that fool the given model (i.e give a different class after applying the perturbation). It allows an understanding limits of existing architectures and calculation of the robustness of the models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f6fdebe8-93a2-5681-bf8e-9ae882ee4964", "question": "Which relevance label category of documents received the most significant rank promotion according to the NegPair reduction metric?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4211b30e-5e8d-5449-8335-9f14cfeb4b9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table5-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which relevance label category of documents received the most significant rank promotion according to the NegPair reduction metric?", "reference_answer": "The perfect results received the largest promotions in rank."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f9058ebd-b7e7-5cad-967c-656514bbaf91", "question": "How does the performance of the ESIM model differ when trained on MNLI alone versus trained on both MNLI and SNLI combined?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ab8d017f-8645-5337-aa84-f52783391b99"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table4-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Figure1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table5-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table2-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the ESIM model differ when trained on MNLI alone versus trained on both MNLI and SNLI combined?", "reference_answer": "When trained on MNLI alone, the ESIM model achieves an accuracy of 60.7% on SNLI, 72.3% on matched genres in MNLI, and 72.1% on mismatched genres in MNLI. However, when trained on both MNLI and SNLI combined, the ESIM model's performance improves across all tasks, reaching 79.7% accuracy on SNLI, 72.4% on matched MNLI genres, and 71.9% on mismatched MNLI genres."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "adce709d-ef4c-528e-9211-ffb39657800b", "question": "Did the annotators agreed and how much?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e279379b-d4ab-513c-b362-0b2c5b8bfb9e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.05260/6-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.05260/1-Figure1-1.png", "data/dataset/spiqa/images/1703.05260/2-Figure2-1.png", "data/dataset/spiqa/images/1703.05260/2-Table1-1.png", "data/dataset/spiqa/images/1703.05260/3-Table2-1.png", "data/dataset/spiqa/images/1703.05260/4-Figure3-1.png", "data/dataset/spiqa/images/1703.05260/6-Figure4-1.png", "data/dataset/spiqa/images/1703.05260/6-Figure5-1.png", "data/dataset/spiqa/images/1703.05260/6-Figure6-1.png", "data/dataset/spiqa/images/1703.05260/7-Figure8-1.png", "data/dataset/spiqa/images/1703.05260/7-Figure9-1.png", "data/dataset/spiqa/images/1703.05260/7-Figure7-1.png", "data/dataset/spiqa/images/1703.05260/8-Figure10-1.png", "data/dataset/spiqa/images/1703.05260/8-Figure11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did the annotators agreed and how much?", "reference_answer": "For event types and participant types, there was a moderate to substantial level of agreement using the Fleiss' Kappa. For coreference chain annotation, there was average agreement of 90.5%.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "93da0243-e517-5ce9-9bcf-83ace6cd4296", "question": "Does the paper report the performance of a baseline model on South African languages LID?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3dd529dd-1a7c-5ba1-a77d-0fcdb3724aa2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.07555/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.07555/2-Table1-1.png", "data/dataset/spiqa/images/1911.07555/4-Table2-1.png", "data/dataset/spiqa/images/1911.07555/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the paper report the performance of a baseline model on South African languages LID?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8d8684f6-7220-5f14-8a98-87595d9a5b41", "question": "Do sluice networks outperform non-transfer learning approaches?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["da8a6d65-437c-5f2a-b68a-769176719724"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08142/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08142/3-Figure1-1.png", "data/dataset/spiqa/images/1705.08142/6-Table1-1.png", "data/dataset/spiqa/images/1705.08142/6-Table2-1.png", "data/dataset/spiqa/images/1705.08142/7-Table3-1.png", "data/dataset/spiqa/images/1705.08142/8-Table4-1.png", "data/dataset/spiqa/images/1705.08142/8-Table5-1.png", "data/dataset/spiqa/images/1705.08142/9-Table6-1.png", "data/dataset/spiqa/images/1705.08142/10-Figure2-1.png", "data/dataset/spiqa/images/1705.08142/10-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do sluice networks outperform non-transfer learning approaches?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "74e52620-03f3-53c2-b7ec-a026635feae4", "question": "What are the different variations of the attention-based approach which are examined?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["326ade97-a3af-5e28-a28c-1690c49dfbda"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13104/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13104/3-Table1-1.png", "data/dataset/spiqa/images/1909.13104/4-Figure1-1.png", "data/dataset/spiqa/images/1909.13104/5-Figure2-1.png", "data/dataset/spiqa/images/1909.13104/7-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the different variations of the attention-based approach which are examined?", "reference_answer": "classic RNN model, avgRNN model, attentionRNN model and multiattention RNN model with and without a projected layer", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "80781aba-5d43-5bff-97f8-192a0cbcc795", "question": "How larger are the training sets of these versions of ELMo compared to the previous ones?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["214ef428-3d1c-5293-9096-7801c0f0cae4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.10049/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.10049/3-Table1-1.png", "data/dataset/spiqa/images/1911.10049/4-Figure1-1.png", "data/dataset/spiqa/images/1911.10049/4-Table2-1.png", "data/dataset/spiqa/images/1911.10049/5-Table3-1.png", "data/dataset/spiqa/images/1911.10049/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How larger are the training sets of these versions of ELMo compared to the previous ones?", "reference_answer": "By 14 times.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6653d2a4-8feb-533f-ab75-928c0ce964a1", "question": "What is the difference between zero-shot fusion and original AdapterFusion?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the difference between zero-shot fusion and original AdapterFusion?", "reference_answer": "In contrast to AdapterFusion where the focus is learning to transfer knowledge to a specific target task, our zero-shot fusion aims to generalize this transfer to any arbitrary target task."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "bf41a123-8669-55a5-9959-524454ffbcee", "question": "What previous methods is the proposed method compared against?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f51cdbb9-07de-5fa8-adc2-c2c5e94449d8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.06044/6-Table5-1.png", "data/dataset/spiqa/images/2003.06044/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.06044/1-Table1-1.png", "data/dataset/spiqa/images/2003.06044/3-Figure1-1.png", "data/dataset/spiqa/images/2003.06044/5-Table2-1.png", "data/dataset/spiqa/images/2003.06044/5-Table3-1.png", "data/dataset/spiqa/images/2003.06044/6-Table4-1.png", "data/dataset/spiqa/images/2003.06044/6-Table5-1.png", "data/dataset/spiqa/images/2003.06044/7-Table6-1.png", "data/dataset/spiqa/images/2003.06044/8-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What previous methods is the proposed method compared against?", "reference_answer": "BLSTM+Attention+BLSTM\nHierarchical BLSTM-CRF\nCRF-ASN\nHierarchical CNN (window 4)\nmLSTM-RNN\nDRLM-Conditional\nLSTM-Softmax\nRCNN\nCNN\nCRF\nLSTM\nBERT", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ef416dde-78b7-5f27-9e75-2691e3f58d6c", "question": "What metrics should be used for comparison of Mask R-CNN to the state of the art on the COCO dataset ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d1c1e345-b84d-5866-8475-acfaa66dadf9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/1-Figure1-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/2-Figure2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/4-Figure3-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Figure4-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Table1-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Figure5-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Table2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/7-Table3-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Figure6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table4-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table5-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/9-Figure7-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/9-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What metrics should be used for comparison of Mask R-CNN to the state of the art on the COCO dataset ?", "reference_answer": "Metrics used for comparison are AP , multi-scale train/test, horizontal flip test, and online hard example mining (OHEM)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "02cc2c69-1227-5d09-b0c3-46b3147723dd", "question": "Which method performs the best when there are a lot of outliers in the data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best when there are a lot of outliers in the data?", "reference_answer": "ChoiceNet."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "bb03466f-941c-513b-acd2-c298dc281f5b", "question": "What performance did they obtain on the SemEval dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4e8cbd3b-5a2f-5823-a2af-ad17af1e1e3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.12569/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.12569/3-Figure1-1.png", "data/dataset/spiqa/images/1911.12569/5-TableI-1.png", "data/dataset/spiqa/images/1911.12569/5-TableII-1.png", "data/dataset/spiqa/images/1911.12569/5-TableIII-1.png", "data/dataset/spiqa/images/1911.12569/5-Figure2-1.png", "data/dataset/spiqa/images/1911.12569/6-TableIV-1.png", "data/dataset/spiqa/images/1911.12569/7-TableXI-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What performance did they obtain on the SemEval dataset?", "reference_answer": "F1 score of 82.10%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1fc2ceaf-b5b9-5808-8987-0358da29e8b3", "question": "What is the role of the Knowledge Aided Similarity Matrix in the KAR model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d32bd564-0b48-5101-817c-090485d59a03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table1-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the Knowledge Aided Similarity Matrix in the KAR model?", "reference_answer": "The Knowledge Aided Similarity Matrix is used to compute the similarity between the question and passage context embeddings. This similarity score is then used to weight the passage context embeddings, giving more weight to those parts of the passage that are most relevant to the question."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7622f869-014c-5f60-85f3-2222bfe031d1", "question": "How were the human judgements assembled?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["10dea418-110f-55c2-a58d-726d7c44b9b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.02482/11-Table2-1.png", "data/dataset/spiqa/images/1612.02482/12-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.02482/6-Figure1-1.png", "data/dataset/spiqa/images/1612.02482/8-Figure2-1.png", "data/dataset/spiqa/images/1612.02482/8-Figure3-1.png", "data/dataset/spiqa/images/1612.02482/9-Figure4-1.png", "data/dataset/spiqa/images/1612.02482/10-Table1-1.png", "data/dataset/spiqa/images/1612.02482/11-Figure5-1.png", "data/dataset/spiqa/images/1612.02482/11-Table2-1.png", "data/dataset/spiqa/images/1612.02482/12-Table3-1.png", "data/dataset/spiqa/images/1612.02482/12-Figure6-1.png", "data/dataset/spiqa/images/1612.02482/13-Figure7-1.png", "data/dataset/spiqa/images/1612.02482/14-Figure8-1.png", "data/dataset/spiqa/images/1612.02482/15-Figure9-1.png", "data/dataset/spiqa/images/1612.02482/16-Figure10-1.png", "data/dataset/spiqa/images/1612.02482/17-Figure11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How were the human judgements assembled?", "reference_answer": "50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "348a24b9-d336-59cb-98b9-b1663c47e1fd", "question": "Which method performed the best according to the LMD metric?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performed the best according to the LMD metric?", "reference_answer": "AMIE (Ours)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e9a90c8e-c5f8-550b-9e81-0f89c2f68424", "question": "How does the number of state-action pairs affect the reward landscape for the surrogate and true reward functions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["291817c4-b436-55c1-a356-e28360b7edb9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure17-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure5-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure18-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure19-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure8-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure14-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure6-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure15-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Table1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure2-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure11-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure16-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure7-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure3-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure12-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure10-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure20-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure17-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure13-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure4-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the number of state-action pairs affect the reward landscape for the surrogate and true reward functions?", "reference_answer": "As the number of state-action pairs increases, the reward landscape for both the surrogate and true reward functions becomes smoother and more accurate."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e09820fb-97f0-5b28-a841-0526cfc16576", "question": "What is the relationship between the ground truth fixation density and the saliency maps?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2e451896-1a65-54a5-9d6c-886582d00353"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure7-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure1-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure4-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure6-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure5-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the ground truth fixation density and the saliency maps?", "reference_answer": "The ground truth fixation density predicts different saliency maps depending on the intended metric."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5cf4ec02-c618-5f49-ba66-fada8856d648", "question": "Are the softmax values of different sets of co-hyponyms compared?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["08315e5d-cabb-5236-ba3c-8e678014f6c6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/7-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/1-Figure1-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/3-Figure2-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/3-Table1-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/4-Figure3-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/4-Figure4-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/5-Table2-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/5-Table3-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/6-Table4-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/6-Table5-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/6-Table6-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/7-Figure5-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/8-Figure6-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Are the softmax values of different sets of co-hyponyms compared?", "reference_answer": "Classification approaches use a softmax layer across all categories to predict the final probability of all classes. This technique would fail for models which combine datasets having similar classes. To overcome the proposed model also use a softmax over all sysnsets that are co-hyponyms.  Hence the final probability is computed by conditional probabilities at every node for the probability of each hyponym of that synset given that synset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "607d3a52-31c1-5186-aa02-c7a939339822", "question": "Which corpus has more sentences, and by how much?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ceff18ab-0cba-5e6b-b40d-ed9534e6f9c1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table3-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table4-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table5-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table1-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which corpus has more sentences, and by how much?", "reference_answer": "The UMBC News corpus has more sentences, by approximately 60.5 million."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3df55586-0f48-5ab3-8a0f-0e88032bdba2", "question": "How many layers does the UTCNN model have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ab22ee71-c77a-5bb5-aae0-5d6a340bab3c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03599/4-Figure2-1.png", "data/dataset/spiqa/images/1611.03599/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03599/3-Figure1-1.png", "data/dataset/spiqa/images/1611.03599/4-Figure2-1.png", "data/dataset/spiqa/images/1611.03599/5-Table1-1.png", "data/dataset/spiqa/images/1611.03599/5-Table2-1.png", "data/dataset/spiqa/images/1611.03599/7-Table3-1.png", "data/dataset/spiqa/images/1611.03599/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many layers does the UTCNN model have?", "reference_answer": "eight layers", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "69c9ce26-7635-511f-9fdd-f20ddd5fe12f", "question": "How does the observed error compare to the underlying true error as CPU time increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ac630ef5-d68e-5774-9cf6-4edd657f3310"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Table1-1.png", "data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure1-1.png", "data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the observed error compare to the underlying true error as CPU time increases?", "reference_answer": "The observed error is initially higher than the underlying true error, but it quickly decreases and converges to the true error as CPU time increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6d72217a-644a-527c-9344-ff4ff3bd902f", "question": "Why is conventional distant supervision problematic?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["427f53cc-34f9-53f5-bfe0-7803daa82b6c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table1-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure1-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure4-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure5-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure6-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure2-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure7-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table2-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table3-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why is conventional distant supervision problematic?", "reference_answer": "Conventional distant supervision can lead to wrong labeling of textual relations with KB relations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5f465b6d-50c2-5e6d-b01e-9c835573c95d", "question": "what was their character error rate?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52401b8c-9c2c-5db5-8107-cbfc6855f629"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png", "data/dataset/spiqa/images/1703.07090/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07090/4-Table1-1.png", "data/dataset/spiqa/images/1703.07090/5-Figure1-1.png", "data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png", "data/dataset/spiqa/images/1703.07090/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what was their character error rate?", "reference_answer": "2.49% for  layer-wise training, 2.63% for distillation, 6.26% for transfer learning.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "95ab7974-0afe-5a80-aab4-6290a69f5752", "question": "What kind of celebrities do they obtain tweets from?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3f9f74ab-d230-56d1-906b-3a9a8bd96612"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.04002/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.04002/2-Figure1-1.png", "data/dataset/spiqa/images/1909.04002/3-Table1-1.png", "data/dataset/spiqa/images/1909.04002/6-Figure2-1.png", "data/dataset/spiqa/images/1909.04002/6-Table2-1.png", "data/dataset/spiqa/images/1909.04002/7-Table3-1.png", "data/dataset/spiqa/images/1909.04002/8-Table4-1.png", "data/dataset/spiqa/images/1909.04002/8-Figure3-1.png", "data/dataset/spiqa/images/1909.04002/8-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What kind of celebrities do they obtain tweets from?", "reference_answer": "Amitabh Bachchan, Ariana Grande, Barack Obama, Bill Gates, Donald Trump,\nEllen DeGeneres, J K Rowling, Jimmy Fallon, Justin Bieber, Kevin Durant, Kim Kardashian, Lady Gaga, LeBron James,Narendra Modi, Oprah Winfrey", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4b69a521-b72d-5cb5-870e-6f14031593a9", "question": " How does the performance of ChoiceNet compare to other methods under different noise settings? Briefly explain the strengths and weaknesses of ChoiceNet.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " How does the performance of ChoiceNet compare to other methods under different noise settings? Briefly explain the strengths and weaknesses of ChoiceNet.", "reference_answer": "ChoiceNet generally performs well compared to other methods, achieving the highest accuracy on both symmetric noise settings (sym-50% and sym-20%). However, it falls to second place under the Pair-45% asymmetric noise setting, indicating a weakness in handling this specific type of noise."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "50554f85-93fa-5dcb-a75f-03f1357848b8", "question": "Which model has the lowest memory consumption and time cost on synthetic data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e12c7d24-8cfc-57b1-b048-9a36c5251d57"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table3-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table4-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table5-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table6-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model has the lowest memory consumption and time cost on synthetic data?", "reference_answer": "MTSA"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e354d673-7250-54cb-89eb-928f5aa73305", "question": "How do the backoff strategies work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e348cca5-a3ac-5ce5-9dd5-cec3f6cfd7fa"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.11268/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.11268/1-Table1-1.png", "data/dataset/spiqa/images/1905.11268/4-Figure1-1.png", "data/dataset/spiqa/images/1905.11268/5-Table2-1.png", "data/dataset/spiqa/images/1905.11268/7-Table3-1.png", "data/dataset/spiqa/images/1905.11268/7-Table4-1.png", "data/dataset/spiqa/images/1905.11268/8-Figure2-1.png", "data/dataset/spiqa/images/1905.11268/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do the backoff strategies work?", "reference_answer": "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bc337d85-af56-56ef-9f87-af485e4aa8bd", "question": "What is the relationship between projection sparsity and normalized reconstruction error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["31d46012-0f02-590b-bcb4-f7f19a18db4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure4-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between projection sparsity and normalized reconstruction error?", "reference_answer": "The normalized reconstruction error decreases as the projection sparsity increases, up to a certain point. After that, the error starts to increase again."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5a6a8d3f-51d8-52c0-b0bf-7b8622496587", "question": "Which fairness criteria results in the highest loan approval rate for the Black group when the loss/profit ratio is -4?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a7193e4-6411-5e3e-9b02-09ce82c0f1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which fairness criteria results in the highest loan approval rate for the Black group when the loss/profit ratio is -4?", "reference_answer": "The maximum profit criteria ($\\maxprof$) results in the highest loan approval rate for the Black group when the loss/profit ratio is -4."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "bb794802-376f-5445-9001-dfb0190544f5", "question": "What is the improvement in performance for Estonian in the NER task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["214ef428-3d1c-5293-9096-7801c0f0cae4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.10049/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.10049/3-Table1-1.png", "data/dataset/spiqa/images/1911.10049/4-Figure1-1.png", "data/dataset/spiqa/images/1911.10049/4-Table2-1.png", "data/dataset/spiqa/images/1911.10049/5-Table3-1.png", "data/dataset/spiqa/images/1911.10049/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the improvement in performance for Estonian in the NER task?", "reference_answer": "5 percent points.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e6b514c4-e808-511e-bc97-c42e50577047", "question": "What are the different types of annotations that are included in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the different types of annotations that are included in the dataset?", "reference_answer": "The dataset includes a rich set of annotations: scene tagging, object bounding box, lane marking, drivable area, full-frame semantic and instance segmentation, multiple object tracking, and multiple object tracking with segmentation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d627a077-b5f8-5d8d-8cbf-e8d45f9f26ab", "question": "Which neural architecture do they use as a base for their attention conflict mechanisms?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["cf3a49ed-56fa-51a6-b35d-b389c2b043f7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.08593/3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.08593/2-Figure1-1.png", "data/dataset/spiqa/images/1906.08593/2-Figure2-1.png", "data/dataset/spiqa/images/1906.08593/3-Figure3-1.png", "data/dataset/spiqa/images/1906.08593/4-Figure5-1.png", "data/dataset/spiqa/images/1906.08593/4-Figure4-1.png", "data/dataset/spiqa/images/1906.08593/5-Table1-1.png", "data/dataset/spiqa/images/1906.08593/5-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which neural architecture do they use as a base for their attention conflict mechanisms?", "reference_answer": "GRU-based encoder, interaction block, and classifier consisting of stacked fully-connected layers.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f16e88c2-87a6-5422-a5b9-06efcf6611ba", "question": "Why the normalization wasn't done taken all anchors into account?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d51a9214-fff1-52cb-8bbc-d55f87c0cd9c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/5-Figure3-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/6-Table1-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/7-Figure4-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/8-Table2-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Figure5-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Figure6-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Figure7-1.png", "data/dataset/spiqa/images/1a857da1a8ce47b2aa185b91b5cb215ddef24de7/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why the normalization wasn't done taken all anchors into account?", "reference_answer": "The normalisation is not done by taking all anchors into account because vast majority of anchors are easy negatives and receive negligible loss values under the focal loss."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "22c6cf57-556f-51f4-8c90-0caacff89e02", "question": "What are the hyperparameters of the bi-GRU?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f8c69bd7-ee40-55f3-9f5c-4e49f6cde607"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.09369/3-Figure1-1.png", "data/dataset/spiqa/images/1907.09369/4-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.09369/2-Table1-1.png", "data/dataset/spiqa/images/1907.09369/2-Table2-1.png", "data/dataset/spiqa/images/1907.09369/3-Figure1-1.png", "data/dataset/spiqa/images/1907.09369/3-Table3-1.png", "data/dataset/spiqa/images/1907.09369/4-Table5-1.png", "data/dataset/spiqa/images/1907.09369/4-Table4-1.png", "data/dataset/spiqa/images/1907.09369/5-Table6-1.png", "data/dataset/spiqa/images/1907.09369/5-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the hyperparameters of the bi-GRU?", "reference_answer": "They use the embedding layer with a size 35 and embedding dimension of 300. They use a dense layer with 70 units and a dropout layer with a rate of 50%.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0c05d930-fe7e-54f7-a35c-d1e649305b2a", "question": "Which of the five methods tested had the lowest average misclassification error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the five methods tested had the lowest average misclassification error?", "reference_answer": "Multi-X"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d3382c5a-1942-5b6e-8bdc-f2728f93e77c", "question": "Which of the two algorithms (GB-KMV or LSH-E) is the fastest on average across all datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the two algorithms (GB-KMV or LSH-E) is the fastest on average across all datasets?", "reference_answer": "LSH-E"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ae931445-6929-5791-8eb8-96928058af42", "question": "What is the difference between foreground and background voxels?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the difference between foreground and background voxels?", "reference_answer": "At the output of the V-Net foreground voxels represents the score for the anatomy and background voxels represents score for not having the anatomy at a region."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f0b50680-10c7-5369-820b-6fc5c89a8712", "question": "Which query type has the highest accuracy when M/|V| is small?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which query type has the highest accuracy when M/|V| is small?", "reference_answer": "Edge query."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d7dda9d3-79db-561a-be2a-818ea9d9e328", "question": "Which year is most associated with the terms \"sept\", \"hijackers\", and \"attacks\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which year is most associated with the terms \"sept\", \"hijackers\", and \"attacks\"?", "reference_answer": "2001"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4e1a4415-234f-584a-9d90-b315807f646d", "question": "Which variation provides the best results on this dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["326ade97-a3af-5e28-a28c-1690c49dfbda"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13104/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13104/3-Table1-1.png", "data/dataset/spiqa/images/1909.13104/4-Figure1-1.png", "data/dataset/spiqa/images/1909.13104/5-Figure2-1.png", "data/dataset/spiqa/images/1909.13104/7-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which variation provides the best results on this dataset?", "reference_answer": "the model with multi-attention mechanism and a projected layer", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d8635b92-dbc9-5746-8fdd-b04e13462009", "question": "What is the effect of increasing the margin on the AUC and MAP values?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of increasing the margin on the AUC and MAP values?", "reference_answer": "The AUC and MAP values initially increase with increasing margin, but then decrease after a certain point."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7c0ba4e0-a38e-5a86-880e-d86c1e18416c", "question": "what dataset was used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e2ee9294-e24c-5a6e-a4e9-15d0ab035817"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.04042/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.04042/2-Table1-1.png", "data/dataset/spiqa/images/1908.04042/4-Figure1-1.png", "data/dataset/spiqa/images/1908.04042/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what dataset was used?", "reference_answer": " E-book annotation data: editor tags, Amazon search terms, and  Amazon review keywords.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4bb40041-a2b0-5899-9264-31bc6b46c70a", "question": "Which digit has the highest average squared distance to other digits in the MNIST dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which digit has the highest average squared distance to other digits in the MNIST dataset?", "reference_answer": "Digit \"1\""}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2cc5ebcf-c53a-5b8d-89b4-d8d8dfb0a08e", "question": "What is the role of the GDU and HFLU modules in the FAKEDETECTOR framework?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["875f670a-b5e4-57b7-9873-8917b1b43681"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure3-1.png", "data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure4-1.png", "data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure5-1.png", "data/dataset/spiqa/images/1805.08751v2/1805.08751v2-TableI-1.png", "data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure7-1.png", "data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure6-1.png", "data/dataset/spiqa/images/1805.08751v2/1805.08751v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the GDU and HFLU modules in the FAKEDETECTOR framework?", "reference_answer": "The GDU (Gated Dilated Unit) modules are responsible for extracting features from the input data, while the HFLU (Hybrid Feature Learning Unit) modules are responsible for fusing the features extracted by the GDU modules."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1ec9d64e-2e02-53fe-b0ef-226a8dab6a9d", "question": "Which method has the lower testing error on the MNIST task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the lower testing error on the MNIST task?", "reference_answer": "ITN"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "23747564-adb6-501d-87d2-f925018b98f4", "question": "Which generative model generates more accurate and realistic samples on the MNIST dataset, AC-GATN or ITN?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which generative model generates more accurate and realistic samples on the MNIST dataset, AC-GATN or ITN?", "reference_answer": "ITN generates more accurate and realistic samples on the MNIST dataset compared to AC-GATN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f20cc938-852b-5586-a8c3-5cfd1083c5d2", "question": "How do the backoff strategies work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e348cca5-a3ac-5ce5-9dd5-cec3f6cfd7fa"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.11268/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.11268/1-Table1-1.png", "data/dataset/spiqa/images/1905.11268/4-Figure1-1.png", "data/dataset/spiqa/images/1905.11268/5-Table2-1.png", "data/dataset/spiqa/images/1905.11268/7-Table3-1.png", "data/dataset/spiqa/images/1905.11268/7-Table4-1.png", "data/dataset/spiqa/images/1905.11268/8-Figure2-1.png", "data/dataset/spiqa/images/1905.11268/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do the backoff strategies work?", "reference_answer": "In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d02da224-81cf-5a26-ba4a-04b84e298df4", "question": "How does the intra-warrant attention mechanism work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0423e038-405f-5171-a89b-75e3079e5aa6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the intra-warrant attention mechanism work?", "reference_answer": "The intra-warrant attention mechanism uses a BiLSTM to encode the reason and claim, and then provides this encoded information as an attention vector to LSTM layers for each warrant. The attention vector allows the model to focus on specific parts of the reason and claim that are most relevant to each warrant."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "99243313-7666-59f7-b8a0-d5c1c1a9551e", "question": "What is the purpose of the UVT cycle link?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the UVT cycle link?", "reference_answer": "The UVT cycle link is used to transfer knowledge between two recurrent generators."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1bf56140-fbb9-5420-81a7-163774017765", "question": "Why did the GoogLENet-RI-H performs poorly in the Thoracoabdominal Lymph Node Detection task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why did the GoogLENet-RI-H performs poorly in the Thoracoabdominal Lymph Node Detection task?", "reference_answer": "The model suffers from over-fitting, as it is a very complex model but it does not have enough training data for training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8da8973c-19d4-5c0f-9ac8-9210f18a4c3b", "question": "What does \"information highways\" mean ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0931f3d2-f642-5062-8737-af4d1805c275"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/3-Figure1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/5-Table3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/7-Figure3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/8-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does \"information highways\" mean ?", "reference_answer": "'information highways' means that some information is not lost while passing through the layer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b2dc528c-ba00-5a32-8d56-5f7c9e1d617c", "question": "What is the results of multimodal compared to unimodal models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["4438fe78-db62-5136-9689-bb1bf996a65f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.03814/7-Table1-1.png", "data/dataset/spiqa/images/1910.03814/7-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.03814/2-Figure1-1.png", "data/dataset/spiqa/images/1910.03814/3-Figure2-1.png", "data/dataset/spiqa/images/1910.03814/4-Figure3-1.png", "data/dataset/spiqa/images/1910.03814/6-Figure4-1.png", "data/dataset/spiqa/images/1910.03814/6-Figure5-1.png", "data/dataset/spiqa/images/1910.03814/7-Table1-1.png", "data/dataset/spiqa/images/1910.03814/7-Figure7-1.png", "data/dataset/spiqa/images/1910.03814/7-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the results of multimodal compared to unimodal models?", "reference_answer": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4efa6f1d-350d-5915-9237-2e7cdf946a47", "question": "Is random search (RS) more efficient that reinforcement learning (RL) for learning neural architectures?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["acb67ddd-a0d1-56d4-871c-f5f79ed59efb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/12-Figure8-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure9-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/2-Figure1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Figure5-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is random search (RS) more efficient that reinforcement learning (RL) for learning neural architectures?", "reference_answer": "No, Reninforcement Learning is more efficient than Random Search for learning neural architectures."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "330c985f-3009-55bc-922f-c0c6fb13bf5d", "question": "Which algorithm performs better in terms of F1 score and precision when the space used is 5%?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm performs better in terms of F1 score and precision when the space used is 5%?", "reference_answer": "GB-KMV performs better in terms of F1 score and precision when the space used is 5%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e6a181d8-6fd1-59bb-a37d-086786147046", "question": "How did the authors verify that YOLO learns very general representation of objects ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How did the authors verify that YOLO learns very general representation of objects ?", "reference_answer": "Since YOLO is trained on full images and end-to-end it can encode contextual information about each class and its appearance. Moreover, it can learn shapes, sizes, and the relationship between objects. Thus it was shown to be generalizable to artwork, although pixel-wise they are different from natural images, and it makes twice as less mistakes with background objects compared to R-CNN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "a261d32f-b6b5-5fca-ac92-aebb3e6b1df8", "question": "According to the authors, the VGG-16 version of Faster R-CNN is 6 time slower than YOLO, what is the actual speed of the model ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "According to the authors, the VGG-16 version of Faster R-CNN is 6 time slower than YOLO, what is the actual speed of the model ?", "reference_answer": "Table 1 reveals that the actual speed of Faster R-CNN with VGG-16 is 7fps with 73.2% mAP. At the same time, YOLO has more than 6 times the higher speed of 45 fps with 63.4% mAP on Pascal VOC 2007."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "959d6813-8b6d-5284-8d1c-02b8620f249f", "question": "What is the difference between an overlapping case and an error case?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d5785d16-c0a5-5e54-9ad7-9ee75cd95b28"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure1-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure5-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure6-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between an overlapping case and an error case?", "reference_answer": "An overlapping case is when multiple aspects share the same opinion snippet, while an error case is when the model incorrectly identifies an aspect or opinion."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9fd06af8-05bc-54a6-b829-6b4cd5f3162e", "question": "What is the improvement in performance for Estonian in the NER task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["214ef428-3d1c-5293-9096-7801c0f0cae4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.10049/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.10049/3-Table1-1.png", "data/dataset/spiqa/images/1911.10049/4-Figure1-1.png", "data/dataset/spiqa/images/1911.10049/4-Table2-1.png", "data/dataset/spiqa/images/1911.10049/5-Table3-1.png", "data/dataset/spiqa/images/1911.10049/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the improvement in performance for Estonian in the NER task?", "reference_answer": "0.05 F1", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d0b4e0d6-133c-55e3-aa18-fb2912600b19", "question": "How does the square hashing process work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the square hashing process work?", "reference_answer": "Square hashing is a process that uses two hash functions to map a source/destination pair to a bucket in a two-dimensional array. The first hash function, h_i(s), maps the source address to a row in the array, and the second hash function, h_i(d), maps the destination address to a column in the array. The intersection of the row and column is the bucket where the fingerprint is stored."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3f3c300b-7eb1-5b9a-85bf-06544758fd77", "question": "What are some common medications used to treat Sickle Cell Anemia?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are some common medications used to treat Sickle Cell Anemia?", "reference_answer": "According to the table, some common medications used to treat Sickle Cell Anemia include:\n\nBeta-adrenergic agents\nAnalgesics (narcotics and non-narcotics)\nNSAIDs (cyclooxygenase inhibitor - type)\nPotassium replacement\nSodium/saline preparations\nGeneral inhalation agents\nLaxatives and cathartics\nIV solutions (dextrose-saline)\nAntiemetic/antivertigo agents\nSedative-hypnotics (non-barbiturate)\nGlucocorticoids (orally inhaled)\nFolic acid preparations\nAnalgesic narcotic anesthetic adjunct agents"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1a101876-a011-5d8f-95ff-53fcba53f17a", "question": "What are some challenges that researchers have encountered when generating 3D face images from 2D images?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are some challenges that researchers have encountered when generating 3D face images from 2D images?", "reference_answer": "The paper mainly talks about research on 3D face data reconstruction in terms of \"one-to-many augmentation\" methods. Also, attempts to enlarge 3D face datasets with the same method are mentioned. However, no challenges or specific issues during the process of 3D face reconstruction are included in the paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ef9cd08c-09ab-5d32-8b12-d3319f798ab3", "question": "How large is their data set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["72250259-7097-560b-adbd-18551626f2e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.01010/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.01010/1-Figure1-1.png", "data/dataset/spiqa/images/1901.01010/3-Figure2-1.png", "data/dataset/spiqa/images/1901.01010/4-Table1-1.png", "data/dataset/spiqa/images/1901.01010/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How large is their data set?", "reference_answer": "a sample of  29,794 wikipedia articles and 2,794 arXiv papers ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9c96e476-1519-5cfc-a17d-8e2123f59a15", "question": "Which method, AMIE or MINE, produces generated frames that are closer in distribution to the real frames?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method, AMIE or MINE, produces generated frames that are closer in distribution to the real frames?", "reference_answer": "MINE"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "84529e50-45d2-51b9-84c5-9fe7fc96cc7e", "question": "What are the advantages of using a flat architecture in SegNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a23ce2a-2593-5a31-9059-32d75394b681"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/4-Figure2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/5-Figure3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/7-Figure4-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure5-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the advantages of using a flat architecture in SegNet?", "reference_answer": "The flat architecture avoids parameter explosion, unlike an expanding deep encoder network with full feature connectivity (same for decoder) and the training time remains almost same for each additional/deeper encoder-decoder pair."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f1b2d664-f669-5c24-af04-4aebd5ba75ff", "question": "Are the academically younger authors cited less than older?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["083c588e-cadb-585b-985f-70949e59e35d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.03562/26-Figure30-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.03562/2-Figure1-1.png", "data/dataset/spiqa/images/1911.03562/3-Figure2-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure3-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure4-1.png", "data/dataset/spiqa/images/1911.03562/6-Figure5-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure6-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure7-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure8-1.png", "data/dataset/spiqa/images/1911.03562/8-Figure9-1.png", "data/dataset/spiqa/images/1911.03562/9-Figure10-1.png", "data/dataset/spiqa/images/1911.03562/10-Figure11-1.png", "data/dataset/spiqa/images/1911.03562/12-Figure12-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure13-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure14-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure15-1.png", "data/dataset/spiqa/images/1911.03562/15-Figure16-1.png", "data/dataset/spiqa/images/1911.03562/16-Figure17-1.png", "data/dataset/spiqa/images/1911.03562/17-Figure18-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure19-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure20-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure21-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure22-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure23-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure24-1.png", "data/dataset/spiqa/images/1911.03562/20-Figure25-1.png", "data/dataset/spiqa/images/1911.03562/21-Figure26-1.png", "data/dataset/spiqa/images/1911.03562/22-Figure27-1.png", "data/dataset/spiqa/images/1911.03562/23-Figure28-1.png", "data/dataset/spiqa/images/1911.03562/24-Figure29-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure30-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure31-1.png", "data/dataset/spiqa/images/1911.03562/28-Figure32-1.png", "data/dataset/spiqa/images/1911.03562/29-Figure33-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the academically younger authors cited less than older?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0409f5d1-cff4-50b4-a24e-21be5e8e0067", "question": "In what 8 languages is PolyResponse engine used for restourant search and booking system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dab4c63a-ff8e-5646-b49a-166b77b6f023"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.01296/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.01296/2-Figure1-1.png", "data/dataset/spiqa/images/1909.01296/5-Figure2-1.png", "data/dataset/spiqa/images/1909.01296/5-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "In what 8 languages is PolyResponse engine used for restourant search and booking system?", "reference_answer": "English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "940ba161-8af3-5d41-99d1-ed63f4de66fd", "question": "What is the relationship between the camera yaw angle and the silhouette distance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the camera yaw angle and the silhouette distance?", "reference_answer": "The silhouette distance generally increases as the camera yaw angle increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8ff63d5c-adbc-5e0e-8272-75adea29770f", "question": "Which method appears to be the safest for autonomous driving on straight lanes with different levels of outlier vehicles?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method appears to be the safest for autonomous driving on straight lanes with different levels of outlier vehicles?", "reference_answer": "ChoiceNet appears to be the safest method for autonomous driving on straight lanes, regardless of the percentage of outlier vehicles present."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f710106b-4795-5797-8e81-c72ce741beea", "question": "Which model performs the best in terms of Entity F1 score when the percentage of unseen entities in the response is low?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best in terms of Entity F1 score when the percentage of unseen entities in the response is low?", "reference_answer": "BoSsNet"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "51a6df87-bfca-59f2-bb0b-a502c14683e3", "question": "did they use a crowdsourcing platform for manual annotations?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["0a9b2ff8-2d23-5232-b095-a4ca2db6a03b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.08699/3-Figure3-1.png", "data/dataset/spiqa/images/1810.08699/3-Figure2-1.png", "data/dataset/spiqa/images/1810.08699/3-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.08699/2-Figure1-1.png", "data/dataset/spiqa/images/1810.08699/3-TableI-1.png", "data/dataset/spiqa/images/1810.08699/3-Figure2-1.png", "data/dataset/spiqa/images/1810.08699/3-Figure3-1.png", "data/dataset/spiqa/images/1810.08699/3-TableII-1.png", "data/dataset/spiqa/images/1810.08699/4-Figure4-1.png", "data/dataset/spiqa/images/1810.08699/5-TableIII-1.png", "data/dataset/spiqa/images/1810.08699/5-TableIV-1.png", "data/dataset/spiqa/images/1810.08699/5-TableV-1.png", "data/dataset/spiqa/images/1810.08699/5-TableVI-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "did they use a crowdsourcing platform for manual annotations?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c9c727f1-789a-5631-9726-6e50408d87d2", "question": "what previous RNN models do they compare with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a2d06101-c08f-50a1-be23-bdb333d26c87"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.09029/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.09029/1-Figure1-1.png", "data/dataset/spiqa/images/1808.09029/2-Figure2-1.png", "data/dataset/spiqa/images/1808.09029/6-Table1-1.png", "data/dataset/spiqa/images/1808.09029/7-Figure3-1.png", "data/dataset/spiqa/images/1808.09029/7-Figure4-1.png", "data/dataset/spiqa/images/1808.09029/8-Table2-1.png", "data/dataset/spiqa/images/1808.09029/8-Figure5-1.png", "data/dataset/spiqa/images/1808.09029/9-Table4-1.png", "data/dataset/spiqa/images/1808.09029/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what previous RNN models do they compare with?", "reference_answer": "Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5dc6f6ab-c7bf-5ed5-a5d6-354cebd2e5d7", "question": "How does the performance of the model with convolutional self-correction compare to the model with no self-correction as the number of images in set $\\mathcal{F}$ increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the model with convolutional self-correction compare to the model with no self-correction as the number of images in set $\\mathcal{F}$ increases?", "reference_answer": "The model with convolutional self-correction consistently outperforms the model with no self-correction as the number of images in set $\\mathcal{F}$ increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7f1f5842-ea4c-5eb8-b0a7-66ff34afa158", "question": "How are sentence embeddings incorporated into the speech recognition system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0610cd2f-12c0-5c89-b0f7-1642177d5bf3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.11604/5-Figure2-1.png", "data/dataset/spiqa/images/1906.11604/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.11604/4-Figure1-1.png", "data/dataset/spiqa/images/1906.11604/5-Table1-1.png", "data/dataset/spiqa/images/1906.11604/5-Figure2-1.png", "data/dataset/spiqa/images/1906.11604/6-Table2-1.png", "data/dataset/spiqa/images/1906.11604/7-Figure3-1.png", "data/dataset/spiqa/images/1906.11604/7-Figure4-1.png", "data/dataset/spiqa/images/1906.11604/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How are sentence embeddings incorporated into the speech recognition system?", "reference_answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "30a11c8c-f1b8-57d6-a073-d0db94250b4e", "question": "How much better were results of the proposed models than base LSTM-RNN model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b41b7931-53be-5e7a-8212-3814f3858231"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.05467/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.05467/3-Figure1-1.png", "data/dataset/spiqa/images/2001.05467/3-Figure2-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure3-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure4-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure5-1.png", "data/dataset/spiqa/images/2001.05467/5-Table1-1.png", "data/dataset/spiqa/images/2001.05467/5-Figure6-1.png", "data/dataset/spiqa/images/2001.05467/6-Table2-1.png", "data/dataset/spiqa/images/2001.05467/6-Table3-1.png", "data/dataset/spiqa/images/2001.05467/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much better were results of the proposed models than base LSTM-RNN model?", "reference_answer": "on diversity 6.87 and on relevance 4.6 points higher", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e2e9a5be-a0ab-59d0-949d-8c22c33b3be9", "question": "What is CTC-training?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["35045ebe-0bfe-541c-875f-e6e407e085f2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b624504240fa52ab76167acfe3156150ca01cf3b/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/b624504240fa52ab76167acfe3156150ca01cf3b/3-Figure1-1.png", "data/dataset/spiqa/images/b624504240fa52ab76167acfe3156150ca01cf3b/5-Figure2-1.png", "data/dataset/spiqa/images/b624504240fa52ab76167acfe3156150ca01cf3b/6-Figure3-1.png", "data/dataset/spiqa/images/b624504240fa52ab76167acfe3156150ca01cf3b/7-Figure4-1.png", "data/dataset/spiqa/images/b624504240fa52ab76167acfe3156150ca01cf3b/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is CTC-training?", "reference_answer": "According to the related work section in the paper, CTC training is the deep-learning-based speech recognization model which performs MAP inference on the alignment as a latent random variable. There is no detailed information on how CTC training works in this paper and presumed to exist in [13]."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b0b92fc1-2ecb-51ea-94f4-b69e0d3b4a49", "question": "How does the performance of ESMM compare to other models on the CVR task and CTCVR task with different training set sizes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f2e1d9a7-fce3-5c7c-af44-2a80ea5a78dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table1-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure3-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of ESMM compare to other models on the CVR task and CTCVR task with different training set sizes?", "reference_answer": "ESMM-NS and ESMM outperform all other models consistently across different training set sizes on both the CVR and CTCVR tasks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "83a3d2f8-f021-5fbe-81d0-3523a5cb3644", "question": "What is the role of the knowledge gates in the KEHNN architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d62d3025-a1b0-5616-84f5-5ea256c9ac90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table3-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table2-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table1-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table4-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table5-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table6-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the knowledge gates in the KEHNN architecture?", "reference_answer": "The knowledge gates are responsible for selecting relevant information from the knowledge base and incorporating it into the model's hidden state."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a0b3a6ef-85db-5d8e-828b-9c7b2a6277fe", "question": "Can you explain why the performance of VAGER is worse than LR for the \"Bubble\" class in the 1-shot binary classification setting, while it performs better for the other nine classes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["77db890f-c739-5abc-a1af-4cdaee857323"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Can you explain why the performance of VAGER is worse than LR for the \"Bubble\" class in the 1-shot binary classification setting, while it performs better for the other nine classes?", "reference_answer": "VAGER leverages transfer learning, while LR does not. This means VAGER attempts to apply knowledge from other classes to improve its performance on new classes. For nine out of the ten novel classes, this strategy seems to be successful, as VAGER consistently outperforms LR. However, for the \"Bubble\" class, the transfer learning approach seems to have a negative impact, causing VAGER to perform worse than LR."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9274b7a7-dbfb-5ff6-9d04-51c17c418104", "question": "How much more prevalent are click events compared to conversion events in the Product Dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f2e1d9a7-fce3-5c7c-af44-2a80ea5a78dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table1-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure3-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How much more prevalent are click events compared to conversion events in the Product Dataset?", "reference_answer": "Click events are roughly 184 times more prevalent than conversion events in the Product Dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "28a882ac-62d2-5325-b159-318b9e521c15", "question": "Which dataset has the highest temporal resolution, meaning it provides data points at the most frequent intervals?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the highest temporal resolution, meaning it provides data points at the most frequent intervals?", "reference_answer": "The solar dataset has the highest temporal resolution."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f1ebd5f2-ab62-5940-832d-520a76df7d63", "question": "How does the classification error of a residual network change as the average path length increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the classification error of a residual network change as the average path length increases?", "reference_answer": "The classification error of a residual network generally increases as the average path length increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "541beb5a-af28-5e3d-aa67-57e6e583ff0b", "question": "What is the difference between the input and output of the frontal face generation process?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the input and output of the frontal face generation process?", "reference_answer": "The input is a low-resolution frontal face image and a high-resolution side-face image. The output is a high-resolution frontal face image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c4f176de-5e14-5330-acf9-01fa481a54a9", "question": "What is the role of the temperature variable t in the CCA decoding algorithm?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the temperature variable t in the CCA decoding algorithm?", "reference_answer": "The temperature variable t controls the probability of accepting a new candidate solution y. As t decreases, the probability of accepting a worse solution decreases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "85002f15-b23d-5c80-9c6f-a68cbff73601", "question": "Explain the motivation of this paper", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["74ebae64-5177-5968-9a94-6626f9954498"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/1-Figure1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/12-Table4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/12-Table5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.3-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/13-FigureA.4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/14-FigureA.5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/14-Table6-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/2-Table1-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/4-Figure2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/4-Figure3-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/5-Figure4-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/6-Figure5-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Figure6-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Figure7-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/7-Table2-1.png", "data/dataset/spiqa/images/5efab88c0cdb11c795fa8f44a5d31b40e2a1c261/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Explain the motivation of this paper", "reference_answer": "The motivation of this paper is analyzing whether pretraining on text is inherently about learning language or if pretraining inject non-linguisitc reasoning to LMs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "72aa09c8-6a13-5bf0-b90c-cd3b888bb8f8", "question": "What is the purpose of the decoder in the 3D mesh prediction pipeline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the decoder in the 3D mesh prediction pipeline?", "reference_answer": "The decoder is responsible for generating the final 3D mesh from the intermediate representations produced by the regression network."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b168a968-1564-579f-8818-cd82d94b7ce4", "question": "What dataset do they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4058e804-d9ea-5fe6-9b3f-911a0f61bb37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.11471/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.11471/4-Figure1-1.png", "data/dataset/spiqa/images/1910.11471/5-Figure2-1.png", "data/dataset/spiqa/images/1910.11471/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What dataset do they use?", "reference_answer": "A parallel corpus where the source is an English expression of code and the target is Python code.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "94e0a9e2-6efe-5660-8d81-7fef6261e43a", "question": "Which basic neural architecture perform best by itself?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which basic neural architecture perform best by itself?", "reference_answer": "BERT", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e5b6e8bd-e930-526c-9891-c3529b5a1573", "question": "What language technologies have been introduced in the past?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de76c135-1d14-5899-823b-094a3d82ba1a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.03457/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.03457/1-Figure1-1.png", "data/dataset/spiqa/images/1912.03457/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What language technologies have been introduced in the past?", "reference_answer": "- Font & Keyboard\n- Speech-to-Text\n- Text-to-Speech\n- Text Prediction\n- Spell Checker\n- Grammar Checker\n- Text Search\n- Machine Translation\n- Voice to Text Search\n- Voice to Speech Search", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "126674d4-425b-5c3b-b844-738b87e113bd", "question": "Which data structure is the fastest for updating on the email-EuAll dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which data structure is the fastest for updating on the email-EuAll dataset?", "reference_answer": "GSS (no sampling)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4e8fbb39-1437-50d6-8d68-1205f59f2160", "question": "How does the maximum link delay affect the segment loss rate and goodput in a TCP connection with one hop?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the maximum link delay affect the segment loss rate and goodput in a TCP connection with one hop?", "reference_answer": "As the maximum link delay increases, the segment loss rate increases and the goodput decreases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d5f8f54a-edf2-5c6e-badb-568a35a38118", "question": "Which category of object is the least common in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which category of object is the least common in the dataset?", "reference_answer": "Train"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c7ad53a6-b43c-5988-88aa-72714236685a", "question": "What are the black-box probes used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3ef2c05c-0862-5d4e-b1c0-c0849ef611c6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11047/8-Table6-1.png", "data/dataset/spiqa/images/1908.11047/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11047/1-Figure1-1.png", "data/dataset/spiqa/images/1908.11047/2-Table1-1.png", "data/dataset/spiqa/images/1908.11047/3-Figure2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table3-1.png", "data/dataset/spiqa/images/1908.11047/5-Table4-1.png", "data/dataset/spiqa/images/1908.11047/8-Table5-1.png", "data/dataset/spiqa/images/1908.11047/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the black-box probes used?", "reference_answer": "CCG Supertagging CCGBank , PTB part-of-speech tagging, EWT part-of-speech tagging,\nChunking, Named Entity Recognition, Semantic Tagging, Grammar Error Detection, Preposition Supersense Role, Preposition Supersense Function, Event Factuality Detection", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "73aaa2a6-1a89-5225-aef7-f70a7d39756b", "question": "Does the additional training on supervised tasks hurt performance in some tasks?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["8f449bb7-feb6-5541-baaa-4d981ba0b479"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.01088/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.01088/4-Table1-1.png", "data/dataset/spiqa/images/1811.01088/5-Table2-1.png", "data/dataset/spiqa/images/1811.01088/6-Figure1-1.png", "data/dataset/spiqa/images/1811.01088/8-Table3-1.png", "data/dataset/spiqa/images/1811.01088/12-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the additional training on supervised tasks hurt performance in some tasks?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "976aee30-2430-5dd3-bdb0-e97be376cc64", "question": "How does the proposed model compare to H.264 in terms of visual quality at low bitrates?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed model compare to H.264 in terms of visual quality at low bitrates?", "reference_answer": "The proposed model delivers significantly better visual quality at low bitrates than H.264."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fb636bfd-4192-5f2b-9c74-a174ecf5cb09", "question": "The authors claims that DeepMedic  behaves very well in preserving the hierarchical structure tumours, is that true ? Have they tried it across different types of varying cases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6b7a7cc4-8550-5ec3-a2bf-f86ba6f4acef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/12-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/10-Table1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/11-Figure10-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/11-Figure11-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/12-Table2-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/13-Table3-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/13-Table4-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/14-Figure13-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/14-Table5-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/15-Figure14-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/17-TableB.1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/17-TableC.1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/2-Figure1-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/4-Figure2-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/5-Figure3-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/5-Figure4-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/6-Figure5-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/8-Figure6-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/8-Figure7-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/8-Figure8-1.png", "data/dataset/spiqa/images/7c2bcf6f32b05a04cd3444c030db743e5666af88/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The authors claims that DeepMedic  behaves very well in preserving the hierarchical structure tumours, is that true ? Have they tried it across different types of varying cases?", "reference_answer": "Figure 12 shows successful cases of segmentation for the hierarchy of brain tumors. As seen in Figure 12, the model understands that the sequence of layers goes from oedema to non-enhancing core to enhancing core to necrotic core, preserving the hierarchical structure of tumors. They also show a relatively unsuccessful case where oversegmentation occurs, but even in this example, the hierarchy of the tumor is preserved."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "82f6ec78-6062-5f56-b108-5e15e6ea9679", "question": "Which of the four methods (ResNet, DANN, CDAN-f, CDAN-fg) is most effective at separating the two classes of data points?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["08eae607-b68b-5938-842d-52805a218768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table5-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table4-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table1-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the four methods (ResNet, DANN, CDAN-f, CDAN-fg) is most effective at separating the two classes of data points?", "reference_answer": "CDAN-fg"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c225c368-2bfb-5fbd-9dd1-d10a69d25fa3", "question": "Which model achieved the highest combined score for informativeness and grammatical correctness on the CamRest dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model achieved the highest combined score for informativeness and grammatical correctness on the CamRest dataset?", "reference_answer": "The BOSSNET model achieved the highest combined score for informativeness and grammatical correctness on the CamRest dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b2e1d3e3-277a-51ab-a731-b21e6bc74d0b", "question": "How were the navigation instructions collected?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0513fa91-ee37-5970-957a-21360f4db676"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.00663/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.00663/2-Figure1-1.png", "data/dataset/spiqa/images/1810.00663/4-Table1-1.png", "data/dataset/spiqa/images/1810.00663/5-Figure2-1.png", "data/dataset/spiqa/images/1810.00663/6-Table2-1.png", "data/dataset/spiqa/images/1810.00663/8-Table3-1.png", "data/dataset/spiqa/images/1810.00663/8-Figure3-1.png", "data/dataset/spiqa/images/1810.00663/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How were the navigation instructions collected?", "reference_answer": "using Amazon Mechanical Turk using simulated environments with topological maps", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f722487f-57a5-5bc4-9ef4-932202ed867b", "question": "Is the new model evaluated on the tasks that BERT and ELMo are evaluated on?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["8f449bb7-feb6-5541-baaa-4d981ba0b479"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.01088/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.01088/4-Table1-1.png", "data/dataset/spiqa/images/1811.01088/5-Table2-1.png", "data/dataset/spiqa/images/1811.01088/6-Figure1-1.png", "data/dataset/spiqa/images/1811.01088/8-Table3-1.png", "data/dataset/spiqa/images/1811.01088/12-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the new model evaluated on the tasks that BERT and ELMo are evaluated on?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6bc5322d-011e-5cb0-9662-04506c6288ec", "question": "Does this method help in sentiment classification task improvement?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3ef2c05c-0862-5d4e-b1c0-c0849ef611c6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11047/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11047/1-Figure1-1.png", "data/dataset/spiqa/images/1908.11047/2-Table1-1.png", "data/dataset/spiqa/images/1908.11047/3-Figure2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table3-1.png", "data/dataset/spiqa/images/1908.11047/5-Table4-1.png", "data/dataset/spiqa/images/1908.11047/8-Table5-1.png", "data/dataset/spiqa/images/1908.11047/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does this method help in sentiment classification task improvement?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0952803d-a5b5-5e35-941d-72d871f51863", "question": "What were the various pre processing techniques used before feeding the data to Neural network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What were the various pre processing techniques used before feeding the data to Neural network?", "reference_answer": "The three preprocessing steps used in this paper are image equalization, image enhancement, and data balancing. First two parts are mainly for increasing image quality, and the last part is for model versatility. The paper answer the question directly."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "20d0548a-2db9-57d3-8d57-7fbd6c87dd3c", "question": "Which language-pair had the better performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["cd407d16-da72-5523-9f61-6b53eba58445"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.07481/4-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.07481/2-Table1-1.png", "data/dataset/spiqa/images/1910.07481/3-Table2-1.png", "data/dataset/spiqa/images/1910.07481/3-Table3-1.png", "data/dataset/spiqa/images/1910.07481/4-Table4-1.png", "data/dataset/spiqa/images/1910.07481/4-Table5-1.png", "data/dataset/spiqa/images/1910.07481/5-Table6-1.png", "data/dataset/spiqa/images/1910.07481/5-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which language-pair had the better performance?", "reference_answer": "French-English", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ff69a445-9f4f-55ee-8e22-764b40fb9c6e", "question": "What is the role of the Cholesky block in the ChoiceNet architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the Cholesky block in the ChoiceNet architecture?", "reference_answer": "The Cholesky block is used to decompose the covariance matrix Σk into a lower triangular matrix and its transpose. This decomposition is used to ensure that the covariance matrix is positive definite, which is a requirement for the Gaussian distribution."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b2bd65ff-e562-55a1-8ec3-5ca59b3a66f0", "question": "Which method performs better, GB-KMV or LSH-E, and how does the performance change with different values of eleFreq and recSize?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs better, GB-KMV or LSH-E, and how does the performance change with different values of eleFreq and recSize?", "reference_answer": "GB-KMV generally performs better than LSH-E, as indicated by the higher F1 scores across the range of eleFreq and recSize values. For both methods, the F1 score tends to decrease as recSize increases, while the impact of eleFreq varies depending on the method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b3dfe66b-eb00-5f48-92bf-90fc308e583e", "question": "Did they compare against other systems?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["a1e5161a-2e8d-5e14-80cd-5aecfa7801d8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.04899/3-Table4-1.png", "data/dataset/spiqa/images/1901.04899/2-Table1-1.png", "data/dataset/spiqa/images/1901.04899/2-Table2-1.png", "data/dataset/spiqa/images/1901.04899/2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.04899/2-Table1-1.png", "data/dataset/spiqa/images/1901.04899/2-Table3-1.png", "data/dataset/spiqa/images/1901.04899/2-Table2-1.png", "data/dataset/spiqa/images/1901.04899/3-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did they compare against other systems?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1a28fe91-ef6c-55be-99eb-6f90cb39557e", "question": "Why does the approach not simply add all feedback examples in memory to the prompt if they will be adding examples anyways?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5e1b0738-5c04-5daf-af64-4361b08a26be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/9-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/15-Figure10-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/15-Figure9-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/16-Figure11-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/17-Figure12-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/19-Figure13-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/2-Figure2-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/20-Figure14-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/24-Figure17-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/24-Table6-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/24-Table7-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/25-Table8-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/26-Figure18-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/26-Table9-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/28-Table10-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/30-Table13-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/4-Table1-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/6-Figure5-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/7-Figure6-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/7-Figure7-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/7-Table2-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/8-Table3-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/9-Figure8-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/9-Table4-1.png", "data/dataset/spiqa/images/41f44979cf1cd3f4cbd615dc130bc33721f5281b/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why does the approach not simply add all feedback examples in memory to the prompt if they will be adding examples anyways?", "reference_answer": "The proposed approach (MemPrompt) probably does not add all feedback examples in memory to the prompt since the size of the prompt is limited to 2048 tokens. Additionally, increasing the size of the prompt leads to higher cost (in terms of compute resources required to process the query)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "dfddab28-6988-57a7-8955-271d12868273", "question": "How strong is the correlation between the prevalence of the #MeToo movement and official reports [of sexual harassment]?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["568d831d-3fbf-5885-9236-11a16976593a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.05970/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.05970/3-Figure1-1.png", "data/dataset/spiqa/images/2001.05970/4-Table1-1.png", "data/dataset/spiqa/images/2001.05970/4-Table2-1.png", "data/dataset/spiqa/images/2001.05970/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How strong is the correlation between the prevalence of the #MeToo movement and official reports [of sexual harassment]?", "reference_answer": "0.9098 correlation", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "614dfb2d-d69f-5452-a7fd-590b98fbaaf7", "question": "What does the authors means by reframing object detection as a \"single regression problem\" ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does the authors means by reframing object detection as a \"single regression problem\" ?", "reference_answer": "Reframing object detection as a simple regression problem means predicting bounding boxes and class probabilities directly from image pixels avoiding complex pipelines and steps which most of the existing (classifier-based) methods do. YOLO can be trained end-to-end and can predict bounding boxes and respective class probabilities directly from an entire image. Also, its loss function directly corresponds to detection performance, which makes optimizing it more intuitive and easier."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "a1ec1b6a-0bac-587b-82da-b8b15ab96ecb", "question": "Do they perform a quantitative analysis of their model displaying knowledge distortions?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["8ab6648a-1650-5d0a-b074-4f95e74c84bf"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.08899/5-Figure2-1.png", "data/dataset/spiqa/images/2002.08899/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.08899/2-Figure1-1.png", "data/dataset/spiqa/images/2002.08899/4-Table1-1.png", "data/dataset/spiqa/images/2002.08899/4-Table2-1.png", "data/dataset/spiqa/images/2002.08899/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they perform a quantitative analysis of their model displaying knowledge distortions?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c6ae4299-4246-53d8-bdb1-ee312052ce67", "question": "By how much is performance improved with multimodality?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c92a0375-1113-5ab2-8a03-db0cfac6b0ed"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13714/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13714/2-Table1-1.png", "data/dataset/spiqa/images/1909.13714/2-Table2-1.png", "data/dataset/spiqa/images/1909.13714/3-Table3-1.png", "data/dataset/spiqa/images/1909.13714/3-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much is performance improved with multimodality?", "reference_answer": "by 2.3-6.8 points in f1 score for intent recognition and 0.8-3.5 for slot filling", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4086a4a6-08ff-510e-bd63-fd01a4fbd376", "question": "How did the accuracy of the model change as the iterations progressed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How did the accuracy of the model change as the iterations progressed?", "reference_answer": "The accuracy of the model increased from 66.7% to 100% as the iterations progressed."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ea811812-09b3-52d0-8152-31b537e35257", "question": "What are previous state of the art results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de9bbc10-18e9-585e-9338-025e9bc604a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.11910/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.11910/2-Figure1-1.png", "data/dataset/spiqa/images/2002.11910/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are previous state of the art results?", "reference_answer": "For Named entity the maximum precision was 66.67%, and the average 62.58%, same values for Recall was 55.97% and 50.33%, and for F1 57.14% and 55.64%. Where for Nominal Mention had maximum recall of 74.48% and average of 73.67%, Recall had values of 54.55% and 53.7%,  and F1 had values of  62.97% and 62.12%. Finally the Overall F1 score had maximum value of 59.11% and average of 58.77%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6daa9a06-6256-5a02-bddf-fe712b31f533", "question": "Which method achieves the highest PSNR on the Vid4 data set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the highest PSNR on the Vid4 data set?", "reference_answer": "DUF"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2e4c7f13-c7fb-5acc-aa5c-f4ad167c79e9", "question": "Which model achieved the highest performance score on the Breakout game?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["edf2543a-ae86-5f4d-b07a-c33d5092ee05"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure5-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure3-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure2-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure4-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model achieved the highest performance score on the Breakout game?", "reference_answer": "A3C-CTS"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3e6db530-4460-5c3f-8290-a5418eefd26a", "question": "Do they study frequent user responses to help automate modelling of those?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["f1cc63e0-5d23-51ed-90a0-2799b7bcd7d8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.10609/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.10609/2-Figure1-1.png", "data/dataset/spiqa/images/1710.10609/3-Figure2-1.png", "data/dataset/spiqa/images/1710.10609/5-Figure3-1.png", "data/dataset/spiqa/images/1710.10609/6-Table1-1.png", "data/dataset/spiqa/images/1710.10609/7-Figure4-1.png", "data/dataset/spiqa/images/1710.10609/7-Figure5-1.png", "data/dataset/spiqa/images/1710.10609/8-Table2-1.png", "data/dataset/spiqa/images/1710.10609/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they study frequent user responses to help automate modelling of those?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bf787826-bbf6-5150-8369-b3d74e9c19f7", "question": "How do they match annotators to instances?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b13e94ad-c5be-53de-bd29-23ca4a2601d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.07791/8-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.07791/3-Table1-1.png", "data/dataset/spiqa/images/1905.07791/4-Table2-1.png", "data/dataset/spiqa/images/1905.07791/4-Figure1-1.png", "data/dataset/spiqa/images/1905.07791/5-Table3-1.png", "data/dataset/spiqa/images/1905.07791/5-Figure2-1.png", "data/dataset/spiqa/images/1905.07791/6-Table4-1.png", "data/dataset/spiqa/images/1905.07791/6-Figure3-1.png", "data/dataset/spiqa/images/1905.07791/8-Figure4-1.png", "data/dataset/spiqa/images/1905.07791/8-Table5-1.png", "data/dataset/spiqa/images/1905.07791/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they match annotators to instances?", "reference_answer": "Annotations from experts are used if they have already been collected.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ba93c731-54fc-5ee2-be00-ca52f8916830", "question": "What is the main difference between the Multilinear Conditioning architecture and the Randomized Multilinear Conditioning architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["08eae607-b68b-5938-842d-52805a218768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table5-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table4-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table1-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the main difference between the Multilinear Conditioning architecture and the Randomized Multilinear Conditioning architecture?", "reference_answer": "The main difference is that the Multilinear Conditioning architecture uses a multilinear map to condition the domain discriminator on the classifier prediction, while the Randomized Multilinear Conditioning architecture uses a randomized multilinear map."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7e8e794f-c9fa-5001-abad-192b7a427420", "question": "Which dataset would be most suitable for training a learning-to-rank model with limited computational resources, and why?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4211b30e-5e8d-5449-8335-9f14cfeb4b9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table5-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset would be most suitable for training a learning-to-rank model with limited computational resources, and why?", "reference_answer": "Microsoft 10k would be the most suitable dataset for training with limited computational resources."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "bf3f1912-84b0-55b9-ba2b-33835c170b9c", "question": "How better is gCAS approach compared to other approaches?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a1b87d72-fb6c-5cf0-b2fd-7e16ff1ab378"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11546/3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11546/1-Table1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure1-1.png", "data/dataset/spiqa/images/1908.11546/2-Figure2-1.png", "data/dataset/spiqa/images/1908.11546/3-Table5-1.png", "data/dataset/spiqa/images/1908.11546/3-Table4-1.png", "data/dataset/spiqa/images/1908.11546/3-Table3-1.png", "data/dataset/spiqa/images/1908.11546/3-Table2-1.png", "data/dataset/spiqa/images/1908.11546/4-Table6-1.png", "data/dataset/spiqa/images/1908.11546/4-Table7-1.png", "data/dataset/spiqa/images/1908.11546/5-Table8-1.png", "data/dataset/spiqa/images/1908.11546/5-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How better is gCAS approach compared to other approaches?", "reference_answer": "For entity  F1 in the movie, taxi and restaurant domain it results in scores of 50.86, 64, and 60.35. For success, it results it outperforms in the movie and restaurant domain with scores of 77.95 and 71.52", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "33fb6146-15d0-5541-89e5-6acbd190882f", "question": "Which dataset presents the biggest challenge for a model trying to distinguish true triplets from decoys, and why?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset presents the biggest challenge for a model trying to distinguish true triplets from decoys, and why?", "reference_answer": "The VQA dataset presents the biggest challenge."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3b1db1be-a6a7-51b3-abeb-dca6b0768026", "question": "How many category tags are considered?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c504fb70-fb71-5199-b408-dd3b4e843e91"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.07758/8-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.07758/1-Figure1-1.png", "data/dataset/spiqa/images/2003.07758/3-Figure2-1.png", "data/dataset/spiqa/images/2003.07758/4-Figure3-1.png", "data/dataset/spiqa/images/2003.07758/6-Table1-1.png", "data/dataset/spiqa/images/2003.07758/7-Table2-1.png", "data/dataset/spiqa/images/2003.07758/7-Table3-1.png", "data/dataset/spiqa/images/2003.07758/8-Figure4-1.png", "data/dataset/spiqa/images/2003.07758/8-Figure5-1.png", "data/dataset/spiqa/images/2003.07758/12-Table4-1.png", "data/dataset/spiqa/images/2003.07758/13-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many category tags are considered?", "reference_answer": "14 categories", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a146796c-70ad-5555-bdba-b0ec21bf1639", "question": "What is the effect of increasing K on the test PPL of the different models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d8d7d2b2-c0c6-5596-baba-bcc14ccd75f0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.00774v3/1704.00774v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.00774v3/1704.00774v3-Figure1-1.png", "data/dataset/spiqa/images/1704.00774v3/1704.00774v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of increasing K on the test PPL of the different models?", "reference_answer": "The test PPL of all the models decreases as K increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c7359380-482f-56b5-a608-bf55a4a09123", "question": "Which method achieved the highest tracking accuracy in terms of minimizing the sum of absolute percentage errors? Does this necessarily mean it had the best overall performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d14c7ae4-acb0-5aa7-bee9-352f4614293c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01989v2/1809.01989v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01989v2/1809.01989v2-Table1-1.png", "data/dataset/spiqa/images/1809.01989v2/1809.01989v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the highest tracking accuracy in terms of minimizing the sum of absolute percentage errors? Does this necessarily mean it had the best overall performance?", "reference_answer": "The Ridge method achieved the lowest sum of absolute percentage errors (136.84), indicating the highest tracking accuracy in terms of minimizing absolute deviations from the index. However, this doesn't necessarily translate to the best overall performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "17445524-df8b-56e1-93d3-8db515217e80", "question": "what is the state of the art?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3a375f59-7b2b-592b-9e01-81d5e3475ca7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.06757/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.06757/3-Figure1-1.png", "data/dataset/spiqa/images/1608.06757/5-Table1-1.png", "data/dataset/spiqa/images/1608.06757/6-Table2-1.png", "data/dataset/spiqa/images/1608.06757/7-Table3-1.png", "data/dataset/spiqa/images/1608.06757/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what is the state of the art?", "reference_answer": "Babelfy, DBpedia Spotlight, Entityclassifier.eu, FOX, LingPipe MUC-7, NERD-ML, Stanford NER, TagMe 2", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "80f55052-db10-5a0c-a8d9-6bb837add4f9", "question": "What language is explored in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1b9157dc-b5be-5eac-8a33-1b106885ce74"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.09215/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.09215/2-Figure1-1.png", "data/dataset/spiqa/images/2001.09215/2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What language is explored in this paper?", "reference_answer": "English language", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e9612582-129a-5aef-8717-ec5c66effeca", "question": "How does the dimension of embedding affect the AUC of RippleNet on MovieLens-1M?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the dimension of embedding affect the AUC of RippleNet on MovieLens-1M?", "reference_answer": "The AUC of RippleNet first increases and then decreases with the increase of the dimension of embedding."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1022482f-b9ae-53bd-b5a1-734e1ba1dbc7", "question": "How does the RL policy compare to the baseline in terms of index blocks accessed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5236776a-47d8-5fdc-9606-592245a5a1ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure1-1.png", "data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure2-1.png", "data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the RL policy compare to the baseline in terms of index blocks accessed?", "reference_answer": "The RL policy accesses fewer index blocks than the baseline."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9014cf3c-5755-5532-9f97-272bb3ed11c7", "question": "How better is accuracy of new model compared to previously reported models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ac614423-9d32-500a-b4e9-b74aac0d8979"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.08859/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.08859/2-Figure1-1.png", "data/dataset/spiqa/images/1909.08859/3-Figure2-1.png", "data/dataset/spiqa/images/1909.08859/5-Figure3-1.png", "data/dataset/spiqa/images/1909.08859/7-Figure4-1.png", "data/dataset/spiqa/images/1909.08859/7-Table1-1.png", "data/dataset/spiqa/images/1909.08859/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How better is accuracy of new model compared to previously reported models?", "reference_answer": "Average accuracy of proposed model vs best prevous result:\nSingle-task Training: 57.57 vs 55.06\nMulti-task Training: 50.17 vs 50.59", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "738442e4-81e6-5599-85df-3602173fa652", "question": "Author took batch_size to be 16 with 50 epochs while training the model . What was the intution behind taking these particular numbers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Author took batch_size to be 16 with 50 epochs while training the model . What was the intution behind taking these particular numbers?", "reference_answer": "Using grid search the batch_size and epochs is determined. Since these are the optimal value hence used in the training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "228e107d-c20b-50bd-b9ce-a18ef2f81696", "question": "Which actions are most challenging for the network to recognize, and how do the proposed methods improve the performance on these actions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f290ed70-eb81-598b-aa2d-1920fc19428f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Table1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure3-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure9-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure10-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which actions are most challenging for the network to recognize, and how do the proposed methods improve the performance on these actions?", "reference_answer": "The actions that are most challenging for the network to recognize are those that include moving directions, such as \"person, move toward (home)\", \"person, move away (home)\", and \"vehicle, move toward (person)\". The proposed methods, distance-based place discretization (DD) and topological feature aggregation (Topo-Agg), significantly improve the average precision on almost all action categories, especially those that are more challenging and are associated with moving directions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "86293031-5fd4-572d-88db-3ee883a8a145", "question": "What is the effect of replacing the loss function in the \"Baseline\" network with the \"adaptive\" loss over wavelet coefficients?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of replacing the loss function in the \"Baseline\" network with the \"adaptive\" loss over wavelet coefficients?", "reference_answer": "Replacing the loss function in the \"Baseline\" network with the \"adaptive\" loss over wavelet coefficients results in significantly improved depth estimates."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "26991b68-4028-5ba9-9df7-ecdddad5457a", "question": "What results do they achieve using their proposed approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["836657b7-d657-5f24-a0b2-9463d99e8e3a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.10503/5-Figure3-1.png", "data/dataset/spiqa/images/1904.10503/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.10503/2-Table1-1.png", "data/dataset/spiqa/images/1904.10503/2-Figure1-1.png", "data/dataset/spiqa/images/1904.10503/4-Figure2-1.png", "data/dataset/spiqa/images/1904.10503/5-Figure3-1.png", "data/dataset/spiqa/images/1904.10503/5-Table2-1.png", "data/dataset/spiqa/images/1904.10503/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What results do they achieve using their proposed approach?", "reference_answer": "F-1 score on the OntoNotes is 88%, and it is 53% on Wiki (gold).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ce20f13a-c48f-557a-af18-0fd317775a82", "question": "What types of non-linearities is used for both layers of the depthwise separable convolution?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What types of non-linearities is used for both layers of the depthwise separable convolution?", "reference_answer": "MobileNet layers use batchnorm and ReLU nonlinearities."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "016f1d93-9946-5b48-9970-0a256af4f855", "question": "What is the relationship between the novel class and the top-3 most similar base classes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["77db890f-c739-5abc-a1af-4cdaee857323"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the novel class and the top-3 most similar base classes?", "reference_answer": "The top-3 most similar base classes are the three classes that are most similar to the novel class, based on the embedding layer in a 5-shot setting."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d23f33f8-d497-5f42-8754-47406fd3e59f", "question": "How does the running time of GB-KM vary with the F-1 score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the running time of GB-KM vary with the F-1 score?", "reference_answer": "The running time of GB-KM increases as the F-1 score increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "862adb6a-c9ed-5a5d-bc50-5e37ae4daf2b", "question": "Are there conceptual benefits to using GCNs over more complex architectures like attention?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["2c7eb87f-1157-5321-865a-644ce9d0cc78"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.06906/3-Figure1-1.png", "data/dataset/spiqa/images/1905.06906/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.06906/3-Figure1-1.png", "data/dataset/spiqa/images/1905.06906/5-Figure2-1.png", "data/dataset/spiqa/images/1905.06906/7-Table1-1.png", "data/dataset/spiqa/images/1905.06906/8-Table2-1.png", "data/dataset/spiqa/images/1905.06906/8-Table3-1.png", "data/dataset/spiqa/images/1905.06906/8-Table4-1.png", "data/dataset/spiqa/images/1905.06906/9-Table5-1.png", "data/dataset/spiqa/images/1905.06906/10-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are there conceptual benefits to using GCNs over more complex architectures like attention?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "afaad0e6-3f7f-55ef-af6c-7bc31b875775", "question": "What neural machine translation models can learn in terms of transfer learning?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["112592e0-4fb6-501f-b686-0e9c72ded87c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.00273/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.00273/3-Figure1-1.png", "data/dataset/spiqa/images/1802.00273/4-Figure2-1.png", "data/dataset/spiqa/images/1802.00273/6-Figure3-1.png", "data/dataset/spiqa/images/1802.00273/7-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What neural machine translation models can learn in terms of transfer learning?", "reference_answer": "Multilingual Neural Machine Translation Models", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6895ebb5-cb2e-52ad-8fb6-e931ecfa7d13", "question": "What factors could the authors have used while deciding the number of specialists to allocate for their task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52fc556e-8d5a-59cf-a7ce-b06619201667"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/5-Table1-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/6-Table2-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table3-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table4-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What factors could the authors have used while deciding the number of specialists to allocate for their task?", "reference_answer": "P0: Through results shown in Table 4, the authors saw a general trend that accuracy improved when more specialists covered a particular class. This could have been a factor that authors considered in deciding on the number of specialists for their task."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d8ab14d4-00d0-5244-a22a-aa83cd6611f2", "question": "what was the baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7d95941e-72b5-59dc-aaa8-a844e57069ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.03060/10-Table13-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.03060/2-Table1-1.png", "data/dataset/spiqa/images/1907.03060/3-Table2-1.png", "data/dataset/spiqa/images/1907.03060/4-Table3-1.png", "data/dataset/spiqa/images/1907.03060/5-Table4-1.png", "data/dataset/spiqa/images/1907.03060/6-Table5-1.png", "data/dataset/spiqa/images/1907.03060/6-Table6-1.png", "data/dataset/spiqa/images/1907.03060/7-Table7-1.png", "data/dataset/spiqa/images/1907.03060/7-Table8-1.png", "data/dataset/spiqa/images/1907.03060/8-Table9-1.png", "data/dataset/spiqa/images/1907.03060/8-Table10-1.png", "data/dataset/spiqa/images/1907.03060/9-Table11-1.png", "data/dataset/spiqa/images/1907.03060/10-Table12-1.png", "data/dataset/spiqa/images/1907.03060/10-Table13-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what was the baseline?", "reference_answer": "M2M Transformer", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "badafaab-2d31-5b73-b4b2-4346c53f9c5e", "question": "What is the relationship between the feature maps of $\\sigma$ and $\\mu$ and the sampled vector?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the feature maps of $\\sigma$ and $\\mu$ and the sampled vector?", "reference_answer": "The sampled vector is element-wise multiplied by the feature map of $\\sigma$ and added to the feature map of $\\mu$."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f1bded5b-e8ba-5fd1-b1d9-2ac244567007", "question": "What stylistic features are used to detect drunk texts?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3bb937a0-4a80-51d3-84fd-f9e14eb336f7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1610.00879/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1610.00879/2-Figure1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table2-1.png", "data/dataset/spiqa/images/1610.00879/4-Table4-1.png", "data/dataset/spiqa/images/1610.00879/4-Table3-1.png", "data/dataset/spiqa/images/1610.00879/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What stylistic features are used to detect drunk texts?", "reference_answer": "LDA unigrams (Presence/Count), POS Ratio, #Named Entity Mentions, #Discourse Connectors, Spelling errors, Repeated characters, Capitalization, Length, Emoticon (Presence/Count), Sentiment Ratio.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "57c2cead-7cc6-5c37-b7c1-3ec84b279af5", "question": "Which model has the highest test accuracy on the SNLI dataset, and how does its training time per epoch compare to the MTSA model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e12c7d24-8cfc-57b1-b048-9a36c5251d57"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table3-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table4-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table5-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table6-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model has the highest test accuracy on the SNLI dataset, and how does its training time per epoch compare to the MTSA model?", "reference_answer": "The model with the highest test accuracy is MTSA, with an accuracy of 86.3%. Its training time per epoch is 180s, which is faster than the training time of several other models with lower accuracy, such as Bi-LSTM (854s), Bi-GRU (850s), and DiSA (390s)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "539809e8-6bfe-519f-a8fb-08490f1646d7", "question": "How does the variance of the hidden state $h_t$ compare to the variance of the input $x_t$ in deep layers of the SRU model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the variance of the hidden state $h_t$ compare to the variance of the input $x_t$ in deep layers of the SRU model?", "reference_answer": "According to the passage, the variance of the hidden state is approximately equal to the variance of the input in deep layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9d538a29-49d2-5c9f-beff-d7142136f1ba", "question": "What was the score of the proposed model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bb612307-6486-5f20-b595-193493d74eca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.07904/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.07904/2-Figure1-1.png", "data/dataset/spiqa/images/1904.07904/2-Figure2-1.png", "data/dataset/spiqa/images/1904.07904/3-Table1-1.png", "data/dataset/spiqa/images/1904.07904/4-Table3-1.png", "data/dataset/spiqa/images/1904.07904/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was the score of the proposed model?", "reference_answer": "Best results authors obtain is EM 51.10 and F1 63.11", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "82070f0a-bf45-55b6-b661-2e156ab67737", "question": "Is CRWIZ already used for data collection, what are the results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8150251b-062b-51df-b4a0-c45ac800066e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.05995/6-Figure4-1.png", "data/dataset/spiqa/images/2003.05995/6-Figure5-1.png", "data/dataset/spiqa/images/2003.05995/8-Table4-1.png", "data/dataset/spiqa/images/2003.05995/7-Table2-1.png", "data/dataset/spiqa/images/2003.05995/7-Table3-1.png", "data/dataset/spiqa/images/2003.05995/9-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.05995/3-Table1-1.png", "data/dataset/spiqa/images/2003.05995/4-Figure1-1.png", "data/dataset/spiqa/images/2003.05995/5-Figure2-1.png", "data/dataset/spiqa/images/2003.05995/5-Figure3-1.png", "data/dataset/spiqa/images/2003.05995/6-Figure4-1.png", "data/dataset/spiqa/images/2003.05995/6-Figure5-1.png", "data/dataset/spiqa/images/2003.05995/7-Table2-1.png", "data/dataset/spiqa/images/2003.05995/7-Table3-1.png", "data/dataset/spiqa/images/2003.05995/8-Table4-1.png", "data/dataset/spiqa/images/2003.05995/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is CRWIZ already used for data collection, what are the results?", "reference_answer": "Yes, CRWIZ has been used for data collection and its initial use resulted in 145 dialogues. The average time taken for the task was close to the estimate of 10 minutes, 14 dialogues (9.66%) resolved the emergency in the scenario, and these dialogues rated consistently higher in subjective and objective ratings than those which did not resolve the emergency. Qualitative results showed that participants believed that they were interacting with an automated assistant.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2d63125a-733c-578b-95b2-55459e348836", "question": "what were the baselines?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c12bf5b-324a-5590-a335-fef7eeb62513"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.05280/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.05280/1-Figure1-1.png", "data/dataset/spiqa/images/1901.05280/2-Table1-1.png", "data/dataset/spiqa/images/1901.05280/4-Figure2-1.png", "data/dataset/spiqa/images/1901.05280/5-Table2-1.png", "data/dataset/spiqa/images/1901.05280/5-Table3-1.png", "data/dataset/spiqa/images/1901.05280/6-Table4-1.png", "data/dataset/spiqa/images/1901.05280/7-Table5-1.png", "data/dataset/spiqa/images/1901.05280/7-Table6-1.png", "data/dataset/spiqa/images/1901.05280/7-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what were the baselines?", "reference_answer": "2008 Punyakanok et al. \n2009 Zhao et al. + ME \n2008 Toutanova et al. \n2010 Bjorkelund et al.  \n2015 FitzGerald et al. \n2015 Zhou and Xu \n2016 Roth and Lapata \n2017 He et al. \n2017 Marcheggiani et al.\n2017 Marcheggiani and Titov \n2018 Tan et al. \n2018 He et al. \n2018 Strubell et al. \n2018 Cai et al. \n2018 He et al. \n2018 Li et al. \n", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "54af3afc-f98c-5b2c-bbf5-4ea54d6c10cb", "question": "How do they analyze contextual similaries across datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["343ce20e-e7d7-590e-aa92-f90f9cfeab0a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.02073/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.02073/2-Table1-1.png", "data/dataset/spiqa/images/1801.02073/3-Table2-1.png", "data/dataset/spiqa/images/1801.02073/3-Figure1-1.png", "data/dataset/spiqa/images/1801.02073/3-Figure2-1.png", "data/dataset/spiqa/images/1801.02073/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they analyze contextual similaries across datasets?", "reference_answer": "They compare the tasks that the datasets are suitable for, average number of answer candidates per question, number of token types, average answer candidate lengths, average question lengths, question-answer word overlap.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e79d2d73-564e-5747-8b97-db5e5d319dcb", "question": "How does the performance of the discriminator in the proposed approach compare to the conventional discriminator in AL? What evidence suggests this difference in performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bf33c3ac-b6da-5fbf-b95a-d731d0dfd2f0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table2-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table4-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table3-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table5-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the discriminator in the proposed approach compare to the conventional discriminator in AL? What evidence suggests this difference in performance?", "reference_answer": "The discriminator in the author's approach achieves higher accuracy (95.72%) compared to the conventional discriminator in AL (94.01%)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b6f19e03-2faf-5a35-a708-4799d1a7eebb", "question": "On top of BERT does the RNN layer work better or the transformer layer?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1a4c5654-a59f-5196-9140-64d46785d6b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.10781/4-Table3-1.png", "data/dataset/spiqa/images/1910.10781/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.10781/2-Figure1-1.png", "data/dataset/spiqa/images/1910.10781/3-Figure2-1.png", "data/dataset/spiqa/images/1910.10781/4-Table2-1.png", "data/dataset/spiqa/images/1910.10781/4-Table3-1.png", "data/dataset/spiqa/images/1910.10781/4-Figure3-1.png", "data/dataset/spiqa/images/1910.10781/4-Table1-1.png", "data/dataset/spiqa/images/1910.10781/5-Table4-1.png", "data/dataset/spiqa/images/1910.10781/5-Table5-1.png", "data/dataset/spiqa/images/1910.10781/5-Figure4-1.png", "data/dataset/spiqa/images/1910.10781/5-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "On top of BERT does the RNN layer work better or the transformer layer?", "reference_answer": "The transformer layer", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2b94a45a-9827-501f-80fb-a5e058ea9071", "question": "Which dataset shows the greatest sensitivity to the choice of $\\power$?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset shows the greatest sensitivity to the choice of $\\power$?", "reference_answer": "RCV1"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fcce39f9-360e-5ff7-9e4b-815017c30329", "question": "What are the differences between the results of the monocular 3D body prediction network trained with different dataset combinations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the differences between the results of the monocular 3D body prediction network trained with different dataset combinations?", "reference_answer": "The results of the monocular 3D body prediction network trained with different dataset combinations show that the Up3d+HUMBI dataset combination produces the most accurate results. This is evident in the images where the predicted 3D body poses are closer to the ground-truth poses than the other dataset combinations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "de17739e-40f1-5fa5-8870-93770f4d1680", "question": "What is the relationship between the variables in the Compositional Active Basis Model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["be0ab42f-3812-52ff-8345-282868119291"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure4-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure5-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the variables in the Compositional Active Basis Model?", "reference_answer": "The variables in the Compositional Active Basis Model are hierarchically dependent. The variables at each layer are dependent on the variables at the layer above it."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f2d95e94-b654-5946-ad80-a022fa8bd51f", "question": "Which modality achieved the highest top-1 accuracy in the multi-shot evaluation on TUM-GAID?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which modality achieved the highest top-1 accuracy in the multi-shot evaluation on TUM-GAID?", "reference_answer": "Body Depth & Head RGB (ms: LSTM & RTA)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "82fb41b2-e588-595c-94a6-8f7087379850", "question": "How does the performance of LSTNet-attn vary with the horizon on the Solar-Energy dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of LSTNet-attn vary with the horizon on the Solar-Energy dataset?", "reference_answer": "The performance of LSTNet-attn generally improves as the horizon increases on the Solar-Energy dataset. This is evident from the fact that both the RMSE and correlation values improve with increasing horizon."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d51ab5da-487c-5dc9-bd3a-ff16fa60c8c5", "question": "How much better than the baseline is LiLi?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a59c5b1f-9720-59f7-9c5d-5f97693017f1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.06024/8-Table6-1.png", "data/dataset/spiqa/images/1802.06024/8-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.06024/3-Figure1-1.png", "data/dataset/spiqa/images/1802.06024/5-Table2-1.png", "data/dataset/spiqa/images/1802.06024/5-Table3-1.png", "data/dataset/spiqa/images/1802.06024/7-Table4-1.png", "data/dataset/spiqa/images/1802.06024/8-Table5-1.png", "data/dataset/spiqa/images/1802.06024/8-Table6-1.png", "data/dataset/spiqa/images/1802.06024/9-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much better than the baseline is LiLi?", "reference_answer": "In case of Freebase knowledge base, LiLi model had better F1 score than the single model by 0.20 , 0.01, 0.159 for kwn, unk, and all test Rel type.  The values for WordNet are 0.25, 0.1, 0.2. \n", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c27fe390-ff9f-5046-a673-0a78452c6574", "question": "What is an example of a health-related tweet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["fa46a9c2-4fb0-5885-8441-f730f7bdc018"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00439/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00439/2-TableI-1.png", "data/dataset/spiqa/images/1901.00439/3-Figure1-1.png", "data/dataset/spiqa/images/1901.00439/5-Figure2-1.png", "data/dataset/spiqa/images/1901.00439/6-Figure3-1.png", "data/dataset/spiqa/images/1901.00439/6-TableII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is an example of a health-related tweet?", "reference_answer": "The health benefits of alcohol consumption are more limited than previously thought, researchers say", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "95e4a262-8603-5ca2-9df2-41b9d63d76b8", "question": "How many layers does their system have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43d86e1b-d8b3-55d5-a16f-bcdcfd2657fd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.11402/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.11402/2-Table1-1.png", "data/dataset/spiqa/images/2002.11402/3-Table2-1.png", "data/dataset/spiqa/images/2002.11402/3-Table3-1.png", "data/dataset/spiqa/images/2002.11402/3-Figure1-1.png", "data/dataset/spiqa/images/2002.11402/6-Table4-1.png", "data/dataset/spiqa/images/2002.11402/6-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many layers does their system have?", "reference_answer": "4 layers", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b7748648-4d31-53d1-8668-858a3d8c7983", "question": "What is the role of the self-correction module in the segmentation framework?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the self-correction module in the segmentation framework?", "reference_answer": "The self-correction module refines the segmentations generated by the ancillary and current primary model for the weak set."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7bd16597-9eff-51ee-a2d4-f1f1e634788a", "question": "What is the difference between the pick and place task in simulation and the real world?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bd1cf1c1-2268-50fb-a8af-8321d7a864ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the pick and place task in simulation and the real world?", "reference_answer": "In the simulation, the robot is able to pick up the object and place it in the desired location without any errors. However, in the real world, the robot makes some errors, such as dropping the object or placing it in the wrong location."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "72bf10db-319e-54f3-b46e-8e78f62e664d", "question": "What is the role of the BiLSTM in the architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6d2648a6-db41-5a23-9cb0-92c59be4fbc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table1-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table2-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table4-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table3-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the BiLSTM in the architecture?", "reference_answer": "The BiLSTM takes as input the character-level representations of the words and outputs a word-level representation for each word."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "db795dd5-051f-5ea0-8491-a4167924096b", "question": "Which topology has the highest transmission rate for GMap 100%?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which topology has the highest transmission rate for GMap 100%?", "reference_answer": "Mesh"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3a47fcd0-3a6c-598c-a0db-41062bf94325", "question": "What are the results from these proposed strategies?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3cf568c1-699a-58bc-bedc-0ed2e4d796db"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.08795/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.08795/2-Figure1-1.png", "data/dataset/spiqa/images/2002.08795/4-Figure2-1.png", "data/dataset/spiqa/images/2002.08795/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the results from these proposed strategies?", "reference_answer": "Reward of 11.8 for the A2C-chained model, 41.8 for the KG-A2C-chained model, 40 for A2C-Explore and 44 for KG-A2C-Explore.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c342c1bd-7c1b-562b-9fc1-b6e87b0debdf", "question": "By how much does their best model outperform the state-of-the-art?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b31e4f8d-6221-54a9-8e27-e5f8eb5d5588"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07333/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07333/3-Figure1-1.png", "data/dataset/spiqa/images/1605.07333/3-Figure2-1.png", "data/dataset/spiqa/images/1605.07333/4-Table1-1.png", "data/dataset/spiqa/images/1605.07333/5-Table2-1.png", "data/dataset/spiqa/images/1605.07333/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much does their best model outperform the state-of-the-art?", "reference_answer": "0.8% F1 better than the best state-of-the-art", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a92ee1d0-6aa8-5a05-871e-b0f9de827349", "question": "Which method achieved the most accurate results for simultaneous line and circle fitting?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the most accurate results for simultaneous line and circle fitting?", "reference_answer": "Multi-X achieved the most accurate results for simultaneous line and circle fitting."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e3d18752-9ef8-594c-a043-455d7454041b", "question": "Which eight NER tasks did they evaluate on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1c2e0a2c-3c92-53ff-9439-639ebdded4d7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.03354/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.03354/2-Table1-1.png", "data/dataset/spiqa/images/2004.03354/3-Table2-1.png", "data/dataset/spiqa/images/2004.03354/4-Figure1-1.png", "data/dataset/spiqa/images/2004.03354/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which eight NER tasks did they evaluate on?", "reference_answer": "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4077bac0-3a13-5035-926a-ac7f003c5bda", "question": "What is the relationship between the number of fixations and the CC score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2e451896-1a65-54a5-9d6c-886582d00353"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure7-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure1-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure4-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure6-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure5-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the number of fixations and the CC score?", "reference_answer": "The CC score increases as the number of fixations increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6791f62f-13a0-524d-a705-1c34fb5867fd", "question": "Do the methods that work best on academic papers also work best on Wikipedia?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["72250259-7097-560b-adbd-18551626f2e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.01010/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.01010/1-Figure1-1.png", "data/dataset/spiqa/images/1901.01010/3-Figure2-1.png", "data/dataset/spiqa/images/1901.01010/4-Table1-1.png", "data/dataset/spiqa/images/1901.01010/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the methods that work best on academic papers also work best on Wikipedia?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "35f5c2fe-b738-5dfa-b645-f8037ff80ecd", "question": "They perform only a qualitative analysis of the proposed model. Is it true?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6b94108c-7ba9-5d71-959f-889739e9041f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/2-Figure2-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/3-Figure3-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/5-Figure4-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/6-Figure5-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/7-Figure6-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/7-Table1-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/7-Table2-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/8-Figure7-1.png", "data/dataset/spiqa/images/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "They perform only a qualitative analysis of the proposed model. Is it true?", "reference_answer": "False. They provided not only qualitative analysis but also quantitive analysis for their model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "634145c1-038f-5c91-a1bf-0cd671213457", "question": "What accuracy score do they obtain?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0e9bcf90-d26d-5b40-a748-7a39f91eb3f1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.13066/9-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.13066/3-Table1-1.png", "data/dataset/spiqa/images/1911.13066/4-Figure1-1.png", "data/dataset/spiqa/images/1911.13066/7-Table2-1.png", "data/dataset/spiqa/images/1911.13066/9-Table3-1.png", "data/dataset/spiqa/images/1911.13066/10-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What accuracy score do they obtain?", "reference_answer": "the best performing model obtained an accuracy of 0.86", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1b851dee-8d28-593b-8f44-96813a5285bd", "question": "Do they test their approach on a dataset without incomplete data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["b0f8cb4c-5420-5ada-b490-7aed7819cfd1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.00137/11-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png", "data/dataset/spiqa/images/2001.00137/8-Table1-1.png", "data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/9-Table3-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png", "data/dataset/spiqa/images/2001.00137/11-Figure2-1.png", "data/dataset/spiqa/images/2001.00137/12-Table5-1.png", "data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/15-Figure3-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure4-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they test their approach on a dataset without incomplete data?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "45bc35c6-ecc1-5349-b66f-fba1d03be37c", "question": "Does the training dataset provide logical form supervision?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3360c1c7-a56e-54f2-ac82-75d1f159d221"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00574/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00574/2-Table1-1.png", "data/dataset/spiqa/images/1909.00574/3-Table2-1.png", "data/dataset/spiqa/images/1909.00574/4-Table3-1.png", "data/dataset/spiqa/images/1909.00574/6-Figure1-1.png", "data/dataset/spiqa/images/1909.00574/8-Table4-1.png", "data/dataset/spiqa/images/1909.00574/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the training dataset provide logical form supervision?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ee5965d8-2f66-5e20-8a68-a2faae3901bb", "question": "How does Action Search use temporal context to reason about where to search next?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6437feca-e73b-5ddd-a3f2-d94ef3737017"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure2-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure1-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure3-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure4-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure5-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does Action Search use temporal context to reason about where to search next?", "reference_answer": "Action Search uses temporal context to reason about where to search next by looking at the frames before and after the current frame. This allows the model to learn the temporal patterns of actions and to predict where the action is most likely to occur in the next frame."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "be46785e-2360-5127-9aa1-e99db0c64208", "question": "How many question types do they find in the datasets analyzed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["343ce20e-e7d7-590e-aa92-f90f9cfeab0a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.02073/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.02073/2-Table1-1.png", "data/dataset/spiqa/images/1801.02073/3-Table2-1.png", "data/dataset/spiqa/images/1801.02073/3-Figure1-1.png", "data/dataset/spiqa/images/1801.02073/3-Figure2-1.png", "data/dataset/spiqa/images/1801.02073/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many question types do they find in the datasets analyzed?", "reference_answer": "7", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6d08e33e-e435-5cc8-a89a-e5c58a7ded5a", "question": "What tasks were evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e9c1ece6-7be1-56f7-a742-69745a5f00d0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.12196/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.12196/4-Figure2-1.png", "data/dataset/spiqa/images/1810.12196/4-Figure1-1.png", "data/dataset/spiqa/images/1810.12196/5-Table1-1.png", "data/dataset/spiqa/images/1810.12196/6-Figure3-1.png", "data/dataset/spiqa/images/1810.12196/6-Figure4-1.png", "data/dataset/spiqa/images/1810.12196/6-Table2-1.png", "data/dataset/spiqa/images/1810.12196/7-Figure5-1.png", "data/dataset/spiqa/images/1810.12196/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What tasks were evaluated?", "reference_answer": "Detection of an aspect in a review, Prediction of the customer general satisfaction, Prediction of the global trend of an aspect in a given review, Prediction of whether the rating of a given aspect is above or under a given value, Prediction of the exact rating of an aspect in a review, Prediction of the list of all the positive/negative aspects mentioned in the review, Comparison between aspects, Prediction of the strengths and weaknesses in a review", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ad29b42f-0f61-589c-b2aa-bfcdb6e4b88e", "question": "How does the Multi-DPP module increase diversity within the selected time-steps?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1291db8d-1be8-551a-a360-7bedc5ef404a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure2-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table3-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table2-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table1-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the Multi-DPP module increase diversity within the selected time-steps?", "reference_answer": "The Multi-DPP module increases diversity within the selected time-steps by using a determinantal point process (DPP) to select a subset of diverse time-steps from the input sequence."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4e6b6bca-a6c8-5952-8cf0-246d7d5ef2cd", "question": " Which type of review was more accurately identified by the human evaluators, human-written or machine-generated? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d2f53917-bc62-5131-9eb4-af4a7211b645"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure8-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure9-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table4-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure10-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure4-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure5-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table3-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table9-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure6-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure1-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table1-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure12-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure7-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table7-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table5-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table8-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table6-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure11-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " Which type of review was more accurately identified by the human evaluators, human-written or machine-generated? ", "reference_answer": "The human evaluators were more accurate at identifying human-written reviews than machine-generated reviews."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "dd0fb75b-dfd8-5ddd-b98c-076b27dc8cec", "question": "Which two datasets does the resource come from?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["81ae03e3-f3c3-5bdc-9ba7-0de63b49cc86"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.02494/2-Figure1-1.png", "data/dataset/spiqa/images/1809.02494/2-Figure2-1.png", "data/dataset/spiqa/images/1809.02494/2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.02494/2-Figure1-1.png", "data/dataset/spiqa/images/1809.02494/2-Figure3-1.png", "data/dataset/spiqa/images/1809.02494/2-Table1-1.png", "data/dataset/spiqa/images/1809.02494/2-Figure2-1.png", "data/dataset/spiqa/images/1809.02494/3-Figure4-1.png", "data/dataset/spiqa/images/1809.02494/3-Figure5-1.png", "data/dataset/spiqa/images/1809.02494/4-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which two datasets does the resource come from?", "reference_answer": "two surveys by two groups - school students and meteorologists to draw on a map a polygon representing a given geographical descriptor", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a54d2937-ad02-57ac-af72-81337ca5d495", "question": "To what other competitive baselines is this approach compared?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b41b7931-53be-5e7a-8212-3814f3858231"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.05467/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.05467/3-Figure1-1.png", "data/dataset/spiqa/images/2001.05467/3-Figure2-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure3-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure4-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure5-1.png", "data/dataset/spiqa/images/2001.05467/5-Table1-1.png", "data/dataset/spiqa/images/2001.05467/5-Figure6-1.png", "data/dataset/spiqa/images/2001.05467/6-Table2-1.png", "data/dataset/spiqa/images/2001.05467/6-Table3-1.png", "data/dataset/spiqa/images/2001.05467/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "To what other competitive baselines is this approach compared?", "reference_answer": "LSTMs with and without attention, HRED, VHRED with and without attention, MMI and Reranking-RL", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ca4eea7b-77dc-54d1-8a62-a65cb17eaa99", "question": "Which genre in the MultiNLI corpus has the highest percentage of sentences where the Stanford Parser produced a parse rooted with an 'S' (sentence) node, and how does this compare to the overall average for the corpus?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ab8d017f-8645-5337-aa84-f52783391b99"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table4-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Figure1-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table5-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table2-1.png", "data/dataset/spiqa/images/1704.05426v4/1704.05426v4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which genre in the MultiNLI corpus has the highest percentage of sentences where the Stanford Parser produced a parse rooted with an 'S' (sentence) node, and how does this compare to the overall average for the corpus?", "reference_answer": "The genre with the highest percentage of 'S' parses is **9/11**, with **99%** of its sentences receiving this parse. This is higher than the overall average for the MultiNLI corpus, which sits at **91%**."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a6ba3cbe-376c-51a0-8267-25e514d78cf0", "question": "Which method achieved the highest accuracy on the Italian language data set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d2648a6-db41-5a23-9cb0-92c59be4fbc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table1-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table2-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table4-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table3-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the highest accuracy on the Italian language data set?", "reference_answer": "Variational J^var (7)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ce3ca525-e955-50e0-a551-05b732e3162c", "question": "What is the probability of finding the pattern {head=F, ant=NAM} in the data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["16d4f6a4-5643-545d-8d8d-cba855ef6f62"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table7-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the probability of finding the pattern {head=F, ant=NAM} in the data?", "reference_answer": "1"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c6065857-5f58-5b9e-b79c-fabe5e094f27", "question": "How long are the essays on average?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["20a6a8bb-4530-596f-bb20-a85794e4b4c7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.11346/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.11346/2-Table1-1.png", "data/dataset/spiqa/images/1804.11346/3-Figure1-1.png", "data/dataset/spiqa/images/1804.11346/3-Table2-1.png", "data/dataset/spiqa/images/1804.11346/3-Table3-1.png", "data/dataset/spiqa/images/1804.11346/4-Figure2-1.png", "data/dataset/spiqa/images/1804.11346/4-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How long are the essays on average?", "reference_answer": "204 tokens", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2b11965d-4639-5541-a06d-5a907c240986", "question": "What is the purpose of the ancillary heatmap shown in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the ancillary heatmap shown in this paper?", "reference_answer": "The ancillary heatmap is used to correct the labels for missing or oversegmented objects in the images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f6735446-0ce2-509b-82c3-2aa6f942974d", "question": "Do α control the strength of the length normalization and β control the strength of the coverage penalty each other?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Do α control the strength of the length normalization and β control the strength of the coverage penalty each other?", "reference_answer": "Yes, Authors found that \"α\" which represents the strength of length normalization and \"β\" which represents coverage penalty are less effective for models with RLrefinment, and improved the original heuristic  by dividing length to the power of α with 0 < α < 1 where α ∈ [0.6 − 0.7] on development set which usually found to be best."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d7d69d4b-d8f0-50bf-8eeb-c462db77556b", "question": "Which embedding method performed the best overall across all model architectures on the Visual7W dataset with IoU + QoU decoys? Was there a significant difference in performance compared to the other methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which embedding method performed the best overall across all model architectures on the Visual7W dataset with IoU + QoU decoys? Was there a significant difference in performance compared to the other methods?", "reference_answer": "The MLP-IQA model achieved the highest accuracy across all embedding methods, reaching 52.5% with GloVe, 51.4% with Translation embeddings, and 52.0% with word2vec. However, the passage notes that there was no significant difference in performance between the different embedding methods."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c53ccc18-16b9-5195-a92d-d801f7f8f226", "question": "What is the most common type of scene in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the most common type of scene in the dataset?", "reference_answer": "City Street"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5a0d4572-bef4-5db2-bd63-52c860b7f87d", "question": "Which node in the generative model represents the latent variable?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which node in the generative model represents the latent variable?", "reference_answer": "The node labeled η represents the latent variable."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d6b0ff9b-80bb-5d9c-9d61-75aaddf9e7ff", "question": "What are previous state of the art results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de9bbc10-18e9-585e-9338-025e9bc604a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.11910/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.11910/2-Figure1-1.png", "data/dataset/spiqa/images/2002.11910/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are previous state of the art results?", "reference_answer": "Overall F1 score:\n- He and Sun (2017) 58.23\n- Peng and Dredze (2017) 58.99\n- Xu et al. (2018) 59.11", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "55937e99-dfdd-5bf3-836d-a0ef1aeae502", "question": "Does DCA or GMM-based attention perform better in experiments?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0cd528af-6c69-5150-bbcc-6142ec3c453a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.10288/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.10288/2-Table2-1.png", "data/dataset/spiqa/images/1910.10288/2-Table1-1.png", "data/dataset/spiqa/images/1910.10288/3-Figure1-1.png", "data/dataset/spiqa/images/1910.10288/3-Figure2-1.png", "data/dataset/spiqa/images/1910.10288/4-Figure3-1.png", "data/dataset/spiqa/images/1910.10288/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does DCA or GMM-based attention perform better in experiments?", "reference_answer": "About the same performance", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3b60ae7b-b868-5faf-af87-b9f7d5ea9a46", "question": "What dataset did they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["447437fc-c974-5df6-b709-a8af1023407d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.03569/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.03569/2-Table1-1.png", "data/dataset/spiqa/images/1707.03569/3-Figure1-1.png", "data/dataset/spiqa/images/1707.03569/3-Table2-1.png", "data/dataset/spiqa/images/1707.03569/5-Table3-1.png", "data/dataset/spiqa/images/1707.03569/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What dataset did they use?", "reference_answer": " high-quality datasets  from SemEval-2016 “Sentiment Analysis in Twitter” task", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "99e550aa-f1f5-5f6d-a5fa-4c987db89c17", "question": "Does the Agent ask for a value of a variable using natural language generated text?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["77a39bd8-8d64-5230-9ff0-d9c17e1e48dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01776/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01776/3-Figure1-1.png", "data/dataset/spiqa/images/1708.01776/4-Figure2-1.png", "data/dataset/spiqa/images/1708.01776/4-Figure3-1.png", "data/dataset/spiqa/images/1708.01776/5-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the Agent ask for a value of a variable using natural language generated text?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bf9fc8f1-b98a-5eee-9e54-fa12bfd1fdb2", "question": "Which coreference model performs best on the CoNLL test set according to the F$_1$ score? Is this performance statistically significant compared to all other models in the table?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["16d4f6a4-5643-545d-8d8d-cba855ef6f62"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table7-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which coreference model performs best on the CoNLL test set according to the F$_1$ score? Is this performance statistically significant compared to all other models in the table?", "reference_answer": "The \"ensemble\" model of e2ef achieves the highest F$_1$ score of 68.83 on the CoNLL test set. Yes, this performance is statistically significant compared to all other models listed in the table, as indicated by the caption and footnote referencing the approximate randomization test."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3a66a934-1b88-5ff8-959d-6ea21a837276", "question": "How is complexity calculated given scale factor of the ShuffleNet model? Given scale factor 0.25 and complexity of ShuffleNet 1x is 140 MFLOPS", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How is complexity calculated given scale factor of the ShuffleNet model? Given scale factor 0.25 and complexity of ShuffleNet 1x is 140 MFLOPS", "reference_answer": "As it is shown in Table 2, the complexity of ShufflNet 0.25x will be 13 MFLOPs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "744325c4-caf7-5683-a464-2cc6b468e0aa", "question": "How does their model learn using mostly raw data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How does their model learn using mostly raw data?", "reference_answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ed988b08-68ca-5903-bca6-e6b7b1b8a00b", "question": "How much is performance improved on NLI?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c01a5f98-2546-5db6-beab-947cbc49a7bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.03405/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.03405/3-Figure1-1.png", "data/dataset/spiqa/images/1909.03405/4-Table1-1.png", "data/dataset/spiqa/images/1909.03405/5-Table2-1.png", "data/dataset/spiqa/images/1909.03405/5-Table3-1.png", "data/dataset/spiqa/images/1909.03405/5-Figure2-1.png", "data/dataset/spiqa/images/1909.03405/6-Figure3-1.png", "data/dataset/spiqa/images/1909.03405/6-Table4-1.png", "data/dataset/spiqa/images/1909.03405/7-Table5-1.png", "data/dataset/spiqa/images/1909.03405/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much is performance improved on NLI?", "reference_answer": "The average score improved by 1.4 points over the previous best result.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "59721abc-f67b-51cf-9b4d-37717cb93289", "question": "What can you say about the relationship between the sentences in a document based on the t-SNE embeddings?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["510d6fc0-d3e0-5dc1-8e0d-4d470f964287"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table4-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table3-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Figure2-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table5-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table1-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What can you say about the relationship between the sentences in a document based on the t-SNE embeddings?", "reference_answer": "Sentences that are closer together in the embedding space are more semantically similar than those that are farther apart."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b7728048-ddcf-522a-948a-3caef52d8200", "question": "What is the relationship between the Silver Snatch and the Gold Snatch?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["72b0d1a9-3397-5940-bf4b-b5fdf8480554"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure3-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure4-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure5-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table1-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the Silver Snatch and the Gold Snatch?", "reference_answer": "The Silver Snatch and the Gold Snatch are positively correlated. As the Gold Snatch increases, the Silver Snatch also increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c4388c8c-d6b8-5e4d-af71-5b5370490398", "question": "Which MCMC sampler appears to have the most consistent performance across the different variables?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["71d0c183-d868-5a29-b5a0-54579f2869e7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure2-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure1-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure7-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure9-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure10-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure6-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure4-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure3-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure8-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which MCMC sampler appears to have the most consistent performance across the different variables?", "reference_answer": "PE-HMC (N=5)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "889142de-5f6b-51f0-a29a-d6c1725a9edd", "question": "What is the relationship between BLEU score and human ranking for CCA and SMT systems?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between BLEU score and human ranking for CCA and SMT systems?", "reference_answer": "The correlation between BLEU scores and human ranking is not high for either CCA or SMT systems."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a493de8b-b52d-51c7-8330-f4971bf1c56b", "question": "What does the induced schema Win <A4, B3, C2> represent?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0369791-b574-5ff8-aaeb-89c221d8f857"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table4-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What does the induced schema Win <A4, B3, C2> represent?", "reference_answer": "The induced schema Win <A4, B3, C2> represents the fact that player A4 won tournament C2, defeating player B3."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4c2d5865-8cb9-5c7d-8e1e-10ae5f8c8f82", "question": "How do they correlate NED with emotional bond levels?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5e4ae97c-4cda-56e6-9861-8588c060ebc0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.08782/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.08782/2-Figure1-1.png", "data/dataset/spiqa/images/1804.08782/4-Table1-1.png", "data/dataset/spiqa/images/1804.08782/4-Figure2-1.png", "data/dataset/spiqa/images/1804.08782/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they correlate NED with emotional bond levels?", "reference_answer": "They compute Pearson’s correlation between NED measure for patient-to-therapist and patient-perceived emotional bond rating and NED measure for therapist-to-patient and patient-perceived emotional bond rating", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "27fbc9be-836b-53f2-959c-065bd637f70d", "question": "Which dataset requires the most storage space when using the LSH-E method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset requires the most storage space when using the LSH-E method?", "reference_answer": "REUTERS"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cb344a6a-339a-58a0-998c-b21ccc824d5c", "question": "How is convolution represented in the frequency domain?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How is convolution represented in the frequency domain?", "reference_answer": "In the frequency domain, convolution is represented by element-wise multiplication."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d7099a19-1b67-51b2-9317-34fb88ecc1e8", "question": "Which one of the four proposed models performed best?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b41b7931-53be-5e7a-8212-3814f3858231"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.05467/7-Table4-1.png", "data/dataset/spiqa/images/2001.05467/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.05467/3-Figure1-1.png", "data/dataset/spiqa/images/2001.05467/3-Figure2-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure3-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure4-1.png", "data/dataset/spiqa/images/2001.05467/4-Figure5-1.png", "data/dataset/spiqa/images/2001.05467/5-Table1-1.png", "data/dataset/spiqa/images/2001.05467/5-Figure6-1.png", "data/dataset/spiqa/images/2001.05467/6-Table2-1.png", "data/dataset/spiqa/images/2001.05467/6-Table3-1.png", "data/dataset/spiqa/images/2001.05467/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which one of the four proposed models performed best?", "reference_answer": "the hybrid model MinAvgOut + RL", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "82716d09-cb5e-5841-a628-ccd49ec8fb1b", "question": "What is the difference between the conventional semantic segmentation pipeline and the proposed framework for joint image denoising and semantic segmentation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0adb94de-50f5-51ff-8e1a-b2e3e72dcfd2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure5-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure2-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure4-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the conventional semantic segmentation pipeline and the proposed framework for joint image denoising and semantic segmentation?", "reference_answer": "The conventional semantic segmentation pipeline performs semantic segmentation directly on the noisy input image, while the proposed framework first denoises the image before performing semantic segmentation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "091e3acc-e727-5163-a72c-7b4fbf794f23", "question": "On the VQAv2-2017 validation set, which model performs best when considering all three sources of information (images, questions, and answers) and how does its performance compare to the model that only uses answers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "On the VQAv2-2017 validation set, which model performs best when considering all three sources of information (images, questions, and answers) and how does its performance compare to the model that only uses answers?", "reference_answer": "The model that performs best on VQAv2-2017 val when considering all three sources of information is MLP-IQA. It achieves an accuracy of 61.1% on the \\IU+\\QU -decoys metric, significantly outperforming the model that only uses answers (MLP-A) which achieves only 27.7% on the same metric. This demonstrates the importance of incorporating all available information for accurate prediction."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5b624f5a-74df-5b91-bd98-48dbfd0163b6", "question": "What is the relationship between the input patches and the generated images?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["570e01d8-2c85-5e04-b7e5-aef3f43f49b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure1-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure6-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure8-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure7-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure13-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure2-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure3-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure9-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure4-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure12-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure11-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure10-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the input patches and the generated images?", "reference_answer": "The input patches are used to generate the images. The generator network takes the input patches as input and generates new images that are similar to the input patches."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d001fd74-231d-563e-bf40-5af6ebbbd3d6", "question": "How do the authors verify that the two characteristics mentioned in the sentence are indispensable for the ideal control signal?  ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["60b654b7-5847-56a5-8aaf-2e22fb679dc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Figure5-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Figure6-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Table1-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/12-Table3-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/13-Figure8-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/13-Figure9-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/15-Table4-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/2-Figure2-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/4-Figure3-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/6-Figure4-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Figure5-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Figure6-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Table1-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/8-Figure7-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/8-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How do the authors verify that the two characteristics mentioned in the sentence are indispensable for the ideal control signal?  ", "reference_answer": "Authors verify their work using a conventions evaluation metrics in prior CIC works. As their quantitative results report in Table 1, you can observe that author's framework can achieve the best performance over almost all metrics and benchmarks. and as for the visualized evaluation, you can observe in Figure 5 that the author's framework always learns a human-like semantic structure based on the VSR and grounded visual regions. and according to the semantic structures, the captioning model can generate near-perfect descriptions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0914ee25-11cb-5fcb-9638-30977bd56f73", "question": "What is the effect of using CHER on the percentage of ads displayed for each user?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f16a3bd9-b17e-5e49-a098-482dcced698c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure9-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure4-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure5-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure6-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure7-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table2-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure8-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of using CHER on the percentage of ads displayed for each user?", "reference_answer": "The percentage of ads displayed for each user is higher when CHER is used."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "649a2e27-d381-5c35-90b3-39fcaa220de4", "question": "Which combination of initial list, model, and loss function achieved the best overall performance on the Yahoo! set 1, as measured by nDCG@10 and ERR@10?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4211b30e-5e8d-5449-8335-9f14cfeb4b9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table5-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which combination of initial list, model, and loss function achieved the best overall performance on the Yahoo! set 1, as measured by nDCG@10 and ERR@10?", "reference_answer": "LambdaMART initial list, DLCM model, and AttRank loss function achieved the best overall performance on the Yahoo! set 1, with an nDCG@10 of 0.743 and an ERR@10 of 0.453."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "90fa36a7-a4ec-5960-8d58-e38839ab94fe", "question": "Which dataset has the most concentrated distribution of gaze and head pose?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the most concentrated distribution of gaze and head pose?", "reference_answer": "MPII-Gaze"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6ad42ea2-b278-51e5-abbf-7d03cf3f963a", "question": "Which topic has the highest internal coherence value?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which topic has the highest internal coherence value?", "reference_answer": "The topic with the highest internal coherence value is \"turks armenian armenia turkish roads escape soviet muslim mountain soul\"."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "405d197f-d254-5fdd-8dbb-f13ad6506743", "question": "How does reattention affect the redundancy and deficiency of attention distributions? Can you explain the observed differences in the impact of reattention on different blocks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e31707d3-f5f4-5c59-86a2-af24ff7cfed7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does reattention affect the redundancy and deficiency of attention distributions? Can you explain the observed differences in the impact of reattention on different blocks?", "reference_answer": "This paper shows that reattention helps alleviate both redundancy and deficiency in attention distributions.\n\nRedundancy: Reattention increases the KL divergence between adjacent attention blocks, indicating that the attention distributions across blocks become more distinct and less redundant.\nDeficiency: Reattention reduces the KL divergence between the normalized attention distribution ($E^t$) and the ideal uniform distribution (${E^t}^*$), suggesting that the attention becomes more balanced and closer to the desired distribution.\nHowever, the improvement in redundancy is more pronounced between the first two blocks ($E^1$ to $E^2$) than the last two blocks ($B^2$ to $B^3$). This suggests that the first reattention is more effective in capturing word pair similarities using the original word representations. In contrast, the later reattention might be negatively impacted by the highly non-linear word representations generated in the previous layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "dcaffcb8-748c-5119-83bd-4a59a9750d1f", "question": "How does scaling correction affect the training of SRU models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does scaling correction affect the training of SRU models?", "reference_answer": "Scaling correction improves the training progress of SRU models, especially for deeper models with many stacked layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "07cf060e-63e7-573d-90de-ee36463ffc4e", "question": "how is mitigation of gender bias evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["215886c6-ec02-5302-8de7-9d92f49ef898"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.12801/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.12801/4-Table1-1.png", "data/dataset/spiqa/images/1905.12801/5-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "how is mitigation of gender bias evaluated?", "reference_answer": "Using INLINEFORM0 and INLINEFORM1", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "417f76c3-02c4-5fb1-8148-50689e5ac2bd", "question": "How can the shortcuts in the Visual7W dataset be remedied?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How can the shortcuts in the Visual7W dataset be remedied?", "reference_answer": "The shortcuts in the Visual7W dataset can be remedied by creating alternative decoys that are more likely to be correct, based on either the image or the question alone. This forces the machine to consider all of the information together in order to select the correct answer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0d001cba-926b-51f7-9b15-deb8a03e4979", "question": "What baseline model is used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3bb937a0-4a80-51d3-84fd-f9e14eb336f7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1610.00879/4-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1610.00879/2-Figure1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table2-1.png", "data/dataset/spiqa/images/1610.00879/4-Table4-1.png", "data/dataset/spiqa/images/1610.00879/4-Table3-1.png", "data/dataset/spiqa/images/1610.00879/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What baseline model is used?", "reference_answer": "Human evaluators", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "140d9133-5ae6-5207-b3a7-bd8865de22d5", "question": " How can Hint Network help with challenging auxiliary tasks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9ef1a4f5-340c-570d-b47d-59d921351b94"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/12-Table4-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/13-Table5-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/13-Table6-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/14-Figure4-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/4-Figure1-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/5-Figure2-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/7-Table1-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/7-Table2-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/8-Figure3-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": " How can Hint Network help with challenging auxiliary tasks?", "reference_answer": "The HintNet is designed to make challenging tasks more solvable by providing the model with additional information at the point of need, specifically by correcting the answer of the learner with its own answer from an augmented graph with hub nodes. The amount of help (correction) provided by the HintNet is optimized to maximize the learner's gain, and the help is determined by weighting functions for HintNet, which are optimized by meta-learning."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "86c9ab71-ef9e-599f-9fd8-529cb9d31c62", "question": "What discourse relations does it work best/worst for?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["09c6d9eb-b2ad-532d-9d53-a15719b1ecca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05918/6-Table1-1.png", "data/dataset/spiqa/images/1804.05918/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05918/4-Figure1-1.png", "data/dataset/spiqa/images/1804.05918/4-Figure2-1.png", "data/dataset/spiqa/images/1804.05918/5-Figure3-1.png", "data/dataset/spiqa/images/1804.05918/6-Table1-1.png", "data/dataset/spiqa/images/1804.05918/6-Table2-1.png", "data/dataset/spiqa/images/1804.05918/7-Table3-1.png", "data/dataset/spiqa/images/1804.05918/8-Table4-1.png", "data/dataset/spiqa/images/1804.05918/8-Table5-1.png", "data/dataset/spiqa/images/1804.05918/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What discourse relations does it work best/worst for?", "reference_answer": "Best: Expansion (Exp). Worst: Comparison (Comp).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7f7bf339-a158-5684-aff5-452dbbc327f9", "question": "How does the NegPair reduction vary with the number of perfect results in a query?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4211b30e-5e8d-5449-8335-9f14cfeb4b9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table4-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table5-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05936v2/1804.05936v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the NegPair reduction vary with the number of perfect results in a query?", "reference_answer": "The NegPair reduction generally increases as the number of perfect results in a query increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "69d1dcbf-a332-5ef3-be24-9ecc4f95a346", "question": "Do they experiment with the dataset?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["9dad9e4b-a3a3-53f7-8306-add047241bb4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.05310/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.05310/3-Table1-1.png", "data/dataset/spiqa/images/1612.05310/7-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they experiment with the dataset?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4c6d105d-06c7-5f51-8387-d74163f6b5a1", "question": "Can we enclose all appearances of prostate MRI volumes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Can we enclose all appearances of prostate MRI volumes?", "reference_answer": "Due to the training/testing and augmentation on the diverse set of prostate scans all appearances of prostate can be encoded with V-Net."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0f082bc3-1b98-537c-9ab1-e7bfea21f014", "question": "What are the characteristics of the rural dialect?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c16572e6-20d3-51c9-8ce9-46e538d854b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.06777/6-Figure7-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.06777/2-Figure1-1.png", "data/dataset/spiqa/images/1702.06777/3-Figure2-1.png", "data/dataset/spiqa/images/1702.06777/4-Figure3-1.png", "data/dataset/spiqa/images/1702.06777/5-Figure4-1.png", "data/dataset/spiqa/images/1702.06777/5-Figure5-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure6-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the characteristics of the rural dialect?", "reference_answer": "It uses particular forms of a concept rather than all of them uniformly", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1a9acc3c-a68b-53ce-9f46-25ebcfe33dcf", "question": "How has the evolution of network architectures in deep face recognition systems, such as the transition from AlexNet to ResNet and SENet, impacted the performance of these systems?\t", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How has the evolution of network architectures in deep face recognition systems, such as the transition from AlexNet to ResNet and SENet, impacted the performance of these systems?\t", "reference_answer": "As deep FR models followed the footsteps of deep object classification network architectures the performance got better, training got more controllable, and models got deeper. It started with DeepFace which was based on AlexNet that achieved 97.35% on the LFW benchmark. Then came the FaceNet based on GoogleNet which achieved 99.63%. VGGFace with a procedure to collect the large-scale dataset on the web and using the VGGNet architecture reached 98.95%. SphereFace used ResNet to achieve 99.42% accuracy. After the new VGGFace2 dataset was introduced Cao et al. trained a SENet-based architecture to achieve the SOTA for several datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "958b734e-5835-5405-a14f-03831ccd237e", "question": "How has deep learning improved the accuracy of face recognition systems compared to traditional methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How has deep learning improved the accuracy of face recognition systems compared to traditional methods?", "reference_answer": "The traditional methods (i.e holistic approaches, local-feature-based methods, shallow learning) were the approaches used before the boom of deep learning based techniques. They could achieve an accuracy of 95%, while the human accuracy was 97.53%. The rapid progress of deep learning methods quickly equaled human performance (DeepFace 97.35%) and later on surpassed them with 99.8%. These methods could achieve such numbers by using bigger and bigger datasets and new architectures."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "4ea2888d-d2c1-5612-aff4-0d30f9d9a4ff", "question": "Which of the methods among Conditional GAN, Unsupervised GAN and Consitional CycleGAN would you expect to produce images that are most visually similar to the real images in the CelebA dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the methods among Conditional GAN, Unsupervised GAN and Consitional CycleGAN would you expect to produce images that are most visually similar to the real images in the CelebA dataset?", "reference_answer": "The Conditional CycleGAN method is expected to produce images most visually similar to the real images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "650e5ee7-8c69-52d7-b129-7de640422c2b", "question": "What different correlations result when using different variants of ROUGE scores?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["429168f0-52ee-5a4f-88a6-f002560e9892"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1604.00400/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1604.00400/4-Table1-1.png", "data/dataset/spiqa/images/1604.00400/5-Table2-1.png", "data/dataset/spiqa/images/1604.00400/6-Table3-1.png", "data/dataset/spiqa/images/1604.00400/7-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What different correlations result when using different variants of ROUGE scores?", "reference_answer": "Using Pearson corelation measure,  for example, ROUGE-1-P is 0.257 and ROUGE-3-F 0.878.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0326edc3-c2ec-5283-9e92-36b669a8841c", "question": "Which module of TCPlp consumes the most memory in the active RAM on TinyOS, and how much memory does it utilize?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which module of TCPlp consumes the most memory in the active RAM on TinyOS, and how much memory does it utilize?", "reference_answer": "The protocol implementation module consumes the most memory in the active RAM on TinyOS, utilizing 488 bytes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9a4a8486-09dd-5190-997b-005a2dc8835d", "question": "What is the McGurk effect?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["63173c63-7b32-5e64-9566-71db7170f6be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.01040/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.01040/2-Figure1-1.png", "data/dataset/spiqa/images/1906.01040/3-Table1-1.png", "data/dataset/spiqa/images/1906.01040/4-Table2-1.png", "data/dataset/spiqa/images/1906.01040/4-Table3-1.png", "data/dataset/spiqa/images/1906.01040/5-Figure2-1.png", "data/dataset/spiqa/images/1906.01040/6-Table4-1.png", "data/dataset/spiqa/images/1906.01040/6-Table5-1.png", "data/dataset/spiqa/images/1906.01040/6-Table6-1.png", "data/dataset/spiqa/images/1906.01040/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the McGurk effect?", "reference_answer": "a perceptual illusion, where listening to a speech sound while watching a mouth pronounce a different sound changes how the audio is heard", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "35b4c583-7f79-59e2-bdc9-c741518f2d50", "question": "Was Transfer learning beneficial on the CADe process? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Was Transfer learning beneficial on the CADe process? ", "reference_answer": "Transfer learning was shown to be beneficial in the paper's experiments, as seen by the differences in performance between AlexNet-TL/GoogLeNet-TL and their non-transfer learning counterparts."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "60496930-c826-5f18-a04a-79c337e85217", "question": "How does the quality of the output heatmap change when the selected concept, predicted concept, and the real entity to be grounded are all aligned?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the quality of the output heatmap change when the selected concept, predicted concept, and the real entity to be grounded are all aligned?", "reference_answer": "When the selected concept, predicted concept, and the real entity to be grounded are all aligned, the generated heatmap produces a good localization of the phrase."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "57f612d5-4f5c-5389-b16c-431abecc6846", "question": "What is CifarNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is CifarNet?", "reference_answer": "CifarNet was a CNN model that was used for the object recognition task using the Cifar10 dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b27147ae-eca7-56a0-abc4-0229909143b8", "question": "How does increasing the training set size affect the performance of the lane marking and drivable area segmentation tasks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does increasing the training set size affect the performance of the lane marking and drivable area segmentation tasks?", "reference_answer": "Increasing the training set size generally leads to improved performance for both lane marking and drivable area segmentation tasks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d4e252e5-2954-53cf-bc83-ec619c04b214", "question": "What is the relationship between the $L_2$-norm of a word vector and its frequency?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0ef7a576-90fe-5b70-81db-8770ba622135"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table2-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Figure1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table4-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table3-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table7-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table8-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table6-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the $L_2$-norm of a word vector and its frequency?", "reference_answer": "The $L_2$-norm of a word vector is inversely proportional to its frequency."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2acbb92e-9807-5316-b90e-71439c104ea6", "question": "Based on the ablation study, which modification to the Devon model architecture had the most significant negative impact on performance for the KITTI 2015 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the ablation study, which modification to the Devon model architecture had the most significant negative impact on performance for the KITTI 2015 dataset?", "reference_answer": "Removing the normalization in the relation modules had the most significant negative impact on performance for the KITTI 2015 dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "373393f8-3922-516e-acc7-920550da99bb", "question": "What is the role of the relation module (Rt) in the Deformable Volume Network (Devon)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the relation module (Rt) in the Deformable Volume Network (Devon)?", "reference_answer": "The relation module (Rt) is responsible for capturing the spatial relationships between the features extracted from the first and second images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "55b343d0-bfd2-53e0-a50d-b1a4d40fc0e0", "question": "Did increasing the network depth improved the results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["98008c07-575a-5ae0-a403-5a072d976ae0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/1-Figure1-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/3-Figure2-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/4-Table1-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/5-Figure3-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/6-Figure5-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/6-Table2-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/7-Figure6-1.png", "data/dataset/spiqa/images/b5f3e5d2912bedbcd9458952d664b08db6aed962/7-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Did increasing the network depth improved the results?", "reference_answer": "Yes, it did boost performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f6a54566-3009-5ba6-b601-0a84cfb763b3", "question": "How CLAHE is better than HE for image equalization?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How CLAHE is better than HE for image equalization?", "reference_answer": "Input image gets high contrast when pass through HE and hence loose information by adding noise. Compare to that CLAHE is a adaptive histogram equalization method in which the contrast amplification is limited, so as to reduce this problem of noise amplification."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "528ef781-4573-52ed-8dad-9a80654c4625", "question": "Which of the algorithms is most efficient in terms of transmission in a tree topology?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the algorithms is most efficient in terms of transmission in a tree topology?", "reference_answer": "Op-based GSet."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a1534520-4a3e-5745-999a-04a6ef14731e", "question": "Do they explore similarity of texts across different doctors?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["b3b7c25e-1665-545d-8834-184bfc11081c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.04152/7-Figure4-1.png", "data/dataset/spiqa/images/1907.04152/6-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.04152/3-Figure1-1.png", "data/dataset/spiqa/images/1907.04152/4-Table1-1.png", "data/dataset/spiqa/images/1907.04152/4-Table2-1.png", "data/dataset/spiqa/images/1907.04152/4-Figure2-1.png", "data/dataset/spiqa/images/1907.04152/5-Table3-1.png", "data/dataset/spiqa/images/1907.04152/6-Figure3-1.png", "data/dataset/spiqa/images/1907.04152/6-Table4-1.png", "data/dataset/spiqa/images/1907.04152/7-Figure4-1.png", "data/dataset/spiqa/images/1907.04152/7-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they explore similarity of texts across different doctors?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3c79bf1d-8fc2-5342-a277-d097ef743361", "question": "Does NASNets perform better than MobileNet, ShuffleNet under resource-constraint setting?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["acb67ddd-a0d1-56d4-871c-f5f79ed59efb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/12-Figure8-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure9-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/2-Figure1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Figure5-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does NASNets perform better than MobileNet, ShuffleNet under resource-constraint setting?", "reference_answer": "From the above evidential sentence, it is obvious that NASNets with 74% accuracy perform better than MobileNet and ShuffleNet with 70.6% and 70.9% accuracies respectively."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "87697da0-9491-5ca8-a81d-87daa4abdfdb", "question": "Is the template-based model realistic?  ", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["2b729e0f-6f9d-5ea1-84c8-671a588248b4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.03407/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.03407/2-Table1-1.png", "data/dataset/spiqa/images/2002.03407/2-Table2-1.png", "data/dataset/spiqa/images/2002.03407/4-Table3-1.png", "data/dataset/spiqa/images/2002.03407/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the template-based model realistic?  ", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "023b0ff3-29bf-5769-8e24-9ab1504bd9fe", "question": "Which component has the greatest impact on performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["80de2d64-8dce-51a3-8dd4-caab45d1c756"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.06267/7-Table3-1.png", "data/dataset/spiqa/images/1908.06267/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.06267/5-Table1-1.png", "data/dataset/spiqa/images/1908.06267/7-Table2-1.png", "data/dataset/spiqa/images/1908.06267/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which component has the greatest impact on performance?", "reference_answer": "Increasing number of message passing iterations showed consistent improvement in performance - around 1 point improvement compared between 1 and 4 iterations", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "309bb7f8-0461-5cc4-abd6-4ba1c9d01a47", "question": "What is the sample complexity lower bound for recovering a tree-structured sparse signal using standard compressed sensing?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["37945375-0719-5574-8298-cf53c070d9e8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.06635v1/1811.06635v1-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.06635v1/1811.06635v1-Table1-1.png", "data/dataset/spiqa/images/1811.06635v1/1811.06635v1-Figure1-1.png", "data/dataset/spiqa/images/1811.06635v1/1811.06635v1-Figure2-1.png", "data/dataset/spiqa/images/1811.06635v1/1811.06635v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the sample complexity lower bound for recovering a tree-structured sparse signal using standard compressed sensing?", "reference_answer": "Ω(s)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2857b629-547b-5879-a148-40f7e06fbea0", "question": "How does the advertising rate for the \"Fix\" curve compare to the \"Oracle\" curve at hour 14?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f16a3bd9-b17e-5e49-a098-482dcced698c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure9-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure4-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure5-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure6-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure7-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table2-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure8-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the advertising rate for the \"Fix\" curve compare to the \"Oracle\" curve at hour 14?", "reference_answer": "The advertising rate for the \"Fix\" curve is lower than the \"Oracle\" curve at hour 14."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cbfc2391-2072-50ff-9cb2-8c81e98a7415", "question": "Does the probability of repaying a debt increase or decrease with credit score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a7193e4-6411-5e3e-9b02-09ce82c0f1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Does the probability of repaying a debt increase or decrease with credit score?", "reference_answer": "The probability of repaying a debt increases with credit score."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "beade68b-2db0-536c-9fcc-a797799939a4", "question": "What languages are evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8a308def-6fbf-5fd4-9efa-22550987414d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01541/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01541/2-Table1-1.png", "data/dataset/spiqa/images/1809.01541/2-Figure1-1.png", "data/dataset/spiqa/images/1809.01541/3-Table2-1.png", "data/dataset/spiqa/images/1809.01541/4-Table3-1.png", "data/dataset/spiqa/images/1809.01541/5-Figure2-1.png", "data/dataset/spiqa/images/1809.01541/5-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What languages are evaluated?", "reference_answer": "German, English, Spanish, Finnish, French, Russian,  Swedish.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f9e91e1e-d598-5157-8c6d-7b484b3c2a7f", "question": "Do they recommend translating the premise and hypothesis together?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["8f2d2808-165b-5206-b171-57f5f3e5c367"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.04721/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.04721/4-Table1-1.png", "data/dataset/spiqa/images/2004.04721/5-Table2-1.png", "data/dataset/spiqa/images/2004.04721/5-Table3-1.png", "data/dataset/spiqa/images/2004.04721/6-Table4-1.png", "data/dataset/spiqa/images/2004.04721/6-Table5-1.png", "data/dataset/spiqa/images/2004.04721/7-Table6-1.png", "data/dataset/spiqa/images/2004.04721/8-Table7-1.png", "data/dataset/spiqa/images/2004.04721/8-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they recommend translating the premise and hypothesis together?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5343ab11-3cf6-5b5f-af14-df371f0d9851", "question": "How does the performance of the model change as the number of views increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1291db8d-1be8-551a-a360-7bedc5ef404a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure2-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table3-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table2-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Table1-1.png", "data/dataset/spiqa/images/1812.00108v4/1812.00108v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the model change as the number of views increases?", "reference_answer": "The performance of the model generally improves as the number of views increases. For example, when the model is trained and tested on two-view data, the F1-score is 29.67. However, when the model is trained and tested on three-view data, the F1-score increases to 30.2. This suggests that the model is able to learn more effectively from data with more views."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7eb9ed0c-c453-5cfe-83f0-2b76c54087ea", "question": "What are the different types of features used by the Layout-induced Video Representation Network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f290ed70-eb81-598b-aa2d-1920fc19428f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Table1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure3-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure9-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure10-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the different types of features used by the Layout-induced Video Representation Network?", "reference_answer": "The Layout-induced Video Representation Network uses three types of features: place-based features, distance-based features, and topological features."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "71bd07da-2715-5b55-a447-73b6ae49edd8", "question": "Which loss function combination is most important for generating realistic mouth movements?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["019cfad5-6d7d-537a-88b5-374e2c85546a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure3-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure1-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure2-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure6-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure4-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure5-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which loss function combination is most important for generating realistic mouth movements?", "reference_answer": "The combination of Lrec, LI, and LV is most important for generating realistic mouth movements."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9875282a-d583-5406-bf8a-f39be13bd162", "question": "What is kernel size used in each layer of SegNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a23ce2a-2593-5a31-9059-32d75394b681"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/4-Figure2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/5-Figure3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/7-Figure4-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure5-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is kernel size used in each layer of SegNet?", "reference_answer": "The kernel size used in each layer of SegNet is 7*7."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "9c48879c-089c-56e9-8fbd-f156f3d19564", "question": "Which dataset has the highest Recall@20 and MRR@20?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the highest Recall@20 and MRR@20?", "reference_answer": "VIDXL has the highest Recall@20 and MRR@20."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0a99c31d-2d90-5b6a-bb03-13115b1f2696", "question": "What is the role of the filter in the convolution operation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the filter in the convolution operation?", "reference_answer": "The filter is used to extract features from the input image. It is a small matrix that is applied to each pixel in the image, and the result is a new pixel value."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1df60d2d-0562-5c99-954c-9f0685b81e2f", "question": "How does the processing time of SRU compare to that of cuDNN LSTM and word-level convolution with filter widths k=2 and k=3?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the processing time of SRU compare to that of cuDNN LSTM and word-level convolution with filter widths k=2 and k=3?", "reference_answer": "The processing time of SRU is significantly faster than that of cuDNN LSTM and word-level convolution with filter widths k=2 and k=3."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0890215a-a3b2-567d-85ad-c87f99b16858", "question": "What was the performance of their model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0513fa91-ee37-5970-957a-21360f4db676"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.00663/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.00663/2-Figure1-1.png", "data/dataset/spiqa/images/1810.00663/4-Table1-1.png", "data/dataset/spiqa/images/1810.00663/5-Figure2-1.png", "data/dataset/spiqa/images/1810.00663/6-Table2-1.png", "data/dataset/spiqa/images/1810.00663/8-Table3-1.png", "data/dataset/spiqa/images/1810.00663/8-Figure3-1.png", "data/dataset/spiqa/images/1810.00663/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was the performance of their model?", "reference_answer": "For test-repeated set, EM score of 61.17, F1 of 93.54, ED of 0.75 and GM of 61.36. For test-new set, EM score of 41.71, F1 of 91.02, ED of 1.22 and GM of 41.81", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "360c6944-034f-5200-a9a3-9c39a9862bf2", "question": "Is it true that they used the output from the bottom decoder layer for y_{i-1}, not the decoder-RNN output from the past decoding time step?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is it true that they used the output from the bottom decoder layer for y_{i-1}, not the decoder-RNN output from the past decoding time step?", "reference_answer": "Authors used only the decoder-RNN output from the past decoding time step in the bottom decoder layer to obtain recurrent attention context which is sent directly to all the remaining decoder layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5e4b91ab-56eb-5e21-9ccd-386c3376b354", "question": "Are other pretrained language models also evaluated for contextual augmentation? ", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["40843903-571a-5d54-9bfb-a3be8e0c346a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06705/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06705/5-Figure1-1.png", "data/dataset/spiqa/images/1812.06705/5-Table1-1.png", "data/dataset/spiqa/images/1812.06705/7-Table2-1.png", "data/dataset/spiqa/images/1812.06705/7-Table3-1.png", "data/dataset/spiqa/images/1812.06705/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are other pretrained language models also evaluated for contextual augmentation? ", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9625eadc-4b0f-5552-b30e-c6b56b79f65c", "question": "Why is the model discouraged even though the generated response (RSP) incorporates relevant content from the N-best response candidates (C#1 and C#2)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bf33c3ac-b6da-5fbf-b95a-d731d0dfd2f0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table2-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table4-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table3-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table5-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why is the model discouraged even though the generated response (RSP) incorporates relevant content from the N-best response candidates (C#1 and C#2)?", "reference_answer": "The model is discouraged because it is trained using the Maximum Likelihood Estimation (MLE) objective, which prioritizes generating responses that are identical to the ground-truth (GT) response. Even though the RSP integrates relevant content from the candidates and seems appropriate in the context, it is penalized because it deviates from the exact wording of the GT."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "85ba79bc-81d1-527c-88cb-f3fe8ad58fe9", "question": "What does it mean the realistic sample?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6ff18ae9-87a4-5a22-9503-e235ec72e411"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/1-Figure1-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/3-Figure2-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/6-Table2-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/7-Table3-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/7-Table4-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/7-Table6-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/8-Figure3-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/8-Figure4-1.png", "data/dataset/spiqa/images/4e6bbeee3e8810de2a5b12941f81920866a6b38b/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does it mean the realistic sample?", "reference_answer": "A realistic sample in this context refers to a 3D object that has undergone a smooth deformation, meaning that the shape of the object changes gradually rather than abruptly. The realistic samples that the authors aim to generate are those that resemble real-world objects with diverse shapes and deformations, such as airplanes with varying wing lengths and directions, guitars with different sizes and aspect ratios, and people with different heights and postures."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c142afa8-8ba2-5800-bc8f-bc81ae53a7b8", "question": "Which gradient approximation method leads to a more stable and lower loss value during training?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which gradient approximation method leads to a more stable and lower loss value during training?", "reference_answer": "The corrected gradient method leads to a more stable and lower loss value during training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "90053f97-4517-5ada-bad9-8dc477c6ff5b", "question": "Does deconvolution and unpooling conduct the same goal in the network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does deconvolution and unpooling conduct the same goal in the network?", "reference_answer": "Yes the purpose of the de-convolution layer is to increase the size similar to un-pooling operation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "898ed8fc-6e47-5c39-8ad4-3f1b247ed650", "question": "What are the metrics used to compare the efficiency of different methods which compute the adversarial perturbations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["4bc68d1d-c421-567f-a14a-076cb7acca37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure3-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure6-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the metrics used to compare the efficiency of different methods which compute the adversarial perturbations?", "reference_answer": "The metrics that are used to compare different methods of finding adversarial perturbations are: the average robustness of the model estimated in some type of norm (2-norm or infinity-norm in the paper); and the average running time needed to find the estimated minimal perturbation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7e8b5299-4cfe-5736-a430-e2bae5ae981b", "question": "Which framework has the lowest total communication cost for MNIST?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which framework has the lowest total communication cost for MNIST?", "reference_answer": "FALCON"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7b88d8c0-d132-5ff9-8bbe-9f0ac4ed71d8", "question": "What are the top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e23d7484-ec68-5c65-bb90-6d11b1d325a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Table1-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure5-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method?", "reference_answer": "The top 5 section recommendations for the Wikipedia article on Lausanne according to the category-section counts method are HISTORY, DEMOGRAPHICS, ECONOMY, EDUCATION, and POLITICS."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2d31b7b4-b134-5ce6-88a4-ee518ad8ddbd", "question": "How does the performance of the Filtering algorithm compare to the performance of MLE with noise?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["031a172b-3552-5f74-bbeb-ea0f4bed4c91"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1606.07384v2/1606.07384v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1606.07384v2/1606.07384v2-Figure1-1.png", "data/dataset/spiqa/images/1606.07384v2/1606.07384v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the Filtering algorithm compare to the performance of MLE with noise?", "reference_answer": "The Filtering algorithm performs better than MLE with noise in both the random tree and random graph settings."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "339af2f6-ba96-59f2-af00-f17c20f0b99d", "question": "How do they damage different neural modules?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8ab6648a-1650-5d0a-b074-4f95e74c84bf"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.08899/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.08899/2-Figure1-1.png", "data/dataset/spiqa/images/2002.08899/4-Table1-1.png", "data/dataset/spiqa/images/2002.08899/4-Table2-1.png", "data/dataset/spiqa/images/2002.08899/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they damage different neural modules?", "reference_answer": "Damage to neural modules is done by randomly initializing their weights, causing the loss of all learned information.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "71d4fd81-adc0-5079-8f3f-100363433e02", "question": "What is the input to the convolutional self-correction model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the input to the convolutional self-correction model?", "reference_answer": "The input to the convolutional self-correction model is the logits generated by the primary and ancillary models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cf3de28d-4cf8-5303-abd3-ffc3fae3c550", "question": "Which type of object is the most common in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which type of object is the most common in the dataset?", "reference_answer": "Cars are the most common object in the dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1ebd9205-b441-599a-a2e0-8310050d4e8e", "question": "Which graph shows the largest improvement in accuracy for the TCM(8*memory) method compared to the GSS(fsize=12) method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which graph shows the largest improvement in accuracy for the TCM(8*memory) method compared to the GSS(fsize=12) method?", "reference_answer": "The graph for the Caida-networkflow dataset shows the largest improvement in accuracy for the TCM(8*memory) method compared to the GSS(fsize=12) method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e5adab09-372d-5398-a50d-6bf391544d41", "question": "Is order of \"words\" important in car speak language?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["232ba8ef-5668-5815-80d6-652fd0cb9475"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.02070/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.02070/1-Figure1-1.png", "data/dataset/spiqa/images/2002.02070/2-Table1-1.png", "data/dataset/spiqa/images/2002.02070/2-Figure2-1.png", "data/dataset/spiqa/images/2002.02070/3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is order of \"words\" important in car speak language?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ed553173-7e13-54ca-8da6-54322c0a2709", "question": "How is the authors' work different from the “fast gradient sign” method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["4bc68d1d-c421-567f-a14a-076cb7acca37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure3-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure6-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How is the authors' work different from the “fast gradient sign” method?", "reference_answer": "The fast gradient sign method is very quick but may lead to sub-optimal perturbations thus damaging the overall robustness estimation, and fine-tuning with such adversarial samples may sometimes result in a drop in the overall performance of the model. On the other hand, DeepFool creates adversarial perturbations that are closer to the absolute minimum compared to others thus giving us a more reliable tool in terms of robustness estimation and fine-tuning."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2a5f16c3-f411-52b9-8235-039c682d9e0d", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["4c4e65d4-3205-5c83-a013-08a7b0d3d5d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.00341/6-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.00341/2-Figure1-1.png", "data/dataset/spiqa/images/1710.00341/3-Figure2-1.png", "data/dataset/spiqa/images/1710.00341/5-Table1-1.png", "data/dataset/spiqa/images/1710.00341/5-Table2-1.png", "data/dataset/spiqa/images/1710.00341/6-Figure3-1.png", "data/dataset/spiqa/images/1710.00341/6-Table3-1.png", "data/dataset/spiqa/images/1710.00341/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4427eb92-0b21-5886-a848-0a9bd516b541", "question": "What genres are covered?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["08b4480d-3698-5a9a-9d0a-9fe1d6331bc8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.01799/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.01799/2-Table2-1.png", "data/dataset/spiqa/images/1911.01799/2-Table1-1.png", "data/dataset/spiqa/images/1911.01799/2-Table3-1.png", "data/dataset/spiqa/images/1911.01799/4-Table4-1.png", "data/dataset/spiqa/images/1911.01799/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What genres are covered?", "reference_answer": "genre, entertainment, interview, singing, play, movie, vlog, live broadcast, speech, drama, recitation and advertisement", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3d41f17d-d60b-53a4-9f87-c33af6062ca0", "question": "Which method performs better in terms of classification accuracy?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["86d109ac-bfba-5548-a67e-8dfd401e8f3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table7-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table6-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table5-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table9-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table2-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table8-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs better in terms of classification accuracy?", "reference_answer": "ZDDA3"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4b329c5b-4f79-5374-b8f2-30e3eb11076f", "question": "Does the paper report the performance of a baseline model on South African languages LID?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3dd529dd-1a7c-5ba1-a77d-0fcdb3724aa2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.07555/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.07555/2-Table1-1.png", "data/dataset/spiqa/images/1911.07555/4-Table2-1.png", "data/dataset/spiqa/images/1911.07555/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the paper report the performance of a baseline model on South African languages LID?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c9f8dfa2-12c8-5206-8299-6a0cc44eff04", "question": "What is the equation that describes the motion of a mass attached to a spring?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6b8de636-72d0-5a8c-8525-ca0566a6552d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.02803v5/1612.02803v5-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.02803v5/1612.02803v5-Table1-1.png", "data/dataset/spiqa/images/1612.02803v5/1612.02803v5-Figure1-1.png", "data/dataset/spiqa/images/1612.02803v5/1612.02803v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the equation that describes the motion of a mass attached to a spring?", "reference_answer": "The equation that describes the motion of a mass attached to a spring is:\n```\nm d^2 X / dt^2 + kX = 0\n```\nwhere:\n* m is the mass of the object\n* X is the displacement of the object from its equilibrium position\n* k is the spring constant\n* t is time"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fb5b33fe-1ef1-5676-8256-a3ed09c8ca02", "question": "Do they employ their indexing-based method to create a sample of a QA Wikipedia dataset?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["343ce20e-e7d7-590e-aa92-f90f9cfeab0a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.02073/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.02073/2-Table1-1.png", "data/dataset/spiqa/images/1801.02073/3-Table2-1.png", "data/dataset/spiqa/images/1801.02073/3-Figure1-1.png", "data/dataset/spiqa/images/1801.02073/3-Figure2-1.png", "data/dataset/spiqa/images/1801.02073/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they employ their indexing-based method to create a sample of a QA Wikipedia dataset?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f46bca50-1dff-538c-b90a-5f6e52012782", "question": "Why is the number of demonstrations after the shift not available for the \"Push to Pose\" task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bd1cf1c1-2268-50fb-a8af-8321d7a864ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why is the number of demonstrations after the shift not available for the \"Push to Pose\" task?", "reference_answer": "The passage mentions that additional trajectories were generated for the \"Pick and Place\" task by reducing the frequency of the recorded demonstrations. This process was not applied to the \"Push to Pose\" task, therefore no \"Demonstrations after shift\" are listed for it."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "86966417-816e-5f27-aebf-5fc3f912475b", "question": "What are the FID values achieved by authors using Diffusion Model on ImageNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the FID values achieved by authors using Diffusion Model on ImageNet?", "reference_answer": "They obtain state-of-the-art image generation on ImageNet 64×64. For higher resolution ImageNet. Table 5 shows the performance of ADM. Metrics include FID, sFID, Prec, Rec."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0bb0a8b1-dffd-5ce1-b74f-024e2c8a1a77", "question": "Which method achieves the highest accuracy on the Shootings dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e0369791-b574-5ff8-aaeb-89c221d8f857"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table4-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the highest accuracy on the Shootings dataset?", "reference_answer": "TFBA"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "45645869-e657-5f6f-b124-bb47b2059ded", "question": "Which method generally achieved a lower objective function value (OFV) for the different datasets, FISVDD or Incremental SVM? Does this imply that one method is definitively better than the other?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b9ddb1a1-9c61-540f-abe1-fc8e33926d1d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.00139v4/1709.00139v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.00139v4/1709.00139v4-Table1-1.png", "data/dataset/spiqa/images/1709.00139v4/1709.00139v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method generally achieved a lower objective function value (OFV) for the different datasets, FISVDD or Incremental SVM? Does this imply that one method is definitively better than the other?", "reference_answer": "For all datasets presented, Incremental SVM achieved a slightly lower OFV compared to FISVDD. However, this does not necessarily mean that Incremental SVM is definitively better."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "28ccbc51-c8ca-5358-ab3f-0b9f34e454be", "question": "How does the quality of the generated samples change as the update threshold increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the quality of the generated samples change as the update threshold increases?", "reference_answer": "The quality of the generated samples decreases as the update threshold increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "56627d7d-1054-58eb-b2aa-7e7d54ee0db9", "question": "Which training approach achieved the best balance between minimizing false negatives (FN) and false positives (FP) in object detection, while also maintaining a high MOTSA score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which training approach achieved the best balance between minimizing false negatives (FN) and false positives (FP) in object detection, while also maintaining a high MOTSA score?", "reference_answer": "The training approach \"Det + T + I + S\" achieved the best balance between minimizing false negatives (FN) and false positives (FP) in object detection, while also maintaining a high MOTSA score."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "aaf35e60-050a-5cfa-a2e7-1531092fe8bf", "question": "How does the training loss of DMRNet compare to that of ResNet on the CIFAR-10 dataset with L = 30?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the training loss of DMRNet compare to that of ResNet on the CIFAR-10 dataset with L = 30?", "reference_answer": "The training loss of DMRNet is lower than that of ResNet on the CIFAR-10 dataset with L = 30."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ee555302-e95a-503c-b1b6-0bba91a315e4", "question": "Do the authors give any examples of major events which draw the public's attention and the impact they have on stock price?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["550c0bef-e1c1-56bd-aa7b-6c89f050fb09"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.02243/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.02243/2-Figure2-1.png", "data/dataset/spiqa/images/1801.02243/2-Figure1-1.png", "data/dataset/spiqa/images/1801.02243/3-Figure3-1.png", "data/dataset/spiqa/images/1801.02243/3-Figure4-1.png", "data/dataset/spiqa/images/1801.02243/4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors give any examples of major events which draw the public's attention and the impact they have on stock price?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a4243c20-aa4c-5fc6-97ae-18a8996b263f", "question": "What is the relationship between gloss and representation error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9104d00a-0d2b-565f-acc8-c4650cf151b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure6-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure7-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure2-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure8-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure12-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure9-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between gloss and representation error?", "reference_answer": "The representation error decreases as the gloss decreases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "09468404-2094-5390-a54c-24f9656162af", "question": "What extraction model did they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["cfbf6ed2-2dbc-5421-919b-2c80506f7355"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1903.00172/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1903.00172/3-Figure1-1.png", "data/dataset/spiqa/images/1903.00172/4-Figure2-1.png", "data/dataset/spiqa/images/1903.00172/5-Table1-1.png", "data/dataset/spiqa/images/1903.00172/6-Table3-1.png", "data/dataset/spiqa/images/1903.00172/7-Table4-1.png", "data/dataset/spiqa/images/1903.00172/7-Figure3-1.png", "data/dataset/spiqa/images/1903.00172/8-Table6-1.png", "data/dataset/spiqa/images/1903.00172/8-Figure4-1.png", "data/dataset/spiqa/images/1903.00172/13-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What extraction model did they use?", "reference_answer": "Multi-Encoder, Constrained-Decoder model", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5ba1f6ae-8903-567f-9ded-5ecd3e142021", "question": "How does the segmentation model perform in areas with no lane markings?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the segmentation model perform in areas with no lane markings?", "reference_answer": "The segmentation model learns to interpolate in areas that have no lane markings."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4a1fffee-ee0c-5379-9a0a-475ec71c39b1", "question": "How does the reliability of CoAP compare to TCPlp and what potential factors contribute to this difference?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the reliability of CoAP compare to TCPlp and what potential factors contribute to this difference?", "reference_answer": "Table 1 shows that CoAP has slightly higher reliability (99.5%) compared to TCPlp (99.3%). While both protocols perform well, this difference could be attributed to several factors, including:\n\nRetransmission mechanisms: CoAP employs a built-in retransmission mechanism for lost packets, while TCPlp relies on the underlying network layer for retransmissions. This could give CoAP an edge in recovering lost packets and achieving higher reliability.\nCongestion control: CoAP includes mechanisms to adapt to network congestion, potentially reducing packet loss and improving reliability.\nPacket size: CoAP typically uses smaller packets compared to TCPlp. Smaller packets are less prone to loss in wireless networks, potentially contributing to CoAP's slightly higher reliability."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0cfa7c05-f688-5b0c-b001-1d750e177c16", "question": "What is a confusion network or lattice?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8be291a4-41a4-5b4f-a4b3-3dfd8097e5a1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.13024/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.13024/2-Figure1-1.png", "data/dataset/spiqa/images/1810.13024/2-Figure2-1.png", "data/dataset/spiqa/images/1810.13024/4-Table1-1.png", "data/dataset/spiqa/images/1810.13024/4-Table5-1.png", "data/dataset/spiqa/images/1810.13024/4-Table2-1.png", "data/dataset/spiqa/images/1810.13024/4-Table3-1.png", "data/dataset/spiqa/images/1810.13024/4-Figure3-1.png", "data/dataset/spiqa/images/1810.13024/4-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is a confusion network or lattice?", "reference_answer": "graph-like structures where arcs connect nodes representing multiple hypothesized words, thus allowing multiple incoming arcs unlike 1-best sequences", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "74246b3c-3908-520b-b7a0-c3765fe5950d", "question": "How much does the success of the EL metric vary depending on which n tokens are used as a prompt for this metric?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2148cb60-8df5-50ee-9b1b-c8262ccf9f54"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/21-Table12-1.png"], "reference_image": ["data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/10-Table4-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/15-Figure4-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/16-Figure5-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/17-Table5-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/18-Table6-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/18-Table7-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/19-Table8-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/19-Table9-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/2-Figure1-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/20-Table10-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/21-Table11-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/21-Table12-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/7-Table1-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/7-Table2-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/8-Figure2-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/9-Figure3-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How much does the success of the EL metric vary depending on which n tokens are used as a prompt for this metric?", "reference_answer": "The average LM perfomance of varying n for the EL metric is shown in Table 13."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "954a6321-2636-596b-b523-b1f246beaee2", "question": "What was the performance of both approaches on their dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["08b4480d-3698-5a9a-9d0a-9fe1d6331bc8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.01799/4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.01799/2-Table2-1.png", "data/dataset/spiqa/images/1911.01799/2-Table1-1.png", "data/dataset/spiqa/images/1911.01799/2-Table3-1.png", "data/dataset/spiqa/images/1911.01799/4-Table4-1.png", "data/dataset/spiqa/images/1911.01799/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was the performance of both approaches on their dataset?", "reference_answer": "ERR of 19.05 with i-vectors and 15.52 with x-vectors", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f8a6aecc-6f4b-50e8-8dd1-8ee4b5992b37", "question": "What performance does the Entity-GCN get on WIKIHOP?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["df4de88d-e624-5e8a-ac1c-1f42eae3e5b9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.09920/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.09920/1-Figure1-1.png", "data/dataset/spiqa/images/1808.09920/3-Figure2-1.png", "data/dataset/spiqa/images/1808.09920/5-Table1-1.png", "data/dataset/spiqa/images/1808.09920/6-Table2-1.png", "data/dataset/spiqa/images/1808.09920/7-Table3-1.png", "data/dataset/spiqa/images/1808.09920/8-Table4-1.png", "data/dataset/spiqa/images/1808.09920/11-Table5-1.png", "data/dataset/spiqa/images/1808.09920/12-Table6-1.png", "data/dataset/spiqa/images/1808.09920/13-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What performance does the Entity-GCN get on WIKIHOP?", "reference_answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "23585ab7-b13f-5a54-915b-342bd2c46063", "question": "How long of dialog history is captured?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d9caab40-7543-5df0-801a-ba929779cf43"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.04056/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.04056/2-Figure1-1.png", "data/dataset/spiqa/images/1701.04056/3-Figure2-1.png", "data/dataset/spiqa/images/1701.04056/3-Figure3-1.png", "data/dataset/spiqa/images/1701.04056/4-Table2-1.png", "data/dataset/spiqa/images/1701.04056/4-Table1-1.png", "data/dataset/spiqa/images/1701.04056/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How long of dialog history is captured?", "reference_answer": "two previous turns", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5027b2c1-2871-5714-abdc-76819d06e0db", "question": "Which method has the fastest convergence and highest converged performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the fastest convergence and highest converged performance?", "reference_answer": "F-DSS"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "87bf6147-4bce-58fb-9606-6fea2f5bda89", "question": "Which dataset would you expect to be the easiest for a model to localize phrases in, and why?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset would you expect to be the easiest for a model to localize phrases in, and why?", "reference_answer": "Flickr30k is likely the easiest dataset for a model to localize phrases in. \nFlickr30k has the shortest average phrase length (2.3 words) and the lowest average noun count (1.2) per phrase. This suggests that the phrases in this dataset are simpler and often directly refer to single objects present in the image. This makes the localization task easier, almost approaching a weakly supervised setting where the object to be localized is explicitly named in the phrase."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f4e3508c-6be8-5bbd-822e-38f61781d96e", "question": "Do they experiment with the toolkits?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["f46bcab5-d304-5403-9a3d-2ce0f1e85765"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.04433/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.04433/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they experiment with the toolkits?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "20c259cf-44d7-5d80-a598-ca29bfbd63db", "question": "What percentage of occlusions last for more than 10 frames?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What percentage of occlusions last for more than 10 frames?", "reference_answer": "Approximately 80%"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "27a8c570-6759-5e5a-bcfd-e8d904d3c082", "question": "Which method is faster, COPA or Helwig?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method is faster, COPA or Helwig?", "reference_answer": "COPA is faster than Helwig."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "40eb745a-4d7d-5c7f-b801-04131cf1f13b", "question": "Which dataset has the highest value for the hyperparameter  λa?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e0369791-b574-5ff8-aaeb-89c221d8f857"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table4-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the highest value for the hyperparameter  λa?", "reference_answer": "The NYT Sports dataset has the highest value for λa (0.9)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "74f371e3-25e8-5f5c-9a71-6b7f95a4273e", "question": "Based on the figure, which type of question does ACNN perform the best on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the figure, which type of question does ACNN perform the best on?", "reference_answer": "ACNN performs best on \"Who\" questions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5066b8ca-b4f0-5b85-9072-b97c47c1411d", "question": "Which method has a lower running time for all datasets - GB-KMV or LSH-E?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has a lower running time for all datasets - GB-KMV or LSH-E?", "reference_answer": "GB-KMV"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e6c6b3bb-48e3-5eb8-8ee7-e87e06312f29", "question": "Do they build a model to automatically detect demographic, lingustic or psycological dimensons of people?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["7891fabf-9192-53ac-91e9-e1dc88f2d154"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.06685/4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.06685/2-Figure1-1.png", "data/dataset/spiqa/images/1612.06685/3-Figure2-1.png", "data/dataset/spiqa/images/1612.06685/3-Figure3-1.png", "data/dataset/spiqa/images/1612.06685/4-Figure4-1.png", "data/dataset/spiqa/images/1612.06685/4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they build a model to automatically detect demographic, lingustic or psycological dimensons of people?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5242c071-629a-5cc8-af93-8f574a27c039", "question": "Which method produces the least amount of artifacts?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method produces the least amount of artifacts?", "reference_answer": "TecoGAN⊖."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d558853f-16d5-5c3e-bc1d-a7bae4dd4835", "question": "How does the number of common k-hop neighbors change as the hop distance increases for items with and without common raters?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the number of common k-hop neighbors change as the hop distance increases for items with and without common raters?", "reference_answer": "The number of common k-hop neighbors generally decreases as the hop distance increases for both items with and without common raters. However, the number of common k-hop neighbors is consistently higher for items with common raters than for items without common raters."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a21ce182-325e-5184-9c7c-b2e8848c501a", "question": "which datasets were used in evaluation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3b7ff31e-201b-5005-92a5-e7f03a4a5cc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.09123/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.09123/5-Table1-1.png", "data/dataset/spiqa/images/1701.09123/6-Table2-1.png", "data/dataset/spiqa/images/1701.09123/9-Table3-1.png", "data/dataset/spiqa/images/1701.09123/11-Figure1-1.png", "data/dataset/spiqa/images/1701.09123/13-Table4-1.png", "data/dataset/spiqa/images/1701.09123/15-Table5-1.png", "data/dataset/spiqa/images/1701.09123/15-Table6-1.png", "data/dataset/spiqa/images/1701.09123/16-Table7-1.png", "data/dataset/spiqa/images/1701.09123/16-Table8-1.png", "data/dataset/spiqa/images/1701.09123/16-Table9-1.png", "data/dataset/spiqa/images/1701.09123/17-Table10-1.png", "data/dataset/spiqa/images/1701.09123/17-Table11-1.png", "data/dataset/spiqa/images/1701.09123/18-Table12-1.png", "data/dataset/spiqa/images/1701.09123/18-Table13-1.png", "data/dataset/spiqa/images/1701.09123/19-Table14-1.png", "data/dataset/spiqa/images/1701.09123/19-Table15-1.png", "data/dataset/spiqa/images/1701.09123/20-Table16-1.png", "data/dataset/spiqa/images/1701.09123/21-Table17-1.png", "data/dataset/spiqa/images/1701.09123/22-Table18-1.png", "data/dataset/spiqa/images/1701.09123/22-Table19-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "which datasets were used in evaluation?", "reference_answer": "CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkaria, MUC7, Wikigold, MEANTIME, SONAR-1, Ancora 2.0", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "58bcd11d-2a89-50d9-a5e7-5ec2dfd1bdb6", "question": "How big is the Japanese data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is the Japanese data?", "reference_answer": "The ACP corpus has around 700k events split into positive and negative polarity ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3b60e328-b992-55d6-bf69-6933da66dba9", "question": "What are the three goals that the proposed algorithm must achieve simultaneously?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["570e01d8-2c85-5e04-b7e5-aef3f43f49b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure1-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure6-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure8-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure7-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure13-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure2-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure3-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure9-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure4-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure12-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure11-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure10-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three goals that the proposed algorithm must achieve simultaneously?", "reference_answer": "The three goals that the proposed algorithm must achieve simultaneously are: \n1. To predict the locations of the input patches. \n2. To generate the entire image based on the predicted locations of the input patches. \n3. To do so without any geometric priors."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "af244f36-8b63-577a-84d2-6bc746caee60", "question": "How does the relevance of terms assigned by the learned graph compare to the relevance assigned by k-NN and A-NN graphs?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the relevance of terms assigned by the learned graph compare to the relevance assigned by k-NN and A-NN graphs?", "reference_answer": "The learned graph assigns weights that correspond much better to the relevance of the terms compared to k-NN and A-NN graphs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c43284b4-8c7b-52dc-ada0-1a2b934750d3", "question": "What do challenging auxiliary tasks mean?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9ef1a4f5-340c-570d-b47d-59d921351b94"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/12-Table4-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/13-Table5-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/13-Table6-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/14-Figure4-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/4-Figure1-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/5-Figure2-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/7-Table1-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/7-Table2-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/8-Figure3-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What do challenging auxiliary tasks mean?", "reference_answer": "Challenging auxiliary tasks refer to tasks that are difficult for the model to learn, which can negatively impact the performance of the primary task. In the case of meta-path prediction, it is considered more challenging than link prediction and node classification because it requires the understanding of long-range relations across heterogeneous nodes. The task becomes even more difficult when mini-batch training is necessary due to the large size of datasets or models, as important nodes and edges for meta-paths may not be available within a mini-batch."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8015c4c8-2f2a-5793-9573-0785bbf18271", "question": "Which method performs best on the TMTA task and how much does data augmentation contribute to its performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best on the TMTA task and how much does data augmentation contribute to its performance?", "reference_answer": "The ITN (B-CNN) method with data augmentation (DA) performs best on the TMTA task, achieving a testing error of 21.31%. Data augmentation contributes significantly to its performance, as the ITN (B-CNN) method without DA has a higher testing error of 31.67%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f959dce8-68a4-532b-89ab-0fe947992acc", "question": "Does this method help in sentiment classification task improvement?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3ef2c05c-0862-5d4e-b1c0-c0849ef611c6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11047/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11047/1-Figure1-1.png", "data/dataset/spiqa/images/1908.11047/2-Table1-1.png", "data/dataset/spiqa/images/1908.11047/3-Figure2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table3-1.png", "data/dataset/spiqa/images/1908.11047/5-Table4-1.png", "data/dataset/spiqa/images/1908.11047/8-Table5-1.png", "data/dataset/spiqa/images/1908.11047/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does this method help in sentiment classification task improvement?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "680d504e-b600-54bd-8761-5c0ed1b40f7e", "question": "What domains are present in the data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5104ffa1-316d-52cb-be9f-8ab20aed4879"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01359/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01359/2-Figure1-1.png", "data/dataset/spiqa/images/2002.01359/3-Figure2-1.png", "data/dataset/spiqa/images/2002.01359/4-Figure3-1.png", "data/dataset/spiqa/images/2002.01359/5-Table1-1.png", "data/dataset/spiqa/images/2002.01359/5-Table2-1.png", "data/dataset/spiqa/images/2002.01359/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What domains are present in the data?", "reference_answer": "Alarm, Banks, Buses, Calendar, Events, Flights, Homes, Hotels, Media, Messaging, Movies, Music, Payment, Rental Cars, Restaurants, Ride Sharing, Services, Train, Travel, Weather", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d78290fb-cdb3-5549-b16a-81202976fd67", "question": "Which method performs better in terms of mean square error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43e9c887-125b-5503-b988-b6cac3e4aa71"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure1-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table3-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Figure2-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table2-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table1-1.png", "data/dataset/spiqa/images/1804.05938v2/1804.05938v2-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs better in terms of mean square error?", "reference_answer": "DLA performs better than RandList in terms of mean square error."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "68bfaa8b-0164-56e9-9aaf-93abfba7e87a", "question": "What are the three main geographical regions where the data for this study was collected?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three main geographical regions where the data for this study was collected?", "reference_answer": "New York, San Francisco Bay Area, and Berkeley."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4048feec-9574-50b2-9fb5-af1e1ba78fe9", "question": "What are the languages they consider in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["89ef5271-e60f-5ec8-882b-415f5433ac40"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.08510/7-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.08510/3-Figure1-1.png", "data/dataset/spiqa/images/1809.08510/4-Figure2-1.png", "data/dataset/spiqa/images/1809.08510/5-Figure3-1.png", "data/dataset/spiqa/images/1809.08510/5-Table1-1.png", "data/dataset/spiqa/images/1809.08510/6-Table2-1.png", "data/dataset/spiqa/images/1809.08510/7-Figure4-1.png", "data/dataset/spiqa/images/1809.08510/7-Figure5-1.png", "data/dataset/spiqa/images/1809.08510/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the languages they consider in this paper?", "reference_answer": "The languages considered were English, Chinese, German, Russian, Arabic, Spanish, French", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "79de9bf2-866c-5a39-88ea-d3237b8c7f4e", "question": "Why are MOTS datasets like KITTI MOTS and MOTS Challenge smaller in size compared to VOS datasets like YouTube VOS, even though BDD100K MOTS has a comparable number of annotations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why are MOTS datasets like KITTI MOTS and MOTS Challenge smaller in size compared to VOS datasets like YouTube VOS, even though BDD100K MOTS has a comparable number of annotations?", "reference_answer": "MOTS datasets require denser annotations per frame because they involve both segmentation and tracking of multiple objects in crowded scenes. This results in smaller dataset sizes compared to VOS datasets, which typically focus on segmenting a single or fewer objects. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9d141761-e168-5dfb-90a7-2d11acd07303", "question": "How does the alpha parameter affect recommendation accuracy for different sample sizes on the CLASS dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the alpha parameter affect recommendation accuracy for different sample sizes on the CLASS dataset?", "reference_answer": "The alpha parameter generally increases recommendation accuracy as the sample size increases. However, the effect of alpha varies depending on the loss function used. For cross-entropy loss, alpha has a relatively small effect on accuracy. For TOP1-max loss, alpha has a larger effect on accuracy, especially for smaller sample sizes. For BPR-max loss, alpha has a very large effect on accuracy, with higher values of alpha leading to much higher accuracy."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "19751813-cf00-5e3c-9655-d09a6ecd1257", "question": "What are some common methods used in facial recognition and how do they compare in terms of effectiveness and challenges?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are some common methods used in facial recognition and how do they compare in terms of effectiveness and challenges?", "reference_answer": "There are broadly 4 methods that are used in FR. Holistic methods were the first-ever attempt to solve the FR problem. But they were too primitive and could not account for uncontrolled facial changes that did not fit its assumptions. Then, there are local feature-based methods that try to extract invariant properties with local filtering. However, although better than holistic methods, these are also short of complexity and capacity to address the vastness of facial appearances. The first learning-based methods also lacked the robustness to address the non-linearity and complexity of FR. Also, the efforts that were made in this direction were too scattered and there were no traditional methods that could address the FR problem entirely. Afterward, deep learning based methods were introduced which surpassed the human ability in FR. Unfortunately, these methods are prone to adversarial noises and need large datasets. In particular, designing bigger and bigger datasets is becoming a privacy issue, that is yet to be handled by deep FR models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d6e2ad0d-a22d-5150-912d-801d0878b7c3", "question": "What is the role of the code layer in the HDMF architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6251b737-ea9f-5728-a709-63edee304768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Figure1-1.png", "data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Table1-1.png", "data/dataset/spiqa/images/1708.03797v1/1708.03797v1-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the code layer in the HDMF architecture?", "reference_answer": "The code layer is responsible for generating a compressed representation of the input data. This compressed representation is then used by the decoder to reconstruct the original data."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ebab6cba-7887-5f71-ac10-6adc4c27970f", "question": "What is 'autokeras' ? How it works?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is 'autokeras' ? How it works?", "reference_answer": "Autokeras is best way to find model parameter. It automatically tries different combination (in this case is 25) and find size of the model network. In this case the best size is 3 hidden layer with 1 input and 1 output."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "39be1e9a-cf54-5f4b-9d0c-a0852f761715", "question": "What is the role of the LSTM network in the model architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["258785e4-0ec6-59ee-8397-e593b722dcb1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.01507v4/1710.01507v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.01507v4/1710.01507v4-Figure1-1.png", "data/dataset/spiqa/images/1710.01507v4/1710.01507v4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the LSTM network in the model architecture?", "reference_answer": "The LSTM network is used to process the post text and generate a post text embedding."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "936ee006-502d-58c8-9493-1251388c4a59", "question": "Which model performs the best for the order discrimination task on the Accidents dataset and how does it compare to the other data-driven approaches?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["510d6fc0-d3e0-5dc1-8e0d-4d470f964287"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table4-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table3-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Figure2-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table5-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table1-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best for the order discrimination task on the Accidents dataset and how does it compare to the other data-driven approaches?", "reference_answer": "The proposed model in this paper achieves the best performance for the order discrimination task on the Accidents dataset with an accuracy of 0.944. It outperforms the other data-driven approaches, namely Window (Recurrent) with 0.840, Window (Recursive) with 0.864, and Seq2seq with 0.930."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "88d76ad9-f3ac-5341-bcf4-2a8fcfb9ba63", "question": "By how much, the proposed method improves BiDAF and DCN on SQuAD dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["afc717bd-b110-569f-895c-204926279652"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.09230/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.09230/4-Figure1-1.png", "data/dataset/spiqa/images/1803.09230/5-Figure2-1.png", "data/dataset/spiqa/images/1803.09230/5-Table1-1.png", "data/dataset/spiqa/images/1803.09230/6-Figure3-1.png", "data/dataset/spiqa/images/1803.09230/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much, the proposed method improves BiDAF and DCN on SQuAD dataset?", "reference_answer": "In terms of F1 score, the Hybrid approach improved by 23.47% and 1.39% on BiDAF and DCN respectively. The DCA approach improved by 23.2% and 1.12% on BiDAF and DCN respectively.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b341140a-f2c4-563b-878e-32a314dd3b48", "question": "Which algorithm achieves a better balance between precision and recall?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm achieves a better balance between precision and recall?", "reference_answer": "F-DSS."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c874c6db-8a71-5cc5-814c-0618f9f90a1a", "question": "How large is the corpus?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["671e0591-8aa2-519a-8c5e-d9e2e1277e52"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.10361/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.10361/2-Table1-1.png", "data/dataset/spiqa/images/2002.10361/3-Table2-1.png", "data/dataset/spiqa/images/2002.10361/3-Table3-1.png", "data/dataset/spiqa/images/2002.10361/4-Table4-1.png", "data/dataset/spiqa/images/2002.10361/4-Figure1-1.png", "data/dataset/spiqa/images/2002.10361/5-Table5-1.png", "data/dataset/spiqa/images/2002.10361/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How large is the corpus?", "reference_answer": "It contains 106,350 documents", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c5def213-a541-5ce0-a29e-68a5dd4c883b", "question": "In what areas has face recognition technology been commonly used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "In what areas has face recognition technology been commonly used?", "reference_answer": "Face recognition is widely used in the military, finance, public security, and daily life."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "76e63666-bbd6-507b-91f0-8e4a255b5c21", "question": "What is the 12 class bilingual text?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0e9bcf90-d26d-5b40-a748-7a39f91eb3f1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.13066/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.13066/3-Table1-1.png", "data/dataset/spiqa/images/1911.13066/4-Figure1-1.png", "data/dataset/spiqa/images/1911.13066/7-Table2-1.png", "data/dataset/spiqa/images/1911.13066/9-Table3-1.png", "data/dataset/spiqa/images/1911.13066/10-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the 12 class bilingual text?", "reference_answer": "Appreciation, Satisfied, Peripheral complaint, Demanded inquiry, Corruption, Lagged response, Unresponsive, Medicine payment, Adverse behavior, Grievance ascribed and Obnoxious/irrelevant", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "fbe72df3-dd8e-5763-8445-6503d043ed11", "question": "Which operation has the lowest online time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which operation has the lowest online time?", "reference_answer": "ReLU"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6bca6e2b-ab46-5985-a910-de849b330179", "question": "During which hours of the day did the most network-related reboots occur?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3f80fd45-b9ba-51bc-a074-f8ce1efaae03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure4-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure5-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure6-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure3-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Table1-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure1-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure2-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure16-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure8-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure12-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure7-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure11-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure9-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure10-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Table2-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure13-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure15-1.png", "data/dataset/spiqa/images/1802.07222v1/1802.07222v1-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "During which hours of the day did the most network-related reboots occur?", "reference_answer": "The most network-related reboots occurred between 18:00 and 20:00."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e1926a97-8e47-5cf7-8a3f-c48e1a3b1b74", "question": "How does the discriminator in the proposed REAT approach use the N-best response candidates?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bf33c3ac-b6da-5fbf-b95a-d731d0dfd2f0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table2-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table4-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table3-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table5-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the discriminator in the proposed REAT approach use the N-best response candidates?", "reference_answer": "The discriminator takes as input a response and the N-best response candidates, and outputs the probability that the response is human-generated."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "713c9496-6683-5de7-aaab-d9ec96a0700e", "question": "Which model performed best on the \"All\" category of Visual7W, and how did its performance compare to human performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed best on the \"All\" category of Visual7W, and how did its performance compare to human performance?", "reference_answer": "The MLP-IQA model achieved the highest accuracy in the \"All\" category of Visual7W, with a score of 45.1%. However, this performance still falls significantly short of human performance, which stands at 84.1% for the same category."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e894752f-20d5-5852-bd99-d2c849e1ef20", "question": "What metrics are used for the evaluation of SLAM systems?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2c7c33de-6339-5f80-bda0-4e61c6318978"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-TableI-1.png"], "reference_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/2-Figure1-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/4-Figure2-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure3-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure4-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-TableI-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure5-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure6-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-TableII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-Figure7-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-TableIII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/9-TableIV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What metrics are used for the evaluation of SLAM systems?", "reference_answer": "for evaluation of SLAM systems two different metrics, the absolute translation RMSE tabs proposed in [3], and the average relative translation trel and rotation rrel errors are used."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "a7a4cf77-a733-5f4c-85e3-c8205be2030e", "question": "Which languages do they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["72250259-7097-560b-adbd-18551626f2e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.01010/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.01010/1-Figure1-1.png", "data/dataset/spiqa/images/1901.01010/3-Figure2-1.png", "data/dataset/spiqa/images/1901.01010/4-Table1-1.png", "data/dataset/spiqa/images/1901.01010/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which languages do they use?", "reference_answer": "English", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2837e13d-b1e6-5e1d-8702-ce3c4060a7f8", "question": "Do they compare with the MAML algorithm?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["0f7f8d2c-ad1a-5ff5-aad3-fffa969de609"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07513/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07513/3-Figure1-1.png", "data/dataset/spiqa/images/1805.07513/4-Figure2-1.png", "data/dataset/spiqa/images/1805.07513/8-Table1-1.png", "data/dataset/spiqa/images/1805.07513/8-Figure3-1.png", "data/dataset/spiqa/images/1805.07513/9-Table2-1.png", "data/dataset/spiqa/images/1805.07513/16-Table3-1.png", "data/dataset/spiqa/images/1805.07513/16-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they compare with the MAML algorithm?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ec9af88b-0e87-584e-836e-96376d1a0c0e", "question": "How much is the gap between using the proposed objective and using only cross-entropy objective?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a380af2d-4f4e-55ea-9683-58263e168a4c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1711.00106/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1711.00106/2-Figure1-1.png", "data/dataset/spiqa/images/1711.00106/5-Figure2-1.png", "data/dataset/spiqa/images/1711.00106/6-Table1-1.png", "data/dataset/spiqa/images/1711.00106/6-Figure3-1.png", "data/dataset/spiqa/images/1711.00106/7-Table2-1.png", "data/dataset/spiqa/images/1711.00106/7-Figure4-1.png", "data/dataset/spiqa/images/1711.00106/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much is the gap between using the proposed objective and using only cross-entropy objective?", "reference_answer": "The mixed objective improves EM by 2.5% and F1 by 2.2%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6e6c079c-69c0-5e07-89f2-23d9688b5cb0", "question": "Which method for setting the shape parameter of the proposed loss function achieved the best performance in terms of average error? How much improvement did it offer compared to the reproduced baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method for setting the shape parameter of the proposed loss function achieved the best performance in terms of average error? How much improvement did it offer compared to the reproduced baseline?", "reference_answer": "The \"adaptive $\\power \\in (0, 2)$\" strategy, where each wavelet coefficient has its own shape parameter that is optimized during training, achieved the best performance in terms of average error. It reduced the average error by approximately 17% compared to the reproduced baseline."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9d88673c-3d42-500e-ba09-6aff92ce4bf4", "question": "Which model and training objective combination performs best on the PubMed + UMLS dataset, and how does it compare to the DPE baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model and training objective combination performs best on the PubMed + UMLS dataset, and how does it compare to the DPE baseline?", "reference_answer": "The SYNONYMNET(Pairwise) model with Leaky Unit performs best on the PubMed + UMLS dataset, achieving an AUC of 0.9838 and a MAP of 0.9872. This is a statistically significant improvement over the DPE baseline, which achieved an AUC of 0.9513 and a MAP of 0.9623."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d9edd2c4-6871-523c-8ca8-34f2049c13ab", "question": "What is a meta-path? Please explain with examples.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9ef1a4f5-340c-570d-b47d-59d921351b94"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/12-Table4-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/13-Table5-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/13-Table6-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/14-Figure4-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/4-Figure1-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/5-Figure2-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/7-Table1-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/7-Table2-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/8-Figure3-1.png", "data/dataset/spiqa/images/4ccdd1fe6cc9c896e910582bea2c33c19317c5ca/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is a meta-path? Please explain with examples.", "reference_answer": "A meta-path is a sequence of node types and edge types in a graph that describes a specific type of relationship between nodes. An example is in a recommendation system, a meta-path could be \"user-item-written.series-item-user\" which describes a relationship between users who like the same book series."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "37f6f1d8-9616-5807-8883-337bdf0669ed", "question": "Which datasets did they experiment on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["cfbf6ed2-2dbc-5421-919b-2c80506f7355"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1903.00172/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1903.00172/3-Figure1-1.png", "data/dataset/spiqa/images/1903.00172/4-Figure2-1.png", "data/dataset/spiqa/images/1903.00172/5-Table1-1.png", "data/dataset/spiqa/images/1903.00172/6-Table3-1.png", "data/dataset/spiqa/images/1903.00172/7-Table4-1.png", "data/dataset/spiqa/images/1903.00172/7-Figure3-1.png", "data/dataset/spiqa/images/1903.00172/8-Table6-1.png", "data/dataset/spiqa/images/1903.00172/8-Figure4-1.png", "data/dataset/spiqa/images/1903.00172/13-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which datasets did they experiment on?", "reference_answer": "ConciergeQA and AmazonQA", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f29836cb-cc76-5bc6-90f6-f55c8e936af6", "question": "Do the authors offer any hypothesis about why the dense mode outperformed the sparse one?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["ffa9c52b-7ece-588c-a8d0-f552e2ff089c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.10686/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.10686/2-Figure1-1.png", "data/dataset/spiqa/images/1804.10686/2-Figure2-1.png", "data/dataset/spiqa/images/1804.10686/3-Figure3-1.png", "data/dataset/spiqa/images/1804.10686/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors offer any hypothesis about why the dense mode outperformed the sparse one?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "79db80d3-dc37-5284-b26c-a3a2f5785c84", "question": "What state-of-the-art results are achieved?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d12d90c-6898-50c2-9c63-eb987796ac17"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00175/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00175/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00175/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What state-of-the-art results are achieved?", "reference_answer": "for the homographic dataset F1 score of 92.19 and 80.19 on detection and location and for the heterographic dataset F1 score of 89.76 on detection", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f6dae629-9483-547d-80ae-a57228ea3210", "question": "Which deep-coref model performed best on the WikiCoref dataset, according to the table?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["16d4f6a4-5643-545d-8d8d-cba855ef6f62"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table7-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which deep-coref model performed best on the WikiCoref dataset, according to the table?", "reference_answer": "The CoNLL model performed best on the WikiCoref dataset, with an F1 score of 53.40 when using the +linguistic evaluation metric."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d6154598-95f1-503e-9974-d5e6fcd21aa5", "question": "Which model performed the best on the Quora Question Pairs dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed the best on the Quora Question Pairs dataset?", "reference_answer": "AdaQA (two-way) + att."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "371d4686-1516-5ccb-b579-2dfdc1035a52", "question": "Why do you think the performance of all models is generally lower on Rest15 compared to Rest14?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d5785d16-c0a5-5e54-9ad7-9ee75cd95b28"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure1-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure5-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure6-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why do you think the performance of all models is generally lower on Rest15 compared to Rest14?", "reference_answer": "The performance of all models is generally lower on Rest15 because it has a larger number of aspect categories (13) compared to Rest14 (5). This increased complexity makes it more challenging for the models to accurately identify and classify the aspects."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fb2b57cc-02ba-5b0b-b3ca-7d7c25dfa89d", "question": "Describe how mobile net use depthwise separable convolution to reduce computation and the model size", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Describe how mobile net use depthwise separable convolution to reduce computation and the model size", "reference_answer": "MobileNets use depthwise convolution with one filter per input channel. The pointwise convolution then combines the depthwise convolution outputs with a 1\\times 1 convolution. This factorization greatly reduces computation and model size."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "9d0ab6a7-54b4-54ef-90e7-e9f8506e6286", "question": "What are some of the limitations of the YOLOv3 object detection model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a876dfa2-33ff-5ea3-a1c5-13580365217e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/1-Figure1-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/2-Figure2-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/2-Table1-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/3-Table2-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/3-Table3-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/4-Figure3-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/6-Figure4-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/6-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are some of the limitations of the YOLOv3 object detection model?", "reference_answer": "Some of the limitations of YOLOv3, based on the information given in the paper are: it is still quite a bit behind other models like RetinaNet in the \"COCO's weired average mAP\" metric (COCO average AP between 95 IOU metric), performance drops significantly as the IOU threshold increases indicating YOLOv3 struggles to get the boxes perfectly aligned with the object, it has comparatively worse performance on medium and larger size objects."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "66564304-dd1b-596d-b5c8-92fcd4b6d47f", "question": "Author said that they achieved to make SOTA RE models. Give an evidences for this statement.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["09e99859-dc08-55c1-b247-30c61f8916b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/11baa9cc02d6158edd9cb1f299579dad7828e162/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/11baa9cc02d6158edd9cb1f299579dad7828e162/4-Table1-1.png", "data/dataset/spiqa/images/11baa9cc02d6158edd9cb1f299579dad7828e162/4-Table2-1.png", "data/dataset/spiqa/images/11baa9cc02d6158edd9cb1f299579dad7828e162/7-Table3-1.png", "data/dataset/spiqa/images/11baa9cc02d6158edd9cb1f299579dad7828e162/7-Table4-1.png", "data/dataset/spiqa/images/11baa9cc02d6158edd9cb1f299579dad7828e162/7-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Author said that they achieved to make SOTA RE models. Give an evidences for this statement.", "reference_answer": "Their improved RE baseline achieved SOTA performance on the RE-TACRED dataset with f1 score of 91.1%. Moreover, Using RoBERTa Liu et al. (2019) as the backbone, they improved baseline model on TACRED and TACREV with f1 score 74.6% and 83.2%, respectively. The RoBERTa model achieves 1.9% higher f1 score than the SOTA model LUKE Yamada et al."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "37f60bde-84a6-5a9a-827a-f1c522b5c8ad", "question": "How does the presence of noise in the input image affect the quality of the generated images?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["570e01d8-2c85-5e04-b7e5-aef3f43f49b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure1-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure6-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure8-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure7-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure13-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure2-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure3-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure9-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure4-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure12-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure11-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure10-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the presence of noise in the input image affect the quality of the generated images?", "reference_answer": "The presence of noise in the input image can degrade the quality of the generated images, but the proposed algorithm is still able to generate realistic images even with a certain amount of noise."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "92885f9a-ffe9-55d5-b7db-63e9364b326b", "question": "Which sentiment analysis data set has a larger performance drop when a 10% error is introduced?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["55b0d70f-b335-5fa7-94d4-7f83398b05e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.12932/4-Figure4-1.png", "data/dataset/spiqa/images/2003.12932/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.12932/2-Figure1-1.png", "data/dataset/spiqa/images/2003.12932/2-Figure2-1.png", "data/dataset/spiqa/images/2003.12932/3-Table1-1.png", "data/dataset/spiqa/images/2003.12932/4-Figure3-1.png", "data/dataset/spiqa/images/2003.12932/4-Figure4-1.png", "data/dataset/spiqa/images/2003.12932/5-Figure5-1.png", "data/dataset/spiqa/images/2003.12932/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which sentiment analysis data set has a larger performance drop when a 10% error is introduced?", "reference_answer": "SST-2 dataset", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7bbb5540-3be3-5e37-8df3-f82865fc2ae8", "question": "Why might CDAN+E be considered a more versatile method for unsupervised domain adaptation compared to UNIT, CyCADA, and GTA?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["08eae607-b68b-5938-842d-52805a218768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table5-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table4-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table1-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why might CDAN+E be considered a more versatile method for unsupervised domain adaptation compared to UNIT, CyCADA, and GTA?", "reference_answer": "CDAN+E performs well across all five datasets listed in the table, including both digit and synthetic-to-real datasets, while UNIT, CyCADA, and GTA show strong results only on the digits and synthetic-to-real datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0efb71b5-65cd-54b4-9757-88055bc08787", "question": "BLINK is Scalable. Is this true?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Figure2-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Table1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Table2-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table3-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "BLINK is Scalable. Is this true?", "reference_answer": "The paper shows the scalability of the proposed simple two-stage method with the experiments conducted on the zero-shot entity-linking dataset where external entity knowledge is not available, which enables the model to be used on various entity linking tasks that contain millions of possible entities to consider. The state-of-the-art result and the extensive evaluation of the accuracy-speed trade-off support that the proposed method is efficient and scalable."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "6c5bbc03-c393-52a8-865f-2aa75b48d586", "question": "What are the four steps involved in the synonym discovery process using {\\modelname}?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the four steps involved in the synonym discovery process using {\\modelname}?", "reference_answer": " The four steps involved in the synonym discovery process are: \n\n1. **Entity representation learning:** Learn entity representations from the corpus using WEMBED.\n2. **NN search:** Perform a nearest neighbor search to find candidate entities for the query entity.\n3. **Synonym score calculation:** Calculate the synonym score between the query entity and each candidate entity using SYNONYM NET.\n4. **Synonym entity discovery:** Select the candidate entities with the highest synonym scores as the discovered synonym entities."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "62ca776a-9a23-5b09-89c0-6734383bb9da", "question": "Which of the three models, KAR, SAN, or QANet (without data augmentation), performs the best on AddSent when trained on the full training set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d32bd564-0b48-5101-817c-090485d59a03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table1-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the three models, KAR, SAN, or QANet (without data augmentation), performs the best on AddSent when trained on the full training set?", "reference_answer": "KAR"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "99feb85d-0018-59ae-a137-baa0298dcb31", "question": "Which dataset shows a higher variance in F1 score with increasing buffer size?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset shows a higher variance in F1 score with increasing buffer size?", "reference_answer": "ENRON"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "deb4d9d2-40d0-5411-a5fd-75bec0053281", "question": "How many hyperparameter combinations were used for the random hyperparameter search?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["96d9113e-0b25-5b72-bf1a-4d570cb7496b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Figure3-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/7-Figure4-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/8-Figure5-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/3-Figure1-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/5-Figure2-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/7-Figure4-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/8-Figure5-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Figure3-1.png", "data/dataset/spiqa/images/1b5a24639fa80056d1a17b15f6997d10e76cc731/9-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many hyperparameter combinations were used for the random hyperparameter search?", "reference_answer": "300 sets of possible hyperparameter combinations then choose four of them that complement each other well."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "89abbc3b-eecd-56ad-bb30-3e4902db9945", "question": "Is the semantic hierarchy representation used for any task?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["263b67f4-4270-5332-b7da-ff656f2e928b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.12140/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.12140/2-Figure1-1.png", "data/dataset/spiqa/images/1909.12140/3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the semantic hierarchy representation used for any task?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ff5bebd7-d714-5340-8ba3-e4394c91c3dd", "question": "How large is the corpus they use?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6a34c59b-851b-5437-aa72-a91164674d90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.08050/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.08050/2-Figure1-1.png", "data/dataset/spiqa/images/1804.08050/3-Figure2-1.png", "data/dataset/spiqa/images/1804.08050/4-Table1-1.png", "data/dataset/spiqa/images/1804.08050/4-Figure3-1.png", "data/dataset/spiqa/images/1804.08050/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How large is the corpus they use?", "reference_answer": "449050", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a193b65e-89f0-5fee-99a0-490760ed75bb", "question": "Which model performs best on the SICK 2014 dataset in terms of average Spearman and Pearson correlation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0ef7a576-90fe-5b70-81db-8770ba622135"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table2-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Figure1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table4-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table3-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table7-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table8-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table6-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best on the SICK 2014 dataset in terms of average Spearman and Pearson correlation?", "reference_answer": "C-PHRASE"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f089dfd3-58de-578f-9824-c1fe09d08cba", "question": "Which of the compared methods is most likely to be the safest?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the compared methods is most likely to be the safest?", "reference_answer": "ChoiceNet"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cc1a8c55-6fe8-536c-a226-1670579ea2c4", "question": "Which model performs the best on CIFAR100 and ILSVRC datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ed9d843d-3ea3-5d22-89db-e8dff591f7ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure3-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure1-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure4-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure5-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best on CIFAR100 and ILSVRC datasets?", "reference_answer": "EANN with AdaLoss performs the best on both CIFAR100 and ILSVRC datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b7f4c2af-2aad-57cb-b76d-7f9eece6c724", "question": "what state of the accuracy did they obtain?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e62bdbe5-1edf-5ed5-bb8b-874354645d9f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05907/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05907/2-Figure1-1.png", "data/dataset/spiqa/images/1704.05907/3-Table1-1.png", "data/dataset/spiqa/images/1704.05907/3-Figure2-1.png", "data/dataset/spiqa/images/1704.05907/4-Table3-1.png", "data/dataset/spiqa/images/1704.05907/4-Figure3-1.png", "data/dataset/spiqa/images/1704.05907/4-Table2-1.png", "data/dataset/spiqa/images/1704.05907/5-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what state of the accuracy did they obtain?", "reference_answer": "51.5", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5729d584-ad98-5280-a43b-0ad80782c7eb", "question": "What are the difference between plain networks and deep highway networks ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0931f3d2-f642-5062-8737-af4d1805c275"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/3-Figure1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/8-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/3-Figure1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table1-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/4-Table2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/5-Table3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/6-Figure2-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/7-Figure3-1.png", "data/dataset/spiqa/images/b92aa7024b87f50737b372e5df31ef091ab54e62/8-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the difference between plain networks and deep highway networks ?", "reference_answer": "A highway network is a layer that uses an information highway layer, and a plain network is a general layer. In highway networks, increasing layer depth does not affect performance, but in plain networks, it can. One layer of the plain network is made up of normal computation units, whereas the highway network is made up of block units."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f4187b9d-f3e4-5819-84ff-06c882120d54", "question": "Which explanation method seems to place the most emphasis on specific, localized features rather than smooth, gradual changes in pixel intensity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["562bd590-5817-560b-97d0-c246b4293ab9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table2-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table3-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table1-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table4-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which explanation method seems to place the most emphasis on specific, localized features rather than smooth, gradual changes in pixel intensity?", "reference_answer": "LIME appears to place the most emphasis on specific, localized features."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "64e080be-b4d2-5a47-b90d-ff58f934ea39", "question": "Which 3 NLP areas are cited the most?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["083c588e-cadb-585b-985f-70949e59e35d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.03562/29-Figure33-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.03562/2-Figure1-1.png", "data/dataset/spiqa/images/1911.03562/3-Figure2-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure3-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure4-1.png", "data/dataset/spiqa/images/1911.03562/6-Figure5-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure6-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure7-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure8-1.png", "data/dataset/spiqa/images/1911.03562/8-Figure9-1.png", "data/dataset/spiqa/images/1911.03562/9-Figure10-1.png", "data/dataset/spiqa/images/1911.03562/10-Figure11-1.png", "data/dataset/spiqa/images/1911.03562/12-Figure12-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure13-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure14-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure15-1.png", "data/dataset/spiqa/images/1911.03562/15-Figure16-1.png", "data/dataset/spiqa/images/1911.03562/16-Figure17-1.png", "data/dataset/spiqa/images/1911.03562/17-Figure18-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure19-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure20-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure21-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure22-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure23-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure24-1.png", "data/dataset/spiqa/images/1911.03562/20-Figure25-1.png", "data/dataset/spiqa/images/1911.03562/21-Figure26-1.png", "data/dataset/spiqa/images/1911.03562/22-Figure27-1.png", "data/dataset/spiqa/images/1911.03562/23-Figure28-1.png", "data/dataset/spiqa/images/1911.03562/24-Figure29-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure30-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure31-1.png", "data/dataset/spiqa/images/1911.03562/28-Figure32-1.png", "data/dataset/spiqa/images/1911.03562/29-Figure33-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which 3 NLP areas are cited the most?", "reference_answer": "machine translation, statistical machine, sentiment analysis", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e74031a3-affa-5786-aa2b-6982bc5c8d32", "question": "How large is the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["671e0591-8aa2-519a-8c5e-d9e2e1277e52"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.10361/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.10361/2-Table1-1.png", "data/dataset/spiqa/images/2002.10361/3-Table2-1.png", "data/dataset/spiqa/images/2002.10361/3-Table3-1.png", "data/dataset/spiqa/images/2002.10361/4-Table4-1.png", "data/dataset/spiqa/images/2002.10361/4-Figure1-1.png", "data/dataset/spiqa/images/2002.10361/5-Table5-1.png", "data/dataset/spiqa/images/2002.10361/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How large is the dataset?", "reference_answer": "over 104k documents", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1553ac33-f297-5cb0-9b78-60fedd1029c9", "question": "Which attack method is the most effective at reducing the accuracy of the Resnet-32 model on the MNIST dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which attack method is the most effective at reducing the accuracy of the Resnet-32 model on the MNIST dataset?", "reference_answer": "The most effective attack method at reducing the accuracy of the Resnet-32 model on the MNIST dataset is BIM/CE."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "44f51eeb-6087-5fc0-8549-879728d1f416", "question": "How does the memory usage of the RIOT OS posix_sockets module compare to the memory used by the protocol and socket layer combined, for both active and passive connections?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the memory usage of the RIOT OS posix_sockets module compare to the memory used by the protocol and socket layer combined, for both active and passive connections?", "reference_answer": "The posix_sockets module consistently uses less memory than the combined usage of the protocol and socket layer. For an active connection, it requires about 5468 B compared to 19972 B + 6216 B = 26188 B for the other layers. Similarly, for a passive connection, it uses 5468 B compared to 19972 B + 6216 B = 26188 B for the other layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "50dc58d8-10c5-5e8e-ad48-8d2ef6e6b297", "question": "How large is the gap in performance between the HMMs and the LSTMs?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["87a9e03f-09ae-5bb4-bc24-68595340bd33"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1606.05320/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1606.05320/2-Figure1-1.png", "data/dataset/spiqa/images/1606.05320/3-Table1-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure2-1.png", "data/dataset/spiqa/images/1606.05320/4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How large is the gap in performance between the HMMs and the LSTMs?", "reference_answer": "With similar number of parameters, the log likelihood is about 0.1 lower for LSTMs across datasets. When the number of parameters in LSTMs is increased, their log likelihood is up to 0.7 lower.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "91cfa2bf-5291-54ce-883f-75833341d5fd", "question": "How do the parameter network and the deformation network differ in terms of complexity and function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the parameter network and the deformation network differ in terms of complexity and function?", "reference_answer": "The parameter network is a simple structure with two fully connected layers, while the deformation network is more complex and contains two fully connected layers followed by two or more four-dimensional de-convolution layers. The parameter network learns how to apply multiple long-range, non-linear deformation fields, while the deformation network learns to generate dense deformation fields to refine the final surface."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "79582364-b859-5320-8793-878e0abec060", "question": "What is the purpose of the residual connection in the decoding module?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the residual connection in the decoding module?", "reference_answer": "The residual connection allows the output of a layer to be added to the output of another layer, which helps to improve the flow of information through the network."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7709fe3e-991c-5af4-aeeb-52781a784e4c", "question": "How does the addition of negative samples affect the gradient of BPR and BPR-max with respect to the target score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the addition of negative samples affect the gradient of BPR and BPR-max with respect to the target score?", "reference_answer": "The addition of negative samples increases the gradient of BPR and BPR-max with respect to the target score."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6f405b37-e031-539a-9250-8ea67f99384c", "question": "How does the landscape concentration of the humanoid-v2 PPO policy change with respect to the number of state-action pairs?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["291817c4-b436-55c1-a356-e28360b7edb9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure20-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure5-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure18-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure19-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure8-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure14-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure6-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure15-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Table1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure2-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure11-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure16-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure7-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure3-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure12-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure10-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure20-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure17-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure13-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure4-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the landscape concentration of the humanoid-v2 PPO policy change with respect to the number of state-action pairs?", "reference_answer": "The landscape concentration increases with the number of state-action pairs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3b840bc8-970b-5c51-a34e-43907d47f82c", "question": "What is the final improved architecture used by authors for experiments in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the final improved architecture used by authors for experiments in this paper?", "reference_answer": "They use variable width with 2 residual blocks per resolution, multiple heads with 64 channels per head, attention at 32, 16 and 8 resolutions, BigGAN residual blocks for up and downsampling, and adaptive group normalization for injecting timestep and class embeddings into residual blocks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0beca83d-ff27-5a8e-93b3-77062cfc69c2", "question": "What is the role of OpenIE in Step 1 of TFBA?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0369791-b574-5ff8-aaeb-89c221d8f857"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table4-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of OpenIE in Step 1 of TFBA?", "reference_answer": "OpenIE is used to extract tuples from the unlabeled text corpus. These tuples are then used to create the 3-mode tensors X1, X2, and X3."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b9618ca7-e01e-5cb3-90b9-b4341738577c", "question": "Assuming the authors performed a brute force hyperparameter search on all permutations of the five hyperparameters - hidden layer sizes, depths, LR, batch size and dropout - how many total experiments would they have had to perform?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Assuming the authors performed a brute force hyperparameter search on all permutations of the five hyperparameters - hidden layer sizes, depths, LR, batch size and dropout - how many total experiments would they have had to perform?", "reference_answer": "For Deep LSTM readers 3 values of hidden layer sizes, 3 values of depths, 3 starting LRs, 2 batch sizes and 3 dropout fractions are considered. This is a total of (3 * 3 * 3 * 2 * 3) = 162 configurations. Similarly for attention models, they experimented with 3 hidden layer sizes, 4 possible learning rates, 3 batch sizes and 4 values of dropout (3*4*3*4) = 144 possible configurations. Thus, if the authors performed a brute force hyperparameter search, they would have had to done 162 experiments for the vanilla Deep LSTM model and 144 experiments for the attention based model, or a total of 162 + 144 = 306 experiments."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b5a25564-9267-5c50-b6a0-24b94e9f0730", "question": "Normally, GAN training is unstable. Does this framework help to make the model stable?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["db57be6f-8829-5091-b1d9-ef653aa08e83"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/8-Figure7-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/11-Figure10-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/12-Figure11-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/13-Figure12-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/14-Figure13-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/15-Figure14-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/15-Figure15-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/16-Figure16-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/16-Figure17-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/2-Figure2-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/3-Figure3-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/4-Figure4-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/6-Figure5-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/6-Figure6-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table1-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table2-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table3-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/7-Table4-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/8-Figure7-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/8-Figure8-1.png", "data/dataset/spiqa/images/c43d954cf8133e6254499f3d68e45218067e4941/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Normally, GAN training is unstable. Does this framework help to make the model stable?", "reference_answer": "[The paper applies two techniques to stabilize its model training procedure. First, for \\mathcal{L}_{\\text{GAN}} (Equation 1), the paper replaces the negative log likelihood objective by a least-squares loss. Secondly, to reduce model oscillation, the paper follows Shrivastava et al.’s strategy and updates the discriminators using a history of generated images rather than the ones produced by the latest generators. The paper keeps an image buffer that stores the 50 previously created images. The paper also evaluates its method with the cycle loss in only one direction and finds that it often incurs training instability and causes mode collapse, especially for the direction of the mapping that was removed.]"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0aea1b05-6002-5ba7-81e5-008953f52074", "question": "What is the initial value of V2 in the interval [0.35, 0.67]?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4713fdd0-d414-5267-9d4e-3c4e85657fe4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure5-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure6-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure4-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table2-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure2-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table1-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure3-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure8-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure1-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the initial value of V2 in the interval [0.35, 0.67]?", "reference_answer": "0.35"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7d6ab324-d0ea-5880-95e4-fb687723f831", "question": "How does the number of cameras used affect the accuracy of the garment reconstruction?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the number of cameras used affect the accuracy of the garment reconstruction?", "reference_answer": "The accuracy of the garment reconstruction increases as the number of cameras used increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ed9ef822-d9e2-50cf-befa-1e22b6bfd390", "question": "What is IS as a measure of fidelity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is IS as a measure of fidelity?", "reference_answer": "IS measures of fidelity but it has a drawback that it does not reward covering the whole distribution or capturing diversity within a class, and models which memorize a small subset of the full dataset will still have high IS."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "88d07a81-c980-5f0b-8589-042cea07c3ff", "question": "Which datasets are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["acde2923-a403-5f4c-a39e-0298b5491253"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.08960/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.08960/1-Figure1-1.png", "data/dataset/spiqa/images/1912.08960/3-Table1-1.png", "data/dataset/spiqa/images/1912.08960/4-Figure2-1.png", "data/dataset/spiqa/images/1912.08960/5-Figure3-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure4-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure6-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which datasets are used?", "reference_answer": "ShapeWorldICE datasets: OneShape, MultiShapes, TwoShapes, MultiShapes, Count, and Ratio", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "14e23b60-21c5-5f1f-bed2-4c0e77fd8806", "question": "Only a small number of examples (32) are randomly selected to be unlearned. Have the authors tried unlearning much larger portions of the training data and observing the effect on the resulting model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2148cb60-8df5-50ee-9b1b-c8262ccf9f54"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/8-Figure2-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/8-Figure2-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/8-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/10-Table4-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/15-Figure4-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/16-Figure5-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/17-Table5-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/18-Table6-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/18-Table7-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/19-Table8-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/19-Table9-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/2-Figure1-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/20-Table10-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/21-Table11-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/21-Table12-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/7-Table1-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/7-Table2-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/8-Figure2-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/9-Figure3-1.png", "data/dataset/spiqa/images/91fb2254c5942048425e642c8a6c8d400006150e/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Only a small number of examples (32) are randomly selected to be unlearned. Have the authors tried unlearning much larger portions of the training data and observing the effect on the resulting model?", "reference_answer": "Results show that forgetting 128 samples at once results in a severe degradation of general LM performance while forgetting 32 samples does not."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "4940ef40-7731-5c03-88ab-d7fe9a917a67", "question": "If a user with 100 followers posts a tweet, how many CRDT updates will be performed in total, and what percentage of the overall workload does this represent?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "If a user with 100 followers posts a tweet, how many CRDT updates will be performed in total, and what percentage of the overall workload does this represent?", "reference_answer": "Posting a tweet will result in 1 + 100 = 101 CRDT updates. This represents 35% of the overall workload."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5e7583de-6f22-501d-8a95-33f18e0a92dd", "question": "Which training dataset allowed for the best generalization to benchmark sets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["906a1415-0b8a-531a-97e8-96878b6c2642"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.09774/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.09774/3-Table1-1.png", "data/dataset/spiqa/images/1810.09774/4-Table2-1.png", "data/dataset/spiqa/images/1810.09774/5-Table3-1.png", "data/dataset/spiqa/images/1810.09774/6-Table4-1.png", "data/dataset/spiqa/images/1810.09774/9-Table5-1.png", "data/dataset/spiqa/images/1810.09774/10-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which training dataset allowed for the best generalization to benchmark sets?", "reference_answer": "MultiNLI", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "79ab5197-1598-5938-9d75-ff367333dc75", "question": "what were the baselines?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["308cff71-46a0-50ee-9116-6a1056686328"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.06264/5-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.06264/1-Table1-1.png", "data/dataset/spiqa/images/1908.06264/3-Figure1-1.png", "data/dataset/spiqa/images/1908.06264/4-Table2-1.png", "data/dataset/spiqa/images/1908.06264/4-Table4-1.png", "data/dataset/spiqa/images/1908.06264/4-Table5-1.png", "data/dataset/spiqa/images/1908.06264/4-Table3-1.png", "data/dataset/spiqa/images/1908.06264/5-Table6-1.png", "data/dataset/spiqa/images/1908.06264/5-Table7-1.png", "data/dataset/spiqa/images/1908.06264/6-Table8-1.png", "data/dataset/spiqa/images/1908.06264/6-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what were the baselines?", "reference_answer": "BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e035835e-2c2f-5727-a933-d66f4bfe32e4", "question": "What can you infer from the training curves for the ACGAN?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dc5584b7-6dd8-5e79-b1ba-1d77ce70df61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure1-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure3-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table2-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What can you infer from the training curves for the ACGAN?", "reference_answer": "The training curves for the ACGAN show that the generator and discriminator losses both decrease over time. This indicates that the ACGAN is able to learn to generate realistic images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "88b5791b-4b99-5209-8265-53eb44edfafc", "question": "Based on the table, which approach achieved the highest mean IoU for semantic segmentation, and how did it perform compared to the baseline Sem-Seg model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the table, which approach achieved the highest mean IoU for semantic segmentation, and how did it perform compared to the baseline Sem-Seg model?", "reference_answer": "The **Sem-Seg + Det** approach achieved the highest mean IoU of 58.3, which is an improvement of 1.4 points compared to the baseline Sem-Seg model with a mean IoU of 56.9."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b27d6272-aba6-51d6-9fc1-75382bc86556", "question": "How is the Hilbert space-filling curve constructed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How is the Hilbert space-filling curve constructed?", "reference_answer": "The Hilbert space-filling curve is constructed recursively. The curve starts with a simple square, and then at each subsequent iteration, the curve is subdivided into four smaller squares. The curve is then drawn through each of these squares in a specific order."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "81323a8f-3361-5f5b-8e31-823f417b78b0", "question": "What are the eight different LSTM variants that the authors experimented with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d2d678fc-c8f2-5edf-b804-f78e6cf64638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/6-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/2-Figure1-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/4-Figure2-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/6-Figure3-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/8-Figure4-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/8-Figure5-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the eight different LSTM variants that the authors experimented with?", "reference_answer": "The authors conducted the experiment with these LSTM variants of the vanilla architecture to empirically compare different LSTM variants: No Input Gate (NIG), No Forget Gate (NFG), No Output Gate (NOG), No Input Activation Function (NIAF), No Output Activation Function (NOAF), Coupled Input and Forget Gate (CIFG), No Peepholes (NP), Full Gate Recurrence (FGR)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7534eaad-4653-5f23-a9a9-762ca82d04d4", "question": "How do TRPO and PPO compare in terms of convergence to the true gradient?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["291817c4-b436-55c1-a356-e28360b7edb9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure10-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure5-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure18-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure19-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure8-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure14-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure6-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure15-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Table1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure2-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure11-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure16-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure7-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure3-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure12-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure10-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure20-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure17-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure13-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure4-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do TRPO and PPO compare in terms of convergence to the true gradient?", "reference_answer": "TRPO generally converges faster to the true gradient than PPO."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "31576cf0-b7a9-5ff5-b67b-a0c700584ee3", "question": "What is the purpose of the residual connection in the encoding module?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the residual connection in the encoding module?", "reference_answer": "The residual connection adds the output of a layer to the output of another layer, which helps to prevent the vanishing gradient problem."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "99429d14-c2d1-5bcf-9fee-7235d26ecd71", "question": "Why is it beneficial to fix the prototype embedding g to have unit length?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["eee65441-957d-5caa-a5e1-e063d3b1526f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/2-Figure1-1.png", "data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/5-Figure2-1.png", "data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/6-Table1-1.png", "data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/6-Table2-1.png", "data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/7-Figure3-1.png", "data/dataset/spiqa/images/c269858a7bb34e8350f2442ccf37797856ae9bca/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why is it beneficial to fix the prototype embedding g to have unit length?", "reference_answer": "[In Zero-shot learning, since the meta-data vector and query point come from different input domains, the paper found it empirically beneficial to fix the prototype embedding g to have unit length, however the paper did not constrain the query embedding f.]"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d4de320a-7b2c-5dcc-9a98-abe9ae75236b", "question": "What were the datasets used in this paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["326ade97-a3af-5e28-a28c-1690c49dfbda"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13104/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13104/3-Table1-1.png", "data/dataset/spiqa/images/1909.13104/4-Figure1-1.png", "data/dataset/spiqa/images/1909.13104/5-Figure2-1.png", "data/dataset/spiqa/images/1909.13104/7-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What were the datasets used in this paper?", "reference_answer": "Twitter dataset provided by organizers containing harassment and non-harassment tweets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "cd61dac7-e0af-5cff-8cba-c03438f3ad45", "question": "How does the accuracy of the US-BS-MQ method compare to that of the S-MQ method when adding SST examples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ffd62601-2bd0-5ace-ac7f-d4fb321dcc10"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure1-1.png", "data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure3-1.png", "data/dataset/spiqa/images/1805.04609v3/1805.04609v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the accuracy of the US-BS-MQ method compare to that of the S-MQ method when adding SST examples?", "reference_answer": "The US-BS-MQ method achieves higher accuracy than the S-MQ method when adding SST examples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4851198b-c338-5e18-876b-a9fc75b88e54", "question": "Can you explain why the BOSSNET with multi-hop encoder performs better on bAbI tasks 3 and 5 compared to the 1-hop encoder, and how this relates to the tasks themselves?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Can you explain why the BOSSNET with multi-hop encoder performs better on bAbI tasks 3 and 5 compared to the 1-hop encoder, and how this relates to the tasks themselves?", "reference_answer": "The multi-hop encoder performs better on bAbI tasks 3 and 5 because these tasks specifically require inferencing over multiple KB tuples. In other words, the model needs to \"hop\" between different pieces of information in the knowledge base to make the correct inferences and recommendations.\n\nTask 3 involves sorting restaurants by rating, and task 5 requires recommending a restaurant based on user preferences. Both tasks necessitate the model to consider various restaurant attributes and their relationships, which the multi-hop encoder facilitates by capturing longer-range dependencies within the knowledge base."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c96e8102-9ef2-55b0-9af1-3eb69dc3f27c", "question": "Is hyperparameter optimization performed independently for the two dataset corpora?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is hyperparameter optimization performed independently for the two dataset corpora?", "reference_answer": "Yes, it does appear that hyperparameter optimization for each dataset is performed independently."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "6f4bf53f-016a-5b4c-a98b-bf382fe04f03", "question": "How does the quality of the reconstructed frames change as the resolution increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the quality of the reconstructed frames change as the resolution increases?", "reference_answer": "The quality of the reconstructed frames increases monotonically as the resolution increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "25ce2bc4-ac13-5cf3-96fa-96e501ccf866", "question": "The paper mentions using Daily News and CNN bullet-point summaries to generate queries. Would the authors' approach towards building this supervised dataset work effectively if these news sources created the summaries by merely extracting sentences from the whole article, instead of rephrasing and condensing text?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The paper mentions using Daily News and CNN bullet-point summaries to generate queries. Would the authors' approach towards building this supervised dataset work effectively if these news sources created the summaries by merely extracting sentences from the whole article, instead of rephrasing and condensing text?", "reference_answer": "The authors, in multiple places, emphasize that their approach relies on the fact that DailyMail and CNN both use abstractive summaries for their bullet points. This fact probably implies that the authors approach would not work on news sources that merely use excerpts or extracts for summaries."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d7b78ebe-1e76-5199-b1bc-69f7591c1a09", "question": "How does the performance of the \"Conv. Self-Correction\" method compare to other methods when using 30% of the training examples as $\\F$ and the remaining as $\\W$ on the Cityscapes validation set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the \"Conv. Self-Correction\" method compare to other methods when using 30% of the training examples as $\\F$ and the remaining as $\\W$ on the Cityscapes validation set?", "reference_answer": "The \"Conv. Self-Correction\" method achieves the highest mIOU score of 79.46 compared to other methods listed in the table under the same data split condition."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fbef036f-a4af-5599-aa9d-b40d4209b20e", "question": "Which model performs the best on qaVG when considering both image understanding (IU) and question understanding (QU) individually, and how does its performance compare to humans?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best on qaVG when considering both image understanding (IU) and question understanding (QU) individually, and how does its performance compare to humans?", "reference_answer": "MLP-QA performs the best when considering both IU and QU individually, achieving 89.3% accuracy on IU and 45.6% accuracy on QU. However, its combined performance (IU+QU) of 43.9% is still significantly lower than human performance, which stands at 82.5%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "70a74133-d834-55f7-9a6d-37356d3fa5cd", "question": "How does the discrimination in the prediction of the two-phase framework (MSG) compare to that of DI, both with and without classifier tweaking, when the sample size is 2000?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ae8d5c70-ce29-53e2-a06e-295997bae48c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.00060v2/1703.00060v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.00060v2/1703.00060v2-Table2-1.png", "data/dataset/spiqa/images/1703.00060v2/1703.00060v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the discrimination in the prediction of the two-phase framework (MSG) compare to that of DI, both with and without classifier tweaking, when the sample size is 2000?", "reference_answer": "When the sample size is 2000, the two-phase framework (MSG) achieves lower discrimination in prediction compared to DI, both with and without classifier tweaking.\n\nWith classifier tweaking: MSG achieves a discrimination level of 0.016 ± 5.3E-4, while DI shows a significantly higher level of 0.095 ± 1.6E-3.\nWithout classifier tweaking: MSG still demonstrates lower discrimination with 0.067 ± 4.3E-3 compared to DI's 0.095 ± 1.6E-3.\n\nThis indicates that the two-phase framework is more effective in removing discrimination from predictions than DI, regardless of whether classifier tweaking is applied."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a412234f-0890-5566-8270-3c26c17db451", "question": "Which data do they use as a starting point for the dialogue dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5afed7c8-6099-51f8-8736-d1d8e8d876a3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1903.03530/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1903.03530/2-Figure1-1.png", "data/dataset/spiqa/images/1903.03530/4-Table1-1.png", "data/dataset/spiqa/images/1903.03530/5-Figure2-1.png", "data/dataset/spiqa/images/1903.03530/6-Table2-1.png", "data/dataset/spiqa/images/1903.03530/6-Figure3-1.png", "data/dataset/spiqa/images/1903.03530/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which data do they use as a starting point for the dialogue dataset?", "reference_answer": "A sample from nurse-initiated telephone conversations for congestive heart failure patients undergoing telepmonitoring, post-discharge from the Health Management Unit at Changi General Hospital", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3ac91a0d-59d5-5c17-bb79-7089ac3bc2ea", "question": "Do they perform manual evaluation?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["1b109dd7-b6a1-51bb-9346-250d98565d8b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.06512/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.06512/2-Figure1-1.png", "data/dataset/spiqa/images/1905.06512/4-Figure2-1.png", "data/dataset/spiqa/images/1905.06512/6-Table1-1.png", "data/dataset/spiqa/images/1905.06512/6-Figure3-1.png", "data/dataset/spiqa/images/1905.06512/7-Table2-1.png", "data/dataset/spiqa/images/1905.06512/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they perform manual evaluation?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "03c907a7-b3b1-5912-81f9-b34ddd49930c", "question": "What is the function of the Hamilton-based PCB in the ultrasonic anemometer?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the function of the Hamilton-based PCB in the ultrasonic anemometer?", "reference_answer": "The Hamilton-based PCB is the electronic control board of the anemometer. It houses the microcontroller, sensors, and other electronic components that are necessary for the anemometer to function."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8ed8049f-712e-5ca9-9df4-29e67fb560e0", "question": "What is the minimum number of sides that a rectilinear polygon with four reflex vertices must have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f51e9f68-1547-5a42-8e74-fbfbfcb7f509"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure5-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure3-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure4-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Table1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the minimum number of sides that a rectilinear polygon with four reflex vertices must have?", "reference_answer": "Six."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4104d018-23a8-512e-ad6a-b5701816f8b4", "question": "What are the competing models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e58d5de7-fb55-553a-b34b-b50ee725fc66"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.11235/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.11235/3-Table1-1.png", "data/dataset/spiqa/images/1910.11235/4-Table2-1.png", "data/dataset/spiqa/images/1910.11235/4-Table3-1.png", "data/dataset/spiqa/images/1910.11235/4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the competing models?", "reference_answer": "TEACHER FORCING (TF), SCHEDULED SAMPLING (SS),  SEQGAN, RANKGAN, LEAKGAN.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1b692abf-d92a-52ad-b3ca-35e35f021ea6", "question": "What is the purpose of the fusion modules in the interactive alignment and self-alignment modules?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e31707d3-f5f4-5c59-86a2-af24ff7cfed7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the fusion modules in the interactive alignment and self-alignment modules?", "reference_answer": "The fusion modules are used to combine the outputs of the interactive alignment and self-alignment modules."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "59ffc679-ca05-5137-981b-56ffbd716f67", "question": "what previous systems were compared to?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["70e11ea7-638c-5b7e-87a9-95c88d35862c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.00108/6-Table3-1.png", "data/dataset/spiqa/images/1705.00108/5-Table1-1.png", "data/dataset/spiqa/images/1705.00108/5-Table2-1.png", "data/dataset/spiqa/images/1705.00108/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.00108/2-Figure1-1.png", "data/dataset/spiqa/images/1705.00108/3-Figure2-1.png", "data/dataset/spiqa/images/1705.00108/5-Table1-1.png", "data/dataset/spiqa/images/1705.00108/5-Table2-1.png", "data/dataset/spiqa/images/1705.00108/6-Table3-1.png", "data/dataset/spiqa/images/1705.00108/6-Table4-1.png", "data/dataset/spiqa/images/1705.00108/6-Table5-1.png", "data/dataset/spiqa/images/1705.00108/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what previous systems were compared to?", "reference_answer": "Chiu and Nichols (2016), Lample et al. (2016), Ma and Hovy (2016), Yang et al. (2017), Hashimoto et al. (2016), Søgaard and Goldberg (2016) ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e8e41728-7a30-5372-89ab-4afd5c61a47e", "question": "What is the difference between the \"True max\" and the \"ALOQ\" curves?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the \"True max\" and the \"ALOQ\" curves?", "reference_answer": "The \"True max\" curve is the true maximum of the function, while the \"ALOQ\" curve is an approximation of the maximum. The \"ALOQ\" curve is lower than the \"True max\" curve, indicating that it underestimates the maximum value of the function."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "aecf6948-3981-582e-b7af-c8fa8ebfba36", "question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f66ecb48-d5bf-558e-800b-964715930502"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.01081/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.01081/2-Figure1-1.png", "data/dataset/spiqa/images/1906.01081/5-Table1-1.png", "data/dataset/spiqa/images/1906.01081/6-Figure2-1.png", "data/dataset/spiqa/images/1906.01081/6-Table2-1.png", "data/dataset/spiqa/images/1906.01081/7-Figure3-1.png", "data/dataset/spiqa/images/1906.01081/7-Figure4-1.png", "data/dataset/spiqa/images/1906.01081/8-Table3-1.png", "data/dataset/spiqa/images/1906.01081/8-Table4-1.png", "data/dataset/spiqa/images/1906.01081/9-Figure5-1.png", "data/dataset/spiqa/images/1906.01081/11-Figure6-1.png", "data/dataset/spiqa/images/1906.01081/11-Table5-1.png", "data/dataset/spiqa/images/1906.01081/12-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "reference_answer": "Their average correlation tops the best other model by 0.155 on WikiBio.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5035dbdd-5612-5768-8823-58c6e4c49f11", "question": "What is the purpose of the Cholesky Block in this figure?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the Cholesky Block in this figure?", "reference_answer": "The Cholesky Block is used to distinguish abnormal patterns from normal patterns."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c91df77a-f1c7-5bd4-a03d-c8fa367eec80", "question": "How does Pairwise Confusion (PC) affect the localization ability of a CNN?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["296788f8-16bc-55ff-9d9a-9fdf5ff3b0e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table4-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does Pairwise Confusion (PC) affect the localization ability of a CNN?", "reference_answer": "PC improves the localization ability of a CNN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "87548141-ff4c-5f42-9884-68733dd3d3b5", "question": "Which ATE estimator is most affected by the presence of noisy confounders?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["af9d16f1-fea7-5ffd-8fce-8a0430f9324e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure3-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure5-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table2-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table5-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure8-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure1-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table1-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table4-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure7-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure6-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table3-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure4-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which ATE estimator is most affected by the presence of noisy confounders?", "reference_answer": "Outcome Regression (OR)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "80692532-cb61-5f90-86b5-e52663105fdf", "question": "What component of LSTNet is most important for its performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What component of LSTNet is most important for its performance?", "reference_answer": "The AR component."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a885eaee-67a4-5c6c-9b6a-7e98205cb561", "question": "What is the difference between testing domain adaptation and testing sensor fusion?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["86d109ac-bfba-5548-a67e-8dfd401e8f3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table7-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table6-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table5-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table9-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table2-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table8-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between testing domain adaptation and testing sensor fusion?", "reference_answer": "In testing domain adaptation, the source and target CNNs are trained on different domains, and the joint classifier is used to predict the class of the target data. In testing sensor fusion, the source and target CNNs are trained on the same domain, and the joint classifier is used to predict the class of the target data using both the source and target data."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a4ef5287-f287-51d8-8349-31bce78d3363", "question": "Which models do they try out?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7e3db540-39e1-58df-960b-83fcd2e7ffd9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.12885/8-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.12885/3-Figure2-1.png", "data/dataset/spiqa/images/1810.12885/4-Figure3-1.png", "data/dataset/spiqa/images/1810.12885/5-Figure4-1.png", "data/dataset/spiqa/images/1810.12885/5-Table1-1.png", "data/dataset/spiqa/images/1810.12885/6-Table2-1.png", "data/dataset/spiqa/images/1810.12885/7-Table3-1.png", "data/dataset/spiqa/images/1810.12885/8-Table4-1.png", "data/dataset/spiqa/images/1810.12885/8-Figure5-1.png", "data/dataset/spiqa/images/1810.12885/9-Figure7-1.png", "data/dataset/spiqa/images/1810.12885/9-Table5-1.png", "data/dataset/spiqa/images/1810.12885/9-Figure6-1.png", "data/dataset/spiqa/images/1810.12885/14-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which models do they try out?", "reference_answer": "DocQA, SAN, QANet, ASReader, LM, Random Guess", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "12e5bac8-9553-5e7c-a2ac-1822d650474e", "question": "Does using horizontal connections depend on the amount and complexity of the data wanted to be segmented?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does using horizontal connections depend on the amount and complexity of the data wanted to be segmented?", "reference_answer": "Yes, more complex data can be finely segmented by using horizontal connections in the CNN network."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "551de871-8b57-5384-9974-8ce4a0ff3b02", "question": "What is the size of the new dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f9d26857-e887-5526-8b66-e0f9cecda38e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.09666/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.09666/2-Table1-1.png", "data/dataset/spiqa/images/1902.09666/3-Table2-1.png", "data/dataset/spiqa/images/1902.09666/4-Table3-1.png", "data/dataset/spiqa/images/1902.09666/5-Table4-1.png", "data/dataset/spiqa/images/1902.09666/5-Table5-1.png", "data/dataset/spiqa/images/1902.09666/5-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the size of the new dataset?", "reference_answer": "14,100 tweets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "93506c54-c860-54c8-8294-3ae2d1175859", "question": "Explain why the \"Last contact\" feature has a significant positive influence on the SSL score in both examples, even though it is not directly used by the SSL algorithm.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["562bd590-5817-560b-97d0-c246b4293ab9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table2-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table3-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table1-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table4-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Explain why the \"Last contact\" feature has a significant positive influence on the SSL score in both examples, even though it is not directly used by the SSL algorithm.", "reference_answer": "The \"Last contact\" feature shows a strong positive influence on the SSL score because it is likely correlated with other features that are used by the algorithm. As the passage mentions, data-driven methods like MIM can assign influence to features that are not directly used by the model if they are correlated with other influential features. In this case, a recent \"Last contact\" date might be correlated with a higher number of recent offenses or other factors that contribute to a higher SSL score."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6bf6328c-b1b7-5191-a451-ab5472c64cbb", "question": "What are the side effects of group convolution?\n", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the side effects of group convolution?\n", "reference_answer": "The side effects of group convolutions are: blocked flow of information between channel groups when multiple group convolutions are combined; and damaged individual convolution filters for each group due to decreased number of input channels."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "126097ac-1893-538f-bddc-b5dc66ef72f7", "question": "How is deep learning used in the process of feature extraction in face recognition systems?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How is deep learning used in the process of feature extraction in face recognition systems?", "reference_answer": "The deep learning model does feature extraction by processing the image through many layers and giving an encoding of the face that can be used to solve different FR tasks. The early layers of a deep learning model tend to represent simple textures that continuously evolve into facial structures in the later layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "22350f52-cf72-5fa1-81a4-03138e6d2541", "question": "Which type of generator generally produced reviews that were most easily identified as machine-generated by the meta-adversarial evaluators?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d2f53917-bc62-5131-9eb4-af4a7211b645"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure8-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure9-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table4-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure10-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure4-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure5-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table3-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table9-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure6-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure1-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table1-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure12-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure7-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table7-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table5-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table8-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table6-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure11-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which type of generator generally produced reviews that were most easily identified as machine-generated by the meta-adversarial evaluators?", "reference_answer": "MLE SeqGAN and Word LSTM with temperature 1.0."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1aaa4f8d-50a2-5cca-a22d-4fe8dc9fb881", "question": "Why might the authors claim that although BOSSNET achieves a lower BLEU score than Mem2Seq on the SMD dataset, it still performs better in conveying necessary entity information?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why might the authors claim that although BOSSNET achieves a lower BLEU score than Mem2Seq on the SMD dataset, it still performs better in conveying necessary entity information?", "reference_answer": "While BOSSNET has a lower BLEU score than Mem2Seq on SMD, it achieves the highest Entity F1 score on that dataset. This suggests that BOSSNET is better at capturing and including the relevant entities in its responses, even though it may not have as much lexical overlap with the gold responses as Mem2Seq."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "26a42e78-88f2-51f2-96bc-3db440783b4e", "question": "How does the ChoiceNet model perform on datasets with uniform corruptions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the ChoiceNet model perform on datasets with uniform corruptions?", "reference_answer": "The ChoiceNet model performs poorly on datasets with uniform corruptions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4bf465ac-9ee3-5751-88d4-656adfb7b748", "question": "Which quality factor improves the most as k is increased?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which quality factor improves the most as k is increased?", "reference_answer": "MS-SSIM"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "237fffb7-dc79-56cd-9f59-b36df42003cd", "question": "Which model performs the best for response selection, and how can we tell?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d62d3025-a1b0-5616-84f5-5ea256c9ac90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table3-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table2-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table1-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table4-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table5-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table6-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best for response selection, and how can we tell?", "reference_answer": "The KEHNN model performs the best for response selection. This is evident because it achieves the highest scores across all metrics (R$2$@1, R${10}$@1, R${10}$@2, and R${10}$@5) compared to all other models in the table."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "be992cb8-92d4-5097-8021-a63bd3c3cbb5", "question": "What accuracy does the proposed system achieve?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c4efe9a-9220-55d0-add7-651e7176d6b1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.05147/6-Table3-1.png", "data/dataset/spiqa/images/1801.05147/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.05147/3-Figure1-1.png", "data/dataset/spiqa/images/1801.05147/5-Table1-1.png", "data/dataset/spiqa/images/1801.05147/6-Table2-1.png", "data/dataset/spiqa/images/1801.05147/6-Table3-1.png", "data/dataset/spiqa/images/1801.05147/7-Figure3-1.png", "data/dataset/spiqa/images/1801.05147/7-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What accuracy does the proposed system achieve?", "reference_answer": "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d2a8f342-e0a0-5e50-8b58-58a52578bb46", "question": "What is the relationship between the success rate of the non-overlapping attack and the number of words changed in the input sentence?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4979a3cd-d95a-5e60-a12e-08263adccd51"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table4-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table5-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table6-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table7-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table8-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table9-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table1-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table2-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the success rate of the non-overlapping attack and the number of words changed in the input sentence?", "reference_answer": "There is a negative correlation between the success rate of the non-overlapping attack and the number of words changed in the input sentence. In other words, the fewer words that are changed, the higher the success rate of the attack."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2ab5c3c9-e8ec-5229-8f7c-df564af97204", "question": "What is the difference between GCounter and GSet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between GCounter and GSet?", "reference_answer": "GCounter measures the number of times an event has occurred, while GSet measures the number of unique elements in a set."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "57a5d7dc-cce2-5794-8d4d-1aea74f11204", "question": "How does the LIVR framework decompose semantic features into different places?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f290ed70-eb81-598b-aa2d-1920fc19428f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Table1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure3-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure9-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure10-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the LIVR framework decompose semantic features into different places?", "reference_answer": "The LIVR framework decomposes semantic features into different places by utilizing bitmaps encoded with the semantic labels of places. This decomposition encourages the network to learn features of generic place-based motion patterns that are independent of scene layouts."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "65ada010-af33-557d-b882-5b15efe5d30e", "question": "What is the key difference in model structure between Mobilenet style models and Shufflenet? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7edfe29a-5f05-5124-91f5-9d8a99732918"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/13-Figure7-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/14-Figure8-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/4-Table1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Figure4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the key difference in model structure between Mobilenet style models and Shufflenet? ", "reference_answer": "ShuffleNet introduces group convolutions and shuffling, while existing mobilenet style models do not have."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c47f46be-5d2e-5e1a-9e98-1389c8308126", "question": "Do they evaluate only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["a5aa33b6-dd50-53f7-9cea-027d1b53f2fd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.07916/3-Figure1-1.png", "data/dataset/spiqa/images/1709.07916/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.07916/3-Figure1-1.png", "data/dataset/spiqa/images/1709.07916/5-Table1-1.png", "data/dataset/spiqa/images/1709.07916/6-Table2-1.png", "data/dataset/spiqa/images/1709.07916/6-Figure2-1.png", "data/dataset/spiqa/images/1709.07916/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they evaluate only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1e228fa6-1a92-58e9-b38b-87434f9221a0", "question": "Do the authors report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["7d28d793-222f-598d-8c6d-f0b832055ea4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.07668/4-Table1-1.png", "data/dataset/spiqa/images/1906.07668/5-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.07668/2-Figure2-1.png", "data/dataset/spiqa/images/1906.07668/2-Figure3-1.png", "data/dataset/spiqa/images/1906.07668/2-Figure1-1.png", "data/dataset/spiqa/images/1906.07668/3-Figure4-1.png", "data/dataset/spiqa/images/1906.07668/4-Table1-1.png", "data/dataset/spiqa/images/1906.07668/5-Figure5-1.png", "data/dataset/spiqa/images/1906.07668/5-Figure6-1.png", "data/dataset/spiqa/images/1906.07668/6-Figure7-1.png", "data/dataset/spiqa/images/1906.07668/6-Table2-1.png", "data/dataset/spiqa/images/1906.07668/7-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bd7e4e75-5416-5681-a457-f7ee1c1ac15b", "question": "How does the quality of the reconstructed frames change as the quantization level of the soft edge detector increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the quality of the reconstructed frames change as the quantization level of the soft edge detector increases?", "reference_answer": "The quality of the reconstructed frames increases as the quantization level of the soft edge detector increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "79d5b738-b883-5bb1-851d-4213bee0e5be", "question": "Which domain discrepancy has a larger impact on object detection performance: city vs. non-city or daytime vs. nighttime?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which domain discrepancy has a larger impact on object detection performance: city vs. non-city or daytime vs. nighttime?", "reference_answer": "Daytime vs. nighttime has a larger impact on object detection performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "843f951a-b009-5c84-acb9-86c21b61f654", "question": "Which method produces the most realistic results for the Vid4 scenes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method produces the most realistic results for the Vid4 scenes?", "reference_answer": "TecoGAN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cd770542-d9dc-56fb-a268-0d2fabbe7efe", "question": "Did the method proposed in this paper perform on par with or better than the state-of-the-art methods that require users to provide spatial masks for editing?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2f4b1745-05e0-5db7-940c-9642e7274ee1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/3-Figure2-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/6-Figure5-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/17-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/10-Figure9-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/11-Figure10-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/11-Figure11-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/12-Figure12-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/17-Figure13-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/18-Figure14-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/19-Figure15-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/2-Figure1-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/3-Figure2-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/4-Figure3-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/5-Figure4-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/6-Figure5-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/7-Figure6-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/8-Figure7-1.png", "data/dataset/spiqa/images/04e541391e8dce14d099d00fb2c21dbbd8afe87f/9-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Did the method proposed in this paper perform on par with or better than the state-of-the-art methods that require users to provide spatial masks for editing?", "reference_answer": "Yes their method did perform better than mask editing methods, as authors demonstrated by examples that their method is more intuitive for users using only prompt, and doesn't require to explicitly mask parts of the image which results to remove important structural information and doesn't modify complex structures information. And their work enables local or global modifications as well and besides their method doesn't require a training network."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b279726a-71ce-59ba-aa48-37fc0fcc179c", "question": "Who collected the queries from MSMARCO-Passage dataset to make MSMARCO-TRAIN query set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c2ce8e68-6fc4-5e1d-b409-ebb07c73d811"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table5-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table6-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table7-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/2-Figure1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/4-Figure2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/5-Figure3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/6-Figure4-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/8-Table1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Who collected the queries from MSMARCO-Passage dataset to make MSMARCO-TRAIN query set?", "reference_answer": "MARCO-Passage collection is a large-scale publicly available corpus and two query sets derived from this corpus are used in the paper: MSMARCO-TRAIN and MSMARCO-DEV. How and who collected the queries from MARCO-Passage to construct MSMARCO-TRAIN cannot be answered from this paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d3d875b1-b6fd-5594-9419-f55aa82a1dc4", "question": "What is the effect of downsampling on the quality of reconstructed frames?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of downsampling on the quality of reconstructed frames?", "reference_answer": "Downsampling reduces the quality of reconstructed frames."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "aacbe68d-c437-5deb-832e-6b3e2d63f72e", "question": "Are some models evaluated using this metric, what are the findings?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["33d97d5e-ad42-5992-ab98-f252ae07947e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.02380/13-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.02380/3-Table1-1.png", "data/dataset/spiqa/images/2001.02380/6-Table2-1.png", "data/dataset/spiqa/images/2001.02380/7-Figure1-1.png", "data/dataset/spiqa/images/2001.02380/8-Table3-1.png", "data/dataset/spiqa/images/2001.02380/9-Figure2-1.png", "data/dataset/spiqa/images/2001.02380/10-Figure3-1.png", "data/dataset/spiqa/images/2001.02380/11-Table4-1.png", "data/dataset/spiqa/images/2001.02380/13-Figure4-1.png", "data/dataset/spiqa/images/2001.02380/14-Table5-1.png", "data/dataset/spiqa/images/2001.02380/18-Figure5-1.png", "data/dataset/spiqa/images/2001.02380/19-Figure6-1.png", "data/dataset/spiqa/images/2001.02380/22-Table6-1.png", "data/dataset/spiqa/images/2001.02380/25-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are some models evaluated using this metric, what are the findings?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "921b5e3e-2b9e-5864-8541-54ac06eaed05", "question": "Which model, VAR or LSTNet, is better at capturing both daily and weekly repeating patterns in the data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model, VAR or LSTNet, is better at capturing both daily and weekly repeating patterns in the data?", "reference_answer": "LSTNet"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "746914fd-f564-56f0-866c-fc171ddbbb8a", "question": "Which method achieved the highest Inception Score (IS) at the end of training for both CIFAR10 and ImageNet datasets? Did this method also achieve the highest initial IS score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dc5584b7-6dd8-5e79-b1ba-1d77ce70df61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure1-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure3-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table2-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the highest Inception Score (IS) at the end of training for both CIFAR10 and ImageNet datasets? Did this method also achieve the highest initial IS score?", "reference_answer": "For CIFAR10, WGAN achieved the highest IS at the end of training (2.42). However, RWGAN had a higher initial IS score (1.86) compared to WGAN's 1.63. \n\nFor ImageNet, WGAN again achieved the highest final IS (2.80), while RWGAN had a slightly higher initial IS (2.04 vs. 2.00). "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9003bcd1-a44d-5de5-acc2-71cd565479f3", "question": "What information from the input images do ORB features extract?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2c7c33de-6339-5f80-bda0-4e61c6318978"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/2-Figure1-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/4-Figure2-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure3-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure4-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-TableI-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure5-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure6-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-TableII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-Figure7-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-TableIII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/9-TableIV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What information from the input images do ORB features extract?", "reference_answer": "ORB features are extracted at salient keypoints in both view of image. For every left ORB image a matching feature can be found at right image. ORB extract such features from images which are robust to rotation and scale and present a good invariance to camera auto-gain and auto-exposure, and illumination changes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f597cf7d-86b4-5651-8215-f562bb4c13c4", "question": "How do feature-based methods work in face recognition?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How do feature-based methods work in face recognition?", "reference_answer": "The only feature-based method that is mentioned in the paper is the local-feature-based methods from the 2000s of Gabor and LBP that tried local filtering to extract invariant properties. But they were too rigid and lacked distinctiveness and compactness."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e2878b4b-8e4d-5ae9-9f22-0a3d5fb3d047", "question": "How larger are the training sets of these versions of ELMo compared to the previous ones?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["214ef428-3d1c-5293-9096-7801c0f0cae4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.10049/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.10049/3-Table1-1.png", "data/dataset/spiqa/images/1911.10049/4-Figure1-1.png", "data/dataset/spiqa/images/1911.10049/4-Table2-1.png", "data/dataset/spiqa/images/1911.10049/5-Table3-1.png", "data/dataset/spiqa/images/1911.10049/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How larger are the training sets of these versions of ELMo compared to the previous ones?", "reference_answer": "up to 1.95 times larger", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "147bba1c-2707-5d00-a500-960f3b2a6637", "question": "Do they explore how useful is the detection history and opinion summary?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["4e29a3f5-6696-55a7-b691-2542f73558ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.00760/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.00760/3-Figure1-1.png", "data/dataset/spiqa/images/1805.00760/4-Table1-1.png", "data/dataset/spiqa/images/1805.00760/5-Table2-1.png", "data/dataset/spiqa/images/1805.00760/6-Figure2-1.png", "data/dataset/spiqa/images/1805.00760/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they explore how useful is the detection history and opinion summary?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "db9b66fe-7a73-579a-9b80-39f09c49837e", "question": "Which method performs the best when the number of shots is 50?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["77db890f-c739-5abc-a1af-4cdaee857323"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table1-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure2-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure4-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure5-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Table3-1.png", "data/dataset/spiqa/images/1710.06177v2/1710.06177v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best when the number of shots is 50?", "reference_answer": "VAGER+Voting"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b8aade16-badd-558b-bf12-640884797e6c", "question": "How does YOLOv3 improve upon previous versions of the YOLO object detection algorithm?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["a876dfa2-33ff-5ea3-a1c5-13580365217e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/6-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/1-Figure1-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/2-Figure2-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/2-Table1-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/3-Table2-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/3-Table3-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/4-Figure3-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/6-Figure4-1.png", "data/dataset/spiqa/images/ebc96892b9bcbf007be9a1d7844e4b09fde9d961/6-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does YOLOv3 improve upon previous versions of the YOLO object detection algorithm?", "reference_answer": "YOLOv3 is faster and better than YOLO. It has more layers. The authors also tried some small tricks and experiments which further improved the overall performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "9a90b65d-8ac9-527a-858b-98606eef5c5b", "question": "Which dataset would likely benefit the most from using the Fac.-Recover approach instead of Recover-Fac. in terms of computational efficiency?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["31d46012-0f02-590b-bcb4-f7f19a18db4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure4-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset would likely benefit the most from using the Fac.-Recover approach instead of Recover-Fac. in terms of computational efficiency?", "reference_answer": "The Leukemia dataset would likely benefit the most from using the Fac.-Recover approach."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f911a916-4ad5-5e5d-a46c-ed8ca625fedd", "question": "What is the role of the \"max\" function in the model architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1d4aae8d-be49-5bef-88ce-e6d9a04354e4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table1-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table2-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table3-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table4-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table5-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the \"max\" function in the model architecture?", "reference_answer": "The \"max\" function is used to select the most probable word at each time step in the decoding process."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e648ff46-4f6f-5166-826c-c5b6b28d6543", "question": "Which other approaches do they compare their model with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["836657b7-d657-5f24-a0b2-9463d99e8e3a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.10503/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.10503/2-Table1-1.png", "data/dataset/spiqa/images/1904.10503/2-Figure1-1.png", "data/dataset/spiqa/images/1904.10503/4-Figure2-1.png", "data/dataset/spiqa/images/1904.10503/5-Figure3-1.png", "data/dataset/spiqa/images/1904.10503/5-Table2-1.png", "data/dataset/spiqa/images/1904.10503/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which other approaches do they compare their model with?", "reference_answer": "Akbik et al. (2018), Link et al. (2012)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "31b41e06-fbf6-586a-bbbe-bfa6e7fc1b93", "question": "Which network has the shortest average path length when L = 9?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which network has the shortest average path length when L = 9?", "reference_answer": "DMRNet"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5371f549-2928-5f85-8431-269286b56998", "question": "In terms of image synthesis, do the GANs perform better than VQ-VAE or not?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "In terms of image synthesis, do the GANs perform better than VQ-VAE or not?", "reference_answer": "Fidelity can be higher, but GANs are not always better in terms of low diversity. In table 5 ImageNet256x256 experiment, BigGAN-deep beats VA-VAE2 about FID, sFID, Precision but lose about Recall."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d2881794-9ad5-567b-a1c3-599c3b760d89", "question": "Can the model add new relations to the knowledge graph, or just new entities?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dcfc3786-6d31-5bb5-9d05-5bb7e6ab503d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1711.03438/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1711.03438/3-Figure1-1.png", "data/dataset/spiqa/images/1711.03438/4-Figure2-1.png", "data/dataset/spiqa/images/1711.03438/5-Figure3-1.png", "data/dataset/spiqa/images/1711.03438/6-Table1-1.png", "data/dataset/spiqa/images/1711.03438/6-Table2-1.png", "data/dataset/spiqa/images/1711.03438/7-Table3-1.png", "data/dataset/spiqa/images/1711.03438/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Can the model add new relations to the knowledge graph, or just new entities?", "reference_answer": "The model does not add new relations to the knowledge graph.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ce5a523b-1c6f-5467-b667-e3aa97c6f41d", "question": "Which journal and conference are cited the most in recent years?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["083c588e-cadb-585b-985f-70949e59e35d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.03562/20-Figure25-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.03562/2-Figure1-1.png", "data/dataset/spiqa/images/1911.03562/3-Figure2-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure3-1.png", "data/dataset/spiqa/images/1911.03562/4-Figure4-1.png", "data/dataset/spiqa/images/1911.03562/6-Figure5-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure6-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure7-1.png", "data/dataset/spiqa/images/1911.03562/7-Figure8-1.png", "data/dataset/spiqa/images/1911.03562/8-Figure9-1.png", "data/dataset/spiqa/images/1911.03562/9-Figure10-1.png", "data/dataset/spiqa/images/1911.03562/10-Figure11-1.png", "data/dataset/spiqa/images/1911.03562/12-Figure12-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure13-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure14-1.png", "data/dataset/spiqa/images/1911.03562/13-Figure15-1.png", "data/dataset/spiqa/images/1911.03562/15-Figure16-1.png", "data/dataset/spiqa/images/1911.03562/16-Figure17-1.png", "data/dataset/spiqa/images/1911.03562/17-Figure18-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure19-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure20-1.png", "data/dataset/spiqa/images/1911.03562/18-Figure21-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure22-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure23-1.png", "data/dataset/spiqa/images/1911.03562/19-Figure24-1.png", "data/dataset/spiqa/images/1911.03562/20-Figure25-1.png", "data/dataset/spiqa/images/1911.03562/21-Figure26-1.png", "data/dataset/spiqa/images/1911.03562/22-Figure27-1.png", "data/dataset/spiqa/images/1911.03562/23-Figure28-1.png", "data/dataset/spiqa/images/1911.03562/24-Figure29-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure30-1.png", "data/dataset/spiqa/images/1911.03562/26-Figure31-1.png", "data/dataset/spiqa/images/1911.03562/28-Figure32-1.png", "data/dataset/spiqa/images/1911.03562/29-Figure33-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which journal and conference are cited the most in recent years?", "reference_answer": "CL Journal and EMNLP conference", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7ca81b20-5614-5145-b7ed-94aae8c55c1d", "question": "Do the hashtag and SemEval datasets contain only English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["dfab3446-3a68-54cd-9b0c-af1f9ef95a4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.00790/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.00790/1-Table1-1.png", "data/dataset/spiqa/images/1906.00790/3-Table2-1.png", "data/dataset/spiqa/images/1906.00790/4-Figure1-1.png", "data/dataset/spiqa/images/1906.00790/5-Table3-1.png", "data/dataset/spiqa/images/1906.00790/6-Table4-1.png", "data/dataset/spiqa/images/1906.00790/6-Table5-1.png", "data/dataset/spiqa/images/1906.00790/7-Table6-1.png", "data/dataset/spiqa/images/1906.00790/7-Table7-1.png", "data/dataset/spiqa/images/1906.00790/8-Figure2-1.png", "data/dataset/spiqa/images/1906.00790/8-Figure3-1.png", "data/dataset/spiqa/images/1906.00790/9-Table9-1.png", "data/dataset/spiqa/images/1906.00790/9-Table10-1.png", "data/dataset/spiqa/images/1906.00790/12-Table11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the hashtag and SemEval datasets contain only English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e8f9d4ed-b91a-5501-91ca-791ff8249f69", "question": "How does the ITN framework generate pseudo-negative samples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the ITN framework generate pseudo-negative samples?", "reference_answer": "The ITN framework generates pseudo-negative samples by applying learned transformations to positive samples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ffe355ee-582a-572d-ab7c-3aefd85ec3d2", "question": "How does KG-Classifier affect zero-shot fusion?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does KG-Classifier affect zero-shot fusion?", "reference_answer": "zero-shot fusion with KG-C adapter fuses the knowledge from different experts with a subtle difference rather than focusing on a single expert severely."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ad225d15-7910-5a43-af30-b82e77f6eeee", "question": "How do the reconstructions compare to the original samples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9104d00a-0d2b-565f-acc8-c4650cf151b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure6-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure7-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure2-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure8-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure12-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure9-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the reconstructions compare to the original samples?", "reference_answer": "The reconstructions are very similar to the original samples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6748a562-1c45-5c0d-826d-021c71913451", "question": "What other sentence embeddings methods are evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c76b968a-995a-5109-a4eb-f329fa710f26"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.10084/7-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.10084/3-Figure1-1.png", "data/dataset/spiqa/images/1908.10084/3-Figure2-1.png", "data/dataset/spiqa/images/1908.10084/4-Table1-1.png", "data/dataset/spiqa/images/1908.10084/5-Table2-1.png", "data/dataset/spiqa/images/1908.10084/6-Table4-1.png", "data/dataset/spiqa/images/1908.10084/6-Table3-1.png", "data/dataset/spiqa/images/1908.10084/7-Table5-1.png", "data/dataset/spiqa/images/1908.10084/7-Table6-1.png", "data/dataset/spiqa/images/1908.10084/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What other sentence embeddings methods are evaluated?", "reference_answer": "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b5ac952b-fded-5852-b7c6-cbe8245978b9", "question": "Which method performs the best on the F-SRE1 test function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best on the F-SRE1 test function?", "reference_answer": "ALOQ"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8e2e10a3-f3f7-5574-ba8b-0730d2697170", "question": "How does the graph of the average IOU vs. number of clusters imply the claim that k = 5 is the optimal choice for the complexity/recall tradeoff?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["08315e5d-cabb-5236-ba3c-8e678014f6c6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/3-Figure2-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/1-Figure1-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/3-Figure2-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/3-Table1-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/4-Figure3-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/4-Figure4-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/5-Table2-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/5-Table3-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/6-Table4-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/6-Table5-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/6-Table6-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/7-Figure5-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/8-Figure6-1.png", "data/dataset/spiqa/images/7d39d69b23424446f0400ef603b2e3e22d0309d6/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does the graph of the average IOU vs. number of clusters imply the claim that k = 5 is the optimal choice for the complexity/recall tradeoff?", "reference_answer": "A graph is shown between average IOU vs. number of clusters. Number of anchar boxes are then hand-picked by comparing the average IOU closest to the prior. K=5 is choosen because At only 5 priors the centroids perform similarly to 9 anchor boxes with an average IOU of 61.0 compared to 60.9."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "00d3dd75-ad88-5579-9c76-906de522079b", "question": "How much F1 was improved after adding skip connections?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["8dc0ccde-f8f2-5974-bfff-7dd9f318bef1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.10435/4-Figure2-1.png", "data/dataset/spiqa/images/1912.10435/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.10435/3-Figure1-1.png", "data/dataset/spiqa/images/1912.10435/4-Figure2-1.png", "data/dataset/spiqa/images/1912.10435/5-Figure3-1.png", "data/dataset/spiqa/images/1912.10435/6-Table1-1.png", "data/dataset/spiqa/images/1912.10435/6-Table2-1.png", "data/dataset/spiqa/images/1912.10435/6-Table3-1.png", "data/dataset/spiqa/images/1912.10435/7-Figure4-1.png", "data/dataset/spiqa/images/1912.10435/7-Figure5-1.png", "data/dataset/spiqa/images/1912.10435/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much F1 was improved after adding skip connections?", "reference_answer": "Simple Skip improves F1 from 74.34 to 74.81\nTransformer Skip improes F1 from 74.34 to 74.95 ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f68ad012-04f7-568a-8729-131eeff8ebb7", "question": "What writing styles are present in the corpus?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["da1f531c-a62e-57ab-86ce-f67f7f6978a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.01247/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.01247/3-Table1-1.png", "data/dataset/spiqa/images/1909.01247/3-Table2-1.png", "data/dataset/spiqa/images/1909.01247/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What writing styles are present in the corpus?", "reference_answer": "current news, historical news, free time, sports, juridical news pieces, personal adverts, editorials.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4f2acb9a-c47d-56b0-ad04-e93ed707468e", "question": "How does the quality of gradient estimation change as the number of state-action pairs used in estimation increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["291817c4-b436-55c1-a356-e28360b7edb9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure5-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure18-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure19-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure8-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure14-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure6-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure15-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Table1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure2-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure11-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure16-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure7-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure3-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure12-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure10-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure20-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure17-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure13-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure4-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the quality of gradient estimation change as the number of state-action pairs used in estimation increases?", "reference_answer": "The quality of gradient estimation increases as the number of state-action pairs used in estimation increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a7b22bed-217c-5f87-b02d-e1bdcc2e9d6b", "question": "Which method achieved the highest accuracy on the 45-tag Penn WSJ dataset, and how does its performance compare to the other methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d2648a6-db41-5a23-9cb0-92c59be4fbc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table1-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table2-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table4-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table3-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the highest accuracy on the 45-tag Penn WSJ dataset, and how does its performance compare to the other methods?", "reference_answer": "The Variational $\\wh{J}^{\\mathrm{var}}$ method achieved the highest accuracy of 78.1% on the 45-tag Penn WSJ dataset. This is significantly higher than all other methods listed in the table, with the next best performing method (Berg-Kirkpatrick et al., 2010) achieving an accuracy of 74.9%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2c08c72d-738c-554f-b1ef-bea876275df0", "question": "What are the characteristics of the accounts that spread fake news?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8af8c20d-5ea8-56a1-9d31-c369865e4fc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.05999/6-Figure9-1.png", "data/dataset/spiqa/images/1712.05999/4-Figure1-1.png", "data/dataset/spiqa/images/1712.05999/5-Figure5-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.05999/4-Figure1-1.png", "data/dataset/spiqa/images/1712.05999/4-Figure2-1.png", "data/dataset/spiqa/images/1712.05999/4-Table1-1.png", "data/dataset/spiqa/images/1712.05999/4-Figure3-1.png", "data/dataset/spiqa/images/1712.05999/5-Figure4-1.png", "data/dataset/spiqa/images/1712.05999/5-Figure5-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure6-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure9-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure10-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure7-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure8-1.png", "data/dataset/spiqa/images/1712.05999/7-Figure11-1.png", "data/dataset/spiqa/images/1712.05999/7-Figure12-1.png", "data/dataset/spiqa/images/1712.05999/8-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the characteristics of the accounts that spread fake news?", "reference_answer": "Accounts that spread fake news are mostly unverified, recently created and have on average high friends/followers ratio", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ab2752e1-9712-5cbb-9a3a-4f8774cd79c0", "question": "what language pairs are explored?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["62880516-8e70-543e-9659-f0abc2daf10b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.01214/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.01214/1-Figure1-1.png", "data/dataset/spiqa/images/1912.01214/3-Figure2-1.png", "data/dataset/spiqa/images/1912.01214/4-Table1-1.png", "data/dataset/spiqa/images/1912.01214/5-Table2-1.png", "data/dataset/spiqa/images/1912.01214/6-Table3-1.png", "data/dataset/spiqa/images/1912.01214/6-Figure3-1.png", "data/dataset/spiqa/images/1912.01214/7-Figure4-1.png", "data/dataset/spiqa/images/1912.01214/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what language pairs are explored?", "reference_answer": "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c126539d-b78e-52de-a035-246e2de2dc14", "question": "Which combination of training procedure and thresholding metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which combination of training procedure and thresholding metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types?", "reference_answer": "RCE training combined with the K-density metric consistently performs the best across both MNIST and CIFAR-10 datasets for all attack types."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5c710c37-096b-5d80-9a70-1851c7214eef", "question": "Which clustering algorithm produced the smallest cut size for highly active users in the US dataset, and how much smaller was it compared to the cut size produced by grid partitioning?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which clustering algorithm produced the smallest cut size for highly active users in the US dataset, and how much smaller was it compared to the cut size produced by grid partitioning?", "reference_answer": "Both GeoCUTS and Linear Embedding produced the smallest cut size for highly active users, with a cut size of 4%. This is 11% smaller than the cut size produced by grid partitioning, which had a cut size of 15%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "aa1ff554-9ede-5dca-979a-3add75f269b9", "question": "Which factor is more related to model performance between pretraining data size and language similarity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Which factor is more related to model performance between pretraining data size and language similarity?", "reference_answer": "Pretraining data size is more related to model performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "552d062c-8685-5f94-bccf-6f1724468a6f", "question": "By how much does their best model outperform the state-of-the-art?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b31e4f8d-6221-54a9-8e27-e5f8eb5d5588"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07333/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07333/3-Figure1-1.png", "data/dataset/spiqa/images/1605.07333/3-Figure2-1.png", "data/dataset/spiqa/images/1605.07333/4-Table1-1.png", "data/dataset/spiqa/images/1605.07333/5-Table2-1.png", "data/dataset/spiqa/images/1605.07333/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much does their best model outperform the state-of-the-art?", "reference_answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b5589514-b35e-5aac-9662-b2f66920a414", "question": "What is the relationship between the length of the interval and the uncertainty in the generated frames?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the length of the interval and the uncertainty in the generated frames?", "reference_answer": "The uncertainty in the generated frames increases with the length of the interval."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6d7f7335-e6ef-5981-9a7a-a01f48f8e16b", "question": "Which synchronization method is the most efficient in terms of CPU processing time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which synchronization method is the most efficient in terms of CPU processing time?", "reference_answer": "The proposed method compared to state-based and delta-based methods."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6a90c669-3101-52c4-bfe2-1f6632d8d65d", "question": "Which topic is most likely to be associated with a pro-immigration stance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which topic is most likely to be associated with a pro-immigration stance?", "reference_answer": "\"english language city spanish community\""}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "617e8eaf-56ad-58cd-bee8-d64dcc3257cd", "question": "Do the authors evaluate their architecture on non-mobile/cellphone type of edge devices such as FPGAs?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7edfe29a-5f05-5124-91f5-9d8a99732918"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/13-Figure7-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/14-Figure8-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/4-Table1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Figure4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Do the authors evaluate their architecture on non-mobile/cellphone type of edge devices such as FPGAs?", "reference_answer": "The authors only evaluated their architecture on mobile devices (Google Pixel 1) and did not evaluated on non-mobile type of devices."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d0bc04b2-392d-5d54-87bd-ea0f008a7c7a", "question": "How was performance measured and was the performance of the human-guided knowledge distilled model significantly higher?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b28d1a00-c062-5a4d-85a5-6dafc63095ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/16-Figure3-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/16-Table4-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/16-Table5-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/17-Figure4-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/4-Figure1-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/5-Figure2-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/8-Table1-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/8-Table2-1.png", "data/dataset/spiqa/images/571469045c49877f78a4522f7f21e8c30e2f5c89/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How was performance measured and was the performance of the human-guided knowledge distilled model significantly higher?", "reference_answer": "Interpretability is measured with the PDR framework. Summarization performance measured in ROUGE is 15% better. Topic segmentation performance measured in F1 is 12% better."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "49f57f74-00b3-55bd-9d59-b64de176eb20", "question": "How channel shuffle operation works for two groups?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How channel shuffle operation works for two groups?", "reference_answer": "In the case of channel shuffle operation for two groups, each group is divided into two and shuffled so each new group has a subgroup from both old groups. For example, |A|B| -> |aa|bb| -> |ab|ab|. In terms of performance, two groups seem to work consistently better than the single group case and consistently worse than having more than 2 groups."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5ca13575-67c1-50c7-9341-607788c8abdd", "question": "Do they report results only on English datasets?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["b0f8cb4c-5420-5ada-b490-7aed7819cfd1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png", "data/dataset/spiqa/images/2001.00137/8-Table1-1.png", "data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/9-Table3-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png", "data/dataset/spiqa/images/2001.00137/11-Figure2-1.png", "data/dataset/spiqa/images/2001.00137/12-Table5-1.png", "data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/15-Figure3-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure4-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English datasets?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e4cbc5f5-200d-5b0b-88a6-b23ea0181ef1", "question": "Which dataset would likely require the most computational resources for C-Tarone to analyze?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["99904617-6a5d-55cb-be9e-259c5fa25b88"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure2-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure5-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure3-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure4-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset would likely require the most computational resources for C-Tarone to analyze?", "reference_answer": "The \"wdbc\" dataset would likely require the most computational resources for C-Tarone to analyze."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2570c949-eca9-58a1-807a-efd509611c01", "question": "Which of the two approaches, density estimation or mixture of classifiers, is more robust to outliers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the two approaches, density estimation or mixture of classifiers, is more robust to outliers?", "reference_answer": "Mixture of classifiers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6e791e75-ebf3-5df6-b66e-02701adc3f42", "question": "Is the KMeans algorithm discussed in the paper require a labelled dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52fc556e-8d5a-59cf-a7ce-b06619201667"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/5-Table1-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/6-Table2-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table3-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table4-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is the KMeans algorithm discussed in the paper require a labelled dataset?", "reference_answer": "The K-means algorithm clusters the set of classes that the models often predict together. In this work, this clustering approach did not require true labels. However, the models themselves were trained using examples from a dataset, JFT, which contains labeled images. Thus, although the K-means algorithm does not require a labeled dataset, the models whose predictions are used in the algorithm required a labeled dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "53c89a6f-bffe-587d-ad18-643587c8bc68", "question": "Is the model evaluated against a CNN baseline?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["0faafe1c-fa8e-5766-8078-51df2fec2ae9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00124/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00124/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00124/4-Table1-1.png", "data/dataset/spiqa/images/1909.00124/5-Table2-1.png", "data/dataset/spiqa/images/1909.00124/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the model evaluated against a CNN baseline?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4e61d00f-e53d-527a-b4f9-b7317a5855d9", "question": "What external sources are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["d0ebe4fc-e32b-52e2-ade5-944b197fd6bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.08960/4-Figure3-1.png", "data/dataset/spiqa/images/1704.08960/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.08960/2-Table1-1.png", "data/dataset/spiqa/images/1704.08960/3-Figure2-1.png", "data/dataset/spiqa/images/1704.08960/3-Figure1-1.png", "data/dataset/spiqa/images/1704.08960/4-Figure3-1.png", "data/dataset/spiqa/images/1704.08960/6-Table2-1.png", "data/dataset/spiqa/images/1704.08960/6-Table3-1.png", "data/dataset/spiqa/images/1704.08960/7-Table4-1.png", "data/dataset/spiqa/images/1704.08960/7-Table5-1.png", "data/dataset/spiqa/images/1704.08960/8-Figure4-1.png", "data/dataset/spiqa/images/1704.08960/8-Figure5-1.png", "data/dataset/spiqa/images/1704.08960/8-Table6-1.png", "data/dataset/spiqa/images/1704.08960/9-Table8-1.png", "data/dataset/spiqa/images/1704.08960/9-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What external sources are used?", "reference_answer": "Raw data from Gigaword, Automatically segmented text from Gigaword, Heterogenous training data from People's Daily, POS data from People's Daily", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0e6bb8a7-7c75-5b8d-8423-90f427f96002", "question": "How many images did the dataset consist of and the number of unique patients ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many images did the dataset consist of and the number of unique patients ?", "reference_answer": "The ILD dataset has 905 image slices from 120 patients."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "4f06d9a0-b4a1-5b5f-b9e6-da4344ad9bf2", "question": "Did the annotators agreed and how much?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e279379b-d4ab-513c-b362-0b2c5b8bfb9e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.05260/6-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.05260/1-Figure1-1.png", "data/dataset/spiqa/images/1703.05260/2-Figure2-1.png", "data/dataset/spiqa/images/1703.05260/2-Table1-1.png", "data/dataset/spiqa/images/1703.05260/3-Table2-1.png", "data/dataset/spiqa/images/1703.05260/4-Figure3-1.png", "data/dataset/spiqa/images/1703.05260/6-Figure4-1.png", "data/dataset/spiqa/images/1703.05260/6-Figure5-1.png", "data/dataset/spiqa/images/1703.05260/6-Figure6-1.png", "data/dataset/spiqa/images/1703.05260/7-Figure8-1.png", "data/dataset/spiqa/images/1703.05260/7-Figure9-1.png", "data/dataset/spiqa/images/1703.05260/7-Figure7-1.png", "data/dataset/spiqa/images/1703.05260/8-Figure10-1.png", "data/dataset/spiqa/images/1703.05260/8-Figure11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did the annotators agreed and how much?", "reference_answer": "Moderate agreement of 0.64-0.68 Fleiss’ Kappa over event type labels, 0.77 Fleiss’ Kappa over participant labels, and good agreement of 90.5% over coreference information.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2dd14058-99ab-5e40-8ed2-8c55fc14d3fe", "question": "What type of documents are supported by the annotation platform?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6002e022-71d0-5092-b68a-6f4265ddd4f4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01861/6-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01861/4-Table1-1.png", "data/dataset/spiqa/images/2002.01861/4-Table2-1.png", "data/dataset/spiqa/images/2002.01861/4-Figure1-1.png", "data/dataset/spiqa/images/2002.01861/4-Figure2-1.png", "data/dataset/spiqa/images/2002.01861/5-Table3-1.png", "data/dataset/spiqa/images/2002.01861/6-Figure3-1.png", "data/dataset/spiqa/images/2002.01861/6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What type of documents are supported by the annotation platform?", "reference_answer": "Variety of formats supported (PDF, Word...), user can define content elements of document", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4fb3efe7-c0bc-5cbc-99f2-6f357771edc1", "question": "What is the function of the DataPreprocessing function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the function of the DataPreprocessing function?", "reference_answer": "The DataPreprocessing function performs Yao Sharing, which is a cryptographic technique for securely sharing data between multiple parties."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "33e1dcde-a157-55b4-9328-bb3b59756422", "question": "How big are the datasets used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["aceed5df-08df-5a31-8fd4-8447541bb4db"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00361/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00361/3-Figure1-1.png", "data/dataset/spiqa/images/1909.00361/5-Figure2-1.png", "data/dataset/spiqa/images/1909.00361/6-Table1-1.png", "data/dataset/spiqa/images/1909.00361/7-Table2-1.png", "data/dataset/spiqa/images/1909.00361/7-Table3-1.png", "data/dataset/spiqa/images/1909.00361/8-Table4-1.png", "data/dataset/spiqa/images/1909.00361/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big are the datasets used?", "reference_answer": "Evaluation datasets used:\nCMRC 2018 - 18939 questions, 10 answers\nDRCD - 33953 questions, 5 answers\nNIST MT02/03/04/05/06/08 Chinese-English - Not specified\n\nSource language train data:\nSQuAD - Not specified", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ec4b08d5-ea3a-5d14-af5e-468416f62da1", "question": "How big was the corpora they trained ELMo on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1bf6a060-f397-515d-b68b-655e070d65da"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.03135/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.03135/2-Table1-1.png", "data/dataset/spiqa/images/1909.03135/3-Table2-1.png", "data/dataset/spiqa/images/1909.03135/4-Table3-1.png", "data/dataset/spiqa/images/1909.03135/4-Table4-1.png", "data/dataset/spiqa/images/1909.03135/5-Figure1-1.png", "data/dataset/spiqa/images/1909.03135/5-Figure2-1.png", "data/dataset/spiqa/images/1909.03135/5-Table5-1.png", "data/dataset/spiqa/images/1909.03135/6-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big was the corpora they trained ELMo on?", "reference_answer": "2174 million tokens for English and 989 million tokens for Russian", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9b4b01b4-9fe8-55b2-b8cd-193eb2ec9fad", "question": "How does the performance of the PE-N=5 sampler compare to the HMC sampler?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["71d0c183-d868-5a29-b5a0-54579f2869e7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure10-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure2-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure1-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure7-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure9-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure10-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure6-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure4-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure3-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure8-1.png", "data/dataset/spiqa/images/1708.05239v3/1708.05239v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the PE-N=5 sampler compare to the HMC sampler?", "reference_answer": "The PE-N=5 sampler performs better than the HMC sampler."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cb4dfcd7-ff71-59b0-8d07-9b0e25b7400c", "question": "Do they build one model per topic or on all topics?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6a3fbed8-8b71-516a-bf3d-4ebb4c54ac9e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1807.09671/9-Table1-1.png", "data/dataset/spiqa/images/1807.09671/20-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1807.09671/9-Table1-1.png", "data/dataset/spiqa/images/1807.09671/10-Table2-1.png", "data/dataset/spiqa/images/1807.09671/11-Table3-1.png", "data/dataset/spiqa/images/1807.09671/12-Table4-1.png", "data/dataset/spiqa/images/1807.09671/13-Table5-1.png", "data/dataset/spiqa/images/1807.09671/15-Table6-1.png", "data/dataset/spiqa/images/1807.09671/15-Table7-1.png", "data/dataset/spiqa/images/1807.09671/16-Table8-1.png", "data/dataset/spiqa/images/1807.09671/17-Table9-1.png", "data/dataset/spiqa/images/1807.09671/19-Figure1-1.png", "data/dataset/spiqa/images/1807.09671/20-Figure2-1.png", "data/dataset/spiqa/images/1807.09671/21-Table10-1.png", "data/dataset/spiqa/images/1807.09671/22-Table11-1.png", "data/dataset/spiqa/images/1807.09671/23-Table13-1.png", "data/dataset/spiqa/images/1807.09671/24-Table14-1.png", "data/dataset/spiqa/images/1807.09671/27-Table15-1.png", "data/dataset/spiqa/images/1807.09671/34-Table16-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they build one model per topic or on all topics?", "reference_answer": "One model per topic.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "231ca849-0aec-5b7f-a53c-66050f1ca610", "question": "What is the difference in recall score between the systems?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["43d86e1b-d8b3-55d5-a16f-bcdcfd2657fd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.11402/3-Table2-1.png", "data/dataset/spiqa/images/2002.11402/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.11402/2-Table1-1.png", "data/dataset/spiqa/images/2002.11402/3-Table2-1.png", "data/dataset/spiqa/images/2002.11402/3-Table3-1.png", "data/dataset/spiqa/images/2002.11402/3-Figure1-1.png", "data/dataset/spiqa/images/2002.11402/6-Table4-1.png", "data/dataset/spiqa/images/2002.11402/6-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the difference in recall score between the systems?", "reference_answer": "Between the model and Stanford, Spacy and Flair the differences are 42.91, 25.03, 69.8 with Traditional NERs as reference and  49.88, 43.36, 62.43 with Wikipedia titles as reference.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "88aeeda4-8949-5c9f-9273-161da99df886", "question": "How does the choice of distribution affect the quality of the reconstructions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the choice of distribution affect the quality of the reconstructions?", "reference_answer": "Reconstructions from models using general distributions tend to be sharper and more detailed than reconstructions from the corresponding model that uses normal distributions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "54223bbd-69b8-5ce8-af81-aa20ee738dfb", "question": "Which method has the highest F-1 score when space used is 10%?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the highest F-1 score when space used is 10%?", "reference_answer": "GB-KMV"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "297b4fb8-1d48-5c3f-a67c-f83972e1e2ed", "question": "Do they inspect their model to see if their model learned to associate image parts with words related to entities?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["236b32a8-cc74-50c1-b2b2-5cdb8d2ca3a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07862/8-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07862/1-Figure1-1.png", "data/dataset/spiqa/images/1802.07862/3-Figure2-1.png", "data/dataset/spiqa/images/1802.07862/6-Table1-1.png", "data/dataset/spiqa/images/1802.07862/7-Table2-1.png", "data/dataset/spiqa/images/1802.07862/8-Figure3-1.png", "data/dataset/spiqa/images/1802.07862/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they inspect their model to see if their model learned to associate image parts with words related to entities?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e7b19acb-a01b-5136-b2a3-e39dfd591e41", "question": "How does the shape of the IRLS weight function change as the shape parameter α increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the shape of the IRLS weight function change as the shape parameter α increases?", "reference_answer": "The IRLS weight function becomes more peaked and concentrated around zero as the shape parameter α increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "70ee4315-3576-549c-a394-b7318762793d", "question": "Explain the likely reason why the \"SDVI loss term 1&3\" model performs worse than the full SDVI model in terms of PSNR and SSIM across all datasets.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Explain the likely reason why the \"SDVI loss term 1&3\" model performs worse than the full SDVI model in terms of PSNR and SSIM across all datasets.", "reference_answer": "The \"SDVI loss term 1&3\" model only uses the pixel reconstruction loss and the inclusive KL divergence loss, while the full SDVI model additionally incorporates the pixel prediction loss and the exclusive KL divergence loss. According to the passage, the exclusive KL divergence term encourages the inference distribution to be more accurate, while the pixel prediction loss further improves video quality during inference. Therefore, the absence of these terms in the \"SDVI loss term 1&3\" model likely explains its inferior performance compared to the full SDVI model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a134f91d-f947-5dcd-87fc-43643caca6da", "question": "What is the role of the virtual environment in the proposed approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bd1cf1c1-2268-50fb-a8af-8321d7a864ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the virtual environment in the proposed approach?", "reference_answer": "The virtual environment is used to collect demonstrations of the task from the user. This allows for safe and efficient data collection."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d9c041b2-eb61-59d8-84b3-84478d122a06", "question": "Which method appears to be most robust to the presence of outliers in the training data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method appears to be most robust to the presence of outliers in the training data?", "reference_answer": "ChoiceNet appears to be the most robust to outliers in the training data."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "13ed6c5d-e70a-52bb-b4dc-d7876a976fc2", "question": "Which of the four methods has the best performance in terms of average error for the step function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the four methods has the best performance in terms of average error for the step function?", "reference_answer": "The proposed method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3a7c69a1-74c1-529f-9401-c37df4b7fccc", "question": "Which methods are considered to find examples of biases and unwarranted inferences??", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7f1b6849-af3b-55d3-bf59-5da71f8f5bcd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.06083/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.06083/1-Figure1-1.png", "data/dataset/spiqa/images/1605.06083/2-Figure2-1.png", "data/dataset/spiqa/images/1605.06083/3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which methods are considered to find examples of biases and unwarranted inferences??", "reference_answer": "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2e0ca048-bbc3-5bb7-8b41-f3419332b4ad", "question": "The deepest model that the authors experimented with had 8 layers in it. True or False? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The deepest model that the authors experimented with had 8 layers in it. True or False? ", "reference_answer": "False. The deepest model the authors experimented with appears to be a four layer DeepLSTM Reader model. For attention models, the authors exclusively used only a single layer model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "60e5413f-54c9-53ab-bf18-1a06cd249c2e", "question": "What are the networks that were constructed from the best three searches?\n", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["acb67ddd-a0d1-56d4-871c-f5f79ed59efb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/12-Figure8-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure9-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/2-Figure1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Figure5-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the networks that were constructed from the best three searches?\n", "reference_answer": "The networks constructed from the best three searches are NASNet-A, NASNet-B and NASNet-C."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "32e62af9-c493-5a53-a5a9-b404063e9cef", "question": "Which algorithm performed better on the arm breakage task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm performed better on the arm breakage task?", "reference_answer": "Both TRPO and Reinforce performed similarly on the arm breakage task."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "89aff0a5-8505-50f2-b936-96f86aa5766a", "question": "How does the Adaptive Question Answering (AdaQA) model generate context-aware filters?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the Adaptive Question Answering (AdaQA) model generate context-aware filters?", "reference_answer": "The AdaQA model generates context-aware filters through the filter generation module. This module takes the question and answer as input and outputs a set of filters that are specific to the question and answer pair."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c1a3b0ee-5599-59a9-8a53-5956f09297b3", "question": "How does the network's focus change as the training epoch increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["570e01d8-2c85-5e04-b7e5-aef3f43f49b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure1-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure6-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure8-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure7-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure13-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure2-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure3-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure9-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure4-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure12-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure11-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure10-1.png", "data/dataset/spiqa/images/1703.10730v2/1703.10730v2-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the network's focus change as the training epoch increases?", "reference_answer": "The network initially focuses on predicting a good mask. As the epoch increases, the input parts become sharper. Finally, the network concentrates on generating realistic images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3903638a-3583-5a1c-b351-c3ad58203141", "question": "How does NGMPool work exactly? How is it different from GMPool?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["03ed11d3-1898-5a76-9960-b239974bb977"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/13-Table3-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/15-Table4-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/16-Figure4-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/2-Figure1-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/5-Table1-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/7-Figure2-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/8-Table2-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/9-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does NGMPool work exactly? How is it different from GMPool?", "reference_answer": "NGMPool is a single-pooling variant of GMPool that does not perform SVD on the grouping matrix, but rather uses the grouping matrix as is."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "496da44a-d916-55f6-85cb-f025e38dd0b3", "question": "Do all the instances contain code-switching?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["45764244-2663-508e-9793-344e40747267"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.08652/1-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.08652/1-Table1-1.png", "data/dataset/spiqa/images/1809.08652/2-Table2-1.png", "data/dataset/spiqa/images/1809.08652/2-Table3-1.png", "data/dataset/spiqa/images/1809.08652/2-Table4-1.png", "data/dataset/spiqa/images/1809.08652/2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do all the instances contain code-switching?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "55b360c6-7dee-5483-bf20-142fdfef6894", "question": "Why are the constraint value of δ and γ separated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why are the constraint value of δ and γ separated?", "reference_answer": "Yes they are separated, as [-δ,δ] is a clipping range to input yt while [−γ, γ] is the clipping range for raw logits."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e26c2983-1fe4-5364-9d61-5a575bdc8725", "question": "How big was the corpora they trained ELMo on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1bf6a060-f397-515d-b68b-655e070d65da"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.03135/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.03135/2-Table1-1.png", "data/dataset/spiqa/images/1909.03135/3-Table2-1.png", "data/dataset/spiqa/images/1909.03135/4-Table3-1.png", "data/dataset/spiqa/images/1909.03135/4-Table4-1.png", "data/dataset/spiqa/images/1909.03135/5-Figure1-1.png", "data/dataset/spiqa/images/1909.03135/5-Figure2-1.png", "data/dataset/spiqa/images/1909.03135/5-Table5-1.png", "data/dataset/spiqa/images/1909.03135/6-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big was the corpora they trained ELMo on?", "reference_answer": "2174000000, 989000000", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "66fbd958-f793-55ac-89c7-1b18284d6db7", "question": "Which modification to the Devon model resulted in the fastest processing time for both forward and backward passes, and how much faster was it compared to the full model in terms of the backward pass? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which modification to the Devon model resulted in the fastest processing time for both forward and backward passes, and how much faster was it compared to the full model in terms of the backward pass? ", "reference_answer": "The \"Without dilation\" configuration resulted in the fastest processing time for both forward and backward passes. It was approximately 29.43 ms faster than the full model in terms of the backward pass (147.74 ms vs. 177.17 ms)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d327325a-7e2f-5c4c-b039-abafb5d7332b", "question": "Do the authors measure the quantify the impact on their model's performance when using RELU6 instead of RELU?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7edfe29a-5f05-5124-91f5-9d8a99732918"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/13-Figure7-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/14-Figure8-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/3-Figure3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/4-Table1-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Figure4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table2-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/5-Table3-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/6-Figure6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table4-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table5-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/7-Table6-1.png", "data/dataset/spiqa/images/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Do the authors measure the quantify the impact on their model's performance when using RELU6 instead of RELU?", "reference_answer": "While the authors showed the effect of inverted residual connections and linear bottlenecks, they did not measure the impact of using RELU6 instead of RELU in the ablation study."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "06787e68-3a82-5bc0-93c4-bf64a6ee3d2b", "question": "How does the performance of the single R.M-Reader model compare to the best single models of other approaches on the SQuAD test set?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e31707d3-f5f4-5c59-86a2-af24ff7cfed7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the single R.M-Reader model compare to the best single models of other approaches on the SQuAD test set?", "reference_answer": "The single R.M-Reader model achieves an EM score of 79.5% and an F1 score of 86.6% on the SQuAD test set. This performance is better than all other single models listed in the table, except for SLQA and Hybrid AoA Reader, which achieve slightly higher F1 scores of 87.0% and 87.3%, respectively."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ccc3e74a-97b3-5695-b5f9-64de3cb4bb9d", "question": "What is the range of values for the context number hyperparameter?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the range of values for the context number hyperparameter?", "reference_answer": "The range of values for the context number hyperparameter is from 1 to 20."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ef51c966-1454-582a-9cb3-22291e5a73f4", "question": "How does the proposed split-rate RGB-to-Depth transfer scheme differ from the R3D [90] method of Yosinski et al.?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed split-rate RGB-to-Depth transfer scheme differ from the R3D [90] method of Yosinski et al.?", "reference_answer": "The proposed split-rate RGB-to-Depth transfer scheme differs from the R3D [90] method in two ways. First, the proposed method uses a different learning rate for the bottom three layers of the network. Second, the proposed method uses a different initialization for the weights of the bottom three layers of the network."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b4c9c983-6e05-5af1-92b2-61b1538371a1", "question": "What's the precision of the system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5aebb790-4fc3-5cff-8d83-23464aded46d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.11180/12-Table3-1.png", "data/dataset/spiqa/images/1906.11180/13-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.11180/3-Figure1-1.png", "data/dataset/spiqa/images/1906.11180/5-Figure2-1.png", "data/dataset/spiqa/images/1906.11180/9-Table1-1.png", "data/dataset/spiqa/images/1906.11180/10-Table2-1.png", "data/dataset/spiqa/images/1906.11180/11-Figure3-1.png", "data/dataset/spiqa/images/1906.11180/12-Figure4-1.png", "data/dataset/spiqa/images/1906.11180/12-Table3-1.png", "data/dataset/spiqa/images/1906.11180/13-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What's the precision of the system?", "reference_answer": "0.8320 on semantic typing, 0.7194 on entity matching", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d30969cd-b3c5-5d41-b367-2d7b52919544", "question": "In what way can SBM-Transformer be considered better than Reformer?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["451ad1b7-2293-5a9c-968a-b1c259dc2a1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/2-Figure1-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/17-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/10-Table4-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/15-Figure6-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/16-Table5-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/16-Table6-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/17-Table7-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/17-Table8-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/17-Table9-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/18-Figure7-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/19-Figure8-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/2-Figure1-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/4-Figure2-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/6-Figure3-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/7-Figure4-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/8-Table1-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/8-Table2-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/9-Figure5-1.png", "data/dataset/spiqa/images/50790468a774f3ecd663e79932e6da4e813048aa/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "In what way can SBM-Transformer be considered better than Reformer?", "reference_answer": "SBM-Transformer allows more flexible attention mask structures between linear to full attention with respective computational costs, while Reformer can only use block-diagonal masks that cannot model hierarchical contexts."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "57e76169-fe2f-54c9-9d35-448bd2fb52cd", "question": "What models are included in baseline benchmarking results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["cbaffb91-ef6b-540e-aeb8-183ea64d9b4f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.05829/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.05829/2-Table1-1.png", "data/dataset/spiqa/images/2002.05829/3-Table2-1.png", "data/dataset/spiqa/images/2002.05829/4-Figure1-1.png", "data/dataset/spiqa/images/2002.05829/4-Table3-1.png", "data/dataset/spiqa/images/2002.05829/5-Table4-1.png", "data/dataset/spiqa/images/2002.05829/6-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What models are included in baseline benchmarking results?", "reference_answer": "BERT, XLNET RoBERTa, ALBERT, DistilBERT", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0e53d5f4-a088-5296-944f-99e1b2447d21", "question": "How does the time needed for learning a graph with a subset of allowed edges $\\mathcal{E}^\\text{allowed}$ change as the number of edges per node increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the time needed for learning a graph with a subset of allowed edges $\\mathcal{E}^\\text{allowed}$ change as the number of edges per node increases?", "reference_answer": "The time needed for learning a graph with a subset of allowed edges $\\mathcal{E}^\\text{allowed}$ increases linearly as the number of edges per node increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0c532d83-cda8-57f8-a7a7-6b3ea5ad0095", "question": "What is the role of the GRU cell in the embedding model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["427f53cc-34f9-53f5-bfe0-7803daa82b6c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table1-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure1-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure4-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure5-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure6-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure2-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure7-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table2-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Table3-1.png", "data/dataset/spiqa/images/1704.05958v2/1704.05958v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the GRU cell in the embedding model?", "reference_answer": "The GRU cell is used to map a textual relation embedding to a probability distribution over KB relations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "54cfeb96-ac7c-5836-9754-d8769d29ec2b", "question": "What is the difference between the encoder and decoder networks in the action-conditional prediction model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["edf2543a-ae86-5f4d-b07a-c33d5092ee05"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure5-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure3-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure2-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure4-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the encoder and decoder networks in the action-conditional prediction model?", "reference_answer": "The encoder network takes a one-hot action and the current state as input and outputs a latent representation of the state. The decoder network takes the latent representation and outputs a prediction of the next state."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d571f1f0-1f8f-592e-939f-93f4e7d7b7ee", "question": " \n\nWhat is the effect of increasing the value of β2 on the precision and recall of the model? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " \n\nWhat is the effect of increasing the value of β2 on the precision and recall of the model? ", "reference_answer": " \n\nIncreasing the value of β2 decreases the precision and increases the recall of the model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7ff87089-133b-5381-819a-c06c5ca73e66", "question": "How does the accuracy of the Mixup method change as the level of random shuffle increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the accuracy of the Mixup method change as the level of random shuffle increases?", "reference_answer": "The accuracy of the Mixup method decreases as the level of random shuffle increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "feb1fff0-5ee1-5cf1-b32a-f092cb68e04f", "question": "How much more accurate is the model than the baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8ad0699d-27b4-5e09-9ef2-3127a445b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.00864/7-Table7-1.png", "data/dataset/spiqa/images/1912.00864/6-Table4-1.png", "data/dataset/spiqa/images/1912.00864/6-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.00864/3-Figure1-1.png", "data/dataset/spiqa/images/1912.00864/5-Table1-1.png", "data/dataset/spiqa/images/1912.00864/5-Table2-1.png", "data/dataset/spiqa/images/1912.00864/6-Table6-1.png", "data/dataset/spiqa/images/1912.00864/6-Table4-1.png", "data/dataset/spiqa/images/1912.00864/7-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much more accurate is the model than the baseline?", "reference_answer": "For the Oshiete-goo dataset, the NAGM model's ROUGE-L score is higher than the highest performing conventional model, Trans, by 0.021, and its BLEU-4 score is higher than the highest performing model CLSTM by 0.037.  For the nfL6 dataset, the NAGM model's ROUGE-L score is higher than the highest performing conventional model, CLSTM, by 0.028, and its BLEU-4 score is higher than the highest performing model CLSTM by 0.040. Human evaluation of the NAGM's generated outputs for the Oshiete-goo dataset had 47% ratings of (1), the highest rating, while CLSTM only received 21% ratings of (1). For the nfL6 dataset, the comparison of (1)'s was NAGM's 50% to CLSTM's 30%. ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d17acf33-2039-5452-937d-c21c766be80d", "question": "Which baseline methods are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["430bf567-c67b-554a-b865-ca96e054ca1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00110/5-Figure3-1.png", "data/dataset/spiqa/images/1707.00110/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00110/3-Figure1-1.png", "data/dataset/spiqa/images/1707.00110/4-Figure2-1.png", "data/dataset/spiqa/images/1707.00110/4-Table1-1.png", "data/dataset/spiqa/images/1707.00110/5-Figure3-1.png", "data/dataset/spiqa/images/1707.00110/6-Figure4-1.png", "data/dataset/spiqa/images/1707.00110/6-Table2-1.png", "data/dataset/spiqa/images/1707.00110/6-Table3-1.png", "data/dataset/spiqa/images/1707.00110/7-Figure5-1.png", "data/dataset/spiqa/images/1707.00110/8-Figure6-1.png", "data/dataset/spiqa/images/1707.00110/8-Figure7-1.png", "data/dataset/spiqa/images/1707.00110/8-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which baseline methods are used?", "reference_answer": "standard parametrized attention and a non-attention baseline", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "07fc5fd0-df88-5d17-aaab-cb854c156385", "question": "Can you explain the discrepancy between the number of messages and responses in each dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bf33c3ac-b6da-5fbf-b95a-d731d0dfd2f0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table2-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table4-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table3-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure1-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Table5-1.png", "data/dataset/spiqa/images/1809.04276v2/1809.04276v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Can you explain the discrepancy between the number of messages and responses in each dataset?", "reference_answer": "Number of responses is significantly higher than number of messages in each dataset (training, validation, and test). This is because each message can have multiple responses associated with it. The passage mentions that users on Sina Weibo can post messages and also comment on other users' messages. These comments are considered as responses in the context of the table. Therefore, one message can have several responses, leading to a higher total number of responses compared to messages."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a17b4270-24ad-519b-99c8-8dbc4c0ea958", "question": "Did they experiment on this dataset?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["a2bf22bf-ee5d-51ff-807e-30693117f271"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.02224/4-Table1-1.png", "data/dataset/spiqa/images/2002.02224/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.02224/4-Figure1-1.png", "data/dataset/spiqa/images/2002.02224/4-Table1-1.png", "data/dataset/spiqa/images/2002.02224/5-Table2-1.png", "data/dataset/spiqa/images/2002.02224/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did they experiment on this dataset?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4fdaa3ad-0ee0-5732-84c5-4f73c7a069e5", "question": "Which task required the highest learning rate and how does this compare to the learning rate used for CamRest?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which task required the highest learning rate and how does this compare to the learning rate used for CamRest?", "reference_answer": "Task T1 and T2 required the highest learning rate of 0.001. This is twice the learning rate used for CamRest, which was trained with a learning rate of 0.0005."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c2c4ebf4-4691-5db1-99b3-cb086f3d3d56", "question": "How do the initial conditions of the simulations vary?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the initial conditions of the simulations vary?", "reference_answer": "The initial conditions of the simulations vary in two dimensions: the position of the liquid drop along the x-axis (α1) and the size of the drop (α2)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "48533b23-86e8-5b8f-a517-7d642b440d53", "question": "How is the input triple translated to a slot-filling task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["cb5918ef-7734-5e87-ad82-62fdec204957"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04115/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04115/1-Figure1-1.png", "data/dataset/spiqa/images/1706.04115/4-Figure2-1.png", "data/dataset/spiqa/images/1706.04115/7-Table1-1.png", "data/dataset/spiqa/images/1706.04115/7-Table3-1.png", "data/dataset/spiqa/images/1706.04115/7-Table2-1.png", "data/dataset/spiqa/images/1706.04115/7-Figure4-1.png", "data/dataset/spiqa/images/1706.04115/8-Figure5-1.png", "data/dataset/spiqa/images/1706.04115/8-Table5-1.png", "data/dataset/spiqa/images/1706.04115/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How is the input triple translated to a slot-filling task?", "reference_answer": "The relation R(x,y) is mapped onto a question q whose answer is y", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "436ebe44-8260-5398-a6e1-c45ab352c6ea", "question": "How many layers of self-attention does the model have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b7c21413-1f78-5ea0-9c21-dcf1d5e8754a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.05246/8-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.05246/4-Table1-1.png", "data/dataset/spiqa/images/1909.05246/5-Table2-1.png", "data/dataset/spiqa/images/1909.05246/6-Table3-1.png", "data/dataset/spiqa/images/1909.05246/7-Table4-1.png", "data/dataset/spiqa/images/1909.05246/7-Table5-1.png", "data/dataset/spiqa/images/1909.05246/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many layers of self-attention does the model have?", "reference_answer": "1, 4, 8, 16, 32, 64", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f8172aa0-d0bb-5fb2-bca0-9a2efe17263e", "question": "How many layers does the MobileNet has?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many layers does the MobileNet has?", "reference_answer": "MobileNet has 28 layers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5c3ecaf6-44b5-5674-b701-012dd7afc085", "question": "Which method has the highest overall accuracy for answering questions about images on the 100 questions sampled from VQA v2 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2f3b7633-fa54-55d7-8802-08f611b754d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure6-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure9-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure10-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the highest overall accuracy for answering questions about images on the 100 questions sampled from VQA v2 dataset?", "reference_answer": "UnCoRd-VG-E"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "41f4d977-d953-5dc1-b9db-f5103886840a", "question": "How much does this system outperform prior work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b0f1fa72-b174-5c1c-96f6-7333e8e58c2a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.09393/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.09393/5-Table1-1.png", "data/dataset/spiqa/images/1902.09393/6-Figure1-1.png", "data/dataset/spiqa/images/1902.09393/7-Table2-1.png", "data/dataset/spiqa/images/1902.09393/7-Figure2-1.png", "data/dataset/spiqa/images/1902.09393/7-Table3-1.png", "data/dataset/spiqa/images/1902.09393/8-Table4-1.png", "data/dataset/spiqa/images/1902.09393/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much does this system outperform prior work?", "reference_answer": "The system outperforms by 27.7% the LSTM model, 38.5% the RL-SPINN model and 41.6% the Gumbel Tree-LSTM", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "dea09e3e-a786-5631-8fe5-e58d52a4ce08", "question": "What is the purpose of the user study?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the user study?", "reference_answer": "The user study is designed to test which of two images is closer to a reference video."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "68d0237b-2405-569e-aaff-0fa3258a0ce8", "question": "What is the difference between AdelaideRMF and Multi-H?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between AdelaideRMF and Multi-H?", "reference_answer": "AdelaideRMF tends to assign points to more planes than Multi-H."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6a93938c-86d4-54f8-a22e-dd1ddb580a95", "question": "How much does it minimally cost to fine-tune some model according to benchmarking framework?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["cbaffb91-ef6b-540e-aeb8-183ea64d9b4f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.05829/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.05829/2-Table1-1.png", "data/dataset/spiqa/images/2002.05829/3-Table2-1.png", "data/dataset/spiqa/images/2002.05829/4-Figure1-1.png", "data/dataset/spiqa/images/2002.05829/4-Table3-1.png", "data/dataset/spiqa/images/2002.05829/5-Table4-1.png", "data/dataset/spiqa/images/2002.05829/6-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much does it minimally cost to fine-tune some model according to benchmarking framework?", "reference_answer": "$1,728", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "81d1dede-7d41-5d81-819d-0c1e1290d39c", "question": "Do they assume sentence-level supervision?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["cd090d0d-c674-5288-babe-e6aec8f2334e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.04913/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.04913/3-Figure1-1.png", "data/dataset/spiqa/images/1707.04913/4-Table2-1.png", "data/dataset/spiqa/images/1707.04913/4-Table1-1.png", "data/dataset/spiqa/images/1707.04913/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they assume sentence-level supervision?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "40e5b6f1-51a5-583f-a95e-04e9f2e2d314", "question": "If you are performing domain adaptation with ZDDA using AlexNet as the base network architecture and $D_F$ as the target domain, which layers of the network would be considered part of the source CNN and which would be part of the source classifier?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["86d109ac-bfba-5548-a67e-8dfd401e8f3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table7-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table6-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table5-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table9-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table2-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table8-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "If you are performing domain adaptation with ZDDA using AlexNet as the base network architecture and $D_F$ as the target domain, which layers of the network would be considered part of the source CNN and which would be part of the source classifier?", "reference_answer": "In this scenario, the source CNN would consist of the AlexNet architecture up to and including the \"fc7\" layer. The remaining layers of AlexNet would then be used as the source classifier."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "49be6dbf-8447-5554-a641-1b8907822f0f", "question": "Which model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, and how does its performance compare to the baselines?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["17c85eec-75f5-5bb9-9f35-9c25d5a9c285"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00189v3/1707.00189v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00189v3/1707.00189v3-Table2-1.png", "data/dataset/spiqa/images/1707.00189v3/1707.00189v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, and how does its performance compare to the baselines?", "reference_answer": "The Conv-KNRM model performs best when trained on the NYT dataset and evaluated on the WT14 dataset, achieving an nDCG@20 score of 0.3215. This performance is significantly better than all the baselines: BM25 (B), WT10 (W), and AOL (A)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4e679ebd-accd-5a9e-9932-693a3947cdd4", "question": "Which model performs the best in terms of test error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["08eae607-b68b-5938-842d-52805a218768"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table5-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table4-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table3-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table2-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Table1-1.png", "data/dataset/spiqa/images/1705.10667v4/1705.10667v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best in terms of test error?", "reference_answer": "CDAN (M)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "85b822c3-61cd-51c6-95e4-110f725b8c51", "question": "Can this approach model n-ary relations?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["d16067e2-c3da-5ef0-92d2-f6e18e4ce3c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.03396/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.03396/3-Figure1-1.png", "data/dataset/spiqa/images/1804.03396/6-Table1-1.png", "data/dataset/spiqa/images/1804.03396/6-Table2-1.png", "data/dataset/spiqa/images/1804.03396/7-Figure2-1.png", "data/dataset/spiqa/images/1804.03396/9-Table3-1.png", "data/dataset/spiqa/images/1804.03396/10-Table4-1.png", "data/dataset/spiqa/images/1804.03396/11-Figure3-1.png", "data/dataset/spiqa/images/1804.03396/12-Table6-1.png", "data/dataset/spiqa/images/1804.03396/13-Table7-1.png", "data/dataset/spiqa/images/1804.03396/14-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Can this approach model n-ary relations?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "96222217-254c-5aec-8317-b1f3de3e3c57", "question": "How well RoBERTa language modeling on Wiki-40B?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How well RoBERTa language modeling on Wiki-40B?", "reference_answer": "RoBERTa performs at about 2.6 BPC on the MLM task with the Wiki-40B dataset. RoBERTa performs better than BERT."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5305851c-95e1-5a9c-910f-8c4e6c2422f9", "question": "How are the bullet-point summaries converted to queries?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How are the bullet-point summaries converted to queries?", "reference_answer": "Each article in the news websites they used (CNN, DailyMail) has a couple of bullet points containing an abstractive summary of the article. They convert each bullet point into a Cloze style question and answer using entity detection algorithms. More details on what Cloze-style questions are is not available in this paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "198343a8-79ed-51a8-96fa-d5b76b8515a4", "question": "What is the difference between an \"agent-in-place\" action and a generic action category?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f290ed70-eb81-598b-aa2d-1920fc19428f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Table1-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure2-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure3-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure8-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure7-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure4-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure9-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure10-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure5-1.png", "data/dataset/spiqa/images/1804.01429v3/1804.01429v3-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between an \"agent-in-place\" action and a generic action category?", "reference_answer": "An agent-in-place action is an action that is performed by an agent in a specific place, while a generic action category is a more general category of action that does not specify the place where the action is performed."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7fbbeaba-2305-5121-b559-1b93c5bfb94b", "question": "According to Table 1 and the passage, how does the performance of the SRU model compare to the LSTM model in terms of both accuracy and training speed on the SQuAD dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "According to Table 1 and the passage, how does the performance of the SRU model compare to the LSTM model in terms of both accuracy and training speed on the SQuAD dataset?", "reference_answer": "The SRU model outperforms the LSTM model in both accuracy and training speed on the SQuAD dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "97f46025-448b-5267-a075-6ba78b3f1e0c", "question": "Out of all the classification datasets used in the experiments of this paper, what is the ratio of number of samples in the largest to the smallest dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c4860d9-c6fc-5c07-b4c7-dc9cd1aff233"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/5-Table1-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table2-1.png", "data/dataset/spiqa/images/ad76c236fe641aa52d1d6c28bf362ae9ffac91e7/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Out of all the classification datasets used in the experiments of this paper, what is the ratio of number of samples in the largest to the smallest dataset?", "reference_answer": "The statistics for each dataset and task are found in Table  1. The ratio of the number of samples in the largest to smallest dataset could be calculated from these statistics."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "4ef7d520-deb3-5c91-9554-c0da80403849", "question": "What are the baseline systems that are compared against?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b0f1fa72-b174-5c1c-96f6-7333e8e58c2a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1902.09393/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1902.09393/5-Table1-1.png", "data/dataset/spiqa/images/1902.09393/6-Figure1-1.png", "data/dataset/spiqa/images/1902.09393/7-Table2-1.png", "data/dataset/spiqa/images/1902.09393/7-Figure2-1.png", "data/dataset/spiqa/images/1902.09393/7-Table3-1.png", "data/dataset/spiqa/images/1902.09393/8-Table4-1.png", "data/dataset/spiqa/images/1902.09393/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the baseline systems that are compared against?", "reference_answer": "The system is compared to baseline models: LSTM, RL-SPINN and Gumbel Tree-LSTM", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "df9d8255-9f6a-5980-8be4-eee5e97d28ee", "question": "What is the difference between the Inference module and the Posterior module?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the Inference module and the Posterior module?", "reference_answer": "The Inference module takes the previous frame (Xt-1) and the dynamic constraint (ĥt) as input, while the Posterior module takes the current frame (Xt) as input. This means that the Inference module is trying to predict the next frame based on the previous frame and the dynamic constraint, while the Posterior module is trying to reconstruct the current frame."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "43e1928b-13f2-53ec-a96a-44646147a408", "question": "Explain why the model trained on both MOT and detection sets has a higher number of identity switches (IDS) compared to the model trained only on the MOT set, even though it achieves better performance in terms of AP, MOTA, and MOTP?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Explain why the model trained on both MOT and detection sets has a higher number of identity switches (IDS) compared to the model trained only on the MOT set, even though it achieves better performance in terms of AP, MOTA, and MOTP?", "reference_answer": "While the model trained on both MOT and detection sets shows improved performance in detection and tracking metrics (AP, MOTA, MOTP), it also exhibits a higher number of identity switches (IDS). This can be attributed to the increased diversity of instances introduced by the detection set. Although the MOT set provides a larger number of bounding boxes for training, the detection set adds varied examples that may lead to more frequent identity switches during tracking, even as it improves the model's overall performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c5bbe069-1fa7-5623-b2e9-e7d5e32e8319", "question": "Which model performs better based on the training curves?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dc5584b7-6dd8-5e79-b1ba-1d77ce70df61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure1-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure3-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table2-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs better based on the training curves?", "reference_answer": "It is difficult to say definitively which model performs better based on the training curves alone. However, it appears that the WGAN(g) model may be performing better than the other models, as its generator and discriminator losses are both lower than the other models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "16ef84d0-8e6d-5ae5-9199-aa7cbc44cc81", "question": "Do they evaluate on downstream tasks?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["c33e99c3-502a-5b26-ae37-4cc75a515479"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.11768/6-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.11768/2-Table1-1.png", "data/dataset/spiqa/images/1910.11768/3-Figure1-1.png", "data/dataset/spiqa/images/1910.11768/4-Table2-1.png", "data/dataset/spiqa/images/1910.11768/4-Table3-1.png", "data/dataset/spiqa/images/1910.11768/6-Table4-1.png", "data/dataset/spiqa/images/1910.11768/6-Table5-1.png", "data/dataset/spiqa/images/1910.11768/6-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they evaluate on downstream tasks?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "46864ac2-2ccf-5c02-a772-cd5bcff81788", "question": "What are their initial results on this task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9db6947b-252e-566d-98c7-02634e4e41a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.05752/6-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.05752/3-Table1-1.png", "data/dataset/spiqa/images/1809.05752/4-Table2-1.png", "data/dataset/spiqa/images/1809.05752/5-Table3-1.png", "data/dataset/spiqa/images/1809.05752/5-Table4-1.png", "data/dataset/spiqa/images/1809.05752/6-Figure1-1.png", "data/dataset/spiqa/images/1809.05752/6-Table5-1.png", "data/dataset/spiqa/images/1809.05752/7-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are their initial results on this task?", "reference_answer": "Achieved the highest per-domain scores on Substance (F1 ≈ 0.8) and the lowest scores on Interpersonal and Mood (F1 ≈ 0.5), and show consistency in per-domain performance rankings between MLP and RBF models.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a67c089a-89b9-5700-8fe5-cc9f7c4c46c3", "question": "Which model performed best on the Rest15 dataset for binary classification, and how does its performance compare to the best model for 3-way classification on the same dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d5785d16-c0a5-5e54-9ad7-9ee75cd95b28"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure1-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure5-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure6-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed best on the Rest15 dataset for binary classification, and how does its performance compare to the best model for 3-way classification on the same dataset?", "reference_answer": "For binary classification on the Rest15 dataset, M-CAN-2$R_o$ achieved the highest performance with an accuracy of 82.14% and Macro-F1 of 81.58%. In comparison, the best performing model for 3-way classification on Rest15 was M-CAN-2$R_s$, achieving an accuracy of 78.22% and Macro-F1 of 55.80%. This indicates that M-CAN-2$R_o$ performed better in both accuracy and Macro-F1 for binary classification compared to the best model for 3-way classification on the same dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "961adfae-9055-5610-b1e4-a75304f2b582", "question": "Which algorithm performs the best in terms of average memory ratio with respect to BP+RR for GMap 10%?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm performs the best in terms of average memory ratio with respect to BP+RR for GMap 10%?", "reference_answer": "Delta-based BP+RR"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "61d615bb-96e0-57a0-8fd8-8b23a8a03bf6", "question": "What happens when there is a conflict between the low-res image and the feature vector?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What happens when there is a conflict between the low-res image and the feature vector?", "reference_answer": "The generated high-res digit follows the given class label."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5795d5e6-dff8-5345-9111-3fe03eb92a0f", "question": "Which dataset has the highest number of samples per class?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["296788f8-16bc-55ff-9d9a-9fdf5ff3b0e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table4-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the highest number of samples per class?", "reference_answer": "SVHN"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "58f31f96-7eb5-5cb5-b585-b4355d392fc4", "question": "How does the proposed method's attention map differ from the VGG16 feature map?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed method's attention map differ from the VGG16 feature map?", "reference_answer": "The attention map generated by proposed method is able to localize regions that were weak or non-existent in the activations of the input maps, while the VGG16 feature map simply amplifies the activations present in VGG16 channels."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8c9c0cce-60b1-51b8-b803-ffffc10d6248", "question": "What is used for measure the quantities of non-English data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is used for measure the quantities of non-English data?", "reference_answer": "Automatic language identification and manual qualitative analysis measure non-English data. They are denominated in lines, tokens, and percentages across the paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d7ea3beb-7b89-5fb9-938b-1992a8d19dda", "question": "Describe the relationship between the update threshold (Tu) and the performance of ITN (B-CNN) on the MNIST dataset.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Describe the relationship between the update threshold (Tu) and the performance of ITN (B-CNN) on the MNIST dataset.", "reference_answer": "The performance of ITN (B-CNN) on the MNIST dataset decreases as the update threshold (Tu) increases. This is evident from the increasing ITN error percentages as Tu goes from 1e-3 to 1e-1."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "904ff32d-0685-59b3-a3e0-5928e0a6bd77", "question": "Which of the methods is able to reconstruct the shape of the liquid properly?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the methods is able to reconstruct the shape of the liquid properly?", "reference_answer": "Only the full method with a deformation network is able to produce a perfect reconstruction."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "57a78388-9c48-5b98-b604-ae412512fd59", "question": "Do they compare executionttime of their model against other models?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["9dd4effb-2e79-520e-8a4e-f49b2e064e4a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.02086/4-Table1-1.png", "data/dataset/spiqa/images/1911.02086/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.02086/3-Figure3-1.png", "data/dataset/spiqa/images/1911.02086/3-Figure1-1.png", "data/dataset/spiqa/images/1911.02086/3-Figure2-1.png", "data/dataset/spiqa/images/1911.02086/4-Table1-1.png", "data/dataset/spiqa/images/1911.02086/4-Figure4-1.png", "data/dataset/spiqa/images/1911.02086/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they compare executionttime of their model against other models?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f78eb101-9547-5f1f-af38-7d75154b8d7a", "question": "What is the relationship between the true market state qt and the noisy version q̂t at time t?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7007d541-1ee3-59d2-859b-1c0e467070ce"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.00899v2/1703.00899v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.00899v2/1703.00899v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the true market state qt and the noisy version q̂t at time t?", "reference_answer": "The noisy version q̂t at time t is equal to the true market state qt plus a sum of Laplace noise vectors obtained by following the arrows all the way back to 0."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5184505f-9df1-5da5-a9b5-91e610ba0cc5", "question": "Why did Seq2Seq and Mem2Seq models perform poorly when the percentage of unseen entities in the knowledge base (KB) increased?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why did Seq2Seq and Mem2Seq models perform poorly when the percentage of unseen entities in the knowledge base (KB) increased?", "reference_answer": "Seq2Seq and Mem2Seq models performed poorly because they struggled to capture the semantic representations of unseen entities. This means they couldn't understand the meaning and relationships of new restaurants introduced in the KB. As a result, they were unable to accurately identify the correct restaurant and provide its address when faced with unseen entities."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c9da1cb8-5dda-59f7-b877-ed964b362546", "question": "How does the initial accuracy of the discriminator affect the BLEU score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7e050ffe-a1b2-5ec1-a6cd-9641ced929b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table3-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table1-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the initial accuracy of the discriminator affect the BLEU score?", "reference_answer": "The BLEU score decreases as the initial accuracy of the discriminator increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9ac6854d-72c7-51c5-a191-e24a8cd8147d", "question": "What is typical GAN architecture for each text-to-image synhesis group?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ae331241-a465-5125-8bfd-ec99ed6bd452"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.09399/12-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.09399/2-Figure1-1.png", "data/dataset/spiqa/images/1910.09399/3-Figure2-1.png", "data/dataset/spiqa/images/1910.09399/3-Figure3-1.png", "data/dataset/spiqa/images/1910.09399/4-Figure4-1.png", "data/dataset/spiqa/images/1910.09399/7-Figure5-1.png", "data/dataset/spiqa/images/1910.09399/8-Figure6-1.png", "data/dataset/spiqa/images/1910.09399/9-Figure7-1.png", "data/dataset/spiqa/images/1910.09399/10-Figure8-1.png", "data/dataset/spiqa/images/1910.09399/12-Figure9-1.png", "data/dataset/spiqa/images/1910.09399/18-Table1-1.png", "data/dataset/spiqa/images/1910.09399/20-Table2-1.png", "data/dataset/spiqa/images/1910.09399/21-Figure10-1.png", "data/dataset/spiqa/images/1910.09399/21-Figure11-1.png", "data/dataset/spiqa/images/1910.09399/22-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is typical GAN architecture for each text-to-image synhesis group?", "reference_answer": "Semantic Enhancement GANs: DC-GANs, MC-GAN\nResolution Enhancement GANs: StackGANs, AttnGAN, HDGAN\nDiversity Enhancement GANs: AC-GAN, TAC-GAN etc.\nMotion Enhancement GAGs: T2S, T2V, StoryGAN", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0da464c2-84b7-5f9d-9541-5db9695e9c5f", "question": "Which model performs best when the percentage of unseen entities in the response is low?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best when the percentage of unseen entities in the response is low?", "reference_answer": "BoSsNet"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6b69cd35-4163-5be3-a425-ea9a63d9741c", "question": "Which method resulted in the highest BLEU score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4979a3cd-d95a-5e60-a12e-08263adccd51"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table4-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table5-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table6-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table7-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table8-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table9-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table1-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table2-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method resulted in the highest BLEU score?", "reference_answer": "The 1-keyword method resulted in the highest BLEU score of 0.705."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4c667773-6583-5ec5-a517-f1af2e6828e1", "question": "Do they compare DeepER against other approaches?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["a7215f10-2663-57d2-89b6-3d5a07009ea8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.08675/20-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.08675/4-Figure1-1.png", "data/dataset/spiqa/images/1605.08675/6-Figure2-1.png", "data/dataset/spiqa/images/1605.08675/12-Figure3-1.png", "data/dataset/spiqa/images/1605.08675/15-Table1-1.png", "data/dataset/spiqa/images/1605.08675/16-Table2-1.png", "data/dataset/spiqa/images/1605.08675/18-Figure4-1.png", "data/dataset/spiqa/images/1605.08675/19-Figure5-1.png", "data/dataset/spiqa/images/1605.08675/19-Figure6-1.png", "data/dataset/spiqa/images/1605.08675/20-Table3-1.png", "data/dataset/spiqa/images/1605.08675/21-Table4-1.png", "data/dataset/spiqa/images/1605.08675/23-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they compare DeepER against other approaches?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "69116d64-8f05-5898-b162-9dba1234514f", "question": "How does the proposed metric of non-ME help detect adversarial examples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed metric of non-ME help detect adversarial examples?", "reference_answer": " The non-ME metric measures the entropy of the normalized non-maximal elements in the final hidden vector of the classifier. Adversarial examples often have low non-ME values, indicating that they are close to the decision boundary and have high confidence in the incorrect class."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1d828b39-f5b1-5ec8-ae1a-1fc74d113969", "question": "Which method performs best on the CIFAR-10 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best on the CIFAR-10 dataset?", "reference_answer": "ITN (ResNet-32) with data augmentation performs best on the CIFAR-10 dataset with a testing error of 5.82%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "372d8066-a787-5dc4-b84d-81316f6317a3", "question": "Are the word embeddings evaluated?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["2ae6f2f0-4119-549c-ad71-ce8f6b2a66cc"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.09332/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.09332/3-Figure1-1.png", "data/dataset/spiqa/images/2001.09332/6-Table1-1.png", "data/dataset/spiqa/images/2001.09332/6-Figure2-1.png", "data/dataset/spiqa/images/2001.09332/7-Table2-1.png", "data/dataset/spiqa/images/2001.09332/7-Figure3-1.png", "data/dataset/spiqa/images/2001.09332/7-Table3-1.png", "data/dataset/spiqa/images/2001.09332/8-Table5-1.png", "data/dataset/spiqa/images/2001.09332/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the word embeddings evaluated?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "306f73e3-d26d-5daf-9bd9-4b8e990c9fb9", "question": "Which dataset has the most 4-hop triples?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the most 4-hop triples?", "reference_answer": "Bing-News."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5bc975e5-07c8-5fb2-95cf-cc81262b190f", "question": "Which of the following statements about the training procedure of ZDDA is true?\n\n(a) ZDDA simulates the target-domain representation using the source-domain data. (b) ZDDA builds a joint network with the supervision from the target domain. (c) ZDDA trains a sensor fusion network in step 1. (d) ZDDA trains a sensor fusion network in step 2.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["86d109ac-bfba-5548-a67e-8dfd401e8f3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table7-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table6-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table5-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table9-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table2-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table8-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the following statements about the training procedure of ZDDA is true?\n\n(a) ZDDA simulates the target-domain representation using the source-domain data. (b) ZDDA builds a joint network with the supervision from the target domain. (c) ZDDA trains a sensor fusion network in step 1. (d) ZDDA trains a sensor fusion network in step 2.", "reference_answer": "(a) ZDDA simulates the target-domain representation using the source-domain data."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9d4dc8b2-781f-5e3a-8edc-7d46cd2959c7", "question": "Which method achieves the highest Top-1 Accuracy for multi-shot person re-identification on the BIWI dataset, and how does it compare to the best single-shot method on the same dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the highest Top-1 Accuracy for multi-shot person re-identification on the BIWI dataset, and how does it compare to the best single-shot method on the same dataset?", "reference_answer": "The proposed method with RTA attention achieves the highest Top-1 Accuracy for multi-shot person re-identification on the BIWI dataset with a score of 50.0%. This is significantly higher than the best single-shot method on the same dataset, which is our method (CNN) with a score of 25.4%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2e05cb60-7db6-5f9b-b3a0-7dd94212e31c", "question": "What is the relationship between the resolution of the simulation and the training time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the resolution of the simulation and the training time?", "reference_answer": " The higher the resolution of the simulation, the longer the training time. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a5bf6d42-3a59-56c4-b90f-329149b20445", "question": "What rouge score do they achieve?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3e23a677-9f88-5a36-a751-7eaaca56c05f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.08345/7-Table4-1.png", "data/dataset/spiqa/images/1908.08345/7-Table3-1.png", "data/dataset/spiqa/images/1908.08345/5-Table1-1.png", "data/dataset/spiqa/images/1908.08345/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.08345/3-Figure1-1.png", "data/dataset/spiqa/images/1908.08345/5-Table1-1.png", "data/dataset/spiqa/images/1908.08345/6-Table2-1.png", "data/dataset/spiqa/images/1908.08345/7-Table4-1.png", "data/dataset/spiqa/images/1908.08345/7-Table3-1.png", "data/dataset/spiqa/images/1908.08345/8-Table5-1.png", "data/dataset/spiqa/images/1908.08345/8-Figure2-1.png", "data/dataset/spiqa/images/1908.08345/9-Figure3-1.png", "data/dataset/spiqa/images/1908.08345/9-Table7-1.png", "data/dataset/spiqa/images/1908.08345/9-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What rouge score do they achieve?", "reference_answer": "Best results on unigram:\nCNN/Daily Mail: Rogue F1 43.85\nNYT: Rogue Recall 49.02\nXSum: Rogue F1 38.81", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ce347bf3-5c20-5d95-b86a-7259f6d1152b", "question": "How much important is the visual grounding in the learning of the multilingual representations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7826e78a-e11d-52fb-b98d-bcf0005fd711"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.12260/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.12260/3-Figure1-1.png", "data/dataset/spiqa/images/1905.12260/5-Figure2-1.png", "data/dataset/spiqa/images/1905.12260/6-Figure3-1.png", "data/dataset/spiqa/images/1905.12260/7-Table1-1.png", "data/dataset/spiqa/images/1905.12260/7-Table2-1.png", "data/dataset/spiqa/images/1905.12260/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much important is the visual grounding in the learning of the multilingual representations?", "reference_answer": "performance is significantly degraded without pixel data", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "425311a9-710f-5e7b-941b-6cd8362d95b2", "question": "How does training pre-training a latent space in Optimus lead to higher performance for dialog generation? Is it because the whole dialog can be encoded in the latent space?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52282141-da72-5ea1-9735-6bb4c9f25cf5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/8-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/13-Figure5-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/13-Figure6-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/14-Table8-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/14-Table9-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/15-Table10-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/15-Table11-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/17-Table12-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/17-Table14-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/18-Table15-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/18-Table16-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/18-Table17-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/19-Table18-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/19-Table19-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/20-Table20-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/20-Table21-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/4-Figure1-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/4-Figure2-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/6-Table1-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/7-Table2-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/7-Table3-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/8-Figure3-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/8-Figure4-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/8-Table4-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/8-Table6-1.png", "data/dataset/spiqa/images/00696ba295d66f049d70272219f7fea4266171be/9-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does training pre-training a latent space in Optimus lead to higher performance for dialog generation? Is it because the whole dialog can be encoded in the latent space?", "reference_answer": "There is no information about dialog generation specifically, to explain if this outperformance by OPTIMUS can be attributed specifically to being able to encode the entire dialog in latent space."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e431bc8c-5a40-5cfd-94e5-4b623d1b423c", "question": "What are the source and target domains?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4d12231b-5489-5dd9-8b53-571fca989879"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00530/11-Table3-1.png", "data/dataset/spiqa/images/1809.00530/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00530/5-Table1-1.png", "data/dataset/spiqa/images/1809.00530/7-Figure1-1.png", "data/dataset/spiqa/images/1809.00530/8-Figure2-1.png", "data/dataset/spiqa/images/1809.00530/8-Figure3-1.png", "data/dataset/spiqa/images/1809.00530/9-Table2-1.png", "data/dataset/spiqa/images/1809.00530/11-Table3-1.png", "data/dataset/spiqa/images/1809.00530/12-Table4-1.png", "data/dataset/spiqa/images/1809.00530/13-Table5-1.png", "data/dataset/spiqa/images/1809.00530/14-Table6-1.png", "data/dataset/spiqa/images/1809.00530/15-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the source and target domains?", "reference_answer": "Book, electronics, beauty, music, IMDB, Yelp, cell phone, baby, DVDs, kitchen", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7d30ea76-7fce-5f02-939f-cf116261d2c4", "question": "Do the authors report performance of conditional bert on tasks without data augmentation?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["40843903-571a-5d54-9bfb-a3be8e0c346a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06705/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06705/5-Figure1-1.png", "data/dataset/spiqa/images/1812.06705/5-Table1-1.png", "data/dataset/spiqa/images/1812.06705/7-Table2-1.png", "data/dataset/spiqa/images/1812.06705/7-Table3-1.png", "data/dataset/spiqa/images/1812.06705/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors report performance of conditional bert on tasks without data augmentation?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "65f56368-f358-5441-a9e0-c4558faf52f4", "question": "Which dataset has the most entities?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has the most entities?", "reference_answer": "MedBook + MKG"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "620f894b-ab03-5d74-ad7b-8e3bc5db3949", "question": "How does the flow of water change as the central wall obstacle is shifted to the right?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the flow of water change as the central wall obstacle is shifted to the right?", "reference_answer": "The flow of water increases as the central wall obstacle is shifted to the right."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2b2ef893-0f05-5bc6-bd39-46a3cd50b662", "question": "Which method performs best for the \"Representation\" task when the view is \"Novel\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9104d00a-0d2b-565f-acc8-c4650cf151b3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure6-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Table1-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure7-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure10-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure2-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure8-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure12-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure11-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure9-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure4-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure3-1.png", "data/dataset/spiqa/images/1804.00863v3/1804.00863v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best for the \"Representation\" task when the view is \"Novel\"?", "reference_answer": "The \"OUR\" method performs best for the \"Representation\" task when the view is \"Novel\"."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "284cd9b1-d6d5-59a1-946d-89b0d0a4dcf0", "question": "What is fusion?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2c7c33de-6339-5f80-bda0-4e61c6318978"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/2-Figure1-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/4-Figure2-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure3-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure4-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-TableI-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure5-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure6-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-TableII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-Figure7-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-TableIII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/9-TableIV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is fusion?", "reference_answer": "Fusion is used in KinectFusion method in which all depth data from the sensor is fused into a volumetric dense model which is then used to track to camera pose."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "b05a79ac-7a42-54c0-b810-c4f2de8980a0", "question": "What are state of the art methods MMM is compared to?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5b6eda76-5309-518c-9ab0-9ed9821669a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.00458/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.00458/1-Table1-1.png", "data/dataset/spiqa/images/1910.00458/2-Figure1-1.png", "data/dataset/spiqa/images/1910.00458/3-Figure2-1.png", "data/dataset/spiqa/images/1910.00458/4-Table2-1.png", "data/dataset/spiqa/images/1910.00458/4-Table3-1.png", "data/dataset/spiqa/images/1910.00458/5-Table4-1.png", "data/dataset/spiqa/images/1910.00458/5-Table5-1.png", "data/dataset/spiqa/images/1910.00458/5-Table6-1.png", "data/dataset/spiqa/images/1910.00458/6-Table7-1.png", "data/dataset/spiqa/images/1910.00458/6-Figure3-1.png", "data/dataset/spiqa/images/1910.00458/6-Figure4-1.png", "data/dataset/spiqa/images/1910.00458/7-Table8-1.png", "data/dataset/spiqa/images/1910.00458/7-Table9-1.png", "data/dataset/spiqa/images/1910.00458/7-Table10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are state of the art methods MMM is compared to?", "reference_answer": "FTLM++, BERT-large, XLNet", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5dd2eaf8-3303-5bcd-82fd-a1c8c4a2b43b", "question": "What is the example of unreliable relations in knowledge graph for passage re-ranking scenario?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c2ce8e68-6fc4-5e1d-b409-ebb07c73d811"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/4-Figure2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table5-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table6-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table7-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/2-Figure1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/4-Figure2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/5-Figure3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/6-Figure4-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/8-Table1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the example of unreliable relations in knowledge graph for passage re-ranking scenario?", "reference_answer": "Unreliable relations in a knowledge graph involve trivial factual triplets that do not bring substantial information gain. For example, in ConceptNet, the entity “hepatitis” has relations with both “infectious disease” and “adult”. To the concept “hepatitis”,  the concept “adults” is more general than “infectious disease” and thus the relationship between “hepatitis” and “infectious disease” is more reliable and informative."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "54b243ca-9d7c-5fb6-84b6-2d4efddfc23b", "question": "Why does Yolo outperform R-CNN in other categories such as cat and train ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why does Yolo outperform R-CNN in other categories such as cat and train ?", "reference_answer": "The paper does not specifically discuss why YOLO is better for cat and train categories in VOC 2012 dataset and worse for the bottle, sheep, and tv/monitor. Thus, it is difficult to answer this question with only the contents of the paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "5d84eec9-e2c7-528a-801a-3e569f3df704", "question": "What are the pros and cons of a global approach and a local approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f124ba10-c318-5d52-ab9a-3be90aca000a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/1-Figure1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/3-Figure2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/4-Figure3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/5-Figure4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure5-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Table3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the pros and cons of a global approach and a local approach?", "reference_answer": "A drawback of the global attention is it had to attend to all words on the source side for each target word, which is expensive and potentially will render it impractical to translate longer sequences, and despite that global attention gives a significant boost of +2.8 BLEU making it better than the base attention system, but the local approach gave further improvement of +0.9 BLEU on top of the global attention model. Also the local approach achieved lower AERs. Not to mention that the local approach is simpler, easier to implement and train, and computationally less expensive. as it focus only on a small subset of the source positions per target word."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "cbf29256-2f88-5da2-a18b-81015af77c27", "question": "Which metropolitan area is predicted by the GeoCUTS algorithm to include San Francisco, Berkeley, and Palo Alto, but not Sacramento?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which metropolitan area is predicted by the GeoCUTS algorithm to include San Francisco, Berkeley, and Palo Alto, but not Sacramento?", "reference_answer": "The Bay Area."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "61d32dbd-d542-5d91-8296-f1b9dacf6db2", "question": "How does the maximum link delay affect the number of TCP timeouts and fast retransmissions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the maximum link delay affect the number of TCP timeouts and fast retransmissions?", "reference_answer": "The number of TCP timeouts and fast retransmissions decreases as the maximum link delay increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ac5325fd-d241-5d2c-8236-31b0ad79e369", "question": " Which denoiser performs the best on the sheep image, and how can you tell?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0adb94de-50f5-51ff-8e1a-b2e3e72dcfd2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure5-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure2-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure4-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " Which denoiser performs the best on the sheep image, and how can you tell?", "reference_answer": " The denoiser trained with the classification network and evaluated for semantic segmentation performs the best on the sheep image. This is because the segmentation label map for this denoiser is the most accurate, and it correctly identifies the sheep's body and legs. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "625035a1-2abb-513e-9269-0331e08b71e4", "question": "Which agent values the entire share $Z_j$?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f51e9f68-1547-5a42-8e74-fbfbfcb7f509"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure5-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure3-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure4-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Table1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which agent values the entire share $Z_j$?", "reference_answer": "Agent $j$."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9c74c17f-4953-52a9-b5c6-0bb5265818e0", "question": "By how much does their method outperform the multi-head attention model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6a34c59b-851b-5437-aa72-a91164674d90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.08050/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.08050/2-Figure1-1.png", "data/dataset/spiqa/images/1804.08050/3-Figure2-1.png", "data/dataset/spiqa/images/1804.08050/4-Table1-1.png", "data/dataset/spiqa/images/1804.08050/4-Figure3-1.png", "data/dataset/spiqa/images/1804.08050/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much does their method outperform the multi-head attention model?", "reference_answer": "Their average improvement in Character Error Rate over the best MHA model was 0.33 percent points.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bc7eb914-df98-598f-b05b-b6f01068447c", "question": "What was the goal behind reducing the filter size and stride of the ALexNet and GoogLeNet ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What was the goal behind reducing the filter size and stride of the ALexNet and GoogLeNet ?", "reference_answer": "The authors reduced the filter size and stride of the two models because the input size used was smaller than what the original models were trained on."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "a7c52ea4-429b-570c-aeee-ab4211c6df4f", "question": "How many labels do the datasets have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4d12231b-5489-5dd9-8b53-571fca989879"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00530/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00530/5-Table1-1.png", "data/dataset/spiqa/images/1809.00530/7-Figure1-1.png", "data/dataset/spiqa/images/1809.00530/8-Figure2-1.png", "data/dataset/spiqa/images/1809.00530/8-Figure3-1.png", "data/dataset/spiqa/images/1809.00530/9-Table2-1.png", "data/dataset/spiqa/images/1809.00530/11-Table3-1.png", "data/dataset/spiqa/images/1809.00530/12-Table4-1.png", "data/dataset/spiqa/images/1809.00530/13-Table5-1.png", "data/dataset/spiqa/images/1809.00530/14-Table6-1.png", "data/dataset/spiqa/images/1809.00530/15-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many labels do the datasets have?", "reference_answer": "719313", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e2e36675-0609-5075-8ed0-2b0e536bc5d4", "question": "Why it is sufficient to predict a binary mask without concern for the categories once the instance has been classified as a whole ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d1c1e345-b84d-5866-8475-acfaa66dadf9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/1-Figure1-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/2-Figure2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/4-Figure3-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Figure4-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/5-Table1-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Figure5-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/6-Table2-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/7-Table3-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Figure6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table4-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table5-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/8-Table6-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/9-Figure7-1.png", "data/dataset/spiqa/images/1a0912bb76777469295bb2c059faee907e7f3258/9-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why it is sufficient to predict a binary mask without concern for the categories once the instance has been classified as a whole ?", "reference_answer": "it is sufficient to predict a binary mask without concern for the categories once the instance has been classified as a whole because Mask R-CNN decouples mask and class prediction: as the existing box branch predicts the class label,a mask is generated  for each class without competition among classes (by a per-pixel sigmoid and a binary loss)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "476f3a61-bf8c-561d-af4b-15a6000639ca", "question": "How does BR-CSGAN compare to MRT in terms of translation performance and what is the likely reason for this difference?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7e050ffe-a1b2-5ec1-a6cd-9641ced929b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table3-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table1-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does BR-CSGAN compare to MRT in terms of translation performance and what is the likely reason for this difference?", "reference_answer": "BR-CSGAN consistently outperforms MRT on both Chinese-English and English-German translation tasks, achieving higher BLEU scores.\n\nWhile both methods optimize similar objectives, BR-CSGAN uses a reinforcement learning procedure with a dynamic discriminator to maximize rewards for the generator. This dynamic feedback seems to be more effective than the static objective and random sampling approach used by MRT, leading to better translation performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "03633fb7-8989-58e2-ba17-e009d5d31ae9", "question": "What is the difference between five-fold cross validation and leave-one-patient out?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the difference between five-fold cross validation and leave-one-patient out?", "reference_answer": "LOO performs better than five-fold cross validation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "feda9c3d-236b-5fc1-9c05-f151a38f218b", "question": "What is the effect of pre-training with the ordering task on the ROUGE-L score for extractive summarization?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["510d6fc0-d3e0-5dc1-8e0d-4d470f964287"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table4-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table3-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Figure2-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table5-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table1-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of pre-training with the ordering task on the ROUGE-L score for extractive summarization?", "reference_answer": "Pre-training with the ordering task increases the ROUGE-L score for extractive summarization."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5b6a3f4b-4f46-50f0-89c9-08508cb0be1b", "question": "Which of the two speech recognition models works better overall on CN-Celeb?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["08b4480d-3698-5a9a-9d0a-9fe1d6331bc8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.01799/4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.01799/2-Table2-1.png", "data/dataset/spiqa/images/1911.01799/2-Table1-1.png", "data/dataset/spiqa/images/1911.01799/2-Table3-1.png", "data/dataset/spiqa/images/1911.01799/4-Table4-1.png", "data/dataset/spiqa/images/1911.01799/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which of the two speech recognition models works better overall on CN-Celeb?", "reference_answer": "x-vector", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7efa9472-31bc-50ed-b1cc-a6380649ace6", "question": "What are the different approaches that have been used in face recognition technology over the years?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the different approaches that have been used in face recognition technology over the years?", "reference_answer": "Starting from the 1990s to the 2000s, holistic approaches were the most prominent direction in face recognition, Later on, local-feature-based face recognition was introduced. In the 2010s, shallow learning-based-local-descriptors were used. In 2014, the DeepFace, a deep learning-based model, was invented. And ever since, the state-of-the-art techniques were from deep learning-based approaches."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f833ad85-2d8a-5d6f-a8f7-1e954fc23bd0", "question": "What are the three different network architectures used in the comparison study?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bd1cf1c1-2268-50fb-a8af-8321d7a864ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three different network architectures used in the comparison study?", "reference_answer": "Feedforward-MSE, LSTM-MSE, and Feedforward-MDN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4666a9f7-3c4c-5af3-b287-73597e139bd6", "question": "by how much did nus outperform abus?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["44d8a08f-db6e-5b1f-bbbd-121efc6ea86a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06966/8-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06966/3-Figure1-1.png", "data/dataset/spiqa/images/1805.06966/5-Table1-1.png", "data/dataset/spiqa/images/1805.06966/6-Figure2-1.png", "data/dataset/spiqa/images/1805.06966/8-Table2-1.png", "data/dataset/spiqa/images/1805.06966/8-Table4-1.png", "data/dataset/spiqa/images/1805.06966/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "by how much did nus outperform abus?", "reference_answer": "Average success rate is higher by 2.6 percent points.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b3090923-05b2-512a-9ff6-c4c8afaadc3f", "question": "What is the role of the frame discriminator in the proposed method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the frame discriminator in the proposed method?", "reference_answer": "The frame discriminator is used to detect whether the generated frame and audio are matched or not."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "daa3bdbd-46b0-5255-99c1-8c566ce4ad7e", "question": "What is the relationship between the residuals prior to thresholding and the Boolean map?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e91f7cea-06b5-5326-88d0-de2c234edf4d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table1-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table5-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table6-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the residuals prior to thresholding and the Boolean map?", "reference_answer": "The Boolean map is obtained by thresholding the residuals prior to thresholding."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1be57bd4-775e-5681-a74a-7218888b2177", "question": "Can using more epochs while training may increase the validation accuracy ? if no why ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Can using more epochs while training may increase the validation accuracy ? if no why ?", "reference_answer": "Optimal hyperparameter is used. Hence for epoch it is the optimal value. More epochs will not give us better accuracy."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0c08c131-97f5-56ee-afd1-00d16ef2f5b8", "question": "Was the performance difference between Self-Instruct training and SuperNI training significant?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f992c4ad-ce9f-584d-b09e-80bcdf9589b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/1-Figure1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/14-Figure8-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table5-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/16-Table6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/19-Figure9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/2-Figure2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/22-Table10-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/23-Table11-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/4-Table1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Table2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/7-Figure6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Was the performance difference between Self-Instruct training and SuperNI training significant?", "reference_answer": "While it does appear as though there is a measurable performance improvement from SuperNI to Self-Instruct, quantifying the impact and magnitude of that improvement is not straightforward. Evaluations with ROGUE-L scores find that the absolute difference between both these methods is not very high, though additional information and context may be needed to judge the meaning of the absolute difference between these numbers. The authors do claim that they outperform T0 or SuperNI by a large margin, which is strong evidence to suggest that the difference was indeed significant, but such claims must be taken with some grains of salt since authors are usually incentivized to show their models are the best."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d27d53f9-5a6f-51c4-aff9-aa4723edd0fa", "question": "What are the models that yielded the least competitive detection accuracy results on the Thoracoabdominal Lymph Node Detection?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the models that yielded the least competitive detection accuracy results on the Thoracoabdominal Lymph Node Detection?", "reference_answer": "CifarNet, AlexNet-ImNet and GoogLeNet-RI-H were the models that had the worst results."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e9961f48-1c0b-58e2-9f03-da6a0e8f5a41", "question": "How do the reconstructed faces in the \"Mean Reconstruction\" differ from those in the \"Sampled Reconstruction\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the reconstructed faces in the \"Mean Reconstruction\" differ from those in the \"Sampled Reconstruction\"?", "reference_answer": "The reconstructed faces in the \"Mean Reconstruction\" are smoother and less detailed than those in the \"Sampled Reconstruction\". This is because the mean reconstruction is based on the average of all the possible reconstructions, while the sampled reconstruction is based on a single sample from the distribution."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8232f416-a93b-5bc1-a61e-8229829ed16d", "question": "In which setting they achieve the state of the art?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0f9749b4-7375-5acb-b964-6f90cbc06f89"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.06492/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.06492/1-Figure1-1.png", "data/dataset/spiqa/images/1703.06492/2-Figure2-1.png", "data/dataset/spiqa/images/1703.06492/5-Table2-1.png", "data/dataset/spiqa/images/1703.06492/5-Table3-1.png", "data/dataset/spiqa/images/1703.06492/5-Table1-1.png", "data/dataset/spiqa/images/1703.06492/6-Table4-1.png", "data/dataset/spiqa/images/1703.06492/6-Table5-1.png", "data/dataset/spiqa/images/1703.06492/7-Table6-1.png", "data/dataset/spiqa/images/1703.06492/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "In which setting they achieve the state of the art?", "reference_answer": "in open-ended task esp. for counting-type questions ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "aee7d191-36a4-500a-a78f-6a0313ede48e", "question": "How does the average metadata required per node for the Op-based BP+RR approach change as the number of nodes in the network increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the average metadata required per node for the Op-based BP+RR approach change as the number of nodes in the network increases?", "reference_answer": "The average metadata required per node for the Op-based BP+RR approach increases as the number of nodes in the network increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "96946438-5780-56b7-9c98-b2afa5f8f1d3", "question": "Did they collected the two datasets?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["ab22ee71-c77a-5bb5-aae0-5d6a340bab3c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03599/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03599/3-Figure1-1.png", "data/dataset/spiqa/images/1611.03599/4-Figure2-1.png", "data/dataset/spiqa/images/1611.03599/5-Table1-1.png", "data/dataset/spiqa/images/1611.03599/5-Table2-1.png", "data/dataset/spiqa/images/1611.03599/7-Table3-1.png", "data/dataset/spiqa/images/1611.03599/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did they collected the two datasets?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4eb42af1-82d3-5ac2-9724-b8644c7788d7", "question": "What is the relationship between the number of Monte Carlo samples (N) and the translation performance of the BR-CSGAN model? Why is there a trade-off when choosing the value of N?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7e050ffe-a1b2-5ec1-a6cd-9641ced929b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table3-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table1-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the number of Monte Carlo samples (N) and the translation performance of the BR-CSGAN model? Why is there a trade-off when choosing the value of N?", "reference_answer": "The table and passage show that the translation performance of the BR-CSGAN model generally improves as the number of Monte Carlo samples (N) increases. However, this improvement plateaus after N reaches a certain point (around 20 in this case).\n\nThere is a trade-off when choosing the value of N because increasing N also increases the computational complexity and training time. While a higher N leads to more accurate reward estimations and better performance, it also requires more computational resources and longer training times. Therefore, choosing the optimal N involves balancing the desired performance with the available computational resources and time constraints."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8eb952bd-a1b0-57b4-b2ca-62580b908805", "question": "What is the effect of adding Gaussian noise to the images on the measured sparsity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of adding Gaussian noise to the images on the measured sparsity?", "reference_answer": "Adding Gaussian noise to the images increases the measured sparsity."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ee7dcf97-285a-59c8-90d1-51a0074dc6a7", "question": "What stylistic features are used to detect drunk texts?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3bb937a0-4a80-51d3-84fd-f9e14eb336f7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1610.00879/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1610.00879/2-Figure1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table2-1.png", "data/dataset/spiqa/images/1610.00879/4-Table4-1.png", "data/dataset/spiqa/images/1610.00879/4-Table3-1.png", "data/dataset/spiqa/images/1610.00879/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What stylistic features are used to detect drunk texts?", "reference_answer": "LDA unigrams (Presence/Count), POS Ratio, #Named Entity Mentions, #Discourse Connectors,  Spelling errors, Repeated characters, Capitalisation, Length,  Emoticon (Presence/Count ) \n and Sentiment Ratio", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "95e028d7-9e2c-5d77-a6e2-3b6cae1d2be0", "question": "What is the learning rate for the generator in the DsOnly model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the learning rate for the generator in the DsOnly model?", "reference_answer": "5.00E-05"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2655d3cc-44a4-5707-a180-084d7abef70e", "question": "What are the different stages of HUMBI body and cloth reconstruction?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the different stages of HUMBI body and cloth reconstruction?", "reference_answer": "The different stages of HUMBI body and cloth reconstruction are: \n1. Input image of the person (Ibody)\n2. Keypoint estimation (Kbody)\n3. Occupancy map generation (Obody)\n4. Body model fitting (Mbody)\n5. Cloth model fitting (Mcloth)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d3f32b4f-e8f8-567f-9886-44f999a0d92d", "question": "Which model performed the best on the AddOneSent dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d32bd564-0b48-5101-817c-090485d59a03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table1-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed the best on the AddOneSent dataset?", "reference_answer": "KAR"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7795a952-de5f-5305-bffb-4323eed71eea", "question": "What is the latest paper covered by this survey?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["254c67d2-be91-57ed-9865-81f6c1b07db1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.08949/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.08949/4-Table1-1.png", "data/dataset/spiqa/images/1905.08949/7-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the latest paper covered by this survey?", "reference_answer": "Kim et al. (2019)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c89a3250-7f61-5332-890e-21b29db3e846", "question": "Which GAN model is able to generate the most realistic blinking motions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which GAN model is able to generate the most realistic blinking motions?", "reference_answer": "TecoGAN"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "987fc56f-be35-54de-ae74-f5f007bebce5", "question": "Why did the author add one more direction in attention flow?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9e8243e5-5426-52eb-9836-d7c4c091f0a0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/12-Table4-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/13-Table5-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/2-Figure1-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/6-Table1-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/7-Figure2-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/7-Table2-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/8-Figure3-1.png", "data/dataset/spiqa/images/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4/9-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why did the author add one more direction in attention flow?", "reference_answer": "In order to obtain a query-aware context representation, author used bi-directional attention flow."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c740cb95-d533-5046-a951-3c66cbe3f0fd", "question": "What can you say about the relationship between the complexity of a cake shape and the minimum number of blanks required for a complete partition into smaller pieces?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f51e9f68-1547-5a42-8e74-fbfbfcb7f509"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure5-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure3-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure4-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Table1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What can you say about the relationship between the complexity of a cake shape and the minimum number of blanks required for a complete partition into smaller pieces?", "reference_answer": "The complexity of the cake shape generally leads to a higher minimum number of blanks required for a complete partition."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5562b4c0-6f82-5d80-af8a-6f82e095b483", "question": "What are their results on both datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["db84a6ac-742e-5550-9c68-84c31177f699"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.05236/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.05236/2-Table1-1.png", "data/dataset/spiqa/images/1707.05236/4-Table2-1.png", "data/dataset/spiqa/images/1707.05236/4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are their results on both datasets?", "reference_answer": "Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b5b890bd-87fd-5534-987f-448c4b2f3f99", "question": "Which model performed the best on the SICK dataset according to the MSE metric?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["510d6fc0-d3e0-5dc1-8e0d-4d470f964287"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table4-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table3-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Figure2-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table5-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table1-1.png", "data/dataset/spiqa/images/1611.02654v2/1611.02654v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed the best on the SICK dataset according to the MSE metric?", "reference_answer": "The supervised model performed the best on the SICK dataset according to the MSE metric."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b5566076-982c-5a37-992b-82f6e6256e14", "question": "what models did they compare to?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e62bdbe5-1edf-5ed5-bb8b-874354645d9f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.05907/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.05907/2-Figure1-1.png", "data/dataset/spiqa/images/1704.05907/3-Table1-1.png", "data/dataset/spiqa/images/1704.05907/3-Figure2-1.png", "data/dataset/spiqa/images/1704.05907/4-Table3-1.png", "data/dataset/spiqa/images/1704.05907/4-Figure3-1.png", "data/dataset/spiqa/images/1704.05907/4-Table2-1.png", "data/dataset/spiqa/images/1704.05907/5-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what models did they compare to?", "reference_answer": "High-order CNN, Tree-LSTM, DRNN, DCNN, CNN-MC, NBoW and SVM ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7be4ad7c-090a-5f28-b599-0f751841e7f1", "question": "What is the difference between the sequential and recurrent generation schemes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["019cfad5-6d7d-537a-88b5-374e2c85546a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure3-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure1-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure2-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure6-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure4-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure5-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the sequential and recurrent generation schemes?", "reference_answer": "The sequential generation scheme generates each frame of the video independently, while the recurrent generation scheme uses the previous frame to generate the next frame. This can be seen in the optical flow images, which show the motion of pixels between frames. The recurrent scheme has a smoother flow of motion, while the sequential scheme has more abrupt changes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "16358ef9-a800-5372-8c75-3330e35a1bdf", "question": "Based on Table 1 and the passage, why does TCP perform poorly on IEEE 802.15.4 networks compared to other network types listed? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on Table 1 and the passage, why does TCP perform poorly on IEEE 802.15.4 networks compared to other network types listed? ", "reference_answer": "TCP performs poorly on IEEE 802.15.4 networks because the Maximum Transmission Unit (MTU) for these networks is significantly smaller than other network types. This small MTU size results in a high percentage of overhead due to the TCP/IP headers, exceeding 50%. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7218a1f7-dbe7-575a-b860-eca5e0387fbe", "question": "What is the performance of classifiers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["232ba8ef-5668-5815-80d6-652fd0cb9475"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.02070/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.02070/1-Figure1-1.png", "data/dataset/spiqa/images/2002.02070/2-Table1-1.png", "data/dataset/spiqa/images/2002.02070/2-Figure2-1.png", "data/dataset/spiqa/images/2002.02070/3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the performance of classifiers?", "reference_answer": "Using F1 Micro measure, the KNN classifier perform 0.6762, the RF 0.6687, SVM 0.6712 and MLP 0.6778.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b8001262-550f-5c06-863f-378c17544eee", "question": "Based on Table 1, which category of objects has the largest total number of annotations in the BDD100K MOT dataset, considering both bounding boxes and instance tracks? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on Table 1, which category of objects has the largest total number of annotations in the BDD100K MOT dataset, considering both bounding boxes and instance tracks? ", "reference_answer": "Cars have the largest total number of annotations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4c3b70a7-5d81-5b4f-b5ad-bad89d29a3b0", "question": "What baseline did they compare Entity-GCN to?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["df4de88d-e624-5e8a-ac1c-1f42eae3e5b9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.09920/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.09920/1-Figure1-1.png", "data/dataset/spiqa/images/1808.09920/3-Figure2-1.png", "data/dataset/spiqa/images/1808.09920/5-Table1-1.png", "data/dataset/spiqa/images/1808.09920/6-Table2-1.png", "data/dataset/spiqa/images/1808.09920/7-Table3-1.png", "data/dataset/spiqa/images/1808.09920/8-Table4-1.png", "data/dataset/spiqa/images/1808.09920/11-Table5-1.png", "data/dataset/spiqa/images/1808.09920/12-Table6-1.png", "data/dataset/spiqa/images/1808.09920/13-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What baseline did they compare Entity-GCN to?", "reference_answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "66c4c490-002d-55fd-96f4-e6b64f96fa82", "question": "How much performance improvements they achieve on SQuAD?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["96410824-320f-5082-825a-61419ae84e77"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.03556/6-Table1-1.png", "data/dataset/spiqa/images/1712.03556/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.03556/2-Figure1-1.png", "data/dataset/spiqa/images/1712.03556/3-Figure2-1.png", "data/dataset/spiqa/images/1712.03556/6-Table1-1.png", "data/dataset/spiqa/images/1712.03556/6-Table2-1.png", "data/dataset/spiqa/images/1712.03556/7-Table3-1.png", "data/dataset/spiqa/images/1712.03556/7-Figure3-1.png", "data/dataset/spiqa/images/1712.03556/7-Table4-1.png", "data/dataset/spiqa/images/1712.03556/8-Figure5-1.png", "data/dataset/spiqa/images/1712.03556/8-Table5-1.png", "data/dataset/spiqa/images/1712.03556/8-Table6-1.png", "data/dataset/spiqa/images/1712.03556/8-Figure4-1.png", "data/dataset/spiqa/images/1712.03556/9-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much performance improvements they achieve on SQuAD?", "reference_answer": "Compared to baselines SAN (Table 1) shows  improvement of 1.096% on EM and 0.689% F1. Compared to other published SQuAD results (Table 2) SAN is ranked second. ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8959c1e3-5551-5a9c-857e-688fb502d622", "question": "How do they encourage understanding of literature as part of their objective function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["012644c8-93af-5fbc-b79f-a9b6cb486d48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.09673/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.09673/2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they encourage understanding of literature as part of their objective function?", "reference_answer": "They group the existing works in terms of the objective function they optimize - within-tweet relationships, inter-tweet relationships, autoencoder, and weak supervision.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "518217ad-f704-5456-9b80-09c6442187c3", "question": "Which method achieved the highest average V-measure (VM) across all languages, and how much higher was its average compared to the Baum-Welch method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d2648a6-db41-5a23-9cb0-92c59be4fbc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table1-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table2-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table4-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table3-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieved the highest average V-measure (VM) across all languages, and how much higher was its average compared to the Baum-Welch method?", "reference_answer": "The Variational $\\wh{J}^{\\mathrm{var}}$ method achieved the highest average VM score (50.4). Its average score is 39.6 points higher than the Baum-Welch method, which achieved an average VM score of 10.8."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "63280e8c-38bf-5bac-a39a-a2767f78e2b0", "question": "How does the average precision of TCM(256*memory) compare to the other two algorithms in the email-EuAll dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the average precision of TCM(256*memory) compare to the other two algorithms in the email-EuAll dataset?", "reference_answer": "The average precision of TCM(256*memory) is lower than the other two algorithms in the email-EuAll dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cc852a78-5f25-5d12-837a-a6078e1fccfd", "question": "For a fixed value of $b$, how does the maximum achievable KL divergence and the corresponding minimum achievable p-value change with increasing values of $a$?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["99904617-6a5d-55cb-be9e-259c5fa25b88"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure2-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure5-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure3-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure4-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "For a fixed value of $b$, how does the maximum achievable KL divergence and the corresponding minimum achievable p-value change with increasing values of $a$?", "reference_answer": "The maximum achievable KL divergence initially increases with increasing values of $a$ until it reaches a peak. Then, it decreases with increasing values of $a$. The minimum achievable p-value initially decreases with increasing values of $a$ until it reaches a minimum. Then, it increases with increasing values of $a$."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "efed9ad0-65a3-5c1e-ac85-8a3d48f30297", "question": "What is best performing model among author's submissions, what performance it had?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is best performing model among author's submissions, what performance it had?", "reference_answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "cf14d64a-6c3f-5ced-9b6a-aeb2b4774a14", "question": "How does the CPU overhead of classic delta-based compare to delta-based BP+RR as the Zipf coefficient increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the CPU overhead of classic delta-based compare to delta-based BP+RR as the Zipf coefficient increases?", "reference_answer": "The CPU overhead of classic delta-based is consistently higher than that of delta-based BP+RR as the Zipf coefficient increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7f6bf745-fb6b-51ff-983a-ef478b4e176b", "question": "Why do the authors claim that human feedback may be less important when their experiments showed that InstructGPT, which had human-generated data, outperformed their model without human-generated data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f992c4ad-ce9f-584d-b09e-80bcdf9589b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/1-Figure1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/14-Figure8-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table5-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/16-Table6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/19-Figure9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/2-Figure2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/22-Table10-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/23-Table11-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/4-Table1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Table2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/7-Figure6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why do the authors claim that human feedback may be less important when their experiments showed that InstructGPT, which had human-generated data, outperformed their model without human-generated data?", "reference_answer": "The authors claim that human feedback might not be essential since their model is able to almost meet the performance of InstructGPT despite not having access to private human-generated training data or manual annotations. They claim that their model's success, of almost reaching InstructGPT performance with only a 5% gap is a strong indication that human data, while useful is not necessarily essential for teaching models how to follow instructions. Additionally, they point out that their work is merely a beginning step in research in this field - while numerous studies have successfully used human annotations to improve performance, studies that attempt to remove the human requirement have not been as explored. Also, the authors do acknowledge that the truth is somewhere in between the two extremes of (1) human instructional data is essential, or (2) such data is largely optional, and similar results can be achieved without it."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0568a9ef-6b66-5cb8-9a6b-eb18188f6fdc", "question": "what are the evaluation metrics?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3b7ff31e-201b-5005-92a5-e7f03a4a5cc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.09123/15-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.09123/5-Table1-1.png", "data/dataset/spiqa/images/1701.09123/6-Table2-1.png", "data/dataset/spiqa/images/1701.09123/9-Table3-1.png", "data/dataset/spiqa/images/1701.09123/11-Figure1-1.png", "data/dataset/spiqa/images/1701.09123/13-Table4-1.png", "data/dataset/spiqa/images/1701.09123/15-Table5-1.png", "data/dataset/spiqa/images/1701.09123/15-Table6-1.png", "data/dataset/spiqa/images/1701.09123/16-Table7-1.png", "data/dataset/spiqa/images/1701.09123/16-Table8-1.png", "data/dataset/spiqa/images/1701.09123/16-Table9-1.png", "data/dataset/spiqa/images/1701.09123/17-Table10-1.png", "data/dataset/spiqa/images/1701.09123/17-Table11-1.png", "data/dataset/spiqa/images/1701.09123/18-Table12-1.png", "data/dataset/spiqa/images/1701.09123/18-Table13-1.png", "data/dataset/spiqa/images/1701.09123/19-Table14-1.png", "data/dataset/spiqa/images/1701.09123/19-Table15-1.png", "data/dataset/spiqa/images/1701.09123/20-Table16-1.png", "data/dataset/spiqa/images/1701.09123/21-Table17-1.png", "data/dataset/spiqa/images/1701.09123/22-Table18-1.png", "data/dataset/spiqa/images/1701.09123/22-Table19-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what are the evaluation metrics?", "reference_answer": "Precision, Recall, F1", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d6583a9f-e47f-57f3-9a8a-4fa82dd55ba1", "question": "What are the results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the results?", "reference_answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "75b7371a-0699-5368-9bf7-344a827a099e", "question": "Which hyperparameters were varied in the experiments on the four tasks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67d10fae-f271-5268-ae3e-124f254dab2d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.01265/4-Table3-1.png", "data/dataset/spiqa/images/1705.01265/3-Table2-1.png", "data/dataset/spiqa/images/1705.01265/5-Table5-1.png", "data/dataset/spiqa/images/1705.01265/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.01265/3-Table1-1.png", "data/dataset/spiqa/images/1705.01265/3-Table2-1.png", "data/dataset/spiqa/images/1705.01265/4-Table3-1.png", "data/dataset/spiqa/images/1705.01265/5-Table4-1.png", "data/dataset/spiqa/images/1705.01265/5-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which hyperparameters were varied in the experiments on the four tasks?", "reference_answer": "number of clusters, seed value in clustering, selection of word vectors, window size and dimension of embedding", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "49d7a34e-28c9-5add-9c34-19eecfcf5934", "question": "Why it is needed to have a two channel volumetric segmentation in the output?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why it is needed to have a two channel volumetric segmentation in the output?", "reference_answer": "Two channel volumetric segmentation is used at the output to perform binary classification of foreground and background classes using soft-max. Each volume represent the logits for each class at each pixel location."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2fe599f2-6abc-58b2-aff8-28f480a16bfa", "question": "By how much is precission increased?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["210dcf52-2bde-59ff-94b1-556cc201b623"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.02776/9-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.02776/6-Figure1-1.png", "data/dataset/spiqa/images/1909.02776/8-Table1-1.png", "data/dataset/spiqa/images/1909.02776/9-Figure2-1.png", "data/dataset/spiqa/images/1909.02776/9-Figure3-1.png", "data/dataset/spiqa/images/1909.02776/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much is precission increased?", "reference_answer": "ROUGE-1 increases by 0.05, ROUGE-2 by 0.06 and ROUGE-L by 0.09", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "46ec0c2c-ab53-540e-9955-d25c5638f389", "question": "What is the distance from equitability for the allocation that can be obtained by cutting at $x$ with the player order $(1,2)$?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4713fdd0-d414-5267-9d4e-3c4e85657fe4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure5-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure6-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure4-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table2-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure2-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Table1-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure3-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure8-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure1-1.png", "data/dataset/spiqa/images/1705.02946v3/1705.02946v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the distance from equitability for the allocation that can be obtained by cutting at $x$ with the player order $(1,2)$?", "reference_answer": "The distance from equitability is $b-a$."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4fbf9acb-015b-5025-8ab7-34905849a888", "question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f66ecb48-d5bf-558e-800b-964715930502"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.01081/7-Figure3-1.png", "data/dataset/spiqa/images/1906.01081/8-Table4-1.png", "data/dataset/spiqa/images/1906.01081/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.01081/2-Figure1-1.png", "data/dataset/spiqa/images/1906.01081/5-Table1-1.png", "data/dataset/spiqa/images/1906.01081/6-Figure2-1.png", "data/dataset/spiqa/images/1906.01081/6-Table2-1.png", "data/dataset/spiqa/images/1906.01081/7-Figure3-1.png", "data/dataset/spiqa/images/1906.01081/7-Figure4-1.png", "data/dataset/spiqa/images/1906.01081/8-Table3-1.png", "data/dataset/spiqa/images/1906.01081/8-Table4-1.png", "data/dataset/spiqa/images/1906.01081/9-Figure5-1.png", "data/dataset/spiqa/images/1906.01081/11-Figure6-1.png", "data/dataset/spiqa/images/1906.01081/11-Table5-1.png", "data/dataset/spiqa/images/1906.01081/12-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "reference_answer": "Best proposed metric has average correlation with human judgement of 0.913 and 0.846 compared to best compared metrics result of 0.758 and 0.829 on WikiBio and WebNLG challenge.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1b1f50b7-20cb-5c54-aa86-11f95a0b5384", "question": "What is the difference between the attention weights in the two-level attention model and the one-level attention model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the attention weights in the two-level attention model and the one-level attention model?", "reference_answer": " The two-level attention model has higher attention weights on the relevant information in the memory, while the one-level attention model has more uniform attention weights."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ec189145-0294-5941-95f5-0bf85b302944", "question": "What is the role of the auxiliary discriminator $D_{X_{\\textit{aux}}}$ in the Conditional CycleGAN for identity-guided face generation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d16eb665-e39f-52cd-a116-0631aeba6a8a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure8-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Table1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure15-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure14-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure13-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure12-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure11-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure9-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure10-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09966v2/1705.09966v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the auxiliary discriminator $D_{X_{\\textit{aux}}}$ in the Conditional CycleGAN for identity-guided face generation?", "reference_answer": " The auxiliary discriminator $D_{X_{\\textit{aux}}}$ helps to enforce the identity constraint in the generated image. It takes the generated image or the ground truth image as input and outputs a feature embedding. This embedding is then used to compute the identity loss, which encourages the generated image to have the same identity as the input image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d59c1506-867d-5ee1-982d-2dba23334547", "question": "Which method produces higher contrast saliency maps, FLoss or Log-FLoss?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b254e747-baa1-520a-aea9-eec21bbbd95e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure3-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure5-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table4-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure6-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure7-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table1-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Table2-1.png", "data/dataset/spiqa/images/1805.07567v2/1805.07567v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method produces higher contrast saliency maps, FLoss or Log-FLoss?", "reference_answer": "FLoss"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cfa9deda-f1eb-599a-b5f8-f05f3ba0e256", "question": "What is the size of the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["162865d9-56e7-532d-82c5-8a951c632c59"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.02265/4-TableI-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.02265/2-Figure1-1.png", "data/dataset/spiqa/images/1909.02265/3-Figure2-1.png", "data/dataset/spiqa/images/1909.02265/4-TableI-1.png", "data/dataset/spiqa/images/1909.02265/5-TableII-1.png", "data/dataset/spiqa/images/1909.02265/5-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the size of the dataset?", "reference_answer": "3029", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ca94eb1f-9e99-56ad-9fee-0c544e88ba77", "question": "Based on the table, which model achieved the best performance on the KITTI 2015 test set in terms of F1-all score, and how does its performance compare to Devon (ft) on the same dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the table, which model achieved the best performance on the KITTI 2015 test set in terms of F1-all score, and how does its performance compare to Devon (ft) on the same dataset?", "reference_answer": "PWC-Net (ft) achieved the best performance on the KITTI 2015 test set with an F1-all score of 9.16%. This is significantly better than Devon (ft), which achieved an F1-all score of 14.31% on the same dataset. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e3a7f1d3-1059-557f-be70-73a35496b74a", "question": "Do they focus on Reading Comprehension or multiple choice question answering?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c35eb6e8-9bca-5609-8a49-d0bb2da6b470"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.13337/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.13337/1-Figure1-1.png", "data/dataset/spiqa/images/1912.13337/3-Table1-1.png", "data/dataset/spiqa/images/1912.13337/4-Figure2-1.png", "data/dataset/spiqa/images/1912.13337/5-Table2-1.png", "data/dataset/spiqa/images/1912.13337/5-Table3-1.png", "data/dataset/spiqa/images/1912.13337/6-Table4-1.png", "data/dataset/spiqa/images/1912.13337/7-Table5-1.png", "data/dataset/spiqa/images/1912.13337/9-Table6-1.png", "data/dataset/spiqa/images/1912.13337/10-Figure3-1.png", "data/dataset/spiqa/images/1912.13337/10-Figure4-1.png", "data/dataset/spiqa/images/1912.13337/11-Table7-1.png", "data/dataset/spiqa/images/1912.13337/11-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they focus on Reading Comprehension or multiple choice question answering?", "reference_answer": "MULTIPLE CHOICE QUESTION ANSWERING", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9fea1253-a3c5-5d71-9e18-5d633ddc0327", "question": "Which objective function resulted in a higher ratio of f2(x∗) > 0 for the MNIST dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9a9562fc-9263-50fb-9345-d05e45925e53"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure2-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure5-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure3-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure1-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure4-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table6-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Figure7-1.png", "data/dataset/spiqa/images/1706.00633v4/1706.00633v4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which objective function resulted in a higher ratio of f2(x∗) > 0 for the MNIST dataset?", "reference_answer": "RCE"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f0bfbd73-035d-5488-a223-39d7e91b8fbf", "question": "Does formal training in reasoning, logic, or argumentation seem to have a significant effect on argument reasoning comprehension accuracy for people with graduate degrees?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0423e038-405f-5171-a89b-75e3079e5aa6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Does formal training in reasoning, logic, or argumentation seem to have a significant effect on argument reasoning comprehension accuracy for people with graduate degrees?", "reference_answer": "No, it does not appear to have a significant effect."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "52023374-175a-5600-bcda-8acd6bd06e19", "question": "How do they obtain the new context represetation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b31e4f8d-6221-54a9-8e27-e5f8eb5d5588"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07333/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07333/3-Figure1-1.png", "data/dataset/spiqa/images/1605.07333/3-Figure2-1.png", "data/dataset/spiqa/images/1605.07333/4-Table1-1.png", "data/dataset/spiqa/images/1605.07333/5-Table2-1.png", "data/dataset/spiqa/images/1605.07333/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they obtain the new context represetation?", "reference_answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7e1ecbf8-4e6d-5386-b560-0cfa78792c1c", "question": "What is the difference between the hierarchical part dictionary learned with the bottom-up process and the holistic object model learned with the top-down process?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["be0ab42f-3812-52ff-8345-282868119291"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure4-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure5-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the hierarchical part dictionary learned with the bottom-up process and the holistic object model learned with the top-down process?", "reference_answer": "The hierarchical part dictionary learned with the bottom-up process is a set of parts that can be combined to create objects. The holistic object model learned with the top-down process is a single model that represents the entire object."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "81e287af-4a90-5026-9c40-4826792b1fd7", "question": "What does the outcome curve tell us about the relationship between selection rate and mean change in score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a7193e4-6411-5e3e-9b02-09ce82c0f1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What does the outcome curve tell us about the relationship between selection rate and mean change in score?", "reference_answer": "The outcome curve shows that the relationship between selection rate and mean change in score is complex and depends on the specific group being considered. For groups with high potential for gain, increasing the selection rate can lead to large increases in mean score. However, for groups with low potential for gain, increasing the selection rate can actually lead to decreases in mean score."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e28e9814-22b3-5801-bd24-086046ea6fda", "question": "What is the difference between the residual block and the merge-and-run block?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the residual block and the merge-and-run block?", "reference_answer": "The residual block assembles two residual branches sequentially, while the merge-and-run block assembles the same two residual branches in parallel."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "dc71945c-d86d-5d0b-aa74-6f2530a5a9ea", "question": "What is the purpose of the second-stage decoder $D_2$?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the second-stage decoder $D_2$?", "reference_answer": "The second-stage decoder $D_2$ takes soft edges $x_G$ as input and produces reconstructed frames."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b06a36f1-06f9-5e66-af9e-b6cdaa588b75", "question": "Why is relying on fragmentation effective for reducing header overhead?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why is relying on fragmentation effective for reducing header overhead?", "reference_answer": "Relying on fragmentation is effective because the TCP/IP headers are only included in the first fragment, not in subsequent fragments. This significantly reduces the overhead in later fragments."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f5cacd0d-8556-52ba-927d-f0f5b3b37a8b", "question": "What is the task that the AMT workers are being asked to do?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d2f53917-bc62-5131-9eb4-af4a7211b645"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure8-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure9-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table4-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure10-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure4-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure5-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table3-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table9-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure6-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure1-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table1-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure12-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure7-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table7-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table5-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table8-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table6-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Figure11-1.png", "data/dataset/spiqa/images/1901.00398v2/1901.00398v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the task that the AMT workers are being asked to do?", "reference_answer": "The AMT workers are being asked to decide whether each of twenty one paragraphs extracted from product reviews is real (written by a person) or fake (written by a computer algorithm)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b0d91d16-7927-5d7c-9a56-e2b32e9d10ce", "question": "What participating systems had better results than ones authors submitted?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What participating systems had better results than ones authors submitted?", "reference_answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4d94e087-7e2a-5c6b-a970-ee918e8b1efd", "question": "Do they jointly tackle multiple tagging problems?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["485379a3-2f01-5a4b-8b99-df4ffb5e00ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.01723/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.01723/2-Figure1-1.png", "data/dataset/spiqa/images/1706.01723/4-Table1-1.png", "data/dataset/spiqa/images/1706.01723/4-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they jointly tackle multiple tagging problems?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "72d23f64-0c77-5242-ace4-11e6599b8e15", "question": "How does the performance of SRU with 8 layers compare to the best reported results on the SUBJ dataset, and how does its training time compare to the other models in the \"Our setup\" section?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of SRU with 8 layers compare to the best reported results on the SUBJ dataset, and how does its training time compare to the other models in the \"Our setup\" section?", "reference_answer": "While SRU with 8 layers achieves high test accuracy within the \"Our setup\" section on the SUBJ dataset (93.7%), it falls slightly short of the best reported result of 95.5% achieved by Zhao et al. (2015). However, SRU's training time of 879 seconds for 100 epochs on the SST dataset is faster than the LSTM model (2409 seconds) but slower than the CNN model (417 seconds) and the QRNN models (345 and 371 seconds)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3820e276-797d-577e-9941-203b05f2a21f", "question": "How many examples do they have in the target domain?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["44ced075-9a39-5dc7-a8ba-8848a429b45f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.06897/6-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.06897/4-Table1-1.png", "data/dataset/spiqa/images/1612.06897/5-Table2-1.png", "data/dataset/spiqa/images/1612.06897/6-Figure1-1.png", "data/dataset/spiqa/images/1612.06897/6-Table3-1.png", "data/dataset/spiqa/images/1612.06897/7-Figure2-1.png", "data/dataset/spiqa/images/1612.06897/7-Table4-1.png", "data/dataset/spiqa/images/1612.06897/8-Table5-1.png", "data/dataset/spiqa/images/1612.06897/8-Table6-1.png", "data/dataset/spiqa/images/1612.06897/9-Figure3-1.png", "data/dataset/spiqa/images/1612.06897/9-Table7-1.png", "data/dataset/spiqa/images/1612.06897/10-Figure4-1.png", "data/dataset/spiqa/images/1612.06897/10-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many examples do they have in the target domain?", "reference_answer": "Around 388k examples, 194k from tst2013 (in-domain) and 194k from newstest2014 (out-of-domain)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e2c85df6-6fad-5ab2-81f8-69a5e89a24a7", "question": "How do they calculate a static embedding for each word?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ec4c774e-94db-5538-b588-a7a5eb319e9b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00512/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00512/5-Figure1-1.png", "data/dataset/spiqa/images/1909.00512/6-Figure2-1.png", "data/dataset/spiqa/images/1909.00512/7-Figure3-1.png", "data/dataset/spiqa/images/1909.00512/8-Figure4-1.png", "data/dataset/spiqa/images/1909.00512/8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they calculate a static embedding for each word?", "reference_answer": "They use the first principal component of a word's contextualized representation in a given layer as its static embedding.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0d904a89-62b5-59b3-81bd-8c4456853e20", "question": "What are the main loss functions that have been explored for improving deep FR methods and how have they evolved over time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the main loss functions that have been explored for improving deep FR methods and how have they evolved over time?", "reference_answer": "There are 3 categories of loss functions for FR: Euclidean-distance-based loss, angular/cosine-margin-based loss, and softmax loss variations. Initially, cross-entropy softmax loss was used, then some models tried using Euclidean-distance-based loss functions which started from contrastive loss and triplet loss. However, due to their instability, the center loss and its variants (range loss, center-invariant loss) were introduced. With a better understanding of loss functions for FR angular/cosine-margin-based loss functions were used. It began with a reformulation of a softmax loss called L-Softmax, later A-Softmax appeared which adopted the L-Softmax idea but tried normalizing the weights. Afterward, there were several improvements such as ArcFace, CosFace, and AMS which facilitated the convergence, while Fairloss and AdaptiveFace dealt with unbalanced data. Lastly, there are different variations of softmax that try to normalize the L2-norms (L2-softmax, Ring loss), the weights, the features, or both weights and features (CoCo loss and vMF mixture loss)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c3e0120b-d8b7-5e22-89a0-ba974cdff5e7", "question": "What is the difference between the outputs of the machine translation system (SMT) and the CCA inference?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the outputs of the machine translation system (SMT) and the CCA inference?", "reference_answer": "The SMT outputs are literal translations of the images, while the CCA outputs take into account the context of the images and generate more natural-sounding descriptions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "499ef86f-bfbf-55d3-98cd-f1909e2e1fe5", "question": "Does the algorithm improve on the state-of-the-art methods?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3dd529dd-1a7c-5ba1-a77d-0fcdb3724aa2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.07555/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.07555/2-Table1-1.png", "data/dataset/spiqa/images/1911.07555/4-Table2-1.png", "data/dataset/spiqa/images/1911.07555/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the algorithm improve on the state-of-the-art methods?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "90a45c95-55a5-561d-a5ec-2e2614c96923", "question": "How do the various social phenomena examined manifest in different types of communities?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["aae95653-9e11-5a60-bbf6-fdb383bf043c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09665/5-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09665/3-Figure1-1.png", "data/dataset/spiqa/images/1705.09665/4-Table1-1.png", "data/dataset/spiqa/images/1705.09665/5-Figure2-1.png", "data/dataset/spiqa/images/1705.09665/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do the various social phenomena examined manifest in different types of communities?", "reference_answer": "Dynamic communities have substantially higher rates of monthly user retention than more stable communities. More distinctive communities exhibit moderately higher monthly retention rates than more generic communities. There is also a strong positive relationship between a community's dynamicity and the average number of months that a user will stay in that community - a short-term trend observed for monthly retention translates into longer-term engagement and suggests that long-term user retention might be strongly driven by the extent to which a community continually provides novel content.\n", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e8eaa708-cef4-500d-b1b7-014d182012bf", "question": "What is the effect of enforcing syntactic constraints on the semantic role labeling output?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of enforcing syntactic constraints on the semantic role labeling output?", "reference_answer": "Enforcing syntactic constraints can correct the number of agreeing spans, and also change the semantic roles assigned to tokens."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e00dbda3-44a8-5b3c-af5f-ed7e464eafac", "question": "Which real-world datasets are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3c3110e0-bdfd-5e3f-97ba-8cff862e1ea9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.00667/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.00667/3-Figure1-1.png", "data/dataset/spiqa/images/1912.00667/4-Figure2-1.png", "data/dataset/spiqa/images/1912.00667/5-Table1-1.png", "data/dataset/spiqa/images/1912.00667/6-Table2-1.png", "data/dataset/spiqa/images/1912.00667/6-Figure3-1.png", "data/dataset/spiqa/images/1912.00667/7-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which real-world datasets are used?", "reference_answer": "Tweets related to CyberAttack and tweets related to PoliticianDeath", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "da26b27e-5129-5996-98e2-4a34a93cd006", "question": "What are the characteristics of the city dialect?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c16572e6-20d3-51c9-8ce9-46e538d854b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.06777/6-Figure7-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.06777/2-Figure1-1.png", "data/dataset/spiqa/images/1702.06777/3-Figure2-1.png", "data/dataset/spiqa/images/1702.06777/4-Figure3-1.png", "data/dataset/spiqa/images/1702.06777/5-Figure4-1.png", "data/dataset/spiqa/images/1702.06777/5-Figure5-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure6-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the characteristics of the city dialect?", "reference_answer": "Lexicon of the cities tend to use most forms of a particular concept", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8542bbc3-0a0b-525a-9708-d676e8a70c53", "question": "What is the purpose of the audio encoder in the proposed conditional recurrent adversarial video generation network structure?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["019cfad5-6d7d-537a-88b5-374e2c85546a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure3-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure1-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure2-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure6-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure4-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Figure5-1.png", "data/dataset/spiqa/images/1804.04786v3/1804.04786v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the audio encoder in the proposed conditional recurrent adversarial video generation network structure?", "reference_answer": "The audio encoder extracts audio features from the MFCC features of each audio segment."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d776241f-a9dd-57ba-b7cc-918fed736bfc", "question": "what was their character error rate?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52401b8c-9c2c-5db5-8107-cbfc6855f629"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07090/4-Table1-1.png", "data/dataset/spiqa/images/1703.07090/5-Figure1-1.png", "data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png", "data/dataset/spiqa/images/1703.07090/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what was their character error rate?", "reference_answer": "Their best model achieved a 2.49% Character Error Rate.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "21cd0e72-a87c-55b1-9c01-798ecc64af00", "question": "How do they enrich the positional embedding with length information", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5a50572f-39a1-5cc3-9a01-d9be6a8478df"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.10408/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.10408/2-Figure1-1.png", "data/dataset/spiqa/images/1910.10408/2-Figure2-1.png", "data/dataset/spiqa/images/1910.10408/4-Figure3-1.png", "data/dataset/spiqa/images/1910.10408/4-Table1-1.png", "data/dataset/spiqa/images/1910.10408/4-Table2-1.png", "data/dataset/spiqa/images/1910.10408/5-Table3-1.png", "data/dataset/spiqa/images/1910.10408/6-Table4-1.png", "data/dataset/spiqa/images/1910.10408/6-Table5-1.png", "data/dataset/spiqa/images/1910.10408/7-Table6-1.png", "data/dataset/spiqa/images/1910.10408/7-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they enrich the positional embedding with length information", "reference_answer": "They introduce new trigonometric encoding which besides information about position uses additional length information (abs or relative).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a50d432a-bd35-5ed9-a1b2-8c6591ef7190", "question": "How many different types of experiments are performed to test the proposed models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["fdbea5d0-0918-54e6-9a09-5197df9c8a79"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/8-Figure7-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/8-Figure7-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Figure11-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Table2-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Figure12-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table4-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/3-Figure1-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/3-Figure2-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure4-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/6-Figure5-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/7-Figure6-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/8-Figure7-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure10-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure8-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many different types of experiments are performed to test the proposed models?", "reference_answer": "5 different types of experiments are performed to test the proposed models. They are Generalization over time scales, Experiments on MNIST, Experiments on Natural Image Patches, Out-of-domain Inputs, and Visualizing Features."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "eed59efa-c794-57eb-9702-10b2c706de0e", "question": "Which model performs the best on the STS16 task with unsupervised training?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ceff18ab-0cba-5e6b-b40d-ed9534e6f9c1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table3-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table4-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table5-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table1-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best on the STS16 task with unsupervised training?", "reference_answer": "The Bijective model performs the best on the STS16 task with unsupervised training."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f0e6fd3b-ba5d-57bb-b60a-a89b30907996", "question": "What datasets are used to evaluate this approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ee3a23d4-fd3a-50ff-9cdd-b845dac79197"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.00563/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.00563/2-Figure1-1.png", "data/dataset/spiqa/images/1905.00563/4-Figure2-1.png", "data/dataset/spiqa/images/1905.00563/5-Table1-1.png", "data/dataset/spiqa/images/1905.00563/5-Table2-1.png", "data/dataset/spiqa/images/1905.00563/5-Figure3-1.png", "data/dataset/spiqa/images/1905.00563/6-Table3-1.png", "data/dataset/spiqa/images/1905.00563/7-Table4-1.png", "data/dataset/spiqa/images/1905.00563/7-Figure4-1.png", "data/dataset/spiqa/images/1905.00563/7-Table5-1.png", "data/dataset/spiqa/images/1905.00563/8-Table6-1.png", "data/dataset/spiqa/images/1905.00563/12-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What datasets are used to evaluate this approach?", "reference_answer": " Kinship and Nations knowledge graphs, YAGO3-10 and WN18KGs knowledge graphs ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a9bc7115-85b8-523c-9c6e-54234331495e", "question": "Does it have anything to do with the nature and complexity of data we are working with ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["78a5265f-bb46-5ae9-bdb0-f22423f3847f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/2-Figure1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/3-Figure2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Figure3-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/5-Table1-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/7-Figure4-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Figure5-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/8-Table2-1.png", "data/dataset/spiqa/images/50004c086ffd6a201a4b782281aaa930fbfe6ecf/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does it have anything to do with the nature and complexity of data we are working with ?", "reference_answer": "In general MRI 3D volume data is complex. Prostate anomaly segmentation also makes the data in consideration unique."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "44969c35-854b-5fc6-9e51-13c46991d4b4", "question": "Do they report results only on English?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["1515042d-e4a7-55b5-8560-6c0c843d1ccc"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.09535/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.09535/2-Table1-1.png", "data/dataset/spiqa/images/1904.09535/3-Figure1-1.png", "data/dataset/spiqa/images/1904.09535/4-Figure2-1.png", "data/dataset/spiqa/images/1904.09535/4-Table2-1.png", "data/dataset/spiqa/images/1904.09535/4-Table3-1.png", "data/dataset/spiqa/images/1904.09535/4-Figure3-1.png", "data/dataset/spiqa/images/1904.09535/5-Table4-1.png", "data/dataset/spiqa/images/1904.09535/5-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ad570472-bc10-5fbd-ae5b-5c7cb64aa611", "question": "What is the relationship between position and click-through rate (CTR)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f16a3bd9-b17e-5e49-a098-482dcced698c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure9-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure4-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table1-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure5-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure6-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table3-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure7-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Table2-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure8-1.png", "data/dataset/spiqa/images/1809.03149v2/1809.03149v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between position and click-through rate (CTR)?", "reference_answer": "The relationship between position and CTR is complex and non-linear. In general, CTR decreases as position increases, but there are also local peaks and valleys in the CTR curve. This suggests that there are other factors besides position that affect CTR."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "995b73c0-780d-566c-8cc1-d28168647330", "question": "By how much did they improve?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["447437fc-c974-5df6-b709-a8af1023407d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.03569/3-Figure1-1.png", "data/dataset/spiqa/images/1707.03569/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.03569/2-Table1-1.png", "data/dataset/spiqa/images/1707.03569/3-Figure1-1.png", "data/dataset/spiqa/images/1707.03569/3-Table2-1.png", "data/dataset/spiqa/images/1707.03569/5-Table3-1.png", "data/dataset/spiqa/images/1707.03569/5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much did they improve?", "reference_answer": "They decrease MAE in 0.34", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c5ece912-f56e-52bc-94c9-d2971177364d", "question": "Are the automatically constructed datasets subject to quality control?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["c35eb6e8-9bca-5609-8a49-d0bb2da6b470"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.13337/1-Figure1-1.png", "data/dataset/spiqa/images/1912.13337/5-Table3-1.png", "data/dataset/spiqa/images/1912.13337/3-Table1-1.png", "data/dataset/spiqa/images/1912.13337/4-Figure2-1.png", "data/dataset/spiqa/images/1912.13337/5-Table2-1.png", "data/dataset/spiqa/images/1912.13337/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.13337/1-Figure1-1.png", "data/dataset/spiqa/images/1912.13337/3-Table1-1.png", "data/dataset/spiqa/images/1912.13337/4-Figure2-1.png", "data/dataset/spiqa/images/1912.13337/5-Table2-1.png", "data/dataset/spiqa/images/1912.13337/5-Table3-1.png", "data/dataset/spiqa/images/1912.13337/6-Table4-1.png", "data/dataset/spiqa/images/1912.13337/7-Table5-1.png", "data/dataset/spiqa/images/1912.13337/9-Table6-1.png", "data/dataset/spiqa/images/1912.13337/10-Figure3-1.png", "data/dataset/spiqa/images/1912.13337/10-Figure4-1.png", "data/dataset/spiqa/images/1912.13337/11-Table7-1.png", "data/dataset/spiqa/images/1912.13337/11-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the automatically constructed datasets subject to quality control?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c10ee8e6-e545-5340-84df-cba46ca624f2", "question": "Do they evaluate grammaticality of generated text?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["21132ce4-5ef4-55e3-80f5-2475fd5f58de"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.09127/10-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.09127/6-Figure1-1.png", "data/dataset/spiqa/images/1712.09127/8-Figure2-1.png", "data/dataset/spiqa/images/1712.09127/10-Table1-1.png", "data/dataset/spiqa/images/1712.09127/11-Table3-1.png", "data/dataset/spiqa/images/1712.09127/11-Figure3-1.png", "data/dataset/spiqa/images/1712.09127/11-Table4-1.png", "data/dataset/spiqa/images/1712.09127/12-Table5-1.png", "data/dataset/spiqa/images/1712.09127/12-Table6-1.png", "data/dataset/spiqa/images/1712.09127/13-Table7-1.png", "data/dataset/spiqa/images/1712.09127/13-Figure4-1.png", "data/dataset/spiqa/images/1712.09127/14-Table8-1.png", "data/dataset/spiqa/images/1712.09127/14-Table9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they evaluate grammaticality of generated text?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b5854d52-6a6f-522d-8971-33410358a30c", "question": "Which model performs the best on COCOQA dataset when considering the combined accuracy of identifying irrelevant image-question pairs (IU) and irrelevant question-answer pairs (QU)? How does this compare to the performance of the model that only observes answers?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de95c70d-a18c-50b5-9de4-b2542ed0e2e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table11-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table9-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table10-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table7-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table5-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table1-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Table12-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure4-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure2-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure3-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure8-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure6-1.png", "data/dataset/spiqa/images/1704.07121v2/1704.07121v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best on COCOQA dataset when considering the combined accuracy of identifying irrelevant image-question pairs (IU) and irrelevant question-answer pairs (QU)? How does this compare to the performance of the model that only observes answers?", "reference_answer": "The MLP-IQA model performs the best when considering the combined accuracy of identifying irrelevant image-question and question-answer pairs, achieving an accuracy of 75.9%. This is significantly higher than the MLP-A model, which only observes answers and achieves a combined accuracy of 26.6%, close to random performance."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "71943f61-18cd-57ba-a2b2-5f284ae4c482", "question": "Is the model evaluated on the graphemes-to-phonemes task?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["090d4e53-9371-57ec-8b54-68cc79b1a6f9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.00139/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.00139/1-Figure1-1.png", "data/dataset/spiqa/images/2004.00139/3-Table1-1.png", "data/dataset/spiqa/images/2004.00139/3-Table2-1.png", "data/dataset/spiqa/images/2004.00139/5-Table3-1.png", "data/dataset/spiqa/images/2004.00139/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the model evaluated on the graphemes-to-phonemes task?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c733da68-3be9-55a6-a568-fe3bc714de9f", "question": "How much better peformance is achieved in human evaluation when model is trained considering proposed metric?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9a88462b-2be7-55d5-89af-030edbbeb85a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.05058/6-Table1-1.png", "data/dataset/spiqa/images/2002.05058/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.05058/4-Figure1-1.png", "data/dataset/spiqa/images/2002.05058/6-Table1-1.png", "data/dataset/spiqa/images/2002.05058/6-Table2-1.png", "data/dataset/spiqa/images/2002.05058/7-Table3-1.png", "data/dataset/spiqa/images/2002.05058/7-Table4-1.png", "data/dataset/spiqa/images/2002.05058/7-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much better peformance is achieved in human evaluation when model is trained considering proposed metric?", "reference_answer": "Pearson correlation to human judgement - proposed vs next best metric\nSample level comparison:\n- Story generation: 0.387 vs 0.148\n- Dialogue: 0.472 vs 0.341\nModel level comparison:\n- Story generation:  0.631 vs 0.302\n- Dialogue: 0.783 vs 0.553", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3343a65e-4e86-5905-a515-973afeb0a871", "question": "How much improvement do they get?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c8a180c-b890-520b-adfe-eceae5a7c0cb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.03788/10-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.03788/4-Table1-1.png", "data/dataset/spiqa/images/2004.03788/8-Table2-1.png", "data/dataset/spiqa/images/2004.03788/9-Table3-1.png", "data/dataset/spiqa/images/2004.03788/9-Table4-1.png", "data/dataset/spiqa/images/2004.03788/10-Table5-1.png", "data/dataset/spiqa/images/2004.03788/10-Table6-1.png", "data/dataset/spiqa/images/2004.03788/10-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much improvement do they get?", "reference_answer": "Their GTRS approach got an improvement of 3.89% compared to SVM and 27.91% compared to Pawlak.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "413ae114-7e49-524c-9e92-e5a1d6e5c5eb", "question": "What are state of the art methods authors compare their work with? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6299940a-9b5e-5df4-991e-04c6e8c214c8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01030/20-Table10-1.png", "data/dataset/spiqa/images/2002.01030/16-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01030/8-Figure1-1.png", "data/dataset/spiqa/images/2002.01030/10-Figure2-1.png", "data/dataset/spiqa/images/2002.01030/11-Figure3-1.png", "data/dataset/spiqa/images/2002.01030/12-Table1-1.png", "data/dataset/spiqa/images/2002.01030/13-Table2-1.png", "data/dataset/spiqa/images/2002.01030/14-Table3-1.png", "data/dataset/spiqa/images/2002.01030/15-Table4-1.png", "data/dataset/spiqa/images/2002.01030/16-Table5-1.png", "data/dataset/spiqa/images/2002.01030/16-Table6-1.png", "data/dataset/spiqa/images/2002.01030/17-Table7-1.png", "data/dataset/spiqa/images/2002.01030/18-Table8-1.png", "data/dataset/spiqa/images/2002.01030/19-Table9-1.png", "data/dataset/spiqa/images/2002.01030/20-Table10-1.png", "data/dataset/spiqa/images/2002.01030/20-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are state of the art methods authors compare their work with? ", "reference_answer": "ISOT dataset: LLVM\nLiar dataset: Hybrid CNN and LSTM with attention", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f07e3293-e503-5f60-8244-678cec46c1bf", "question": "How does the performance of the model vary with respect to the bounding box area and the similarity of the concept with ImageNet classes?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ffa8b9fb-8788-5f11-8613-49773b454ff1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure1-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure5-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure3-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure7-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure4-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure2-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Figure6-1.png", "data/dataset/spiqa/images/1803.06506v3/1803.06506v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the model vary with respect to the bounding box area and the similarity of the concept with ImageNet classes?", "reference_answer": "The performance of the model increases with increasing bounding box area and decreases with increasing similarity of the concept with ImageNet classes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a40caddb-e523-58ed-b80f-fbc65034bc91", "question": "Is RoBERTa better for cross-lingual transfer rather than BERT?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is RoBERTa better for cross-lingual transfer rather than BERT?", "reference_answer": "Yes, it is."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e187d71d-d592-5595-8057-923693858610", "question": "Which algorithm performs the best in the Joint Breakage experiment?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm performs the best in the Joint Breakage experiment?", "reference_answer": "ALOQ"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9c2a7685-7fab-5b69-80f5-9d138b40aa8a", "question": "How does the predicted return change as a function of θ for a fixed value of π = 1.5?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the predicted return change as a function of θ for a fixed value of π = 1.5?", "reference_answer": "The predicted return decreases as θ increases, with a minimum at around θ = 0.5."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f6946ea7-63a9-58aa-b360-d9dd6d8249ce", "question": "Do they test their approach on a dataset without incomplete data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["b0f8cb4c-5420-5ada-b490-7aed7819cfd1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.00137/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png", "data/dataset/spiqa/images/2001.00137/8-Table1-1.png", "data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/9-Table3-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png", "data/dataset/spiqa/images/2001.00137/11-Figure2-1.png", "data/dataset/spiqa/images/2001.00137/12-Table5-1.png", "data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/15-Figure3-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure4-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they test their approach on a dataset without incomplete data?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6389857f-7263-5e8c-b2b3-3e7dcaea13de", "question": "Which dataset and evaluation metric combination shows the largest performance gap between the best performing model and the baseline model DPE?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9dfc0881-3729-5198-9c85-aa07e3123e20"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table5-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table6-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table1-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table4-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table3-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Table2-1.png", "data/dataset/spiqa/images/1901.00056v2/1901.00056v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset and evaluation metric combination shows the largest performance gap between the best performing model and the baseline model DPE?", "reference_answer": "The largest performance gap is observed in the PubMed + UMLS dataset using the F1@K metric with K=1."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "eb09f907-348f-5305-836f-4d2d1f5561d7", "question": "Do they evaluate only on English datasets?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["37a3b37c-413a-5e0f-bdfc-abe642fa6fad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1807.07961/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1807.07961/2-Table1-1.png", "data/dataset/spiqa/images/1807.07961/3-Figure1-1.png", "data/dataset/spiqa/images/1807.07961/4-Figure2-1.png", "data/dataset/spiqa/images/1807.07961/5-Table2-1.png", "data/dataset/spiqa/images/1807.07961/6-Table3-1.png", "data/dataset/spiqa/images/1807.07961/7-Figure3-1.png", "data/dataset/spiqa/images/1807.07961/7-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they evaluate only on English datasets?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "fb03eebb-b992-5447-ba3d-8627dd91e591", "question": "What is the range of the number of non-English tokens found in English corpus? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the range of the number of non-English tokens found in English corpus? ", "reference_answer": "Non-English tokens make up 300k to 406M in the datasets investigated."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "320acb30-8b5f-5a42-92fd-dd47cbaf8832", "question": "What classifiers have been trained?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["232ba8ef-5668-5815-80d6-652fd0cb9475"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.02070/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.02070/1-Figure1-1.png", "data/dataset/spiqa/images/2002.02070/2-Table1-1.png", "data/dataset/spiqa/images/2002.02070/2-Figure2-1.png", "data/dataset/spiqa/images/2002.02070/3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What classifiers have been trained?", "reference_answer": "KNN\nRF\nSVM\nMLP", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "579c840f-f86d-5554-9ef2-7edd05037693", "question": "What is the role of the shared weights in the Siamese-like architecture shown in the first figure?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["296788f8-16bc-55ff-9d9a-9fdf5ff3b0e9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table2-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table1-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table4-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Table3-1.png", "data/dataset/spiqa/images/1705.08016v3/1705.08016v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the shared weights in the Siamese-like architecture shown in the first figure?", "reference_answer": "The shared weights allow the two branches of the network to learn similar representations of the input images. This helps to improve the performance of the Euclidean Confusion loss, which measures the distance between the conditional probability distributions of the two branches."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "108437a6-b047-54f3-8d7a-c84e872f0dd9", "question": "How do the backoff strategies work?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e348cca5-a3ac-5ce5-9dd5-cec3f6cfd7fa"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.11268/4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.11268/1-Table1-1.png", "data/dataset/spiqa/images/1905.11268/4-Figure1-1.png", "data/dataset/spiqa/images/1905.11268/5-Table2-1.png", "data/dataset/spiqa/images/1905.11268/7-Table3-1.png", "data/dataset/spiqa/images/1905.11268/7-Table4-1.png", "data/dataset/spiqa/images/1905.11268/8-Figure2-1.png", "data/dataset/spiqa/images/1905.11268/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do the backoff strategies work?", "reference_answer": "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "787bfa80-5b51-5272-b87b-576b9238f480", "question": "What is the effect of training on more diverse data on the accuracy of graph representation for VQA?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2f3b7633-fa54-55d7-8802-08f611b754d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table5-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure6-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure2-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table7-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table8-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure9-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure10-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Figure4-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table3-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table1-1.png", "data/dataset/spiqa/images/1811.08481v2/1811.08481v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of training on more diverse data on the accuracy of graph representation for VQA?", "reference_answer": "Training on more diverse data improves the accuracy of graph representation for VQA."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2184af20-c1b5-50bf-be11-ff32648dc019", "question": "How do the outcome curves for the black and white groups differ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a7193e4-6411-5e3e-9b02-09ce82c0f1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04383v2/1803.04383v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the outcome curves for the black and white groups differ?", "reference_answer": "The outcome curve for the black group is generally lower than the outcome curve for the white group. This indicates that, for a given selection rate, the black group experiences a smaller change in credit score than the white group."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7211cc61-9729-509e-b6c5-0d070544774c", "question": "Which model performed the best on the MSRP task for the Ordered Sentences dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0ef7a576-90fe-5b70-81db-8770ba622135"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table2-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Figure1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table4-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table3-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table7-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table8-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table6-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed the best on the MSRP task for the Ordered Sentences dataset?", "reference_answer": "SkipThought"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "10ab99b6-d959-537c-a783-26fb0579b5d1", "question": "Do they inspect their model to see if their model learned to associate image parts with words related to entities?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["236b32a8-cc74-50c1-b2b2-5cdb8d2ca3a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07862/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07862/1-Figure1-1.png", "data/dataset/spiqa/images/1802.07862/3-Figure2-1.png", "data/dataset/spiqa/images/1802.07862/6-Table1-1.png", "data/dataset/spiqa/images/1802.07862/7-Table2-1.png", "data/dataset/spiqa/images/1802.07862/8-Figure3-1.png", "data/dataset/spiqa/images/1802.07862/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they inspect their model to see if their model learned to associate image parts with words related to entities?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a494d5bc-7393-5d20-b55f-6bb9570a85ea", "question": "How does batching affect the radio duty cycle and CPU duty cycle?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does batching affect the radio duty cycle and CPU duty cycle?", "reference_answer": "Batching reduces both the radio duty cycle and CPU duty cycle."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5d7fe94d-c73f-58b2-bcd7-bb8d8bc4813d", "question": "Which dataset has a higher proportion of sentences containing multiple aspects: Rest14 or Rest15?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d5785d16-c0a5-5e54-9ad7-9ee75cd95b28"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure1-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure5-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure6-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset has a higher proportion of sentences containing multiple aspects: Rest14 or Rest15?", "reference_answer": "Rest14 has a higher proportion of sentences containing multiple aspects compared to Rest15."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "69041e42-3d30-5f38-98df-5cc83773c5e7", "question": "How does the performance of KAR, SAN, and QANet (without data augmentation) change as the proportion of available training examples decreases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d32bd564-0b48-5101-817c-090485d59a03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table1-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of KAR, SAN, and QANet (without data augmentation) change as the proportion of available training examples decreases?", "reference_answer": "The performance of all three models decreases as the proportion of available training examples decreases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "92df564b-8894-560d-a169-ad1045b7138f", "question": "How does the accuracy of the WideResNet model compare to the ChoiceNet model on the CIFAR-10 dataset with 50% random shuffle?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the accuracy of the WideResNet model compare to the ChoiceNet model on the CIFAR-10 dataset with 50% random shuffle?", "reference_answer": "The WideResNet model has higher accuracy than the ChoiceNet model on the CIFAR-10 dataset with 50% random shuffle."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a177b8de-326e-56de-9c3f-2387fd94096a", "question": "How big is performance improvement proposed methods are used?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["add5cbc6-123f-5686-afd7-c3cdc2a6d864"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.05153/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.05153/2-Figure1-1.png", "data/dataset/spiqa/images/1911.05153/2-Table1-1.png", "data/dataset/spiqa/images/1911.05153/3-Figure2-1.png", "data/dataset/spiqa/images/1911.05153/3-Table2-1.png", "data/dataset/spiqa/images/1911.05153/5-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is performance improvement proposed methods are used?", "reference_answer": "Data augmentation (es)  improved Adv es by 20% comparing to baseline \nData augmentation (cs) improved Adv cs by 16.5% comparing to baseline\nData augmentation (cs+es) improved both Adv cs and Adv es by at least 10% comparing to baseline \nAll models show improvements over adversarial sets  \n", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f5d19151-472b-5447-b346-909a312f79d1", "question": "Which algorithm is generally faster for fitting planes and cylinders: Multi-X or T-Linkage?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm is generally faster for fitting planes and cylinders: Multi-X or T-Linkage?", "reference_answer": "Multi-X is generally faster for fitting planes and cylinders compared to T-Linkage."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f6df17f0-f078-5a4b-b246-f6cdbb81c873", "question": "What is the main mathematical difference between the attentive LSTM reader and the vanilla Deep LSTM?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Figure5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/10-Table6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/11-Figure6-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/12-Figure7-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure10-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/13-Figure11-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure12-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/14-Figure13-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/2-Table1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/3-Table3-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/4-Table4-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/5-Figure1-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Figure2-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/7-Table5-1.png", "data/dataset/spiqa/images/d1505c6123c102e53eb19dff312cb25cea840b72/8-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the main mathematical difference between the attentive LSTM reader and the vanilla Deep LSTM?", "reference_answer": "The main difference between the attention-based LSTM and the vanilla one is that the former addresses the limitation of vanilla LSTM’s fixed and limited context size by taking into account the entire context of every token via a token-level attention mechanism."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "cbc9365f-398b-5c34-9a1e-3949509fd44c", "question": "What are some common metrics used to evaluate the performance of face recognition systems?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are some common metrics used to evaluate the performance of face recognition systems?", "reference_answer": "Common metrics that are used to evaluate the accuracy of FR models are: ROC, Acc. for face verification; rank-N and CMC curve for closed-set face identification, and DET curve for open-set face identification. Also, the metrics for the complexity and size of FR models are important. Lastly, the metrics that measure the age/gender/racial bias of the FR models are becoming necessary."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2b438a7c-7f3f-5801-ab4d-d44e6bf55fab", "question": "The authors proposed approach only works for classification models, and not for models that have other types of outputs. True or False?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52fc556e-8d5a-59cf-a7ce-b06619201667"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/5-Table1-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/6-Table2-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table3-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table4-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The authors proposed approach only works for classification models, and not for models that have other types of outputs. True or False?", "reference_answer": "In this work, the approach assumes that there are classes that the models should be able to predict. The work focuses on classification models. Thus, whether the approach can work on models with other types of outputs cannot be answered from this paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ca6d64a8-20c3-5148-b947-a52c01069221", "question": "How big are significant improvements?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b0035e75-2647-56d7-9d1e-a1c5713aab06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.06036/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.06036/1-Figure1-1.png", "data/dataset/spiqa/images/1910.06036/2-Table1-1.png", "data/dataset/spiqa/images/1910.06036/3-Table2-1.png", "data/dataset/spiqa/images/1910.06036/3-Figure2-1.png", "data/dataset/spiqa/images/1910.06036/4-Figure3-1.png", "data/dataset/spiqa/images/1910.06036/5-Table3-1.png", "data/dataset/spiqa/images/1910.06036/6-Table4-1.png", "data/dataset/spiqa/images/1910.06036/7-Table5-1.png", "data/dataset/spiqa/images/1910.06036/7-Figure4-1.png", "data/dataset/spiqa/images/1910.06036/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big are significant improvements?", "reference_answer": "Metrics show better results on all metrics compared to baseline except Bleu1  on Zhou split (worse by 0.11 compared to baseline). Bleu1 score on DuSplit is 45.66 compared to best baseline 43.47, other metrics on average by 1", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "02afd535-cd5e-5ec9-aa49-e4c7007ba244", "question": "Does the model evaluated on NLG datasets or dialog datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["653efdbb-7301-587d-b22c-90e494b7c43d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00139/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00139/3-Figure1-1.png", "data/dataset/spiqa/images/1706.00139/3-Figure2-1.png", "data/dataset/spiqa/images/1706.00139/5-Table1-1.png", "data/dataset/spiqa/images/1706.00139/6-Table2-1.png", "data/dataset/spiqa/images/1706.00139/6-Table3-1.png", "data/dataset/spiqa/images/1706.00139/7-Figure3-1.png", "data/dataset/spiqa/images/1706.00139/7-Figure4-1.png", "data/dataset/spiqa/images/1706.00139/7-Figure5-1.png", "data/dataset/spiqa/images/1706.00139/8-Table4-1.png", "data/dataset/spiqa/images/1706.00139/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the model evaluated on NLG datasets or dialog datasets?", "reference_answer": "NLG datasets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d1c4d7e8-9a55-5fa6-8639-37c485204be2", "question": "What is the highest accuracy score achieved?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4e3ed22d-89b9-5755-8b25-c700aa38123b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1607.06025/15-Table4-1.png", "data/dataset/spiqa/images/1607.06025/15-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1607.06025/2-Table1-1.png", "data/dataset/spiqa/images/1607.06025/3-Figure1-1.png", "data/dataset/spiqa/images/1607.06025/6-Figure2-1.png", "data/dataset/spiqa/images/1607.06025/6-Figure3-1.png", "data/dataset/spiqa/images/1607.06025/9-Figure4-1.png", "data/dataset/spiqa/images/1607.06025/11-Table2-1.png", "data/dataset/spiqa/images/1607.06025/12-Figure5-1.png", "data/dataset/spiqa/images/1607.06025/12-Figure6-1.png", "data/dataset/spiqa/images/1607.06025/14-Figure7-1.png", "data/dataset/spiqa/images/1607.06025/15-Table3-1.png", "data/dataset/spiqa/images/1607.06025/15-Table4-1.png", "data/dataset/spiqa/images/1607.06025/16-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the highest accuracy score achieved?", "reference_answer": "82.0%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "87f2ccf7-d26d-5a58-801c-bf873109080c", "question": "Which method generally performed better in the HalfCheetah task, ChoiceNet or MDN? How does the performance gap between these two methods change as the percentage of outliers increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method generally performed better in the HalfCheetah task, ChoiceNet or MDN? How does the performance gap between these two methods change as the percentage of outliers increases?", "reference_answer": "ChoiceNet generally performed better than MDN in the HalfCheetah task. This is evident from the higher average returns of ChoiceNet across all outlier percentages (10%, 20%, and 30%).\n\nThe performance gap between ChoiceNet and MDN appears to decrease as the percentage of outliers increases. At 10% outliers, ChoiceNet has a significantly higher average return than MDN (2068.14 vs. 192.53). However, at 30% outliers, the difference in average return is smaller (2035.91 vs. 363.08)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f9daed45-8fb8-5c23-8c88-9b6b482af1b5", "question": "Which model achieves the best NPMI scores (both internal and external) in the unsupervised setting, and what trade-off does this model exhibit compared to other models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model achieves the best NPMI scores (both internal and external) in the unsupervised setting, and what trade-off does this model exhibit compared to other models?", "reference_answer": "The Scholar + w.v. model achieves the best NPMI scores (both internal and external) in the unsupervised setting. However, this model also has the highest number of people parameters, indicating a trade-off between topic coherence and model complexity."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6e454cf9-ed2d-54e1-a3ab-f8083600fb14", "question": "Which evaluation criteria was used to compare the performance of action recognition models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["fdbea5d0-0918-54e6-9a09-5197df9c8a79"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Figure11-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Table2-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Figure12-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table4-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/3-Figure1-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/3-Figure2-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure4-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/6-Figure5-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/7-Figure6-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/8-Figure7-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure10-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure8-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Which evaluation criteria was used to compare the performance of action recognition models?", "reference_answer": "Evaluation criteria are measure on RGB data(single or multiple frames) and flow features."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ab5a7b2e-2123-5dee-bb61-5d32c6216855", "question": "What was the result of the highest performing system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0a573a64-ad08-5280-84bd-2dc03f494990"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.10217/4-Table5-1.png", "data/dataset/spiqa/images/1709.10217/4-Table4-1.png", "data/dataset/spiqa/images/1709.10217/5-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.10217/1-Figure1-1.png", "data/dataset/spiqa/images/1709.10217/2-Table1-1.png", "data/dataset/spiqa/images/1709.10217/2-Table2-1.png", "data/dataset/spiqa/images/1709.10217/4-Table3-1.png", "data/dataset/spiqa/images/1709.10217/4-Table4-1.png", "data/dataset/spiqa/images/1709.10217/4-Table5-1.png", "data/dataset/spiqa/images/1709.10217/5-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was the result of the highest performing system?", "reference_answer": "For task 1 best F1 score was 0.9391 on closed and 0.9414 on open test.\nFor task2 best result had: Ratio 0.3175 , Satisfaction 64.53, Fluency 0, Turns -1 and Guide 2", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f9c5c096-5596-506e-9035-7f1def2a864a", "question": "How would be the results and performance considering accuracy and losses while using window-with-size r self-attention approach with shorter sequences?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/6-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/13-Figure3-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/14-Figure4-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/15-Figure5-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/3-Figure1-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/4-Figure2-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/6-Table1-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/8-Table2-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/9-Table3-1.png", "data/dataset/spiqa/images/204e3073870fae3d05bcbc2f6a8e263d9b72e776/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How would be the results and performance considering accuracy and losses while using window-with-size r self-attention approach with shorter sequences?", "reference_answer": "Window-with-size r self-attention approach is only recommended to only improve computational performance for tasks involving very long sequences."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2a7a9f0a-17cf-518f-843b-f6d96edcd253", "question": "Which feature has the highest dimensionality in the first two dimensions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which feature has the highest dimensionality in the first two dimensions?", "reference_answer": "All features have the same dimensionality in the first two dimensions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "12ea1bf9-1492-531e-bc59-5d2ce0461cef", "question": "What is the difference between the filter responses from the “conv1”, “conv2” and “conv3” layers for a given frame from the TUM GAID data using a framework for person re-identification from RGB and the feature embedding fCNN of a framework that utilizes depth data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the filter responses from the “conv1”, “conv2” and “conv3” layers for a given frame from the TUM GAID data using a framework for person re-identification from RGB and the feature embedding fCNN of a framework that utilizes depth data?", "reference_answer": "The filter responses from the “conv1”, “conv2” and “conv3” layers for a given frame from the TUM GAID data using a framework for person re-identification from RGB are more detailed and contain more information than the filter responses from the fCNN of a framework that utilizes depth data. This is because RGB images contain more information than depth images."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b5fbee03-5ca2-56cd-a40e-00a393a826b5", "question": "Which models achieve state-of-the-art performances?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e9f86328-afc3-5d9e-81a2-0c543538dc03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13362/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13362/2-Figure1-1.png", "data/dataset/spiqa/images/1909.13362/3-Figure2-1.png", "data/dataset/spiqa/images/1909.13362/5-TableI-1.png", "data/dataset/spiqa/images/1909.13362/5-TableII-1.png", "data/dataset/spiqa/images/1909.13362/6-TableIII-1.png", "data/dataset/spiqa/images/1909.13362/6-TableIV-1.png", "data/dataset/spiqa/images/1909.13362/7-TableV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which models achieve state-of-the-art performances?", "reference_answer": "CELEX (Dutch and English) - SVM-HMM\nFestival, E-Hitz and OpenLexique - Liang hyphenation\nIIT-Guwahat - Entropy CRF", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "75170ab2-bda0-5bf6-9941-fb8f07fc9534", "question": "Which part of the model is responsible for deciding which frames are most important for the re-identification task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which part of the model is responsible for deciding which frames are most important for the re-identification task?", "reference_answer": "The Reinforced Temporal Attention (RTA) unit."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "7d2df3ae-df96-5419-b9bf-9e14edf58171", "question": "Which model performs the best when trained on 60% of the training data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d32bd564-0b48-5101-817c-090485d59a03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table1-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best when trained on 60% of the training data?", "reference_answer": "KAR"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a6bb6a95-3a2a-5a54-881a-e49c0f966edb", "question": "How do the different methods compare in terms of their ability to generate realistic faces?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the different methods compare in terms of their ability to generate realistic faces?", "reference_answer": "The baseline method generates faces that are blurry and unrealistic, while the other methods generate faces that are more realistic."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5f274168-8e93-5579-9396-5866541e5ba2", "question": "How does the C-Tarone method compare to the binarization method in terms of precision, recall, F-measure, and running time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["99904617-6a5d-55cb-be9e-259c5fa25b88"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure2-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure5-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure3-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure4-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the C-Tarone method compare to the binarization method in terms of precision, recall, F-measure, and running time?", "reference_answer": "The C-Tarone method has higher precision and F-measure than the binarization method in all datasets. The C-Tarone method has better or competitive recall than the binarization method. The running time of the C-Tarone method is competitive with the binarization method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "32a552c4-c4d3-50ca-9fd2-7fcb35c06b90", "question": "What is the trend in precision and recall as the number of recommended sections k increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e23d7484-ec68-5c65-bb90-6d11b1d325a5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure3-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Table1-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure5-1.png", "data/dataset/spiqa/images/1804.05995v2/1804.05995v2-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the trend in precision and recall as the number of recommended sections k increases?", "reference_answer": "Precision generally decreases and recall generally increases as k increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "66154343-04a4-5776-a5da-f4079f4b4a19", "question": "How many categories used in non-English text classifier?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many categories used in non-English text classifier?", "reference_answer": "Non-English text classifier uses six categories."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e7a1c5cc-7999-58bc-9310-3c39bddbd689", "question": "Which network architecture has the highest accuracy on the CIFAR-10 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bb551ad0-9186-52f0-a159-8fc47da634ac"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure1-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure2-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure7-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure3-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Table5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure8-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure4-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure5-1.png", "data/dataset/spiqa/images/1611.07718v2/1611.07718v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which network architecture has the highest accuracy on the CIFAR-10 dataset?", "reference_answer": "DMRNet-Wide"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9fcd87a5-d7b5-51ce-bb1a-8c446ef2e796", "question": "Which method performs the best in terms of NMI and what percentage of datasets does it outperform the other methods on?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ac630ef5-d68e-5774-9cf6-4edd657f3310"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Table1-1.png", "data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure1-1.png", "data/dataset/spiqa/images/1702.03584v3/1702.03584v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs the best in terms of NMI and what percentage of datasets does it outperform the other methods on?", "reference_answer": "The SPIRAL-MSM-kMeans method performs the best in terms of NMI with a score of 0.365. It outperforms the other methods on 89.4% of the datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b2647f99-1a9a-5e42-818d-67a96f41758a", "question": "How does the frequency reduction process create multiple trajectories from a single demonstration?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bd1cf1c1-2268-50fb-a8af-8321d7a864ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the frequency reduction process create multiple trajectories from a single demonstration?", "reference_answer": " The frequency reduction process takes a high-frequency trajectory and samples it at a lower frequency, resulting in multiple trajectories with different starting and ending points. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "299567b2-85f9-5bf6-951d-26c09b81cbc9", "question": "Can image content and style be \"fully\" or \"completely\" separated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6a8f9289-7ec8-5bee-bee9-e1056092b845"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/3-Figure1-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/5-Figure2-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/5-Figure2-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/7-Figure3-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/7-Figure3-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/7-Figure3-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/7-Figure3-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/7-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/3-Figure1-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/5-Figure2-1.png", "data/dataset/spiqa/images/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6/7-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Can image content and style be \"fully\" or \"completely\" separated?", "reference_answer": "The paper suggests that it is impossible to completely separate the content and the style of the image. But it is possible to extract their representations to then combine them with a loss function that allows the generation of visually appealing images that somewhat satisfy (not fully) the content and stylistic constraints. It is important to mention that the artistic style representation is just a correlation of filter responses between layers in CNN. The paper suggests that this is a plausible way to obtain the content-independent visual appearance of the image. When the object recognition model is learning, it has to be able to extract features that are invariant to different variations of images. Thus, it allows the separation of content and style representations. Previous methods use non-parametric techniques that directly manipulate the pixels of the image without such separation of representations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "a1ebbc31-e68e-5f47-a349-a4f9268455af", "question": "Which method achieves the best overall F1 score across all categories? Is this method consistently the best across all individual categories?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e91f7cea-06b5-5326-88d0-de2c234edf4d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table1-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table5-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table6-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Table4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03550v3/1809.03550v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves the best overall F1 score across all categories? Is this method consistently the best across all individual categories?", "reference_answer": "According to the table, Algorithm 2 w/ Geman-McLure) achieves the best overall F1 score of 0.56514. However, this method is not consistently the best across all individual categories. For example, OMoGMF has a higher F1 score for the \"badWeather\" category."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d6ec97b3-3738-5022-b9f9-aa0f3269811b", "question": "What are the key differences between Seq2Sick and existing attack methods on RNN-based models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4979a3cd-d95a-5e60-a12e-08263adccd51"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table4-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table5-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table6-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table7-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table8-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table9-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table1-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table2-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the key differences between Seq2Sick and existing attack methods on RNN-based models?", "reference_answer": "Seq2Sick differs from existing attack methods in two key aspects:\n\n1. Search Strategy: While previous methods primarily rely on greedy search, which becomes increasingly inefficient for longer sequences, Seq2Sick employs group lasso regularization and projected gradient descent with gradient regularization. This allows for simultaneous searching of all replacement positions, leading to improved efficiency.\n\n2. Targeted Attack Type: Existing methods focus on targeting specific classes or binary classifications, while Seq2Sick introduces a novel \"keyword\" target type, allowing attacks to be directed towards specific keywords within the generated sequence."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1e84d84c-06c7-5672-8dc0-81a528a94001", "question": "Which model performs the best in terms of AUC on the MovieLens-1M dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best in terms of AUC on the MovieLens-1M dataset?", "reference_answer": "RippleNet*"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f53aff0f-9aa2-5057-bfaf-234da7fae671", "question": "What is the role of the LSTM-MDN network in the training phase?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bd1cf1c1-2268-50fb-a8af-8321d7a864ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure3-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Table1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure2-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure1-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure4-1.png", "data/dataset/spiqa/images/1603.03833v4/1603.03833v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the LSTM-MDN network in the training phase?", "reference_answer": "The LSTM-MDN network is used to learn the relationship between the gripper pose and status, the pose of relevant objects, and the joint angles of the robot arm."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b87a1690-00fc-5592-a8c1-d80520129fa9", "question": "what metrics are used in evaluation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["70e11ea7-638c-5b7e-87a9-95c88d35862c"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.00108/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.00108/2-Figure1-1.png", "data/dataset/spiqa/images/1705.00108/3-Figure2-1.png", "data/dataset/spiqa/images/1705.00108/5-Table1-1.png", "data/dataset/spiqa/images/1705.00108/5-Table2-1.png", "data/dataset/spiqa/images/1705.00108/6-Table3-1.png", "data/dataset/spiqa/images/1705.00108/6-Table4-1.png", "data/dataset/spiqa/images/1705.00108/6-Table5-1.png", "data/dataset/spiqa/images/1705.00108/7-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what metrics are used in evaluation?", "reference_answer": "micro-averaged F1", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "5df0852e-0e15-5f89-95e9-57968b1d92c2", "question": "Do they experiment with the toolkits?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["f46bcab5-d304-5403-9a3d-2ce0f1e85765"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1907.04433/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1907.04433/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they experiment with the toolkits?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1ddaa517-0e9b-56c0-97c4-997a3f981727", "question": "How they extract \"structured answer-relevant relation\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b0035e75-2647-56d7-9d1e-a1c5713aab06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.06036/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.06036/1-Figure1-1.png", "data/dataset/spiqa/images/1910.06036/2-Table1-1.png", "data/dataset/spiqa/images/1910.06036/3-Table2-1.png", "data/dataset/spiqa/images/1910.06036/3-Figure2-1.png", "data/dataset/spiqa/images/1910.06036/4-Figure3-1.png", "data/dataset/spiqa/images/1910.06036/5-Table3-1.png", "data/dataset/spiqa/images/1910.06036/6-Table4-1.png", "data/dataset/spiqa/images/1910.06036/7-Table5-1.png", "data/dataset/spiqa/images/1910.06036/7-Figure4-1.png", "data/dataset/spiqa/images/1910.06036/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How they extract \"structured answer-relevant relation\"?", "reference_answer": "Using the OpenIE toolbox and applying heuristic rules to select the most relevant relation.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3f1e8713-9a2b-593c-bf75-5406f59fbfff", "question": "which neural embedding model works better?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abd3e4c5-927d-52de-9b64-24f038923cae"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.03342/16-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.03342/3-Table1-1.png", "data/dataset/spiqa/images/1702.03342/7-Figure1-1.png", "data/dataset/spiqa/images/1702.03342/9-Table2-1.png", "data/dataset/spiqa/images/1702.03342/14-Table3-1.png", "data/dataset/spiqa/images/1702.03342/15-Table4-1.png", "data/dataset/spiqa/images/1702.03342/16-Table5-1.png", "data/dataset/spiqa/images/1702.03342/17-Table6-1.png", "data/dataset/spiqa/images/1702.03342/18-Table7-1.png", "data/dataset/spiqa/images/1702.03342/19-Figure2-1.png", "data/dataset/spiqa/images/1702.03342/19-Table8-1.png", "data/dataset/spiqa/images/1702.03342/20-Figure3-1.png", "data/dataset/spiqa/images/1702.03342/20-Table9-1.png", "data/dataset/spiqa/images/1702.03342/21-Table10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "which neural embedding model works better?", "reference_answer": "the CRX model", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "eac0e599-55b7-5a14-b4df-c0406126e13c", "question": "What are the two main tasks that the CAN network is designed to perform?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d5785d16-c0a5-5e54-9ad7-9ee75cd95b28"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure1-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure2-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure4-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure5-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure3-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Figure6-1.png", "data/dataset/spiqa/images/1812.10735v2/1812.10735v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the two main tasks that the CAN network is designed to perform?", "reference_answer": "Aspect-level sentiment classification (ALSC) and aspect category detection (ACD)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6962b498-b1e5-56e8-922b-4423c5205e23", "question": "What is the relationship between the fixation density map and the ground truth fixations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2e451896-1a65-54a5-9d6c-886582d00353"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure7-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure1-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure4-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure6-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure5-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the fixation density map and the ground truth fixations?", "reference_answer": "The fixation density map predicts the probability of a person fixating on a particular location in the image. The ground truth fixations are the actual locations where people fixated on the image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f9547c1d-8162-5a35-b57a-911dd7eba49d", "question": "Are the images from a specific domain?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["acde2923-a403-5f4c-a39e-0298b5491253"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1912.08960/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1912.08960/1-Figure1-1.png", "data/dataset/spiqa/images/1912.08960/3-Table1-1.png", "data/dataset/spiqa/images/1912.08960/4-Figure2-1.png", "data/dataset/spiqa/images/1912.08960/5-Figure3-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure4-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure6-1.png", "data/dataset/spiqa/images/1912.08960/6-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Are the images from a specific domain?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bd3c7387-e099-57c7-a6e3-4e221f83a098", "question": "How are relations used to propagate polarity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How are relations used to propagate polarity?", "reference_answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4198f2b7-0668-5a63-b4db-5defc34aef03", "question": "Where did they get training data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["cfbf6ed2-2dbc-5421-919b-2c80506f7355"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1903.00172/7-Table4-1.png", "data/dataset/spiqa/images/1903.00172/6-Table3-1.png", "data/dataset/spiqa/images/1903.00172/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1903.00172/3-Figure1-1.png", "data/dataset/spiqa/images/1903.00172/4-Figure2-1.png", "data/dataset/spiqa/images/1903.00172/5-Table1-1.png", "data/dataset/spiqa/images/1903.00172/6-Table3-1.png", "data/dataset/spiqa/images/1903.00172/7-Table4-1.png", "data/dataset/spiqa/images/1903.00172/7-Figure3-1.png", "data/dataset/spiqa/images/1903.00172/8-Table6-1.png", "data/dataset/spiqa/images/1903.00172/8-Figure4-1.png", "data/dataset/spiqa/images/1903.00172/13-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Where did they get training data?", "reference_answer": "AmazonQA and ConciergeQA datasets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e468d0d1-6024-5408-b797-3ffbf18e258e", "question": "What is the relationship between the number of shifts and the accuracy of the output?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the number of shifts and the accuracy of the output?", "reference_answer": "The accuracy of the output increases as the number of shifts increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "be715a88-513a-570e-83b7-b81bd41d652b", "question": "How many iterations did the greedy EM-type learning process take to learn the part models for the watch image?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["be0ab42f-3812-52ff-8345-282868119291"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure4-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table1-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Table2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure2-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure5-1.png", "data/dataset/spiqa/images/1701.06171v4/1701.06171v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How many iterations did the greedy EM-type learning process take to learn the part models for the watch image?", "reference_answer": "22 iterations"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9a0396cf-2851-5f7f-83fa-8ef98ad9c7b6", "question": "What is the support value of the node \"ana=NAM\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["16d4f6a4-5643-545d-8d8d-cba855ef6f62"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Figure3-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table4-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table5-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table1-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table2-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table7-1.png", "data/dataset/spiqa/images/1708.00160v2/1708.00160v2-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the support value of the node \"ana=NAM\"?", "reference_answer": "2"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6740cedb-0a60-589b-809c-40c20d96ea18", "question": "How do angular/cosine-margin-based loss functions improve the separability of learned features in deep face recognition?\t", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How do angular/cosine-margin-based loss functions improve the separability of learned features in deep face recognition?\t", "reference_answer": "Angular/cosine-margin-based loss allows the separation of learned features with larger angular/cosine distance. When the bias is removed and the weights are normalized in softmax, the outcome only depends on the angle between the weight and the features. Based on the prior that the human face lies on a manifold, the angular/cosine-margin-based loss explicitly adds discriminative constraints on a hypersphere manifold."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0200992a-0a14-5f6a-bf93-cb40b89b12ea", "question": "What is the role of the discriminator (D) in the proposed BR-CSGAN model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7e050ffe-a1b2-5ec1-a6cd-9641ced929b8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table3-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table2-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Table1-1.png", "data/dataset/spiqa/images/1703.04887v4/1703.04887v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the discriminator (D) in the proposed BR-CSGAN model?", "reference_answer": " The discriminator (D) is responsible for distinguishing between real sentence pairs translated by humans and generated sentence pairs produced by the generator (G). It provides feedback to G in the form of rewards, helping G improve its ability to generate realistic sentence pairs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c915effd-6669-5b7a-8b4c-241dd2f39572", "question": "What context modelling methods are evaluated?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["75e302ec-400c-578f-87d4-047888e2dffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.00652/5-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.00652/1-Figure1-1.png", "data/dataset/spiqa/images/2002.00652/2-Figure2-1.png", "data/dataset/spiqa/images/2002.00652/3-Figure3-1.png", "data/dataset/spiqa/images/2002.00652/4-Figure4-1.png", "data/dataset/spiqa/images/2002.00652/4-Table1-1.png", "data/dataset/spiqa/images/2002.00652/5-Figure6-1.png", "data/dataset/spiqa/images/2002.00652/5-Figure5-1.png", "data/dataset/spiqa/images/2002.00652/6-Table2-1.png", "data/dataset/spiqa/images/2002.00652/6-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What context modelling methods are evaluated?", "reference_answer": "Concat\nTurn\nGate\nAction Copy\nTree Copy\nSQL Attn\nConcat + Action Copy\nConcat + Tree Copy\nConcat + SQL Attn\nTurn + Action Copy\nTurn + Tree Copy\nTurn + SQL Attn\nTurn + SQL Attn + Action Copy", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c9107ccb-0ee8-5aae-8d25-0ef0d8d3357f", "question": "Do they perform some annotation?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["45764244-2663-508e-9793-344e40747267"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.08652/2-Table2-1.png", "data/dataset/spiqa/images/1809.08652/2-Figure1-1.png", "data/dataset/spiqa/images/1809.08652/1-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.08652/1-Table1-1.png", "data/dataset/spiqa/images/1809.08652/2-Table2-1.png", "data/dataset/spiqa/images/1809.08652/2-Table3-1.png", "data/dataset/spiqa/images/1809.08652/2-Table4-1.png", "data/dataset/spiqa/images/1809.08652/2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they perform some annotation?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "00a88caf-eeb3-5799-a336-835ded5f6c28", "question": "Does the algorithm improve on the state-of-the-art methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3dd529dd-1a7c-5ba1-a77d-0fcdb3724aa2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.07555/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.07555/2-Table1-1.png", "data/dataset/spiqa/images/1911.07555/4-Table2-1.png", "data/dataset/spiqa/images/1911.07555/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the algorithm improve on the state-of-the-art methods?", "reference_answer": "From all reported results proposed method (NB+Lex) shows best accuracy on all 3 datasets - some models are not evaluated and not available in literature.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ecc2bdc2-c2c9-5f58-bb3f-238808724405", "question": "By how much does their model outperform existing methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4fb65934-36b7-53d9-81bf-8ff67eb535e8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.03261/6-TableII-1.png", "data/dataset/spiqa/images/1705.03261/6-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.03261/2-TableI-1.png", "data/dataset/spiqa/images/1705.03261/2-Figure1-1.png", "data/dataset/spiqa/images/1705.03261/3-Figure2-1.png", "data/dataset/spiqa/images/1705.03261/4-Figure3-1.png", "data/dataset/spiqa/images/1705.03261/5-Figure4-1.png", "data/dataset/spiqa/images/1705.03261/5-Figure5-1.png", "data/dataset/spiqa/images/1705.03261/6-TableII-1.png", "data/dataset/spiqa/images/1705.03261/6-Figure6-1.png", "data/dataset/spiqa/images/1705.03261/6-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much does their model outperform existing methods?", "reference_answer": "Answer with content missing: (Table II) Proposed model has F1 score of  0.7220 compared to 0.7148 best state-state-of-the-art result.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "160a46f1-e729-5c52-bdcf-f27f5ec1857e", "question": "Which model performed the best on the MSRP task for the Twitter dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0ef7a576-90fe-5b70-81db-8770ba622135"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table2-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Figure1-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table4-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table3-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table7-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table8-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table6-1.png", "data/dataset/spiqa/images/1703.02507v3/1703.02507v3-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed the best on the MSRP task for the Twitter dataset?", "reference_answer": "The Sent2Vec uni. + bi. model performed the best on the MSRP task for the Twitter dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "612b78f2-dea1-5741-b914-3f633bb7e826", "question": "How close do clusters match to ground truth tone categories?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["53a48927-a1df-55d7-a959-b35d8e27e014"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.08987/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.08987/1-Figure1-1.png", "data/dataset/spiqa/images/1910.08987/2-Figure2-1.png", "data/dataset/spiqa/images/1910.08987/3-Figure3-1.png", "data/dataset/spiqa/images/1910.08987/4-Table3-1.png", "data/dataset/spiqa/images/1910.08987/4-Table1-1.png", "data/dataset/spiqa/images/1910.08987/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How close do clusters match to ground truth tone categories?", "reference_answer": "NMI between cluster assignments and ground truth tones for all sylables is:\nMandarin: 0.641\nCantonese: 0.464", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ef99ee6b-8c4f-5335-86bd-907921ced04b", "question": "What is the role of the ripple sets in the RippleNet framework?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the ripple sets in the RippleNet framework?", "reference_answer": "The ripple sets are used to propagate a user's preferences from his or her click history to his or her relevant entities."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ae92ce61-7bb1-51a6-b17e-d4918b53c25c", "question": "How do the authors measure performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["40843903-571a-5d54-9bfb-a3be8e0c346a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06705/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06705/5-Figure1-1.png", "data/dataset/spiqa/images/1812.06705/5-Table1-1.png", "data/dataset/spiqa/images/1812.06705/7-Table2-1.png", "data/dataset/spiqa/images/1812.06705/7-Table3-1.png", "data/dataset/spiqa/images/1812.06705/8-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do the authors measure performance?", "reference_answer": "Accuracy across six datasets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d9cd87ab-86b4-5e00-8e7b-912500b164a2", "question": "How does the depth of the residual networks affect their performance in the experiments?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0ecdf509-8128-595a-9a9f-46dd6d41fd71"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/5-Figure4-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/5-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/1-Figure1-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/11-Table11-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/11-Table12-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/11-Table9-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/12-Table13-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/12-Table14-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/2-Figure2-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/4-Figure3-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/5-Figure4-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/5-Table1-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/5-Table2-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/6-Figure5-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/6-Table3-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/6-Table4-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/6-Table5-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/7-Table6-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/8-Figure6-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/8-Figure7-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/8-Table7-1.png", "data/dataset/spiqa/images/2c03df8b48bf3fa39054345bafabfeff15bfd11d/8-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does the depth of the residual networks affect their performance in the experiments?", "reference_answer": "[The increased depth of Residual network improves performance of this network, lower training error and make it generalizable to data. It also addresses degradation problem ]"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2e36c688-a8f1-556e-89c3-982d2ca98d2c", "question": "What are the languages they use in their experiment?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8f2d2808-165b-5206-b171-57f5f3e5c367"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2004.04721/4-Table1-1.png", "data/dataset/spiqa/images/2004.04721/6-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/2004.04721/4-Table1-1.png", "data/dataset/spiqa/images/2004.04721/5-Table2-1.png", "data/dataset/spiqa/images/2004.04721/5-Table3-1.png", "data/dataset/spiqa/images/2004.04721/6-Table4-1.png", "data/dataset/spiqa/images/2004.04721/6-Table5-1.png", "data/dataset/spiqa/images/2004.04721/7-Table6-1.png", "data/dataset/spiqa/images/2004.04721/8-Table7-1.png", "data/dataset/spiqa/images/2004.04721/8-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the languages they use in their experiment?", "reference_answer": "English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnish", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f2741be3-bf9c-5850-a212-50176b9dfb20", "question": "On what dataset is Aristo system trained?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d5c6d170-6c46-5139-bc14-e9ed2523c2f6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.01958/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.01958/3-Figure2-1.png", "data/dataset/spiqa/images/1909.01958/4-Figure3-1.png", "data/dataset/spiqa/images/1909.01958/4-Figure4-1.png", "data/dataset/spiqa/images/1909.01958/5-Table1-1.png", "data/dataset/spiqa/images/1909.01958/5-Figure5-1.png", "data/dataset/spiqa/images/1909.01958/6-Figure6-1.png", "data/dataset/spiqa/images/1909.01958/7-Table2-1.png", "data/dataset/spiqa/images/1909.01958/7-Table3-1.png", "data/dataset/spiqa/images/1909.01958/8-Table4-1.png", "data/dataset/spiqa/images/1909.01958/8-Table5-1.png", "data/dataset/spiqa/images/1909.01958/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "On what dataset is Aristo system trained?", "reference_answer": "Aristo Corpus\nRegents 4th\nRegents 8th\nRegents `12th\nARC-Easy\nARC-challenge ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ae13471e-b4ee-5204-8469-eb73eb5eac32", "question": "What is the difference between a standard cost volume and a deformable cost volume?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["da205164-6de7-5d67-bb1a-131ebb9a8d46"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure8-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure9-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure10-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure4-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure3-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure5-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure6-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Table1-1.png", "data/dataset/spiqa/images/1802.07351v2/1802.07351v2-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between a standard cost volume and a deformable cost volume?", "reference_answer": "A standard cost volume computes the matching costs for a neighborhood of the same location on the feature maps of the first and second images. A deformable cost volume computes the matching costs for a dilated neighborhood of the same location on the feature maps of the first and second images, offset by a flow vector."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d29f41a3-3b28-5296-beba-33193693613a", "question": "Who is responsible for designating the control signal?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["60b654b7-5847-56a5-8aaf-2e22fb679dc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/12-Table3-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/13-Figure8-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/13-Figure9-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/15-Table4-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/2-Figure2-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/4-Figure3-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/6-Figure4-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Figure5-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Figure6-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/7-Table1-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/8-Figure7-1.png", "data/dataset/spiqa/images/ada35e2c099fbde9d07a279311f4abe698341cd8/8-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Who is responsible for designating the control signal?", "reference_answer": "control signal is designated by each author in their work. as the authors of this paper proposed a \"verb-specific semantic role\" \"VSR\" as control signal for customized captions. while a recent surge of efforts by other works introduced extra control signals as constrains of the generated captions [16, 10, 19, 78, 48, 77, 27, 20]."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "d9da4015-c46a-5a65-ba48-15a80072c4d2", "question": "How big is the Japanese data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big is the Japanese data?", "reference_answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "dbbc1f67-e1de-592f-97b6-68febd97aa62", "question": "How do the temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients?", "reference_answer": "The temporal patterns of phenotype magnitude differ between sickle cell anemia and leukemia patients in terms of both shape and magnitude. For sickle cell anemia patients, the patterns are generally smoother and more periodic, with lower overall magnitude. For leukemia patients, the patterns are more erratic and have higher overall magnitude."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "02906aa9-aebf-5728-8d26-ebb636caca41", "question": "Does the system trained only using XR loss outperform the fully supervised neural system?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3dae5fd3-3062-58cd-9fd7-b1b01d71b45d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00430/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00430/5-Figure1-1.png", "data/dataset/spiqa/images/1909.00430/5-Figure2-1.png", "data/dataset/spiqa/images/1909.00430/7-Table1-1.png", "data/dataset/spiqa/images/1909.00430/9-Figure3-1.png", "data/dataset/spiqa/images/1909.00430/9-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the system trained only using XR loss outperform the fully supervised neural system?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "90c33ab4-630b-5af0-bad7-0c36d60e7624", "question": "By how much is performance on CN-Celeb inferior to performance on VoxCeleb?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["08b4480d-3698-5a9a-9d0a-9fe1d6331bc8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.01799/4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.01799/2-Table2-1.png", "data/dataset/spiqa/images/1911.01799/2-Table1-1.png", "data/dataset/spiqa/images/1911.01799/2-Table3-1.png", "data/dataset/spiqa/images/1911.01799/4-Table4-1.png", "data/dataset/spiqa/images/1911.01799/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much is performance on CN-Celeb inferior to performance on VoxCeleb?", "reference_answer": "For i-vector system, performances are 11.75% inferior to voxceleb. For x-vector system, performances are 10.74% inferior to voxceleb", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bf98ee3b-e787-5c69-a2e2-a5c971551dfa", "question": "Was evaluation metrics and criteria were used to evaluate the output of the cascaded multimodal speech translation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e7e92a23-753a-5657-8bf3-f1a2067adda0"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.13215/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.13215/3-Figure1-1.png", "data/dataset/spiqa/images/1910.13215/4-Figure2-1.png", "data/dataset/spiqa/images/1910.13215/4-Figure3-1.png", "data/dataset/spiqa/images/1910.13215/5-Table1-1.png", "data/dataset/spiqa/images/1910.13215/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Was evaluation metrics and criteria were used to evaluate the output of the cascaded multimodal speech translation?", "reference_answer": "BLEU scores", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d59959c1-869f-5e65-bcd5-1324507015bd", "question": "Which dataset provides data for **both** facial expressions and full-body motion capture, including clothing, in a natural setting (not synthesized)? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset provides data for **both** facial expressions and full-body motion capture, including clothing, in a natural setting (not synthesized)? ", "reference_answer": "HUMBI is the only dataset that provides data for both facial expressions and full-body motion capture, including clothing, in a natural setting. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2bbe2a82-48a0-528b-8361-c3de4d1ec555", "question": "How does the average number of inter-word semantic connections per word change as the value of κ increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d32bd564-0b48-5101-817c-090485d59a03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure4-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table3-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table2-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Table1-1.png", "data/dataset/spiqa/images/1809.03449v3/1809.03449v3-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the average number of inter-word semantic connections per word change as the value of κ increases?", "reference_answer": "The average number of inter-word semantic connections per word increases as the value of κ increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "16238744-3bc0-5323-91d0-25ab8cd9892e", "question": "Can the approach be generalized to other technical domains as well? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["ac6c155c-4842-5f6a-9021-25a4148014cf"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.04521/5-Figure3-1.png", "data/dataset/spiqa/images/1704.04521/4-Figure2-1.png", "data/dataset/spiqa/images/1704.04521/6-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.04521/2-Figure1-1.png", "data/dataset/spiqa/images/1704.04521/4-Figure2-1.png", "data/dataset/spiqa/images/1704.04521/5-Figure3-1.png", "data/dataset/spiqa/images/1704.04521/6-Figure4-1.png", "data/dataset/spiqa/images/1704.04521/7-Table1-1.png", "data/dataset/spiqa/images/1704.04521/7-Table2-1.png", "data/dataset/spiqa/images/1704.04521/8-Figure5-1.png", "data/dataset/spiqa/images/1704.04521/9-Figure6-1.png", "data/dataset/spiqa/images/1704.04521/9-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Can the approach be generalized to other technical domains as well? ", "reference_answer": "There is no reason to think that this approach wouldn't also be successful for other technical domains. Technical terms are replaced with tokens, therefore so as long as there is a corresponding process for identifying and replacing technical terms in the new domain this approach could be viable.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8c2113bd-f670-5789-848a-bb7dad8fe8ed", "question": "Would more recent approaches such as DECAF extreme classification (2021) serve as a stronger baseline than the specialized models discussed in the paper?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52fc556e-8d5a-59cf-a7ce-b06619201667"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/5-Table1-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/6-Table2-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table3-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/7-Table4-1.png", "data/dataset/spiqa/images/0c908739fbff75f03469d13d4a1a07de3414ee19/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Would more recent approaches such as DECAF extreme classification (2021) serve as a stronger baseline than the specialized models discussed in the paper?", "reference_answer": "The specialist models were started from the baseline model which was Google’s deep convolutional network for JFT. The function and performance of DECAF, and how it compares to the JFT baseline model used in this work cannot be answered from this paper."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "27ae121b-cda1-55be-80c4-55fa4651c8a7", "question": "How does the dynamic attention block improve the transition of generated video for arbitrary identities?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["daf21a63-7d62-58c3-a905-5c2613ba48e3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure1-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure6-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure2-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure4-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure3-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Figure5-1.png", "data/dataset/spiqa/images/1812.06589v2/1812.06589v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the dynamic attention block improve the transition of generated video for arbitrary identities?", "reference_answer": "The dynamic attention block decouples the lip-related and identity-related information, allowing the network to focus on the most important area for generating realistic talking faces."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "81c7d262-aec9-5c0e-80fc-a45d9b3e3965", "question": "Which method achieves lower approximation error when the compression factor is greater than 3?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["31d46012-0f02-590b-bcb4-f7f19a18db4e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure5-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure6-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure4-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Table1-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure2-1.png", "data/dataset/spiqa/images/1706.08146v3/1706.08146v3-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method achieves lower approximation error when the compression factor is greater than 3?", "reference_answer": "Factorize-Recover"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "43d9696e-477f-5ce4-b8c9-79c93397feb7", "question": "Do they report results only on English data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image", "table"], "anchor_pdf": ["999456fd-dfa1-55ae-9b0b-c37de34db04a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.10344/7-Figure3-1.png", "data/dataset/spiqa/images/1703.10344/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.10344/1-Figure1-1.png", "data/dataset/spiqa/images/1703.10344/2-Figure2-1.png", "data/dataset/spiqa/images/1703.10344/4-Table1-1.png", "data/dataset/spiqa/images/1703.10344/6-Table2-1.png", "data/dataset/spiqa/images/1703.10344/7-Figure3-1.png", "data/dataset/spiqa/images/1703.10344/7-Table3-1.png", "data/dataset/spiqa/images/1703.10344/8-Table4-1.png", "data/dataset/spiqa/images/1703.10344/8-Table5-1.png", "data/dataset/spiqa/images/1703.10344/9-Figure4-1.png", "data/dataset/spiqa/images/1703.10344/9-Figure5-1.png", "data/dataset/spiqa/images/1703.10344/10-Figure6-1.png", "data/dataset/spiqa/images/1703.10344/10-Figure7-1.png", "data/dataset/spiqa/images/1703.10344/11-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they report results only on English data?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "7ade8c57-a4fe-5d38-b1da-f6dad3f86f85", "question": "Which system performs best on the IT domain in terms of full-cycle Smatch score, and how does its performance compare to the projection-based system in the same domain?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["72b0d1a9-3397-5940-bf4b-b5fdf8480554"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure3-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure4-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure5-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table1-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which system performs best on the IT domain in terms of full-cycle Smatch score, and how does its performance compare to the projection-based system in the same domain?", "reference_answer": "The GT system achieves the highest full-cycle Smatch score in the IT domain with a score of 59. This is 14 points higher than the projection-based system in the same domain, which scored 45."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fd925ea0-7dcb-5b9b-8458-3f1ede7723d2", "question": "How much performance gap between their approach and the strong handcrafted method?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2ece6f2e-bc3e-5ce9-a48b-6f126bd0bc0e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.07044/7-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.07044/3-Figure1-1.png", "data/dataset/spiqa/images/1603.07044/3-Figure2-1.png", "data/dataset/spiqa/images/1603.07044/5-Figure3-1.png", "data/dataset/spiqa/images/1603.07044/5-Figure4-1.png", "data/dataset/spiqa/images/1603.07044/5-Table2-1.png", "data/dataset/spiqa/images/1603.07044/7-Table3-1.png", "data/dataset/spiqa/images/1603.07044/7-Table4-1.png", "data/dataset/spiqa/images/1603.07044/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much performance gap between their approach and the strong handcrafted method?", "reference_answer": "0.007 MAP on Task A, 0.032 MAP on Task B, 0.055 MAP on Task C", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "292d5704-a41e-5d7c-b820-c443e4b70336", "question": "Does all the layers of the MobileNet use depthwise separable convolution?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["1af749b8-291e-54d3-9305-39e9f0c8d4ee"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/2-Figure1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/3-Figure2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Figure3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table1-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/4-Table2-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table3-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/5-Table6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure4-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Figure5-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table10-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table11-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/6-Table8-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Figure6-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/7-Table12-1.png", "data/dataset/spiqa/images/3647d6d0f151dc05626449ee09cc7bce55be497e/8-Table14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does all the layers of the MobileNet use depthwise separable convolution?", "reference_answer": "The first layer of MobileNet is a full convolution, and the rest are depthwise separable convolutions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "8b68e9f5-d350-51cb-9482-0fbeb640376f", "question": "How are relations used to propagate polarity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6f0eec4a-c5d3-5663-8366-89829794faa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00694/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table1-1.png", "data/dataset/spiqa/images/1909.00694/4-Table2-1.png", "data/dataset/spiqa/images/1909.00694/5-Table5-1.png", "data/dataset/spiqa/images/1909.00694/5-Table3-1.png", "data/dataset/spiqa/images/1909.00694/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How are relations used to propagate polarity?", "reference_answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event ", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "99b628cb-e3e6-58aa-bd4a-fff172cc3238", "question": "Which model performs the best for caption retrieval in terms of R@1 and MEDR? Briefly explain why the performance might be better than other models.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1d4aae8d-be49-5bef-88ce-e6d9a04354e4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table1-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table2-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table3-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table4-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table5-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best for caption retrieval in terms of R@1 and MEDR? Briefly explain why the performance might be better than other models.", "reference_answer": "Cap2Img performs the best for caption retrieval in terms of both R@1 (27.1) and MEDR (4.0). This suggests that the model is more successful at retrieving the most relevant caption for a given image compared to other models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "555cc13c-0842-590c-af86-ce3c3e2f59d3", "question": "What supplemental tasks are used for multitask learning?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2ece6f2e-bc3e-5ce9-a48b-6f126bd0bc0e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.07044/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.07044/3-Figure1-1.png", "data/dataset/spiqa/images/1603.07044/3-Figure2-1.png", "data/dataset/spiqa/images/1603.07044/5-Figure3-1.png", "data/dataset/spiqa/images/1603.07044/5-Figure4-1.png", "data/dataset/spiqa/images/1603.07044/5-Table2-1.png", "data/dataset/spiqa/images/1603.07044/7-Table3-1.png", "data/dataset/spiqa/images/1603.07044/7-Table4-1.png", "data/dataset/spiqa/images/1603.07044/8-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What supplemental tasks are used for multitask learning?", "reference_answer": "Multitask learning is used for the task of predicting relevance of a comment on a different question to a given question, where the supplemental tasks are predicting relevance between the questions, and between the comment and the corresponding question", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ab8096ff-6201-5d58-8de4-7905e50f268c", "question": "Which variants of LSTM encoder-decoder models are used in this study?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["fdbea5d0-0918-54e6-9a09-5197df9c8a79"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/6-Figure5-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Figure11-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/10-Table2-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Figure12-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/11-Table4-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/3-Figure1-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/3-Figure2-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure3-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/4-Figure4-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/6-Figure5-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/7-Figure6-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/8-Figure7-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure10-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure8-1.png", "data/dataset/spiqa/images/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Which variants of LSTM encoder-decoder models are used in this study?", "reference_answer": "Future Predictor, Composite Model, Conditional Future Predictor, Composite Model with Conditional Future Predictor are the variants of LSTM encoder-decoder models are used in this study."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2b08ab13-066a-5536-9048-fdd89e9df76b", "question": "What is the purpose of using a non-isotropic Gaussian prior in the VAE model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["fb950852-bf9e-520f-85e4-b5c40d844997"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3f51216e1834c4fe06b08df87901ae0d77de2567/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/3f51216e1834c4fe06b08df87901ae0d77de2567/10-Figure3-1.png", "data/dataset/spiqa/images/3f51216e1834c4fe06b08df87901ae0d77de2567/3-Figure1-1.png", "data/dataset/spiqa/images/3f51216e1834c4fe06b08df87901ae0d77de2567/4-Figure2-1.png", "data/dataset/spiqa/images/3f51216e1834c4fe06b08df87901ae0d77de2567/9-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the purpose of using a non-isotropic Gaussian prior in the VAE model?", "reference_answer": "the purpose of using a non-isotropic Gaussian prior in the VAE model is to get better disentanglement scores, with further improvement achieved when the prior variance is learnt"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c75bc155-3adb-5238-9b1d-654111da6310", "question": "Which game has the highest code loss in phase 2?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["edf2543a-ae86-5f4d-b07a-c33d5092ee05"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure5-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure3-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure2-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure4-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which game has the highest code loss in phase 2?", "reference_answer": "Pacman"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fcf4a9a9-d10e-5894-88de-99d5245b0587", "question": "Which method performs best for highly active users in the US?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best for highly active users in the US?", "reference_answer": "Both GeoCUTS and DMA perform equally well for highly active users in the US."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e2c766db-e724-5ccf-9f12-969926ff89c6", "question": "Do they use dropout?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["45764244-2663-508e-9793-344e40747267"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.08652/2-Figure1-1.png", "data/dataset/spiqa/images/1809.08652/2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.08652/1-Table1-1.png", "data/dataset/spiqa/images/1809.08652/2-Table2-1.png", "data/dataset/spiqa/images/1809.08652/2-Table3-1.png", "data/dataset/spiqa/images/1809.08652/2-Table4-1.png", "data/dataset/spiqa/images/1809.08652/2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they use dropout?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d92e52a2-4566-54c5-b18c-b8acaeab453f", "question": "The paper's algorithm yields very small perturbations which are believed to be good approximations of the minimal perturbation. Quantitatively, how far is the paper's approximation from the minimal perturbation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4bc68d1d-c421-567f-a14a-076cb7acca37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure3-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure6-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "The paper's algorithm yields very small perturbations which are believed to be good approximations of the minimal perturbation. Quantitatively, how far is the paper's approximation from the minimal perturbation?", "reference_answer": "The authors only claim that the DeepFool can be used as a baseline for adversarial perturbation calculation and that it heavily depends on existing optimization methods. In the paper, its effectiveness is proven relative to other state-of-the-art methods. Although the analysis of how far the estimated perturbation from the actual minimal perturbation can be found in referenced papers, the more sophisticated analysis is not mentioned in the paper. Thus, it is difficult to answer the question entirely."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "62bc628f-162a-5521-b295-0a0495e65656", "question": "What was their result on Stance Sentiment Emotion Corpus?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4e8cbd3b-5a2f-5823-a2af-ad17af1e1e3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.12569/5-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.12569/3-Figure1-1.png", "data/dataset/spiqa/images/1911.12569/5-TableI-1.png", "data/dataset/spiqa/images/1911.12569/5-TableII-1.png", "data/dataset/spiqa/images/1911.12569/5-TableIII-1.png", "data/dataset/spiqa/images/1911.12569/5-Figure2-1.png", "data/dataset/spiqa/images/1911.12569/6-TableIV-1.png", "data/dataset/spiqa/images/1911.12569/7-TableXI-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was their result on Stance Sentiment Emotion Corpus?", "reference_answer": "F1 score of 66.66%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2ec8ba8e-553d-5b8d-ae7b-633b82c3d9a1", "question": "Why did they think this was a good idea?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["83e57399-04a3-5a79-b97e-2a5e9633bc51"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1801.09030/1-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1801.09030/1-Table1-1.png", "data/dataset/spiqa/images/1801.09030/4-Figure1-1.png", "data/dataset/spiqa/images/1801.09030/6-Table2-1.png", "data/dataset/spiqa/images/1801.09030/6-Table3-1.png", "data/dataset/spiqa/images/1801.09030/7-Table4-1.png", "data/dataset/spiqa/images/1801.09030/7-Table5-1.png", "data/dataset/spiqa/images/1801.09030/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Why did they think this was a good idea?", "reference_answer": "They think it will help human TCM practitioners make prescriptions.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "de77cbc4-b9bb-5d5d-b280-84b74156e0f0", "question": "How does the author conclude that non-local means filter is the best filter for denoising the images ? Are there any other filters that can be used for the same task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["56dfdd88-9d7e-5b5a-8202-a5027d1190ad"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/3-TableI-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure2-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure3-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/4-Figure4-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure5-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-Figure6-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/5-TableII-1.png", "data/dataset/spiqa/images/9317eb761d51f6eb428a157a02e2114a90b409e4/6-Figure8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does the author conclude that non-local means filter is the best filter for denoising the images ? Are there any other filters that can be used for the same task?", "reference_answer": "The author tested images on multiple filters including gaussian filter, median filter with kernel_size = 3, bilateral filter, and non-local means filter with patch_size = 3 and patch_distance = 5. Comparing with other filter non-local means filter best result by preserving all the edges and reducing noise."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "42557ad6-3606-55c3-aff8-2dc1ea9d84b4", "question": "What is the relationship between the query graph and the interference graph?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the query graph and the interference graph?", "reference_answer": " The interference graph is a folded version of the query graph. The nodes in the interference graph represent regions, and the edges represent the interference between regions. The edge weights in the interference graph are calculated from the edge weights in the query graph."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8ca78656-c25d-5ab9-8c26-5947ed674c77", "question": "Does the paper report macro F1?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["464c4041-96c7-5006-b564-02de05e9b455"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.07723/8-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.07723/3-Figure1-1.png", "data/dataset/spiqa/images/2003.07723/3-Table1-1.png", "data/dataset/spiqa/images/2003.07723/4-Table2-1.png", "data/dataset/spiqa/images/2003.07723/4-Table3-1.png", "data/dataset/spiqa/images/2003.07723/4-Table4-1.png", "data/dataset/spiqa/images/2003.07723/5-Figure2-1.png", "data/dataset/spiqa/images/2003.07723/6-Figure3-1.png", "data/dataset/spiqa/images/2003.07723/7-Table5-1.png", "data/dataset/spiqa/images/2003.07723/7-Figure4-1.png", "data/dataset/spiqa/images/2003.07723/8-Table6-1.png", "data/dataset/spiqa/images/2003.07723/8-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the paper report macro F1?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4ccede3d-bbbf-5494-b193-09c8550f31ba", "question": "Do they show an example of usage for INFODENS?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["43ec6a7d-2648-52f1-8192-0e7513c1a8ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.07091/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.07091/2-Figure1-1.png", "data/dataset/spiqa/images/1810.07091/3-Figure2-1.png", "data/dataset/spiqa/images/1810.07091/4-Figure3-1.png", "data/dataset/spiqa/images/1810.07091/5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they show an example of usage for INFODENS?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a7e8e137-3e20-5432-bfd0-c200808c3e78", "question": "In which scenario did Multi-X perform worse than another method in terms of misclassification error for simultaneous plane and cylinder fitting?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "In which scenario did Multi-X perform worse than another method in terms of misclassification error for simultaneous plane and cylinder fitting?", "reference_answer": "Multi-X performed worse than PEARL in test case (6), with a misclassification error of 21.72% compared to PEARL's 17.35%. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ff9fcac4-39c0-519a-8eed-ba353e730977", "question": "What is the effect of performing a left-swap on a binary vector y at index j′?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e1aa1e3d-5d21-56dd-8d07-b5f655a99aa4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02418v2/1709.02418v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02418v2/1709.02418v2-Figure1-1.png", "data/dataset/spiqa/images/1709.02418v2/1709.02418v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of performing a left-swap on a binary vector y at index j′?", "reference_answer": "The left-swap increases the number of misclassified pairs by one."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "53cbf1bb-4cff-546c-971f-8b22a3c51cbc", "question": "Which estimator performs best in the presence of noisy confounders and how does it compare to the Covariate Control (CC) estimator?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["af9d16f1-fea7-5ffd-8fce-8a0430f9324e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure3-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure5-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table2-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table5-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure8-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure1-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table1-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table4-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure7-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure6-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Table3-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure4-1.png", "data/dataset/spiqa/images/1906.10843v1/1906.10843v1-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which estimator performs best in the presence of noisy confounders and how does it compare to the Covariate Control (CC) estimator?", "reference_answer": "The Entropy Balancing (EB) estimator performs best across all measures (Bias, MAE, and MSE) when confounders are noisy. While the CC estimator also performs well, it exhibits slightly higher bias and MAE compared to EB."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "199a3e32-c704-5d2b-b32f-7d6446286cc2", "question": "What is the relationship between the average X_ref entropy and the generalization gap?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["7eef245d-f7ec-5aa3-ab7f-bebb0acde1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table2-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table4-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table5-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table6-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table3-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure3-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table11-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table12-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure5-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure6-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure7-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure1-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure4-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table7-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table8-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table9-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table10-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table1-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the average X_ref entropy and the generalization gap?", "reference_answer": "The generalization gap increases as the average X_ref entropy increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8a36039e-3721-5c17-8a1d-f87515698e82", "question": "Do they quantitavely or qualitatively evalute the output of their low-rank approximation to verify the grouping of lexical items?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6a3fbed8-8b71-516a-bf3d-4ebb4c54ac9e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1807.09671/15-Table7-1.png", "data/dataset/spiqa/images/1807.09671/10-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1807.09671/9-Table1-1.png", "data/dataset/spiqa/images/1807.09671/10-Table2-1.png", "data/dataset/spiqa/images/1807.09671/11-Table3-1.png", "data/dataset/spiqa/images/1807.09671/12-Table4-1.png", "data/dataset/spiqa/images/1807.09671/13-Table5-1.png", "data/dataset/spiqa/images/1807.09671/15-Table6-1.png", "data/dataset/spiqa/images/1807.09671/15-Table7-1.png", "data/dataset/spiqa/images/1807.09671/16-Table8-1.png", "data/dataset/spiqa/images/1807.09671/17-Table9-1.png", "data/dataset/spiqa/images/1807.09671/19-Figure1-1.png", "data/dataset/spiqa/images/1807.09671/20-Figure2-1.png", "data/dataset/spiqa/images/1807.09671/21-Table10-1.png", "data/dataset/spiqa/images/1807.09671/22-Table11-1.png", "data/dataset/spiqa/images/1807.09671/23-Table13-1.png", "data/dataset/spiqa/images/1807.09671/24-Table14-1.png", "data/dataset/spiqa/images/1807.09671/27-Table15-1.png", "data/dataset/spiqa/images/1807.09671/34-Table16-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they quantitavely or qualitatively evalute the output of their low-rank approximation to verify the grouping of lexical items?", "reference_answer": "They evaluate quantitatively.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "06fc2e10-fee4-500c-aa21-8b0c2ce6cec3", "question": "How does the BDD100K dataset compare to the KITTI and MOT17 datasets in terms of size and complexity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["67c43ba5-b9c9-52a8-975d-ef5dfd463b1f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table11-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table10-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure4-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure2-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure15-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure14-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table9-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure5-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure6-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table1-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure13-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table12-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure8-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table3-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Figure7-1.png", "data/dataset/spiqa/images/1805.04687v2/1805.04687v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the BDD100K dataset compare to the KITTI and MOT17 datasets in terms of size and complexity?", "reference_answer": "The BDD100K dataset is significantly larger and more complex than both the KITTI and MOT17 datasets. It contains roughly 40 times more frames, 16 times more sequences, and 13 times more identities than KITTI. Compared to MOT17, BDD100K has about 10 times more frames, 80 times more sequences, and 8 times more identities. This increase in size and complexity makes BDD100K a more challenging and comprehensive benchmark for multiple object tracking algorithms. "}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3f75d4ca-f9b7-5c85-8acc-325852d2c6e4", "question": "How does the performance of the proposed model compare to other models when trained on the LDC2017T10 dataset, and what does this suggest about the effectiveness of incorporating syntax into the model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e81915ee-6436-5660-8f3e-a8d93e4e8f32"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Figure1-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table3-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table2-1.png", "data/dataset/spiqa/images/1804.07707v2/1804.07707v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the proposed model compare to other models when trained on the LDC2017T10 dataset, and what does this suggest about the effectiveness of incorporating syntax into the model?", "reference_answer": "When trained on the LDC2017T10 dataset, the proposed model achieves the highest BLEU scores on both Dev and Test sets compared to other models listed in the table. This suggests that incorporating syntax into the model significantly improves its performance in generating text from AMR representations."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "310058a4-8e84-5a06-9cb3-7510c3969897", "question": "Is the \\delta a hyper-parameter?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is the \\delta a hyper-parameter?", "reference_answer": "Yes it's hyper-parameter, as it's within fixed range during training noting that it's fixed within this range during inference."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c5d5f40b-b238-5ac4-b443-ca6668d0bb09", "question": "How does varying the buffer size affect TCP goodput?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does varying the buffer size affect TCP goodput?", "reference_answer": "Increasing the buffer size generally leads to increased TCP goodput, but only up to a certain point."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d7ad4817-7445-5891-b936-0525cc14e971", "question": "Which model variant achieves the best performance on the CNSS dataset in terms of F1-score, and what are its key components?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3883ee7d-6df2-5037-93dc-13b5b7ad891a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table1-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table2-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model variant achieves the best performance on the CNSS dataset in terms of F1-score, and what are its key components?", "reference_answer": "Model XVIII, CIG-Sim&Siam-GCN-Sim$^{g}$, achieves the best performance on the CNSS dataset with an F1-score of 90.29%. This model utilizes the following key components:\n\n1. CIG: It directly uses keywords as concepts without community detection.\n2. Sim & Siam: It employs both term-based similarity encoder (\"Sim\") and Siamese encoder (\"Siam\") for generating matching vectors on vertices.\n3. GCN: It performs convolution on local matching vectors through GCN layers.\n4. Sim$^{g}$: It incorporates additional global features based on the five term-based similarity metrics."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "59151f4f-6410-5062-a042-7e265f1de1ed", "question": "Does model uses pretrained Transformer encoders?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["26252a5b-2acc-5f77-b67b-f796bffaf6c8"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.02562/3-Figure2-1.png", "data/dataset/spiqa/images/2002.02562/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.02562/1-Figure1-1.png", "data/dataset/spiqa/images/2002.02562/3-Table2-1.png", "data/dataset/spiqa/images/2002.02562/3-Figure2-1.png", "data/dataset/spiqa/images/2002.02562/3-Table3-1.png", "data/dataset/spiqa/images/2002.02562/3-Table1-1.png", "data/dataset/spiqa/images/2002.02562/4-Table5-1.png", "data/dataset/spiqa/images/2002.02562/4-Figure3-1.png", "data/dataset/spiqa/images/2002.02562/4-Table6-1.png", "data/dataset/spiqa/images/2002.02562/4-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does model uses pretrained Transformer encoders?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "acaff1a8-dba7-52b6-a096-8eb75bba6325", "question": "How does GeoCUTS perform compared to other clusterings for highly active users?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does GeoCUTS perform compared to other clusterings for highly active users?", "reference_answer": "GeoCUTS performs comparably to other clusterings for highly active users."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c7724969-d09b-52c7-bc9a-00b46515f2cc", "question": "What is the performance of proposed model on entire DROP dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3b00efc6-7dc4-596c-9d4e-6847f1652175"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13375/6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13375/6-Table1-1.png", "data/dataset/spiqa/images/1909.13375/6-Table2-1.png", "data/dataset/spiqa/images/1909.13375/6-Table3-1.png", "data/dataset/spiqa/images/1909.13375/7-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the performance of proposed model on entire DROP dataset?", "reference_answer": "The proposed model achieves  EM 77,63 and F1 80,73  on the test and EM  76,95 and  F1 80,25 on the dev", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "332f832a-67a4-5e60-aa63-e99b30bd9b2a", "question": "What is the role of the residual connections in the RBConvLSTM network?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the residual connections in the RBConvLSTM network?", "reference_answer": "The residual connections add the output of the previous layer to the input of the next layer. This helps to improve the flow of information through the network and can help to prevent vanishing gradients."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8a892862-3a4f-58e7-a42b-68b26ce658cf", "question": "What does STL stand for?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does STL stand for?", "reference_answer": "Single-Task Learning (STL): The model is pre-trained on a synthetic QA dataset generated from a single KG."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ff79d32c-8b23-5dc4-91ad-5d0b30332c16", "question": "Do they visualize the difference between AM-Softmax and regular softmax?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["546f4cb0-d8ed-555e-9992-c52d788c13b7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.10826/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.10826/2-Figure1-1.png", "data/dataset/spiqa/images/1901.10826/3-Figure2-1.png", "data/dataset/spiqa/images/1901.10826/4-TableI-1.png", "data/dataset/spiqa/images/1901.10826/4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they visualize the difference between AM-Softmax and regular softmax?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "64665b6f-b3b7-50c1-bbe9-9908b1cebfba", "question": "What makes GMPool and NGMPool novel compared to existing graph pooling methods?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["03ed11d3-1898-5a76-9960-b239974bb977"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/13-Table3-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/15-Table4-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/16-Figure4-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/2-Figure1-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/5-Table1-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/7-Figure2-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/8-Table2-1.png", "data/dataset/spiqa/images/c7bbe399aad2da39ba8f988fec83129d60aa5d52/9-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What makes GMPool and NGMPool novel compared to existing graph pooling methods?", "reference_answer": "GMPool and NGMPool overcome the limitation of existing pooling frameworks that require a universal number of clusters as user parameter by first building a grouping matrix and decomposing the matrix into its square-root form."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "6ae82c62-030d-5f5d-ba2f-7d97a9e277ad", "question": "What are the two factors to show potential reason for cross-lingual generalization", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the two factors to show potential reason for cross-lingual generalization", "reference_answer": "They are quantity of target language data in the pre-training corpora and language similarity."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "89edb649-944c-517c-949d-c3eaa2075f48", "question": "What is the difference between the Euclidean and Mahalanobis Bregman cost functions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dc5584b7-6dd8-5e79-b1ba-1d77ce70df61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure1-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Figure3-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table2-1.png", "data/dataset/spiqa/images/1705.07164v8/1705.07164v8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the Euclidean and Mahalanobis Bregman cost functions?", "reference_answer": "The Euclidean Bregman cost function is simply the squared difference between two points, while the Mahalanobis Bregman cost function takes into account the covariance of the data."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "0357ed2a-404d-572d-9594-90e6ebd3d32a", "question": "Which method performs best when there is no label corruption (p = 0%) on the Large Movie Review dataset and how does its performance change as the corruption level increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performs best when there is no label corruption (p = 0%) on the Large Movie Review dataset and how does its performance change as the corruption level increases?", "reference_answer": "When there is no label corruption (p = 0%), Mixup achieves the highest test accuracy of 79.77%. However, as the corruption level increases, Mixup's performance deteriorates more rapidly compared to other methods. ChoiceNet, on the other hand, demonstrates a more stable performance across different corruption levels, maintaining the highest accuracy when p is 10%, 20%, 30%, and 40%."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2b6d19e1-23d7-524e-a9f5-3049407e2854", "question": "What were their distribution results?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8af8c20d-5ea8-56a1-9d31-c369865e4fc6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.05999/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.05999/4-Figure1-1.png", "data/dataset/spiqa/images/1712.05999/4-Figure2-1.png", "data/dataset/spiqa/images/1712.05999/4-Table1-1.png", "data/dataset/spiqa/images/1712.05999/4-Figure3-1.png", "data/dataset/spiqa/images/1712.05999/5-Figure4-1.png", "data/dataset/spiqa/images/1712.05999/5-Figure5-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure6-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure9-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure10-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure7-1.png", "data/dataset/spiqa/images/1712.05999/6-Figure8-1.png", "data/dataset/spiqa/images/1712.05999/7-Figure11-1.png", "data/dataset/spiqa/images/1712.05999/7-Figure12-1.png", "data/dataset/spiqa/images/1712.05999/8-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What were their distribution results?", "reference_answer": "Distributions of Followers, Friends and URLs are significantly different between the set of tweets containing fake news and those non containing them, but for Favourites, Mentions, Media, Retweets and Hashtags they are not significantly different", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "eddbd39c-98ca-551e-ac51-b806ef38dba4", "question": "What is the effect of the sliding tendency of SepConv on the generated images?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of the sliding tendency of SepConv on the generated images?", "reference_answer": "The sliding tendency of SepConv will cause motion errors and high LMS."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ba7baf77-e85a-5b13-b829-5bde581d5f16", "question": "Which method has the best perceptual performance according to the tOF score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the best perceptual performance according to the tOF score?", "reference_answer": "TecoGAN."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "58619c31-ef8f-54b2-bdae-15d1ffe2f4e3", "question": "what dataset statistics are provided?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1476648e-0d55-550f-8e3c-ecc0dafb09a1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.05223/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.05223/1-Figure1-1.png", "data/dataset/spiqa/images/1803.05223/3-Table1-1.png", "data/dataset/spiqa/images/1803.05223/4-Figure2-1.png", "data/dataset/spiqa/images/1803.05223/4-Figure3-1.png", "data/dataset/spiqa/images/1803.05223/6-Figure4-1.png", "data/dataset/spiqa/images/1803.05223/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what dataset statistics are provided?", "reference_answer": "Distribution of category labels, number of answerable-not answerable questions, number of text-based and script-based questions, average text, question, and answer length, number of questions per text", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c9ea8183-1fd2-5fea-b914-12e9db07f1c8", "question": "what amounts of size were used on german-english?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4ce40e08-1444-5cc4-b8a9-38cff5d5d120"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.11901/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.11901/1-Figure4-1.png", "data/dataset/spiqa/images/1905.11901/3-Table1-1.png", "data/dataset/spiqa/images/1905.11901/4-Table2-1.png", "data/dataset/spiqa/images/1905.11901/4-Figure2-1.png", "data/dataset/spiqa/images/1905.11901/5-Table3-1.png", "data/dataset/spiqa/images/1905.11901/5-Table4-1.png", "data/dataset/spiqa/images/1905.11901/10-Table5-1.png", "data/dataset/spiqa/images/1905.11901/11-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "what amounts of size were used on german-english?", "reference_answer": "Training data with 159000, 80000, 40000, 20000, 10000 and 5000 sentences, and 7584 sentences for development", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d8c37016-a2c0-5db2-8bef-3ec9053fa17d", "question": "How does proposed word embeddings compare to Sindhi fastText word representations?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7f8efd0e-5d39-59ac-b90a-0be783c17b7e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.12579/15-Table7-1.png", "data/dataset/spiqa/images/1911.12579/15-Table8-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.12579/4-Table1-1.png", "data/dataset/spiqa/images/1911.12579/5-Figure1-1.png", "data/dataset/spiqa/images/1911.12579/8-Table2-1.png", "data/dataset/spiqa/images/1911.12579/9-Figure2-1.png", "data/dataset/spiqa/images/1911.12579/10-Table3-1.png", "data/dataset/spiqa/images/1911.12579/11-Table4-1.png", "data/dataset/spiqa/images/1911.12579/12-Figure3-1.png", "data/dataset/spiqa/images/1911.12579/12-Table5-1.png", "data/dataset/spiqa/images/1911.12579/14-Table6-1.png", "data/dataset/spiqa/images/1911.12579/15-Table7-1.png", "data/dataset/spiqa/images/1911.12579/15-Table8-1.png", "data/dataset/spiqa/images/1911.12579/16-Table9-1.png", "data/dataset/spiqa/images/1911.12579/17-Figure4-1.png", "data/dataset/spiqa/images/1911.12579/17-Figure5-1.png", "data/dataset/spiqa/images/1911.12579/17-Figure6-1.png", "data/dataset/spiqa/images/1911.12579/18-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How does proposed word embeddings compare to Sindhi fastText word representations?", "reference_answer": "Proposed SG model vs SINDHI FASTTEXT:\nAverage cosine similarity score: 0.650 vs 0.388\nAverage semantic relatedness similarity score between countries and their capitals: 0.663 vs 0.391", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "e85bfd83-45f0-5313-837b-e78efadb3929", "question": "Which saliency map method achieved the highest score for the sAUC metric, and how does its performance compare to other methods based on this metric? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2e451896-1a65-54a5-9d6c-886582d00353"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure7-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table3-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure1-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure4-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure6-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table2-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Figure5-1.png", "data/dataset/spiqa/images/1704.08615v2/1704.08615v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which saliency map method achieved the highest score for the sAUC metric, and how does its performance compare to other methods based on this metric? ", "reference_answer": "The saliency map method with the highest sAUC score is **SIM**. Its sAUC score appears to be significantly higher than all other methods listed in the table."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "60dd9c6d-c857-5b92-b891-805b764e6c7a", "question": "What are the citation intent labels in the datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["2455efdf-563f-5df7-a967-6d55d1c2996b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.01608/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.01608/1-Figure1-1.png", "data/dataset/spiqa/images/1904.01608/2-Figure2-1.png", "data/dataset/spiqa/images/1904.01608/4-Table1-1.png", "data/dataset/spiqa/images/1904.01608/4-Table2-1.png", "data/dataset/spiqa/images/1904.01608/6-Table3-1.png", "data/dataset/spiqa/images/1904.01608/7-Table4-1.png", "data/dataset/spiqa/images/1904.01608/7-Figure3-1.png", "data/dataset/spiqa/images/1904.01608/8-Table5-1.png", "data/dataset/spiqa/images/1904.01608/8-Table6-1.png", "data/dataset/spiqa/images/1904.01608/8-Table7-1.png", "data/dataset/spiqa/images/1904.01608/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the citation intent labels in the datasets?", "reference_answer": "Background, extends, uses, motivation, compare/contrast, and future work for the ACL-ARC dataset. Background, method, result comparison for the SciCite dataset.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "27487eaf-78d2-5cc0-84e9-1ead1db3e07b", "question": "What are the three main components of the Action Search model architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6437feca-e73b-5ddd-a3f2-d94ef3737017"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure2-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure1-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure3-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure4-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Figure5-1.png", "data/dataset/spiqa/images/1706.04269v2/1706.04269v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the three main components of the Action Search model architecture?", "reference_answer": "The three main components of the Action Search model architecture are the visual encoder, the LSTM, and the spotting target."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d6cbe5ac-f7b5-57d2-9621-fdddce299555", "question": "What are the qualitative experiments performed on benchmark datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["127cdc54-de6d-58c7-b24d-a696f68fd57b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.06118/5-Table3-1.png", "data/dataset/spiqa/images/1911.06118/5-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.06118/4-Table2-1.png", "data/dataset/spiqa/images/1911.06118/4-Table1-1.png", "data/dataset/spiqa/images/1911.06118/5-Table3-1.png", "data/dataset/spiqa/images/1911.06118/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the qualitative experiments performed on benchmark datasets?", "reference_answer": "Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a275d8f4-13f7-5545-8d22-538c7e3750dc", "question": "Why is there decrease of the performance of the zeor-shot fusion without ATOMIC?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e0e0c3ea-9abe-52ce-a896-82f41642de8f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/11-Table6-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Figure7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table7-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/12-Table8-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table10-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/14-Table9-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/3-Table1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/4-Figure1-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/5-Figure2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/6-Table2-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure3-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/7-Figure4-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure5-1.png", "data/dataset/spiqa/images/6f9aa703c1dea0bd316ff7c758381199b321a3ba/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why is there decrease of the performance of the zeor-shot fusion without ATOMIC?", "reference_answer": "In both framework, the slightly degraded performance of the combination of KGs without ATOMIC could be due to the strong alignment between ATOMIC and SIQA."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "a720ebd3-358b-5178-b2e3-a811d5117182", "question": "Which geographical regions correlate to the trend?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["568d831d-3fbf-5885-9236-11a16976593a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.05970/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.05970/3-Figure1-1.png", "data/dataset/spiqa/images/2001.05970/4-Table1-1.png", "data/dataset/spiqa/images/2001.05970/4-Table2-1.png", "data/dataset/spiqa/images/2001.05970/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which geographical regions correlate to the trend?", "reference_answer": "Northeast U.S., West U.S. and South U.S.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8feb9094-131a-55ef-a7e8-50ee76792327", "question": "Why did the authors choose to use a nonlinearity to curve α before fitting the cubic hermite spline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Why did the authors choose to use a nonlinearity to curve α before fitting the cubic hermite spline?", "reference_answer": "The authors chose to use a nonlinearity to curve α before fitting the cubic hermite spline because it allows for increased knot density near α = 2 and decreased knot density when α > 4. This helps to better approximate the log partition function, which is difficult to evaluate for arbitrary inputs."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6b28b47b-7544-575c-a420-c682fd3de12e", "question": "Did ensemble schemes help in boosting peformance, by how much?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did ensemble schemes help in boosting peformance, by how much?", "reference_answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external).", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d17883bd-a6c0-5861-8a66-f0d5bd8ac468", "question": "What is the purpose of the `SubsetGate` function in the MaxPooling function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the `SubsetGate` function in the MaxPooling function?", "reference_answer": "The `SubsetGate` function is used to split the input `x` into `k` pieces."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4bc68776-4eba-5406-b1a5-102894d4c5d1", "question": "How does the bounding box encoder network influence the segmentation process?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the bounding box encoder network influence the segmentation process?", "reference_answer": "The bounding box encoder network embeds bounding box information at different scales and outputs attention maps that are used to fuse with feature maps from the encoder before being passed to the decoder."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "51164962-51be-5f5e-a871-85d4b1ec6d1b", "question": "What is the key difference between ZDDA and UDA/MVL in terms of the available training data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["86d109ac-bfba-5548-a67e-8dfd401e8f3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table7-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table6-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table3-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table5-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table1-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table9-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table4-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table2-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Table8-1.png", "data/dataset/spiqa/images/1707.01922v5/1707.01922v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the key difference between ZDDA and UDA/MVL in terms of the available training data?", "reference_answer": "The key difference lies in the availability of target-domain training data. While UDA and MVL methods require T-R training data from the target domain, ZDDA does not. ZDDA only requires T-R training data from a single source domain."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "cbaa4997-5ba4-5ee5-86e2-4defe4e4d2e8", "question": "How did they get relations between mentions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["df4de88d-e624-5e8a-ac1c-1f42eae3e5b9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.09920/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.09920/1-Figure1-1.png", "data/dataset/spiqa/images/1808.09920/3-Figure2-1.png", "data/dataset/spiqa/images/1808.09920/5-Table1-1.png", "data/dataset/spiqa/images/1808.09920/6-Table2-1.png", "data/dataset/spiqa/images/1808.09920/7-Table3-1.png", "data/dataset/spiqa/images/1808.09920/8-Table4-1.png", "data/dataset/spiqa/images/1808.09920/11-Table5-1.png", "data/dataset/spiqa/images/1808.09920/12-Table6-1.png", "data/dataset/spiqa/images/1808.09920/13-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How did they get relations between mentions?", "reference_answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a3c8b940-9f1a-54c8-a06a-60020f70e7e8", "question": "Do the authors mention any possible confounds in their study?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["c16572e6-20d3-51c9-8ce9-46e538d854b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.06777/6-Figure7-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.06777/2-Figure1-1.png", "data/dataset/spiqa/images/1702.06777/3-Figure2-1.png", "data/dataset/spiqa/images/1702.06777/4-Figure3-1.png", "data/dataset/spiqa/images/1702.06777/5-Figure4-1.png", "data/dataset/spiqa/images/1702.06777/5-Figure5-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure6-1.png", "data/dataset/spiqa/images/1702.06777/6-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do the authors mention any possible confounds in their study?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ff58cab8-ea0e-56bc-aa1a-3e5c597e1e7a", "question": "Does the fact that GCNs can perform well on this tell us that the task is simpler than previously thought?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["2c7eb87f-1157-5321-865a-644ce9d0cc78"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.06906/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.06906/3-Figure1-1.png", "data/dataset/spiqa/images/1905.06906/5-Figure2-1.png", "data/dataset/spiqa/images/1905.06906/7-Table1-1.png", "data/dataset/spiqa/images/1905.06906/8-Table2-1.png", "data/dataset/spiqa/images/1905.06906/8-Table3-1.png", "data/dataset/spiqa/images/1905.06906/8-Table4-1.png", "data/dataset/spiqa/images/1905.06906/9-Table5-1.png", "data/dataset/spiqa/images/1905.06906/10-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the fact that GCNs can perform well on this tell us that the task is simpler than previously thought?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "6555073a-d081-53e0-877a-d466d4d7679a", "question": "If we use the lexicographic product with a chain as the first component and a distributive lattice as the second component to design a CRDT, will the resulting CRDT lattice be guaranteed to be distributive and satisfy the descending chain condition (DCC)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "If we use the lexicographic product with a chain as the first component and a distributive lattice as the second component to design a CRDT, will the resulting CRDT lattice be guaranteed to be distributive and satisfy the descending chain condition (DCC)?", "reference_answer": "Yes, the resulting CRDT lattice will be guaranteed to be both distributive and satisfy the DCC."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5ecdb4f5-7255-5343-b3d7-259a36e59649", "question": "how was annotation done?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["fab5a07a-e65a-516e-9e5e-f3961fdef8fc"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.02385/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.02385/3-Figure1-1.png", "data/dataset/spiqa/images/1704.02385/4-Figure2-1.png", "data/dataset/spiqa/images/1704.02385/8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "how was annotation done?", "reference_answer": "Annotation was done with the help of annotators from Amazon Mechanical Turk on snippets of conversations", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0c6a5530-b523-5b5f-96cb-a6e4bdf263ba", "question": "According to the ablation experiments, which factor contributes the most to the best model's performance compared to the baseline model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d2648a6-db41-5a23-9cb0-92c59be4fbc1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table1-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table2-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table4-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Table3-1.png", "data/dataset/spiqa/images/1804.07849v4/1804.07849v4-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "According to the ablation experiments, which factor contributes the most to the best model's performance compared to the baseline model?", "reference_answer": "Morphological modeling with LSTMs contributes the most to the best model's performance compared to the baseline model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "474949df-fa47-5559-a468-b5561e36001f", "question": "What is the difference between the grayscale depth representation and the result after background subtraction?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9c53c0eb-cd2f-5c9c-9500-8cf758588e70"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure5-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure7-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table2-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure6-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Table1-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure4-1.png", "data/dataset/spiqa/images/1705.09882v2/1705.09882v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the grayscale depth representation and the result after background subtraction?", "reference_answer": " The grayscale depth representation shows the depth of each pixel in the image, with darker pixels representing closer objects and lighter pixels representing further objects. The result after background subtraction shows only the foreground object, with the background removed."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "069a8e68-6e1c-545c-8a97-7d8d6aeec16f", "question": "How much improvement does their method get over the fine tuning baseline?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["06d17564-3b4b-5ca2-b611-17ff84da98df"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03214/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03214/2-Figure1-1.png", "data/dataset/spiqa/images/1701.03214/2-Figure2-1.png", "data/dataset/spiqa/images/1701.03214/3-Table1-1.png", "data/dataset/spiqa/images/1701.03214/3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How much improvement does their method get over the fine tuning baseline?", "reference_answer": "0.08 points on the 2011 test set, 0.44 points on the 2012 test set, 0.42 points on the 2013 test set for IWSLT-CE.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "172c2975-9664-5388-9a4c-a9a50b68c88a", "question": "In what ways can it be said that the concatenation acts as a skip connection?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["bd8023bb-64d7-5ad9-900c-96f486794091"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6b7d6e6416343b2a122f8416e69059ce919026ef/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/6b7d6e6416343b2a122f8416e69059ce919026ef/19-Figure3-1.png", "data/dataset/spiqa/images/6b7d6e6416343b2a122f8416e69059ce919026ef/2-Figure1-1.png", "data/dataset/spiqa/images/6b7d6e6416343b2a122f8416e69059ce919026ef/7-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "In what ways can it be said that the concatenation acts as a skip connection?", "reference_answer": "Skip connection is to consider information from different search depths or layers simultaneously.\nGraphSAGE use a set of weight matrices and concatenation to consider information from diverse search depths. \nIt can be interpreted as a skip connection.\nThe reason is that a set of weight matrices are used to propagate information \n between different layers of the model or search depths, while considering different search depth is a kind of skip-connection."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "feb57ef8-d9d0-5d14-87a9-3c53623c821d", "question": "What is the role of the Motion Compensation block in the Frame-Recurrent Generator?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the Motion Compensation block in the Frame-Recurrent Generator?", "reference_answer": "The Motion Compensation block estimates the motion between the previous frame and the current frame, and uses this information to warp the previous frame to the current frame. This helps the generator to produce more realistic images by taking into account the temporal information in the video sequence."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8fcb2dc6-60fd-5f80-83ae-e52cf82992b7", "question": "How does the performance of the different models change as the corruption level increases? Which model appears to be the most robust to label corruption?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the different models change as the corruption level increases? Which model appears to be the most robust to label corruption?", "reference_answer": "As the corruption level increases, the performance of all models decreases. However, ChoiceNet consistently outperforms both ConvNet and ConvNet+Mixup across all corruption levels, maintaining high accuracy even when almost half of the labels are incorrect. This suggests that ChoiceNet is significantly more robust to label corruption compared to the other models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b78161db-0233-5008-892f-0b784f3a22c7", "question": "Which algorithm performs better in terms of F1 Score and Precision on ENRON?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm performs better in terms of F1 Score and Precision on ENRON?", "reference_answer": "GB-KMV performs better than LSH-E in terms of F1 Score and Precision."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5aae4f0c-0122-56f2-8f78-4f8207bc16d7", "question": "What is the relationship between the buffer percentage and the width of the room?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["b2e88660-671f-5a29-bb26-d0a38bf0b01e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure5-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure6-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure12-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure13-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure1-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure11-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure10-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure2-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure8-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-TableI-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure9-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure4-1.png", "data/dataset/spiqa/images/1809.01246v1/1809.01246v1-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the buffer percentage and the width of the room?", "reference_answer": "The buffer percentage decreases as the width of the room increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2503556b-5e5a-5a39-a3c4-4e56862fdc5e", "question": "How does the connectivity of the Daitch hard scalable model compare to the Daitch soft scalable model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["899c7847-3791-54c0-a744-bb747ecb1fd5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure8-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure9-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure10-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure15-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure1-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure7-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure11-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure4-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure5-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure12-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure13-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure6-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Figure14-1.png", "data/dataset/spiqa/images/1710.05654v2/1710.05654v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the connectivity of the Daitch hard scalable model compare to the Daitch soft scalable model?", "reference_answer": "The Daitch hard scalable model has a higher connectivity than the Daitch soft scalable model. This can be seen in the figure, where the bars for the hard model are generally higher than the bars for the soft model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5f16d600-e0d2-5828-83d2-1c1547fe6ff4", "question": "which lstm models did they compare with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["52401b8c-9c2c-5db5-8107-cbfc6855f629"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07090/4-Table1-1.png", "data/dataset/spiqa/images/1703.07090/5-Figure1-1.png", "data/dataset/spiqa/images/1703.07090/6-Table3-1.png", "data/dataset/spiqa/images/1703.07090/6-Table2-1.png", "data/dataset/spiqa/images/1703.07090/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "which lstm models did they compare with?", "reference_answer": "Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "03a833bf-7949-5a52-aa70-2fcd6145b5de", "question": "How many people participated in their evaluation study of table-to-text models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f66ecb48-d5bf-558e-800b-964715930502"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.01081/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.01081/2-Figure1-1.png", "data/dataset/spiqa/images/1906.01081/5-Table1-1.png", "data/dataset/spiqa/images/1906.01081/6-Figure2-1.png", "data/dataset/spiqa/images/1906.01081/6-Table2-1.png", "data/dataset/spiqa/images/1906.01081/7-Figure3-1.png", "data/dataset/spiqa/images/1906.01081/7-Figure4-1.png", "data/dataset/spiqa/images/1906.01081/8-Table3-1.png", "data/dataset/spiqa/images/1906.01081/8-Table4-1.png", "data/dataset/spiqa/images/1906.01081/9-Figure5-1.png", "data/dataset/spiqa/images/1906.01081/11-Figure6-1.png", "data/dataset/spiqa/images/1906.01081/11-Table5-1.png", "data/dataset/spiqa/images/1906.01081/12-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many people participated in their evaluation study of table-to-text models?", "reference_answer": "about 500", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a8fc10c9-5ac9-50de-9915-7b75055756d3", "question": "Fast YOLO processes double the mAP of other real-time detectors, what is the actual value of the mAP ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Fast YOLO processes double the mAP of other real-time detectors, what is the actual value of the mAP ?", "reference_answer": "The baseline YOLO model shows 63.4% mAP at 45fps on the Pascal VOC dataset, while Fast YOLO is on 52.7 mAP at 150fps. Still, they are more than twice more accurate compared to other real-time detectors. However, the YOLO network was observed to struggle with small objects but is generalizable well to other domains."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "11177dee-2c68-59e4-9ccb-2c154c3da5b5", "question": "Which baselines did they compare against?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9b317efd-a981-5ed6-8252-048914d85be5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.02286/6-Table1-1.png", "data/dataset/spiqa/images/1809.02286/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.02286/3-Figure1-1.png", "data/dataset/spiqa/images/1809.02286/4-Figure2-1.png", "data/dataset/spiqa/images/1809.02286/6-Table1-1.png", "data/dataset/spiqa/images/1809.02286/6-Table2-1.png", "data/dataset/spiqa/images/1809.02286/7-Figure4-1.png", "data/dataset/spiqa/images/1809.02286/7-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which baselines did they compare against?", "reference_answer": "Various tree structured neural networks including variants of Tree-LSTM, Tree-based CNN, RNTN, and non-tree models including variants of LSTMs, CNNs, residual, and self-attention based networks", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "28d00f09-c4a0-53df-ba27-5e697d8de0bf", "question": "How are documents ranked and pruned in the telescoping architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5236776a-47d8-5fdc-9606-592245a5a1ba"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure1-1.png", "data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Figure2-1.png", "data/dataset/spiqa/images/1804.04410v2/1804.04410v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How are documents ranked and pruned in the telescoping architecture?", "reference_answer": "Documents are first matched using a pre-defined match plan. Then, they are passed through additional rank-and-prune stages, which are implemented as a cascade of machine learning models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b9bb6024-8e50-5fed-82c6-91b2b4fa0365", "question": "How does the performance of the two-way AdaQA model compare to the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bfcb995d-5e61-5fa9-952c-acca02545555"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table4-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure1-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table5-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure3-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Figure2-1.png", "data/dataset/spiqa/images/1709.08294v3/1709.08294v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of the two-way AdaQA model compare to the one-way AdaQA model and other CNN-based baseline models on the WikiQA dataset?", "reference_answer": "The two-way AdaQA model significantly outperforms the one-way AdaQA model and all other CNN-based baseline models on the WikiQA dataset. This is evident from the higher MAP and MRR values achieved by the two-way model (0.7107 and 0.7304 respectively) compared to the one-way model (0.7005 and 0.7161) and the baseline models."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "de275312-249e-5f84-8588-b0df6418a02e", "question": "What is the relationship between clicks and impressions?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f2e1d9a7-fce3-5c7c-af44-2a80ea5a78dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table1-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure3-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between clicks and impressions?", "reference_answer": "Clicks are a subset of impressions."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "53765f6c-2675-519e-9faf-59fb0589104b", "question": "Is the difference between ORB-SLAM and ORB-SLAM2 that ORB-SLAM only supports monocular cameras?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2c7c33de-6339-5f80-bda0-4e61c6318978"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/2-Figure1-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/4-Figure2-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure3-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-Figure4-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/6-TableI-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure5-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-Figure6-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/7-TableII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-Figure7-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/8-TableIII-1.png", "data/dataset/spiqa/images/877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6/9-TableIV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is the difference between ORB-SLAM and ORB-SLAM2 that ORB-SLAM only supports monocular cameras?", "reference_answer": "ORB-SLAM2 for stereo and RGB-D cameras is built on monocular feature-based ORB-SLAM. This shows that ORB-SLAM only supports monocular cameras as compared with ORB-SLAM."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ba42b907-d6bc-5d07-a983-19a6a3858022", "question": "Which method, C-Tarone or Binarization, achieves higher precision when the number of features is small and the number of data points is large?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["99904617-6a5d-55cb-be9e-259c5fa25b88"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure2-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table1-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure5-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure3-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Figure4-1.png", "data/dataset/spiqa/images/1702.08694v3/1702.08694v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method, C-Tarone or Binarization, achieves higher precision when the number of features is small and the number of data points is large?", "reference_answer": "C-Tarone."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5f23a7b4-c9b4-5dc4-9f2f-fb51436eb37d", "question": "How are the main international development topics that states raise identified?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0036b375-c6e0-51bf-b3f7-ab61d7edf0a4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.05873/2-Figure1-1.png", "data/dataset/spiqa/images/1708.05873/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.05873/2-Figure1-1.png", "data/dataset/spiqa/images/1708.05873/2-Figure2-1.png", "data/dataset/spiqa/images/1708.05873/3-Figure3-1.png", "data/dataset/spiqa/images/1708.05873/4-Figure4-1.png", "data/dataset/spiqa/images/1708.05873/4-Figure5-1.png", "data/dataset/spiqa/images/1708.05873/4-Figure6-1.png", "data/dataset/spiqa/images/1708.05873/5-Figure7-1.png", "data/dataset/spiqa/images/1708.05873/5-Figure9-1.png", "data/dataset/spiqa/images/1708.05873/5-Figure8-1.png", "data/dataset/spiqa/images/1708.05873/6-Figure10-1.png", "data/dataset/spiqa/images/1708.05873/6-Figure11-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How are the main international development topics that states raise identified?", "reference_answer": " They focus on exclusivity and semantic coherence measures: Highly frequent words in a given topic that do not appear very often in other topics are viewed as making that topic exclusive. They select select the 16-topic model, which has the largest positive residual in the regression fit, and provides higher exclusivity at the same level of semantic coherence.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "509dc13e-718e-5608-af21-9eca49fe1a90", "question": "Why is it crucial for the pipeline to identify whether the instruction represents a classification task? How are classification tasks particularly distinct or special?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image", "table"], "anchor_pdf": ["f992c4ad-ce9f-584d-b09e-80bcdf9589b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/1-Figure1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/14-Figure8-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table5-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/16-Table6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/19-Figure9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/2-Figure2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/22-Table10-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/23-Table11-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/4-Table1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Table2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/7-Figure6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why is it crucial for the pipeline to identify whether the instruction represents a classification task? How are classification tasks particularly distinct or special?", "reference_answer": "The main reason why this is a crucial step is because the authors’ pipeline uses a different approach for classification tasks. For non-classification tasks, the authors first prompt a language model to come up with the input fields require, then provide sample inputs, for which the language model generates outputs. However, for classification tasks, the authors first generate the list of classes, and then require the model to provide an example for that instruction for each class. They do this because the first approach, used for non-classification instructions, does not work well for unbalanced classes. This step, of identifying classification tasks, is important since it is not possible to use the same generation technique for both classification and non-classification tasks effectively with the same generation method."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "65dd2251-c13d-57ee-92cc-3a3eceb1f973", "question": "What is the performance of GRU4Rec relative to the baseline in terms of watch time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["471dd631-5637-545b-8765-7491230ef76f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure1-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure4-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure5-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table2-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure6-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Table3-1.png", "data/dataset/spiqa/images/1706.03847v3/1706.03847v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the performance of GRU4Rec relative to the baseline in terms of watch time?", "reference_answer": "GRU4Rec has a slightly higher performance than the baseline in terms of watch time."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1a9a742d-94c3-5ed6-97e7-1cbdf82788e3", "question": "How does the number of state-action pairs affect the optimization landscape for the PPO algorithm?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["291817c4-b436-55c1-a356-e28360b7edb9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure5-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure18-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure19-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure8-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure14-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure6-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure15-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Table1-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure2-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure11-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure16-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure7-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure3-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure12-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure10-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure20-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure17-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure13-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure4-1.png", "data/dataset/spiqa/images/1811.02553v4/1811.02553v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the number of state-action pairs affect the optimization landscape for the PPO algorithm?", "reference_answer": "As the number of state-action pairs increases, the optimization landscape becomes more complex and has more local optima. This makes it more difficult for the PPO algorithm to find the global optimum."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fd2cd643-f3a8-51af-88e2-013afd027480", "question": "How does the NetVLAD layer differ from the original VLAD?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c804ee67-1926-5ef9-b327-509f4405fea3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/1-Figure1-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure2-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/4-Figure3-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/5-Figure4-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/7-Figure5-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/8-Figure6-1.png", "data/dataset/spiqa/images/f971a22287ead6aa23ecd84a4afd8efca57cee3c/8-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How does the NetVLAD layer differ from the original VLAD?", "reference_answer": "The original VLAD method uses hand-crafted features and applies the VLAD technique to them by concatenating multiple VLADs. On the other hand, NetVLAD layer uses a CNN to extract features and applies the VLAD technique in a single layer by learning the aggregation weights of the residuals (xi − ck) in different parts of the descriptor space. The NetVLAD layer has three independent sets of parameters, {wk}, {bk} and {ck}, that enables greater flexibility and adaptability to the CNN features than the original VLAD method which uses only {ck}."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "ef611dde-9d89-5c55-be72-20b08987b3c6", "question": "What baselines do they compare with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d12d90c-6898-50c2-9c63-eb987796ac17"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00175/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00175/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00175/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What baselines do they compare with?", "reference_answer": "They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "04516009-1aaf-59cb-8394-ea41304b0d47", "question": "Which algorithm converged faster in both cases of target rank?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fc029aa-ec59-529b-be86-ab1fa5d4b0d9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure3-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table1-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure8-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table2-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure6-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure7-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure4-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Figure5-1.png", "data/dataset/spiqa/images/1803.04572v2/1803.04572v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm converged faster in both cases of target rank?", "reference_answer": "SPARTan converged faster in both cases of target rank."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9963a432-5ebd-5031-a181-968e88ee7eb4", "question": "What is the GhostVLAD approach?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["de3148dd-ff01-5fd2-b6fa-9438245883a3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01664/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01664/2-Figure1-1.png", "data/dataset/spiqa/images/2002.01664/3-Table1-1.png", "data/dataset/spiqa/images/2002.01664/4-Table4-1.png", "data/dataset/spiqa/images/2002.01664/4-Table2-1.png", "data/dataset/spiqa/images/2002.01664/4-Figure2-1.png", "data/dataset/spiqa/images/2002.01664/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the GhostVLAD approach?", "reference_answer": "An extension of NetVLAD which replaces hard assignment-based clustering with soft assignment-based clustering with the additon o fusing Ghost clusters to deal with noisy content.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f163982e-3dc3-54c8-9e4d-968a784f9bfc", "question": "Why did the authors have to scale the classifier gradients by a constant factor larger than 1?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["43af4858-0022-5994-85b9-91a867f9919d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/1-Figure1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/10-Table5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Figure6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/11-Table6-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/17-Table8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table10-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/18-Table9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure7-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/20-Figure8-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/21-Figure9-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/24-Figure12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table11-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/27-Table12-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/28-Table14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/29-Table15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/30-Figure13-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/31-Figure14-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/32-Figure15-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/33-Figure16-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/34-Figure17-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/35-Figure18-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/36-Figure19-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/37-Figure20-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/38-Figure21-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/39-Figure22-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/4-Table1-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/40-Figure23-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/41-Figure24-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/42-Figure25-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/43-Figure26-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/44-Figure27-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Figure2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table2-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/5-Table3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/8-Figure3-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure4-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Figure5-1.png", "data/dataset/spiqa/images/64ea8f180d0682e6c18d1eb688afdb2027c02794/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why did the authors have to scale the classifier gradients by a constant factor larger than 1?", "reference_answer": "When using a scale of 1, they observed that the classifier assigned reasonable probabilities (around 50%) to the desired classes for the final samples, but these samples did not match the intended classes upon visual inspection. Scaling up the classifier gradients remedied this problem, and the class probabilities from the classifier increased to nearly 100%. When using a larger gradient scale focuses more on the modes of the classifier, which is potentially desirable for producing higher fidelity (but less diverse) samples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "56084e33-e3d3-5409-b18a-a859fc9f1fa3", "question": "How does the difficulty of performing a successful targeted keywords attack change as the number of targeted keywords increases?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4979a3cd-d95a-5e60-a12e-08263adccd51"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table4-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table5-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table6-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table7-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table8-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table9-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table1-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table2-1.png", "data/dataset/spiqa/images/1803.01128v3/1803.01128v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the difficulty of performing a successful targeted keywords attack change as the number of targeted keywords increases?", "reference_answer": "The difficulty of performing a successful targeted keywords attack increases as the number of targeted keywords increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "f46b33bf-5a0c-5ff4-8805-d1510e152e2c", "question": "What is the relationship between the number of workers per \"expert\" and Cohen's kappa agreement for stance annotation?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0423e038-405f-5171-a89b-75e3079e5aa6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the number of workers per \"expert\" and Cohen's kappa agreement for stance annotation?", "reference_answer": "The Cohen's kappa agreement for stance annotation increases as the number of workers per \"expert\" increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "8737fd11-86ce-5749-bf82-ad190979d086", "question": "Why does YOLO struggle in localizing objects correctly ?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f77f0f0e-3bcc-5fd4-bcee-a4a9fd41a566"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/1-Figure1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/2-Figure2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/3-Figure3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Figure4-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table1-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/6-Table2-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/7-Table3-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure5-1.png", "data/dataset/spiqa/images/f8e79ac0ea341056ef20f2616628b3e964764cfd/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why does YOLO struggle in localizing objects correctly ?", "reference_answer": "Although YOLO is a really fast model, it usually struggles with localizing small objects in a group or objects near each other. In fact, localization errors take up more than half of all YOLO's errors. It happens because YOLO has only a limited number of bounding boxes per grid cell and the loss function penalizes the errors in the large and small bounding boxes the same. On top of that, the model uses coarse features to predict bounding boxes, and it may have problems with unusual aspect ratios and configurations of objects."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "cfeca792-4599-5b59-8f7d-b9198f0a1f85", "question": "How does increasing the parameter value (ρ for LIME with Euclidean distance, μ for LIME with cosine similarity, and σ for Parzen) seem to affect the influence vectors?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["562bd590-5817-560b-97d0-c246b4293ab9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table2-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table3-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table1-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Table4-1.png", "data/dataset/spiqa/images/1708.02153v2/1708.02153v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does increasing the parameter value (ρ for LIME with Euclidean distance, μ for LIME with cosine similarity, and σ for Parzen) seem to affect the influence vectors?", "reference_answer": "As the parameter value increases, the influence vectors generally become smoother and less noisy."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a6d4183b-bb34-5bcf-871c-d478ffb63ab1", "question": "How does the number of classes affect the setup and online time for the Softmax?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the number of classes affect the setup and online time for the Softmax?", "reference_answer": "The setup and online time for the Softmax increases as the number of classes increases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "04fa46da-06dc-5168-8715-d603aa70c834", "question": "How does the proposed method compare to H.264 in terms of MS-SSIM score at low bitrates?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the proposed method compare to H.264 in terms of MS-SSIM score at low bitrates?", "reference_answer": "The proposed method achieves significantly higher MS-SSIM scores than H.264 at bitrates below 10 Kbps."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ba96ccc9-f3b5-5d77-8c72-7884d8979683", "question": "What is the role of the RR optimization in the delta-based synchronization of a GSet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["db5ff7ab-804d-53f2-b53f-6241e3d0bbc2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure1-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableI-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure6-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure7-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure13-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure2-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure3-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure8-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure4-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure5-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure9-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure10-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIII-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-TableIV-1.png", "data/dataset/spiqa/images/1803.02750v3/1803.02750v3-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the RR optimization in the delta-based synchronization of a GSet?", "reference_answer": "The RR optimization helps to reduce the number of messages that need to be exchanged between replicas."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5f7b7988-67de-5977-828e-04e402b24a15", "question": "Why did the authors measure the perturbations using the L`2 norm?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4bc68d1d-c421-567f-a14a-076cb7acca37"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/1-Figure1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/3-Figure3-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure4-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/4-Figure5-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table1-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/6-Table2-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure6-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/7-Figure7-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure8-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Figure9-1.png", "data/dataset/spiqa/images/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Why did the authors measure the perturbations using the L`2 norm?", "reference_answer": "The authors claim that the DeepFool algorithm is a well-founded baseline for finding adversarial perturbations for state-of-the-art models. Although the use of the l-2 norm is not explicitly justified within the paper, it is a reasonable choice taking into account the scarcity of baseline methods. Also, the method can be easily adapted to any l-p norm and the claims of the paper seem to hold for the l-infinity norm."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "671cfff8-d9ac-5b5d-9406-095b478cf4bf", "question": "Which of the methods generated the sharpest details?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["230fe7f5-2b3b-5dce-a866-f96ac306f155"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure14-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure13-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure15-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure16-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure8-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure12-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure2-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure23-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure9-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure10-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure4-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table6-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure22-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Table3-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure11-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure5-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure19-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure18-1.png", "data/dataset/spiqa/images/1811.09393v4/1811.09393v4-Figure20-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the methods generated the sharpest details?", "reference_answer": "TecoGAN"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "48722da2-b645-57e3-b90e-4ee38a87b38d", "question": "How does the model capture different perspectives on immigration when considering tone as a covariate?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["8e42cbff-6fda-595c-a48a-e93888562944"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table6-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure2-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure3-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Figure1-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table4-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table5-1.png", "data/dataset/spiqa/images/1705.09296v2/1705.09296v2-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the model capture different perspectives on immigration when considering tone as a covariate?", "reference_answer": "The model captures different perspectives on immigration by highlighting contrasting words associated with the same topic, depending on whether the tone is anti-immigration or pro-immigration."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1e7bff76-e181-5c31-a6da-1078a59b70c5", "question": "How many labels do the datasets have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4d12231b-5489-5dd9-8b53-571fca989879"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00530/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00530/5-Table1-1.png", "data/dataset/spiqa/images/1809.00530/7-Figure1-1.png", "data/dataset/spiqa/images/1809.00530/8-Figure2-1.png", "data/dataset/spiqa/images/1809.00530/8-Figure3-1.png", "data/dataset/spiqa/images/1809.00530/9-Table2-1.png", "data/dataset/spiqa/images/1809.00530/11-Table3-1.png", "data/dataset/spiqa/images/1809.00530/12-Table4-1.png", "data/dataset/spiqa/images/1809.00530/13-Table5-1.png", "data/dataset/spiqa/images/1809.00530/14-Table6-1.png", "data/dataset/spiqa/images/1809.00530/15-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many labels do the datasets have?", "reference_answer": "Book, Electronics, Beauty and Music each have 6000, IMDB 84919, Yelp 231163, Cell Phone 194792 and Baby 160792 labeled data.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "abc6e1cd-bbc3-5cdc-bf3c-f22bb98b904f", "question": "Can this adversarial approach be used to directly improve model accuracy?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["ee3a23d4-fd3a-50ff-9cdd-b845dac79197"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.00563/12-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.00563/2-Figure1-1.png", "data/dataset/spiqa/images/1905.00563/4-Figure2-1.png", "data/dataset/spiqa/images/1905.00563/5-Table1-1.png", "data/dataset/spiqa/images/1905.00563/5-Table2-1.png", "data/dataset/spiqa/images/1905.00563/5-Figure3-1.png", "data/dataset/spiqa/images/1905.00563/6-Table3-1.png", "data/dataset/spiqa/images/1905.00563/7-Table4-1.png", "data/dataset/spiqa/images/1905.00563/7-Figure4-1.png", "data/dataset/spiqa/images/1905.00563/7-Table5-1.png", "data/dataset/spiqa/images/1905.00563/8-Table6-1.png", "data/dataset/spiqa/images/1905.00563/12-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Can this adversarial approach be used to directly improve model accuracy?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3c0cfdf3-aafb-50aa-92c6-ae497a067349", "question": "How does the size of the reference set ($X_\\textsf{ref}$) used for DMP training differ between the Purchase/Texas datasets and the CIFAR datasets? Explain the rationale behind this difference.", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7eef245d-f7ec-5aa3-ab7f-bebb0acde1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table2-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table4-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table5-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table6-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table3-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure3-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table11-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table12-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure5-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure6-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure7-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure1-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure4-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table7-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table8-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table9-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table10-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table1-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the size of the reference set ($X_\\textsf{ref}$) used for DMP training differ between the Purchase/Texas datasets and the CIFAR datasets? Explain the rationale behind this difference.", "reference_answer": "For Purchase and Texas datasets, $X_\\textsf{ref}$ is specifically selected and contains 10,000 data points. In contrast, for CIFAR datasets, the entire remaining data (25,000 points) after selecting $D_\\textsf{tr}$ is used as $X_\\textsf{ref}$. This difference is due to the smaller size of the CIFAR datasets. Using the entire remaining data as $X_\\textsf{ref}$ ensures sufficient data for effective DMP training in these cases."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "95a4fa57-79d0-57f2-9f53-5d9e99d759b4", "question": "Which algorithm performs best on the ENRON dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ff09d751-b356-516e-bf8e-46987535dddb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure4-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure3-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure5-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure15-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure14-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure16-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableI-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableIII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure12-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure13-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure11-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure1-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure8-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure7-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure9-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure10-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-TableII-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure2-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure19-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure18-1.png", "data/dataset/spiqa/images/1809.00458v1/1809.00458v1-Figure17-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which algorithm performs best on the ENRON dataset?", "reference_answer": "GB-KMV"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d4b9dca1-56cf-5045-9e7f-cc8f08a081bd", "question": "What languages are represented in the dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["71d35c80-94df-58b3-985c-3aa94932a9e4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.06748/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.06748/2-Table1-1.png", "data/dataset/spiqa/images/1910.06748/3-Table2-1.png", "data/dataset/spiqa/images/1910.06748/5-Figure1-1.png", "data/dataset/spiqa/images/1910.06748/6-Table3-1.png", "data/dataset/spiqa/images/1910.06748/7-Table4-1.png", "data/dataset/spiqa/images/1910.06748/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What languages are represented in the dataset?", "reference_answer": "EN, JA, ES, AR, PT, KO, TH, FR, TR, RU, IT, DE, PL, NL, EL, SV, FA, VI, FI, CS, UK, HI, DA, HU, NO, RO, SR, LV, BG, UR, TA, MR, BN, IN, KN, ET, SL, GU, CY, ZH, CKB, IS, LT, ML, SI, IW, NE, KM, MY, TL, KA, BO", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d76b5bdb-1d9b-5ef7-9952-b2ac7d31fe4b", "question": "Which component of the model seems to have the biggest impact on the F1 score on SQuAD dataset, and how much does removing it affect the score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e31707d3-f5f4-5c59-86a2-af24ff7cfed7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which component of the model seems to have the biggest impact on the F1 score on SQuAD dataset, and how much does removing it affect the score?", "reference_answer": "The DCRL training method appears to have the biggest impact on the F1 score. Removing it leads to a drop of 0.9 points in F1, which is the largest decrease observed for any single component in the ablation study."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b41b0c96-a6bf-5af9-a211-f5017bb108e3", "question": "What TIMIT datasets are used for testing?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["4343d7d9-68ce-515d-b50d-99598da35960"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.07601/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.07601/3-Figure1-1.png", "data/dataset/spiqa/images/1910.07601/4-Figure2-1.png", "data/dataset/spiqa/images/1910.07601/4-Table1-1.png", "data/dataset/spiqa/images/1910.07601/5-Figure3-1.png", "data/dataset/spiqa/images/1910.07601/5-Table2-1.png", "data/dataset/spiqa/images/1910.07601/6-Figure4-1.png", "data/dataset/spiqa/images/1910.07601/6-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What TIMIT datasets are used for testing?", "reference_answer": "Once split into 8 subsets (A-H), the test set used are blocks D+H and blocks F+H", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "05bc43ae-65b3-5310-ba62-4457ab4efa1b", "question": " \n\nWhy does the author state that there is a qualitative difference between 2-D and 1-D division?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f51e9f68-1547-5a42-8e74-fbfbfcb7f509"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure5-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure3-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure4-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Table1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure1-1.png", "data/dataset/spiqa/images/1603.00286v5/1603.00286v5-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": " \n\nWhy does the author state that there is a qualitative difference between 2-D and 1-D division?", "reference_answer": " \n\nIn 2-D division, there may be unallocated cake even when there are geometric constraints on the pieces, as shown in Figure 1. This is not the case in 1-D division, where the entire cake can always be allocated."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "3b14fc08-89fe-56d8-9d0f-649cd25c2772", "question": "Is the baseline a non-heirarchical model like BERT?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5d3ec964-0a02-5cb6-b18d-64c632411270"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1905.06566/7-Table1-1.png", "data/dataset/spiqa/images/1905.06566/8-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1905.06566/3-Figure1-1.png", "data/dataset/spiqa/images/1905.06566/5-Figure2-1.png", "data/dataset/spiqa/images/1905.06566/7-Table1-1.png", "data/dataset/spiqa/images/1905.06566/8-Table4-1.png", "data/dataset/spiqa/images/1905.06566/8-Table2-1.png", "data/dataset/spiqa/images/1905.06566/8-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the baseline a non-heirarchical model like BERT?", "reference_answer": "There were hierarchical and non-hierarchical baselines; BERT was one of those baselines", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "1e08b1be-85a0-597d-be90-7f26367c8f4a", "question": "Which method performed the best on the PASCAL VOC 2012 test set and how does it compare to the baseline model without self-correction?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["47d9e949-3f5f-5dba-8bff-559cc8bbac1e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table3-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Table2-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure1-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure4-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure5-1.png", "data/dataset/spiqa/images/1811.07073v3/1811.07073v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method performed the best on the PASCAL VOC 2012 test set and how does it compare to the baseline model without self-correction?", "reference_answer": "The Conv. Self-Corr. method achieved the highest performance on the PASCAL VOC 2012 test set with a score of 82.72. This is approximately 1.11 points higher than the baseline model (\"No Self-Corr.\") which achieved a score of 81.61."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "546c797c-535e-56f0-8ed7-7ae69d6c8281", "question": "Which model performed the best on the test data?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7eef245d-f7ec-5aa3-ab7f-bebb0acde1ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table10-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table2-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table4-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table5-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table6-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table3-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure3-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table11-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table12-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure5-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure6-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure7-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure1-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure4-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table7-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table8-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table9-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table10-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Table1-1.png", "data/dataset/spiqa/images/1906.06589v3/1906.06589v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed the best on the test data?", "reference_answer": "P-FC"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "10182322-2683-5eae-bfd2-123b60e67039", "question": "What is the relationship between the movies \"Forrest Gump\" and \"Cast Away\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["dcb4ff69-afbb-52d2-a697-cf08cb0e132a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table1-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure6-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure7-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure2-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure3-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table4-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Table5-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure8-1.png", "data/dataset/spiqa/images/1803.03467v4/1803.03467v4-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the movies \"Forrest Gump\" and \"Cast Away\"?", "reference_answer": "The movies \"Forrest Gump\" and \"Cast Away\" are connected by the actor Tom Hanks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c0aba71c-7efb-54cb-ad24-dc116674a556", "question": "Based on the table, how does MTSA compare to the Bi-LSTM and Multi-CNN baselines in terms of performance and training time?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e12c7d24-8cfc-57b1-b048-9a36c5251d57"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table3-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table4-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table5-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table6-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Based on the table, how does MTSA compare to the Bi-LSTM and Multi-CNN baselines in terms of performance and training time?", "reference_answer": "MTSA outperforms both Bi-LSTM and Multi-CNN baselines across all evaluation metrics (P, R, F1, and Comp.) on all three test sets (Development, WSJ Test, and Brown Test). While MTSA achieves the highest scores, its training time is comparable to Multi-head and Multi-CNN, and significantly faster than Bi-LSTM."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c5da86d3-cd10-5e22-89f4-2f5ed24cf8eb", "question": "is the dataset balanced across the four languages?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["82c6dc69-cf50-5a75-9149-2372efec282e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1710.09589/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1710.09589/1-Figure1-1.png", "data/dataset/spiqa/images/1710.09589/2-Table1-1.png", "data/dataset/spiqa/images/1710.09589/2-Figure2-1.png", "data/dataset/spiqa/images/1710.09589/4-Table3-1.png", "data/dataset/spiqa/images/1710.09589/4-Table2-1.png", "data/dataset/spiqa/images/1710.09589/5-Table5-1.png", "data/dataset/spiqa/images/1710.09589/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "is the dataset balanced across the four languages?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "cd717713-af37-5be7-ab11-341209463de7", "question": "What is the role of the parameter network in the weighting and refinement stage?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c22744dc-9ec3-5d8b-a70f-fe331e4ec8a7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure4-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure5-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure6-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure7-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure11-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure15-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure14-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure8-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure2-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure16-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure13-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure10-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure9-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Table1-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure18-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure17-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure3-1.png", "data/dataset/spiqa/images/1704.07854v4/1704.07854v4-Figure12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the role of the parameter network in the weighting and refinement stage?", "reference_answer": "The parameter network is used to infer a weighting function."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e6e178c0-ea9b-5281-a6ae-d15b123edf2d", "question": "which non-english language had the best performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["fffd3285-1bba-5935-a5b9-c4e567574c61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1806.04511/3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1806.04511/2-Figure1-1.png", "data/dataset/spiqa/images/1806.04511/3-Table2-1.png", "data/dataset/spiqa/images/1806.04511/3-Figure2-1.png", "data/dataset/spiqa/images/1806.04511/3-Table3-1.png", "data/dataset/spiqa/images/1806.04511/3-Table1-1.png", "data/dataset/spiqa/images/1806.04511/3-Table4-1.png", "data/dataset/spiqa/images/1806.04511/4-Figure3-1.png", "data/dataset/spiqa/images/1806.04511/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "which non-english language had the best performance?", "reference_answer": "Russsian", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b5010ff4-ad4d-5134-972c-6364620c2c21", "question": "Which pooling method is the most accurate for the AFEW database?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5ce6798c-a395-5175-8b83-6e7fa08c4245"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure1-1.png", "data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure2-1.png", "data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which pooling method is the most accurate for the AFEW database?", "reference_answer": "W-ProjPooling"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4d872a2a-dc2f-5cff-9321-16a40f018429", "question": "How many roles are proposed?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c3721d2c-0998-51bc-aef7-eebcb51b73ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1806.07711/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1806.07711/3-Figure1-1.png", "data/dataset/spiqa/images/1806.07711/4-Figure2-1.png", "data/dataset/spiqa/images/1806.07711/5-Table1-1.png", "data/dataset/spiqa/images/1806.07711/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many roles are proposed?", "reference_answer": "12", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ce836946-ee33-5a0f-9a95-8ab78e91aa0e", "question": "Which system from Ortiz et al. achieved the highest BLEU and METEOR scores, and how does it compare to the CCA inference algorithm in terms of performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9fc65b20-aacf-5ce9-985f-563eea766f61"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure4-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure5-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure6-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure1-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure2-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Figure3-1.png", "data/dataset/spiqa/images/1608.02784v2/1608.02784v2-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which system from Ortiz et al. achieved the highest BLEU and METEOR scores, and how does it compare to the CCA inference algorithm in terms of performance?", "reference_answer": "The SMT system from Ortiz et al. achieved the highest BLEU score (43.7) and METEOR score (35.6) among their tested systems. While the SMT system outperforms the CCA inference algorithm in terms of BLEU score, the CCA algorithm achieves a slightly higher METEOR score (25.6 vs 25.5)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "1997e0a9-8984-52ab-94e0-fd7eda856622", "question": "Does the author showed that the distillation on the knowledge graph can be useful for re-ranking task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c2ce8e68-6fc4-5e1d-b409-ebb07c73d811"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table5-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table6-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/10-Table7-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/2-Figure1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/4-Figure2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/5-Figure3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/6-Figure4-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/8-Table1-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table2-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table3-1.png", "data/dataset/spiqa/images/ca8f25b6c49c7f34380a7c6623e74f63f3a48771/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does the author showed that the distillation on the knowledge graph can be useful for re-ranking task?", "reference_answer": "This work proposes using knowledge graph distillation as it can help retain only informative knowledge needed for passage re-ranking. By investigating the effect of global and local distillation separately, this work found that the MRR@10 score and efficiency decreased slightly without global distillation, and that time efficiency decreased the most without local distillation. Therefore, this work demonstrates that both global and local distillation of knowledge graphs is useful for re-ranking tasks in terms of performance and efficiency."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "709b7cea-2958-543d-a397-bd5ab7db79a3", "question": "How big are the datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7a28686d-3c69-56cf-986e-fac95a530ad2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1911.00069/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1911.00069/3-Figure1-1.png", "data/dataset/spiqa/images/1911.00069/6-Table1-1.png", "data/dataset/spiqa/images/1911.00069/6-Table2-1.png", "data/dataset/spiqa/images/1911.00069/7-Figure2-1.png", "data/dataset/spiqa/images/1911.00069/7-Table3-1.png", "data/dataset/spiqa/images/1911.00069/8-Table4-1.png", "data/dataset/spiqa/images/1911.00069/9-Table5-1.png", "data/dataset/spiqa/images/1911.00069/9-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How big are the datasets?", "reference_answer": "In-house dataset consists of  3716 documents \nACE05 dataset consists of  1635 documents", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bf8d034f-2d45-5fc9-a65c-96804b34a6d6", "question": "did they use a crowdsourcing platform for manual annotations?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["0a9b2ff8-2d23-5232-b095-a4ca2db6a03b"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1810.08699/3-Figure3-1.png", "data/dataset/spiqa/images/1810.08699/3-Figure2-1.png", "data/dataset/spiqa/images/1810.08699/3-TableII-1.png"], "reference_image": ["data/dataset/spiqa/images/1810.08699/2-Figure1-1.png", "data/dataset/spiqa/images/1810.08699/3-TableI-1.png", "data/dataset/spiqa/images/1810.08699/3-Figure2-1.png", "data/dataset/spiqa/images/1810.08699/3-Figure3-1.png", "data/dataset/spiqa/images/1810.08699/3-TableII-1.png", "data/dataset/spiqa/images/1810.08699/4-Figure4-1.png", "data/dataset/spiqa/images/1810.08699/5-TableIII-1.png", "data/dataset/spiqa/images/1810.08699/5-TableIV-1.png", "data/dataset/spiqa/images/1810.08699/5-TableV-1.png", "data/dataset/spiqa/images/1810.08699/5-TableVI-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "did they use a crowdsourcing platform for manual annotations?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "85e331ae-d977-5a74-b4bd-a4840f1ea949", "question": "When they say \"comparable performance\", how much of a performance drop do these new embeddings result in?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0cbe7c41-fdbf-5d2f-a995-e85a1575d1fb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.03547/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.03547/4-Table1-1.png", "data/dataset/spiqa/images/1712.03547/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "When they say \"comparable performance\", how much of a performance drop do these new embeddings result in?", "reference_answer": "Performance was comparable, with the proposed method quite close and sometimes exceeding performance of baseline method.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "97d5e7f0-8a4e-5e30-b9a9-06e2e90093a5", "question": "How BLINK can achieved zero-shot linking?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/2-Figure1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Figure2-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Table1-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/4-Table2-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table3-1.png", "data/dataset/spiqa/images/592a6691373f3936631bc4ac122f69df09c842bd/5-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How BLINK can achieved zero-shot linking?", "reference_answer": "The BLINK model used a two-stage approach for entity linking based on fine-tuned BERT architectures that first encode the mention context and entity text with the bi-encoder for the candidate retrieval and utilize the cross-encoder to score and rank them. These pre-trained architectures are simple yet scalable and effective for entity link tasks without the help of task-specific heuristics or external knowledge. The authors showed that BLINK can achieve state-of-the-art performance for the large-scale entity linking on the dataset with a zero-shot setup. (WikilinksNED Unseen-Mentions and TACKBP-201)"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f5a00fe1-7fc2-59a1-8b24-931f453ab7cd", "question": "How many feature maps are generated for a given triple?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["2287765e-006c-57a2-ace2-6bb971359e5f"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1712.02121/3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1712.02121/2-Table1-1.png", "data/dataset/spiqa/images/1712.02121/3-Table2-1.png", "data/dataset/spiqa/images/1712.02121/3-Figure1-1.png", "data/dataset/spiqa/images/1712.02121/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How many feature maps are generated for a given triple?", "reference_answer": "3 feature maps for a given tuple", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0012be75-2bac-52fe-ac28-82b55725c495", "question": "Which component is the least impactful?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["80de2d64-8dce-51a3-8dd4-caab45d1c756"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.06267/7-Table3-1.png", "data/dataset/spiqa/images/1908.06267/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.06267/5-Table1-1.png", "data/dataset/spiqa/images/1908.06267/7-Table2-1.png", "data/dataset/spiqa/images/1908.06267/7-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which component is the least impactful?", "reference_answer": "Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2cb4e7af-08a9-51bd-8b44-32c760205d76", "question": "Do they train a different training method except from scheduled sampling?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["c515d7fb-6048-5942-8cd3-8f8daf2609b5"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.07023/6-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.07023/1-Table1-1.png", "data/dataset/spiqa/images/1812.07023/3-Figure1-1.png", "data/dataset/spiqa/images/1812.07023/3-Figure2-1.png", "data/dataset/spiqa/images/1812.07023/3-Figure3-1.png", "data/dataset/spiqa/images/1812.07023/4-Table2-1.png", "data/dataset/spiqa/images/1812.07023/5-Table3-1.png", "data/dataset/spiqa/images/1812.07023/6-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Do they train a different training method except from scheduled sampling?", "reference_answer": "Answer with content missing: (list missing) \nScheduled sampling: In our experiments, we found that models trained with scheduled sampling performed better (about 0.004 BLEU-4 on validation set) than the ones trained using teacher-forcing for the AVSD dataset. Hence, we use scheduled sampling for all the results we report in this paper.\n\nYes.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "47e4a4b9-04bf-5eeb-a682-cb0477733277", "question": "Does making higher resolution have to be incorporated into the network? Can't we do this as a separate process?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6289cc59-2b2e-5bd4-960b-464736490910"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/7-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/14-Figure5-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/3-Figure1-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/5-Table1-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/6-Table3-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/7-Figure2-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/7-Table4-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/8-Figure3-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/8-Table5-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/8-Table6-1.png", "data/dataset/spiqa/images/3b2a675bb617ae1a920e8e29d535cdf27826e999/9-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does making higher resolution have to be incorporated into the network? Can't we do this as a separate process?", "reference_answer": "Video diffusion models modify little of the archicture to accommodate video data within the memory constraints of deep learning accelerators. They approach with the standard diffusion modelformalism. In their method, one of skill to make high resolution video is the spatial upsampling introduced by Menick and Kalchbrenner (2019).\nAlso, reconstruction guidance is extended to constuct the high-resolution model. When they have low resolution ground truth videos, it upsamples them into high resolution videos using an unconditional high resolution diffusion model."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "29a07263-9c5c-5ec4-957a-12211b397823", "question": "Which of the algorithms performs the best on the robotic arm joint breakage task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8c7be9b7-996b-52f8-8ae5-0edf75c44da1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table2-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure4-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure6-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure11-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure10-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure1-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Table3-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure9-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure8-1.png", "data/dataset/spiqa/images/1605.07496v3/1605.07496v3-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which of the algorithms performs the best on the robotic arm joint breakage task?", "reference_answer": "ALOQ."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9007d6c0-a958-50f5-be5e-57e2c82da74e", "question": "Which TCP stack provides the most complete implementation of core TCP features, and which stack lacks the most features?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["abe29837-d342-5b88-bbad-5d04f8eeb2be"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table4-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure10-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure3-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure13-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure12-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure5-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table2-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table7-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure11-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure6-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table8-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table9-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Figure1-1.png", "data/dataset/spiqa/images/1811.02721v3/1811.02721v3-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which TCP stack provides the most complete implementation of core TCP features, and which stack lacks the most features?", "reference_answer": "The TCP stack presented in this paper (TCPlp) provides the most complete implementation of core TCP features, including flow control, congestion control, RTT estimation, MSS option, OOO reassembly, and various advanced features like timestamps and selective ACKs. In contrast, BLIP lacks the most features, as it does not implement congestion control, RTT estimation, or several other functionalities present in other stacks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e1868795-6585-5f28-9dbd-f1610b62bf0d", "question": "How does the performance of ChoiceNet compare to other methods under different noise settings on the CIFAR-10 dataset? Briefly explain the strengths and weaknesses of ChoiceNet. ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["39616d7f-7cca-5af8-a183-7a1fe3ecd0ef"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure8-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table15-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table5-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table6-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure7-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure1-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table4-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure2-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure12-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table11-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table10-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table14-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure13-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure3-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Table9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure9-1.png", "data/dataset/spiqa/images/1805.06431v4/1805.06431v4-Figure10-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of ChoiceNet compare to other methods under different noise settings on the CIFAR-10 dataset? Briefly explain the strengths and weaknesses of ChoiceNet. ", "reference_answer": "ChoiceNet generally performs well compared to other methods, achieving the highest accuracy on both symmetric noise settings (sym-50% and sym-20%). However, it falls to second place under the Pair-45% asymmetric noise setting, indicating a weakness in handling this specific type of noise."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "db53cfbb-ccdb-527b-a8f7-202ad947ee72", "question": "What are the linguistic differences between each class?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d3ad5387-9dcd-5b57-a355-223a051c9569"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.05404/8-Table9-1.png", "data/dataset/spiqa/images/1709.05404/9-Table12-1.png", "data/dataset/spiqa/images/1709.05404/8-Table10-1.png", "data/dataset/spiqa/images/1709.05404/9-Table11-1.png", "data/dataset/spiqa/images/1709.05404/9-Table13-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.05404/2-Table1-1.png", "data/dataset/spiqa/images/1709.05404/2-Table2-1.png", "data/dataset/spiqa/images/1709.05404/3-Figure1-1.png", "data/dataset/spiqa/images/1709.05404/4-Table3-1.png", "data/dataset/spiqa/images/1709.05404/4-Table4-1.png", "data/dataset/spiqa/images/1709.05404/5-Figure2-1.png", "data/dataset/spiqa/images/1709.05404/5-Table5-1.png", "data/dataset/spiqa/images/1709.05404/5-Table6-1.png", "data/dataset/spiqa/images/1709.05404/6-Table7-1.png", "data/dataset/spiqa/images/1709.05404/6-Figure3-1.png", "data/dataset/spiqa/images/1709.05404/7-Table8-1.png", "data/dataset/spiqa/images/1709.05404/8-Table9-1.png", "data/dataset/spiqa/images/1709.05404/8-Figure4-1.png", "data/dataset/spiqa/images/1709.05404/8-Table10-1.png", "data/dataset/spiqa/images/1709.05404/9-Table13-1.png", "data/dataset/spiqa/images/1709.05404/9-Table11-1.png", "data/dataset/spiqa/images/1709.05404/9-Table12-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the linguistic differences between each class?", "reference_answer": "Each class has different patterns in adjectives, adverbs and verbs for sarcastic and non-sarcastic classes", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "3881beb8-a1c0-5705-a088-d2d8515e5b73", "question": "Is the data acquired under distant supervision verified by humans at any stage?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["3bb937a0-4a80-51d3-84fd-f9e14eb336f7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1610.00879/4-Table5-1.png", "data/dataset/spiqa/images/1610.00879/4-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1610.00879/2-Figure1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table1-1.png", "data/dataset/spiqa/images/1610.00879/3-Table2-1.png", "data/dataset/spiqa/images/1610.00879/4-Table4-1.png", "data/dataset/spiqa/images/1610.00879/4-Table3-1.png", "data/dataset/spiqa/images/1610.00879/4-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the data acquired under distant supervision verified by humans at any stage?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "de7346c6-5d89-5b6e-b912-b826c78aff46", "question": "did they outperform previous methods?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["6c8ee233-4bf5-5bba-9235-f9496c1ed0b4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1806.00722/7-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1806.00722/3-Figure1-1.png", "data/dataset/spiqa/images/1806.00722/3-Figure2-1.png", "data/dataset/spiqa/images/1806.00722/5-Figure3-1.png", "data/dataset/spiqa/images/1806.00722/6-Figure4-1.png", "data/dataset/spiqa/images/1806.00722/6-Figure5-1.png", "data/dataset/spiqa/images/1806.00722/7-Table1-1.png", "data/dataset/spiqa/images/1806.00722/7-Table2-1.png", "data/dataset/spiqa/images/1806.00722/8-Table3-1.png", "data/dataset/spiqa/images/1806.00722/8-Table4-1.png", "data/dataset/spiqa/images/1806.00722/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "did they outperform previous methods?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "ad08e0d3-151f-5992-bf42-efabb8583ede", "question": "Which dataset exhibits the strongest seasonality?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8bc3fcf8-16f0-5f56-9ce9-25a6702751ca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure3-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure1-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure56-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Table2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure6-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure7-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure2-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure4-1.png", "data/dataset/spiqa/images/1703.07015v3/1703.07015v3-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which dataset exhibits the strongest seasonality?", "reference_answer": "The Traffic dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d938c4ed-dd0b-5dd4-9a44-d3aceec0140a", "question": "What are the different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3883ee7d-6df2-5037-93dc-13b5b7ad891a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table1-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure1-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Table2-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure2-1.png", "data/dataset/spiqa/images/1802.07459v2/1802.07459v2-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents?", "reference_answer": "The different stages involved in constructing the Concept Interaction Graph (CIG) from a pair of documents are: (a) Representation, (b) Encoding, (c) Transformation, and (d) Aggregation."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "dce900d4-2134-54ef-81e7-b77d2c1dd105", "question": "How does the encoder understand the last user utterance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9645ca54-1ba7-5f80-b3cc-42fc660c0a06"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table1-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure2-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table13-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table14-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table11-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table12-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure4-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure5-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table6-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure3-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure10-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table9-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table7-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Table8-1.png", "data/dataset/spiqa/images/1805.01216v3/1805.01216v3-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the encoder understand the last user utterance?", "reference_answer": "The encoder understands the last user utterance by using the memory cell representations of the dialog history and KB tuples."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "c538c7c1-5672-5780-853d-073d3524351c", "question": "Is there exactly one \"answer style\" per dataset?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["03783a9f-aefc-568a-94a9-d775185b2072"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1901.02262/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1901.02262/1-Figure1-1.png", "data/dataset/spiqa/images/1901.02262/2-Figure2-1.png", "data/dataset/spiqa/images/1901.02262/4-Figure3-1.png", "data/dataset/spiqa/images/1901.02262/5-Table1-1.png", "data/dataset/spiqa/images/1901.02262/6-Table2-1.png", "data/dataset/spiqa/images/1901.02262/6-Table3-1.png", "data/dataset/spiqa/images/1901.02262/6-Table4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure4-1.png", "data/dataset/spiqa/images/1901.02262/7-Figure5-1.png", "data/dataset/spiqa/images/1901.02262/8-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is there exactly one \"answer style\" per dataset?", "reference_answer": true, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "c10a5401-1a5c-5229-a09b-032424ea49a0", "question": "How does the performance of ITN-V2 compare to other methods when both DDT and ST transformations are applied to the CIFAR-10 dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0968d1f8-8afd-562a-81d4-73b71952f82a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table2-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table6-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure4-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure5-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table7-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table8-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure3-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Table1-1.png", "data/dataset/spiqa/images/1805.06447v3/1805.06447v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the performance of ITN-V2 compare to other methods when both DDT and ST transformations are applied to the CIFAR-10 dataset?", "reference_answer": "ITN-V2 achieves the lowest testing error (56.95%) among all methods listed when both DDT and ST transformations are applied to the CIFAR-10 dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "30d9c950-e81f-52ce-93f6-500cdb1a2d37", "question": "How do the word embeddings learned by the Cap2Img model compare to the original GloVe embeddings in terms of semantic similarity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1d4aae8d-be49-5bef-88ce-e6d9a04354e4"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table5-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table1-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table2-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table3-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table4-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Table5-1.png", "data/dataset/spiqa/images/1707.06320v2/1707.06320v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How do the word embeddings learned by the Cap2Img model compare to the original GloVe embeddings in terms of semantic similarity?", "reference_answer": "The word embeddings learned by the Cap2Img model outperform the original GloVe embeddings in terms of semantic similarity."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "31eb571e-b06d-543e-9a67-5372fa126b40", "question": "Which framework is faster for setting up and running the FC layer?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["5c2232d2-4806-5161-87e6-d90e3dc9a54a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table5-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table6-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure4-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure1-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table3-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Table2-1.png", "data/dataset/spiqa/images/1811.08257v1/1811.08257v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which framework is faster for setting up and running the FC layer?", "reference_answer": "FALCON is faster for both setting up and running the FC layer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "b43850cd-489a-51a1-a3c7-880f597853cc", "question": "Do the authors use different ratios of test-train-validation split for each dataset? ", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["d2d678fc-c8f2-5edf-b804-f78e6cf64638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/2-Figure1-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/4-Figure2-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/6-Figure3-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/8-Figure4-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/8-Figure5-1.png", "data/dataset/spiqa/images/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081/9-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Do the authors use different ratios of test-train-validation split for each dataset? ", "reference_answer": "The authors use different ratios of test-train-validation split for each dataset. Speficially, the authors did not use the predefined ratio value when splitting the data into train-validation-test sets for the three datasets (TIMIT Speech corpus, IAM Online Handwriting Database, and JSB Chorales dataset) used in the experiment. Instead, they used the predefined data split for IAM Online Handwriting Database and JSB Chorales dataset. (5355:3859:2956 and 229:77:76) They also followed Halberstadt [37] in splitting the TIMIT dataset (3696:400:192)."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "accb8fbe-10b8-5f6a-9ef0-5770267f8a35", "question": "Should their approach be applied only when dealing with incomplete data?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["b0f8cb4c-5420-5ada-b490-7aed7819cfd1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png", "data/dataset/spiqa/images/2001.00137/8-Table1-1.png", "data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/9-Table3-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png", "data/dataset/spiqa/images/2001.00137/11-Figure2-1.png", "data/dataset/spiqa/images/2001.00137/12-Table5-1.png", "data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/15-Figure3-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure4-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Should their approach be applied only when dealing with incomplete data?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9333bd64-be68-57c7-bdd2-73973c5e5922", "question": "How large are the improvements of the Attention-Sum Reader model when using the BookTest dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b2a61ef5-bc8a-5e67-9d1b-2f26caa5ec96"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1610.00956/7-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1610.00956/3-Table1-1.png", "data/dataset/spiqa/images/1610.00956/6-Figure1-1.png", "data/dataset/spiqa/images/1610.00956/7-Table2-1.png", "data/dataset/spiqa/images/1610.00956/8-Table3-1.png", "data/dataset/spiqa/images/1610.00956/10-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How large are the improvements of the Attention-Sum Reader model when using the BookTest dataset?", "reference_answer": "Answer with content missing: (Table 2) Accuracy of best AS reader results including ensembles are 78.4 and 83.7 when trained on BookTest compared to 71.0 and 68.9 when trained on CBT for Named endity and Common noun respectively.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "720b9563-818f-5be9-ac73-bef393910a58", "question": "Does the model evaluated on NLG datasets or dialog datasets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["653efdbb-7301-587d-b22c-90e494b7c43d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00139/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00139/3-Figure1-1.png", "data/dataset/spiqa/images/1706.00139/3-Figure2-1.png", "data/dataset/spiqa/images/1706.00139/5-Table1-1.png", "data/dataset/spiqa/images/1706.00139/6-Table2-1.png", "data/dataset/spiqa/images/1706.00139/6-Table3-1.png", "data/dataset/spiqa/images/1706.00139/7-Figure3-1.png", "data/dataset/spiqa/images/1706.00139/7-Figure4-1.png", "data/dataset/spiqa/images/1706.00139/7-Figure5-1.png", "data/dataset/spiqa/images/1706.00139/8-Table4-1.png", "data/dataset/spiqa/images/1706.00139/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Does the model evaluated on NLG datasets or dialog datasets?", "reference_answer": "NLG datasets", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "0f5c00bd-69d3-56fe-ab10-a7285afb40e2", "question": "In terms of the effectivenesses of coverage penalty and length normalization, how does having RL-based model refinement differ from not having RL-based model refinement?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["17c92e0f-7035-5840-9e6c-60569ab107ea"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/11-Figure4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/13-Table3-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/15-Figure5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table4-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/16-Table5-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table7-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/17-Table8-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table10-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/18-Table9-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/19-Figure6-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/23-Table11-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/4-Figure1-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/5-Figure2-1.png", "data/dataset/spiqa/images/c6850869aa5e78a107c378d2e8bfa39633158c0c/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "In terms of the effectivenesses of coverage penalty and length normalization, how does having RL-based model refinement differ from not having RL-based model refinement?", "reference_answer": "It was found that models with RL refinement are less affected by length normalization \"α\" and coverage penalty \"β\", authors explain this to the fact that during RL refinement, models already learn to pay attention to the full source sentence to not under-translate or over-translate. The authors also found an overlap between the wins from RL refinement and decoder fine-tuning, and the win from RL on a less fine-tuned decoder would have been bigger. The impact of length normalization \"α\" and coverage penalty \"β\" on RL-based and non-RL-based models can be found in Tables 2 and 3."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "7e0293fb-b85e-5ccf-b6d1-15308158958e", "question": "By how much do they outperform other models in the sentiment in intent classification tasks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["b0f8cb4c-5420-5ada-b490-7aed7819cfd1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/2001.00137/5-Figure1-1.png", "data/dataset/spiqa/images/2001.00137/8-Table1-1.png", "data/dataset/spiqa/images/2001.00137/9-Table2-1.png", "data/dataset/spiqa/images/2001.00137/9-Table3-1.png", "data/dataset/spiqa/images/2001.00137/10-Table4-1.png", "data/dataset/spiqa/images/2001.00137/11-Figure2-1.png", "data/dataset/spiqa/images/2001.00137/12-Table5-1.png", "data/dataset/spiqa/images/2001.00137/14-Table6-1.png", "data/dataset/spiqa/images/2001.00137/15-Figure3-1.png", "data/dataset/spiqa/images/2001.00137/16-Table7-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure4-1.png", "data/dataset/spiqa/images/2001.00137/17-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much do they outperform other models in the sentiment in intent classification tasks?", "reference_answer": "In the sentiment classification task by 6% to 8% and in the intent classification task by 0.94% on average", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d099cdad-2783-56f5-accb-f6fb5d438eda", "question": "What is the number of images and classes does the ImageNet dataset have?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ef730ec2-c376-5f4c-8aa6-c4262cb257c2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png"], "reference_image": ["data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-Figure10-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVI-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/10-TableVII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/11-TableVIII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure11-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/12-Figure12-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/13-Figure13-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure1-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/3-Figure2-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure3-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/4-Figure4-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure5-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure6-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/5-Figure7-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-Figure8-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/7-TableII-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-Figure9-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableIV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/8-TableV-1.png", "data/dataset/spiqa/images/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f/9-TableIII-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What is the number of images and classes does the ImageNet dataset have?", "reference_answer": "ImageNet has more than 1.2 million images and about 1000 classes."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "357e9415-2639-5cf1-b6c8-cc1bc5d88e46", "question": "What evaluations did the authors use on their system?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["dd2e44d3-ddc1-504f-bc99-6611d778ff10"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1711.11221/9-Table3-1.png", "data/dataset/spiqa/images/1711.11221/8-Table1-1.png", "data/dataset/spiqa/images/1711.11221/10-Table6-1.png"], "reference_image": ["data/dataset/spiqa/images/1711.11221/4-Figure1-1.png", "data/dataset/spiqa/images/1711.11221/5-Figure2-1.png", "data/dataset/spiqa/images/1711.11221/5-Figure3-1.png", "data/dataset/spiqa/images/1711.11221/8-Table1-1.png", "data/dataset/spiqa/images/1711.11221/8-Table2-1.png", "data/dataset/spiqa/images/1711.11221/9-Table3-1.png", "data/dataset/spiqa/images/1711.11221/9-Table4-1.png", "data/dataset/spiqa/images/1711.11221/9-Table5-1.png", "data/dataset/spiqa/images/1711.11221/10-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What evaluations did the authors use on their system?", "reference_answer": "BLEU scores, exact matches of words in both translations and topic cache, and cosine similarities of adjacent sentences for coherence.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "637c90c3-b8a1-5f49-8c7c-48cb7e27f53c", "question": "What is the shape of the tensor $x^1$ for the Shootings dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e0369791-b574-5ff8-aaeb-89c221d8f857"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table3-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table2-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Figure1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table1-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table4-1.png", "data/dataset/spiqa/images/1707.01917v2/1707.01917v2-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the shape of the tensor $x^1$ for the Shootings dataset?", "reference_answer": "The shape of the tensor $x^1$ for the Shootings dataset is 3365 x 1295 x 50."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d1508d62-6a25-5b2a-842f-7d37a0f1ebd0", "question": "What are two strong baseline methods authors refer to?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["98fc6c15-8779-5c22-8492-0514d955e3cd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.11204/8-Table7-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.11204/1-Figure1-1.png", "data/dataset/spiqa/images/1910.11204/3-Figure2-1.png", "data/dataset/spiqa/images/1910.11204/4-Figure3-1.png", "data/dataset/spiqa/images/1910.11204/5-Table1-1.png", "data/dataset/spiqa/images/1910.11204/5-Figure4-1.png", "data/dataset/spiqa/images/1910.11204/6-Table2-1.png", "data/dataset/spiqa/images/1910.11204/6-Table3-1.png", "data/dataset/spiqa/images/1910.11204/7-Table4-1.png", "data/dataset/spiqa/images/1910.11204/7-Table5-1.png", "data/dataset/spiqa/images/1910.11204/7-Table6-1.png", "data/dataset/spiqa/images/1910.11204/8-Table7-1.png", "data/dataset/spiqa/images/1910.11204/9-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are two strong baseline methods authors refer to?", "reference_answer": "Marcheggiani and Titov (2017) and Cai et al. (2018)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "b64e5a20-2f71-5edf-8417-7314951237ff", "question": "What is the network architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["9fe83b03-3a03-5a56-bdca-1313c32b0a9d"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1612.09113/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1612.09113/2-Figure1-1.png", "data/dataset/spiqa/images/1612.09113/3-Table2-1.png", "data/dataset/spiqa/images/1612.09113/3-Table1-1.png", "data/dataset/spiqa/images/1612.09113/4-Figure2-1.png", "data/dataset/spiqa/images/1612.09113/4-Table3-1.png", "data/dataset/spiqa/images/1612.09113/4-Table4-1.png", "data/dataset/spiqa/images/1612.09113/4-Table5-1.png", "data/dataset/spiqa/images/1612.09113/4-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the network architecture?", "reference_answer": "The network architecture has a multi-task Bi-Directional Recurrent Neural Network, with an unsupervised sequence labeling task and a low-dimensional embedding layer between tasks. There is a hidden layer after each successive task with skip connections to the senior supervised layers.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f637ed73-7ea8-5576-b240-4d187d145e84", "question": "What are the steps involved in the second encoding stage ($E_2$)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3d6ad977-6633-55e3-b0b7-99d999295321"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure6-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table1-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure7-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Table2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure8-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure2-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure3-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure9-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure10-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure4-1.png", "data/dataset/spiqa/images/1811.10673v1/1811.10673v1-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the steps involved in the second encoding stage ($E_2$)?", "reference_answer": "The second encoding stage involves three steps: down-sampling, soft edge detection, and spatio-temporal edge map compression."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ecae52a6-e346-520c-aa6b-49f24f3d19cc", "question": "What are the datasets used for the task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e9f86328-afc3-5d9e-81a2-0c543538dc03"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.13362/5-TableI-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.13362/2-Figure1-1.png", "data/dataset/spiqa/images/1909.13362/3-Figure2-1.png", "data/dataset/spiqa/images/1909.13362/5-TableI-1.png", "data/dataset/spiqa/images/1909.13362/5-TableII-1.png", "data/dataset/spiqa/images/1909.13362/6-TableIII-1.png", "data/dataset/spiqa/images/1909.13362/6-TableIV-1.png", "data/dataset/spiqa/images/1909.13362/7-TableV-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the datasets used for the task?", "reference_answer": "Datasets used are Celex (English, Dutch), Festival (Italian), OpenLexuque (French), IIT-Guwahati (Manipuri), E-Hitz (Basque)", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "2541d39e-c6fc-5db3-b537-61ae0d0e56b4", "question": "By how much do they outpeform previous results on the word discrimination task?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7a4edf26-691b-5910-a969-753290f1fdb7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.02550/5-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.02550/2-Figure1-1.png", "data/dataset/spiqa/images/1611.02550/5-Figure2-1.png", "data/dataset/spiqa/images/1611.02550/5-Table1-1.png", "data/dataset/spiqa/images/1611.02550/5-Table2-1.png", "data/dataset/spiqa/images/1611.02550/6-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "By how much do they outpeform previous results on the word discrimination task?", "reference_answer": "Their best average precision tops previous best result by 0.202", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "8e3a940c-30b5-5ed9-9b19-7867f5c6062b", "question": "How many features are used in each layer of SegNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a23ce2a-2593-5a31-9059-32d75394b681"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/4-Figure2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/5-Figure3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/7-Figure4-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure5-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How many features are used in each layer of SegNet?", "reference_answer": "64 features are used in each layer of SegNet."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "f018446a-bd2f-5e50-8a1f-d535de2b5322", "question": "Which method has the lowest average misclassification error?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["27057b6a-bb90-5120-b0f2-33812893fa3e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table1-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table6-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure3-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure2-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure4-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure5-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table7-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Table8-1.png", "data/dataset/spiqa/images/1706.00827v2/1706.00827v2-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which method has the lowest average misclassification error?", "reference_answer": "Multi-X"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "597045f2-fd8d-55da-97a5-0f1aafd559ae", "question": "What is the performance change of the textual semantic similarity task when no error and maximum errors (noise) are present?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["55b0d70f-b335-5fa7-94d4-7f83398b05e6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2003.12932/5-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/2003.12932/2-Figure1-1.png", "data/dataset/spiqa/images/2003.12932/2-Figure2-1.png", "data/dataset/spiqa/images/2003.12932/3-Table1-1.png", "data/dataset/spiqa/images/2003.12932/4-Figure3-1.png", "data/dataset/spiqa/images/2003.12932/4-Figure4-1.png", "data/dataset/spiqa/images/2003.12932/5-Figure5-1.png", "data/dataset/spiqa/images/2003.12932/6-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What is the performance change of the textual semantic similarity task when no error and maximum errors (noise) are present?", "reference_answer": "10 Epochs: pearson-Spearman correlation  drops  60 points when error increase by 20%\n50 Epochs: pearson-Spearman correlation  drops  55 points when error increase by 20%", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "07b44cfe-217f-55ba-b54d-095f70d37395", "question": "How does HUMBI compare to other datasets in terms of the number of subjects?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["6fee6efc-f882-5a46-9a7a-94d8013358d2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure5-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure15-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure16-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure2-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table4-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure12-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table1-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure11-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure10-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table7-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure8-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Table6-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure3-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure9-1.png", "data/dataset/spiqa/images/1812.00281v3/1812.00281v3-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does HUMBI compare to other datasets in terms of the number of subjects?", "reference_answer": "HUMBI has the highest number of subjects compared to the other datasets."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "ae78258e-f534-58da-bfd6-604a98a6c152", "question": "What does \"variable-length alignment\" mean?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f124ba10-c318-5d52-ab9a-3be90aca000a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/1-Figure1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/3-Figure2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/4-Figure3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/5-Figure4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure5-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Table3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What does \"variable-length alignment\" mean?", "reference_answer": "a variable-length alignment is a vector derived by comparing the current target hidden state with each source hidden state, and the size of it equals the number of time steps on the source side as it's explained in Figure 2."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "feec54a6-58bd-596f-91aa-5b2c7b71d60d", "question": "Which inference method consistently leads to the highest F1 score on the failure set across all three networks (Net3, Net4, and Net5)?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["1fef60ff-74d5-51ea-8c95-ca7247e0cffd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table11-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table10-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table5-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table9-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table7-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table8-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table6-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table4-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table3-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table1-1.png", "data/dataset/spiqa/images/1707.08608v3/1707.08608v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which inference method consistently leads to the highest F1 score on the failure set across all three networks (Net3, Net4, and Net5)?", "reference_answer": "Beam search with a width of 9 consistently leads to the highest F1 score on the failure set across all three networks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "487d14c9-0ea4-5e65-9f4d-77cdacd13bc5", "question": "What are the different steps involved in reconstructing implicit warrants for argument reasoning comprehension?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["0423e038-405f-5171-a89b-75e3079e5aa6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure3-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table2-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure4-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Table1-1.png", "data/dataset/spiqa/images/1708.01425v4/1708.01425v4-Figure5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the different steps involved in reconstructing implicit warrants for argument reasoning comprehension?", "reference_answer": "The different steps involved in reconstructing implicit warrants for argument reasoning comprehension are:\n1. Sampling comments\n2. Stance annotation\n3. Reason span annotations\n4. Reason gist summarization\n5. Reason disambiguation\n6. Alternative warrant\n7. Alternative warrant validation\n8. Warrant for original claim\n9. Warrant validation"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a669ce4f-1d37-5a3b-9706-9f4c3a9743c9", "question": "What are the 12 AV approaches which are examined?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["eca36618-8e25-5ad7-a22b-5e71fbb4c6eb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1906.10551/6-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1906.10551/5-Figure1-1.png", "data/dataset/spiqa/images/1906.10551/5-Table1-1.png", "data/dataset/spiqa/images/1906.10551/6-Table2-1.png", "data/dataset/spiqa/images/1906.10551/7-Table3-1.png", "data/dataset/spiqa/images/1906.10551/7-Table4-1.png", "data/dataset/spiqa/images/1906.10551/8-Figure2-1.png", "data/dataset/spiqa/images/1906.10551/8-Table5-1.png", "data/dataset/spiqa/images/1906.10551/8-Table6-1.png", "data/dataset/spiqa/images/1906.10551/10-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What are the 12 AV approaches which are examined?", "reference_answer": "MOCC, OCCAV, COAV, AVeer, GLAD, DistAV, Unmasking, Caravel, GenIM, ImpGI, SPATIUM and NNCD", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d9d4150e-bb80-5250-b2ed-f38f8da3290b", "question": "How does the average number of answers per question differ between the training and development sets? What might be a possible explanation for this difference?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d62d3025-a1b0-5616-84f5-5ea256c9ac90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table3-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table2-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table1-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table4-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table5-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table6-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the average number of answers per question differ between the training and development sets? What might be a possible explanation for this difference?", "reference_answer": "The training set has a higher average number of answers per question (6.36) compared to the development set (5.48). This suggests that questions in the training set tend to have more potential answers associated with them than those in the development set."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "e8281172-eaf0-5a90-b8c8-55f6e32ee608", "question": "What is the purpose of the positional mask in the TSA mechanism?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["e12c7d24-8cfc-57b1-b048-9a36c5251d57"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table3-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table1-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table4-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table5-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure2-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Table6-1.png", "data/dataset/spiqa/images/1805.00912v4/1805.00912v4-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the purpose of the positional mask in the TSA mechanism?", "reference_answer": "The positional mask is used to provide information about the relative position of tokens in the input sequence. This information is used to compute the attention weights, which determine how much each token attends to each other token."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "43114fc9-58a9-53ac-8afb-3dae1ba504ae", "question": "Which model performs the best on the AddOneSent dataset in terms of F1 score?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["e31707d3-f5f4-5c59-86a2-af24ff7cfed7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table4-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table1-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Table5-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure2-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure3-1.png", "data/dataset/spiqa/images/1705.02798v6/1705.02798v6-Figure4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs the best on the AddOneSent dataset in terms of F1 score?", "reference_answer": "R.M.-Reader."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d7e3882a-8e7e-58c1-ad49-94ad8e757ef6", "question": "What is the relationship between the shape parameter α and the shape of the loss function?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["070d0ea4-6b65-5bd5-aa78-c6afa083f638"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure8-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure13-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure5-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure7-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure12-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure11-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure10-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure16-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure9-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table4-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure6-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure2-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure17-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure15-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Table1-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure3-1.png", "data/dataset/spiqa/images/1701.03077v10/1701.03077v10-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the relationship between the shape parameter α and the shape of the loss function?", "reference_answer": "The shape parameter α controls the shape of the loss function. As α increases, the loss function becomes more peaked, and as α decreases, the loss function becomes more flat."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "a4beed24-762a-5028-8f86-43390469f8a9", "question": "What is the difference between the parsing trees for \"I like eating\" and \"I like grapes\"?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["72b0d1a9-3397-5940-bf4b-b5fdf8480554"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure4-1.png"], "reference_image": ["data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure3-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure4-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Figure5-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table1-1.png", "data/dataset/spiqa/images/1704.04539v2/1704.04539v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the parsing trees for \"I like eating\" and \"I like grapes\"?", "reference_answer": "The parsing tree for \"I like eating\" has only one argument, while the parsing tree for \"I like grapes\" has two arguments."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "9ab1b95d-2b5c-54df-a133-538439c53990", "question": "How ShuffleNet allowed more feature maps for a given computational complexity?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["7c980410-c800-51e3-9156-a2b04a3590d1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/2-Figure1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/3-Figure2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table1-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/4-Table2-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/5-Table3-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table4-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/6-Table5-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table6-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table7-1.png", "data/dataset/spiqa/images/9da734397acd7ff7c557960c62fb1b400b27bd89/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How ShuffleNet allowed more feature maps for a given computational complexity?", "reference_answer": "The ShuffleNet uses pointwise group convolution with channel shuffling, thus design-wise it has less complexity (requires hw(2cm/g+9m) FLOPs). This means it allows wider feature maps for a given computational budget. And the effect seems to increase the performance better as the model gets smaller."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "2e0c7fee-b5a0-5a34-9ed8-42e8a50f73f9", "question": "What is the value of the learning rate α for the BAIR dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["966ef86f-9278-5fa3-b41e-a3be5ec127a6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure7-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure9-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure2-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Table1-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure10-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure3-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure16-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure12-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure13-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure11-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure4-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure5-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure6-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure15-1.png", "data/dataset/spiqa/images/1809.00263v5/1809.00263v5-Figure14-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the value of the learning rate α for the BAIR dataset?", "reference_answer": "0.0002"}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "4472f051-8174-5e7e-880d-8e2c0a75209e", "question": "Is the dataset balanced between speakers of different L1s?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "table"], "anchor_pdf": ["20a6a8bb-4530-596f-bb20-a85794e4b4c7"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.11346/3-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.11346/2-Table1-1.png", "data/dataset/spiqa/images/1804.11346/3-Figure1-1.png", "data/dataset/spiqa/images/1804.11346/3-Table2-1.png", "data/dataset/spiqa/images/1804.11346/3-Table3-1.png", "data/dataset/spiqa/images/1804.11346/4-Figure2-1.png", "data/dataset/spiqa/images/1804.11346/4-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Is the dataset balanced between speakers of different L1s?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "9b37292a-fcf1-5069-8de3-efde80dd4846", "question": "Did they use a relation extraction method to construct the edges in the graph?", "answer_format": "Your answer should be a Python boolean, i.e., `true` or `false`.", "tags": ["single", "text", "objective", "image"], "anchor_pdf": ["df4de88d-e624-5e8a-ac1c-1f42eae3e5b9"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1808.09920/3-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1808.09920/1-Figure1-1.png", "data/dataset/spiqa/images/1808.09920/3-Figure2-1.png", "data/dataset/spiqa/images/1808.09920/5-Table1-1.png", "data/dataset/spiqa/images/1808.09920/6-Table2-1.png", "data/dataset/spiqa/images/1808.09920/7-Table3-1.png", "data/dataset/spiqa/images/1808.09920/8-Table4-1.png", "data/dataset/spiqa/images/1808.09920/11-Table5-1.png", "data/dataset/spiqa/images/1808.09920/12-Table6-1.png", "data/dataset/spiqa/images/1808.09920/13-Figure3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Did they use a relation extraction method to construct the edges in the graph?", "reference_answer": false, "is_boolean": true}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "f139c596-9840-5f1a-aacd-1e87ed0df9c2", "question": "How has the quality and diversity of generated 3D face images improved over time, and what advances have contributed to these improvements?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f1dd6485-3dd2-5f0d-a7b2-8aa4ef121d6e"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png"], "reference_image": ["data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/10-Figure12-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/11-Figure13-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/12-Figure14-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure15-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure16-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-Figure17-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/13-TableVI-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/14-TableVII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-Figure18-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableIX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableVIII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/15-TableX-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure19-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure20-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/18-Figure21-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure22-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/19-Figure23-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure1-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/2-Figure2-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/20-Figure24-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-Figure3-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/4-TableII-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/5-Figure4-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-Figure5-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/6-TableIV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure6-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-Figure7-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/7-TableV-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/8-Figure8-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure10-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure11-1.png", "data/dataset/spiqa/images/21117380118ddce47b3c515c5228372c513e61ba/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How has the quality and diversity of generated 3D face images improved over time, and what advances have contributed to these improvements?", "reference_answer": "The paper only talks about the line of work on 3D image reconstruction, in other words, the methods and approaches to reconstruct 3D face images. However, the quality and improvements that were made are not mentioned explicitly, but only referenced."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "eb05091d-bbdc-5591-a7c4-e438b9d6bb32", "question": "Does large model always shows better performance than small model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d85f50b2-fa24-5b35-9fdd-00222f679121"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/2-Figure1-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/4-Table1-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/4-Table2-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/5-Table3-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/5-Table4-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/6-Table5-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Figure2-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Table6-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Table7-1.png", "data/dataset/spiqa/images/891ce1687e2befddd19f54e4eef1d3f39c8dbaf7/7-Table8-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Does large model always shows better performance than small model?", "reference_answer": "No."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "c650fa54-5d6a-5144-8b7c-0eddaaebd125", "question": "Which model performs best overall on both the CVR and CTCVR tasks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["f2e1d9a7-fce3-5c7c-af44-2a80ea5a78dd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table1-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Table2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure3-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure2-1.png", "data/dataset/spiqa/images/1804.07931v2/1804.07931v2-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performs best overall on both the CVR and CTCVR tasks?", "reference_answer": "The ESMM model performs the best overall on both the CVR and CTCVR tasks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "5d9cf44a-cc7d-5a76-a11e-c734838b2e91", "question": "How are the results of the input-first and output-first approach different?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f992c4ad-ce9f-584d-b09e-80bcdf9589b2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png"], "reference_image": ["data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/1-Figure1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/14-Figure8-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/15-Table5-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/16-Table6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/19-Figure9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/2-Figure2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/21-Table9-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/22-Table10-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/23-Table11-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/4-Table1-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Figure4-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/5-Table2-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/6-Table3-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/7-Figure6-1.png", "data/dataset/spiqa/images/e65b346d442e9962a4276dc1c1af2956d9d5f1eb/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How are the results of the input-first and output-first approach different?", "reference_answer": "If by results, you are referring to the outputs of these approaches, then the final output will look very similar - the output for each instance will consist of a tuple of an (input, output) where input and output follow the instructions for a certain task. However, the order in which this output is generated will differ -- for example, in \"input first\" approach, the input is generated first, while in the output first case, the language model is conditioned to provide the required output. On the other hand, if, by results, you are referring to \"performance\" of both of these approaches, the authors mention that the input first approach performs very poorly on classification instances, which is why they proposed the alternative approach of output-first generation for classification tasks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "cb9bcf25-b7cc-505a-9a59-7402bbcc2c0b", "question": "What extracted features were most influencial on performance?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["4a8af5af-ae48-5931-bb66-e2152e63e0d3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.06162/2-Table1-1.png", "data/dataset/spiqa/images/1909.06162/3-Figure1-1.png", "data/dataset/spiqa/images/1909.06162/3-Table2-1.png", "data/dataset/spiqa/images/1909.06162/4-Table4-1.png", "data/dataset/spiqa/images/1909.06162/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What extracted features were most influencial on performance?", "reference_answer": "Linguistic", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "4d5ae678-5085-5e3e-a7e1-c402398a2264", "question": "How does the validation accuracy of the SRU model compare to that of the cuDNN LSTM and CNN models?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["8134e300-8c76-5ac9-ad86-93545a3af519"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure3-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure1-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure6-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Figure2-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table4-1.png", "data/dataset/spiqa/images/1709.02755v5/1709.02755v5-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "How does the validation accuracy of the SRU model compare to that of the cuDNN LSTM and CNN models?", "reference_answer": "The SRU model achieves comparable or slightly higher validation accuracy than the cuDNN LSTM and CNN models on all six benchmarks."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "61cf20c4-c917-58c0-b953-046804f4b3d4", "question": "Which model performed best on average across all tasks?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["ceff18ab-0cba-5e6b-b40d-ed9534e6f9c1"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table4-1.png"], "reference_image": ["data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table3-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table4-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table5-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table1-1.png", "data/dataset/spiqa/images/1809.02731v3/1809.02731v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which model performed best on average across all tasks?", "reference_answer": "The Linear model performed best on average with a score of 70.0."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "d0ed7bc5-c577-5ca1-938c-f9b13c35a03e", "question": "Which denoising method performs the best on average across all noise levels tested on the Kodak dataset?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["0adb94de-50f5-51ff-8e1a-b2e3e72dcfd2"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure5-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure2-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table1-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Figure4-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table3-1.png", "data/dataset/spiqa/images/1706.04284v3/1706.04284v3-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which denoising method performs the best on average across all noise levels tested on the Kodak dataset?", "reference_answer": "The proposed method performs the best on average across all noise levels tested on the Kodak dataset."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "405524ac-ae25-5cc3-b146-f1c531390201", "question": "What kinds of domain knowledge do the authors refer to in this context?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f124ba10-c318-5d52-ab9a-3be90aca000a"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/1-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/1-Figure1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/3-Figure2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/4-Figure3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/5-Figure4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table1-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/6-Table2-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure5-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Figure6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/7-Table3-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table4-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/8-Table6-1.png", "data/dataset/spiqa/images/93499a7c7f699b6630a86fad964536f9423bb6d0/9-Table5-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What kinds of domain knowledge do the authors refer to in this context?", "reference_answer": "Authors refer to translation domain knowledge, as they refer to Luong's et al. (2015) Neural Machine Translation as it reads through all source words until the end of a sentence, then starts translation by emitting one target word at a time as illustrated in Figure 1."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "874e8291-f75e-57d0-a123-207399cbe6da", "question": "What is the effect of increasing the budget in FLOPS on the test Top-1 error rate for the three different training strategies?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["ed9d843d-3ea3-5d22-89db-e8dff591f7ff"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure3-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure1-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure4-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure5-1.png", "data/dataset/spiqa/images/1708.06832v3/1708.06832v3-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the effect of increasing the budget in FLOPS on the test Top-1 error rate for the three different training strategies?", "reference_answer": "The test Top-1 error rate decreases as the budget in FLOPS increases for all three training strategies."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "6118e184-9d54-5c0d-82f3-05f1e1edd230", "question": "What was the score of the proposed model?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["bb612307-6486-5f20-b595-193493d74eca"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1904.07904/4-Table2-1.png"], "reference_image": ["data/dataset/spiqa/images/1904.07904/2-Figure1-1.png", "data/dataset/spiqa/images/1904.07904/2-Figure2-1.png", "data/dataset/spiqa/images/1904.07904/3-Table1-1.png", "data/dataset/spiqa/images/1904.07904/4-Table3-1.png", "data/dataset/spiqa/images/1904.07904/4-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What was the score of the proposed model?", "reference_answer": "EM Score of 51.10", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "d471a6cf-6137-5faf-953d-da5b5d4d0bbc", "question": "What are the total number of encoders and decoders used in SegNet?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["3a23ce2a-2593-5a31-9059-32d75394b681"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/4-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/2-Figure1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/4-Figure2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/5-Figure3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table1-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table2-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/6-Table3-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/7-Figure4-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure5-1.png", "data/dataset/spiqa/images/6f9f143ec602aac743e07d092165b708fa8f1473/8-Figure6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "What are the total number of encoders and decoders used in SegNet?", "reference_answer": "4 encoders and 4 decoders are used in SegNet."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "08231d94-8b3d-5af7-9ffa-ffe3d1f4a443", "question": "What is the difference between the predicted frame and the reconstructed frame for each task domain?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["edf2543a-ae86-5f4d-b07a-c33d5092ee05"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure5-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure3-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure1-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure2-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Figure4-1.png", "data/dataset/spiqa/images/1707.00524v2/1707.00524v2-Table2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the difference between the predicted frame and the reconstructed frame for each task domain?", "reference_answer": "The predicted frame is generated by the prediction model, while the reconstructed frame is generated by the autoencoder. The predicted frame is typically more accurate than the reconstructed frame, as the prediction model is trained to predict the future state of the environment, while the autoencoder is only trained to reconstruct the input image."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "fce1e47a-f064-5f5c-8940-c38568dbc1d2", "question": "What is the function of the ReOrth Layer in the Projection Block of the Grassmann Network architecture?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5ce6798c-a395-5175-8b83-6e7fa08c4245"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure1-1.png", "data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Figure2-1.png", "data/dataset/spiqa/images/1611.05742v3/1611.05742v3-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What is the function of the ReOrth Layer in the Projection Block of the Grassmann Network architecture?", "reference_answer": "The ReOrth Layer re-orthogonalizes the output of the FRMap Layer."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "046d222c-ac5a-5c1e-8d11-9b1d2d6d008f", "question": "What state-of-the-art results are achieved?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["6d12d90c-6898-50c2-9c63-eb987796ac17"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1909.00175/4-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1909.00175/2-Figure1-1.png", "data/dataset/spiqa/images/1909.00175/4-Table1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "What state-of-the-art results are achieved?", "reference_answer": "F1 score of 92.19 on homographic pun detection, 80.19 on homographic pun location, 89.76 on heterographic pun detection.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "038b2e35-7796-5608-91db-0015d67c9162", "question": "What are the main differences between the educational philosophies of the Bonaparte and Voltaire schools?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["d62d3025-a1b0-5616-84f5-5ea256c9ac90"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table3-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table2-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table1-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table4-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table5-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Table6-1.png", "data/dataset/spiqa/images/1611.04684v1/1611.04684v1-Figure1-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "What are the main differences between the educational philosophies of the Bonaparte and Voltaire schools?", "reference_answer": "The Bonaparte school focuses on outdoor physical activities, maneuvers, and strategies, with a specialization in horse riding, lances, and swords. They aim to develop students into good leaders. The Voltaire school, on the other hand, encourages independent thinking and focuses on indoor activities. They aim to instill good moral values and develop students into philosophical thinkers."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "37cdf488-c872-5765-ac0a-43c56661a956", "question": "For how many probe tasks the shallow-syntax-aware contextual embedding perform better than ELMo’s embedding?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["3ef2c05c-0862-5d4e-b1c0-c0849ef611c6"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1908.11047/5-Table3-1.png"], "reference_image": ["data/dataset/spiqa/images/1908.11047/1-Figure1-1.png", "data/dataset/spiqa/images/1908.11047/2-Table1-1.png", "data/dataset/spiqa/images/1908.11047/3-Figure2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table2-1.png", "data/dataset/spiqa/images/1908.11047/5-Table3-1.png", "data/dataset/spiqa/images/1908.11047/5-Table4-1.png", "data/dataset/spiqa/images/1908.11047/8-Table5-1.png", "data/dataset/spiqa/images/1908.11047/8-Table6-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "For how many probe tasks the shallow-syntax-aware contextual embedding perform better than ELMo’s embedding?", "reference_answer": "3", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "20fd35a9-94d6-5036-ba94-1b4abfae6803", "question": "How the architecture is chosen", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["306a761c-369e-577f-a3e6-fe478f83d3cd"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/9-Figure8-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/8-Table1-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/8-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/10-Figure11-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/10-Table2-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/10-Table3-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/11-Table4-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/12-Figure12-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/13-Figure13-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/14-Figure14-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/14-Figure15-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/2-Figure1-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/3-Figure2-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/5-Figure3-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/6-Figure4-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/6-Figure5-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/7-Figure6-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/7-Figure7-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/8-Table1-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/9-Figure10-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/9-Figure8-1.png", "data/dataset/spiqa/images/53b047e503f4c24602f376a774d653f7ed56c024/9-Figure9-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How the architecture is chosen", "reference_answer": "The adversary (attacking part) must at least have some partial knowledge of the input (e.g., images, text) and expected output (e.g., classification) in order to select the architecture of the attacking system. The adversary selects an appropriate architecture adapted to the input-output relation. For instance, if the task is image classification or machine visioon, a convolutional neural network is the best choice. The parameters of the system (Deep Neural Network), like training epochs, number of layers , nodes etc., have relatively little impact on the success of the attack, so they do not determine the architecture."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "e8e4b399-a00b-56f4-8b4e-53c0a349b621", "question": "Which metropolitan areas are correctly identified by the GeoCUTS algorithm in France?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["f6698b9d-b767-5c34-a75a-e44af36b00bb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png"], "reference_image": ["data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table3-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table2-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure1-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table4-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Table5-1.png", "data/dataset/spiqa/images/1611.03780v2/1611.03780v2-Figure2-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testa", "question": "Which metropolitan areas are correctly identified by the GeoCUTS algorithm in France?", "reference_answer": "Paris, Bordeaux, and Lyon."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testa"}
{"uuid": "2ed2ce85-e259-5b7b-844d-00ca747eb3f3", "question": "Which 7 Indian languages do they experiment with?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["de3148dd-ff01-5fd2-b6fa-9438245883a3"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/2002.01664/3-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/2002.01664/2-Figure1-1.png", "data/dataset/spiqa/images/2002.01664/3-Table1-1.png", "data/dataset/spiqa/images/2002.01664/4-Table4-1.png", "data/dataset/spiqa/images/2002.01664/4-Table2-1.png", "data/dataset/spiqa/images/2002.01664/4-Figure2-1.png", "data/dataset/spiqa/images/2002.01664/4-Table3-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "Which 7 Indian languages do they experiment with?", "reference_answer": "Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "bb0ff4ea-7688-5e39-a159-1a2f23ab2fda", "question": "How do they condition the output to a given target-source class?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["5a50572f-39a1-5cc3-9a01-d9be6a8478df"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/1910.10408/2-Figure2-1.png"], "reference_image": ["data/dataset/spiqa/images/1910.10408/2-Figure1-1.png", "data/dataset/spiqa/images/1910.10408/2-Figure2-1.png", "data/dataset/spiqa/images/1910.10408/4-Figure3-1.png", "data/dataset/spiqa/images/1910.10408/4-Table1-1.png", "data/dataset/spiqa/images/1910.10408/4-Table2-1.png", "data/dataset/spiqa/images/1910.10408/5-Table3-1.png", "data/dataset/spiqa/images/1910.10408/6-Table4-1.png", "data/dataset/spiqa/images/1910.10408/6-Table5-1.png", "data/dataset/spiqa/images/1910.10408/7-Table6-1.png", "data/dataset/spiqa/images/1910.10408/7-Table7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testc", "question": "How do they condition the output to a given target-source class?", "reference_answer": "They use three groups short/normal/long translation classes to learn length token, which is in inference used to bias network to generate desired length group.", "is_boolean": false}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testc"}
{"uuid": "a71344df-9968-5502-970f-58a47d5816dd", "question": "Is the line contains both English and non-English text is the most common in classifier?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "table"], "anchor_pdf": ["9d032d32-2bf8-5371-9342-84b374bf1b48"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png"], "reference_image": ["data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/1-Figure1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/10-Table5-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/11-Table6-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/12-Table7-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/2-Table1-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/3-Figure2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/4-Table2-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/8-Table3-1.png", "data/dataset/spiqa/images/48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775/9-Table4-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "Is the line contains both English and non-English text is the most common in classifier?", "reference_answer": "No, it is not."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
{"uuid": "0270b4f2-1f59-5d84-b5dd-33d4e76fe34d", "question": "How is normal cell different from reduction cell for NASNets?", "answer_format": "Your answer should be concise free-form text string, directly answering the question(s).", "tags": ["single", "text", "subjective", "image"], "anchor_pdf": ["acb67ddd-a0d1-56d4-871c-f5f79ed59efb"], "reference_pdf": [], "anchor_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png"], "reference_image": ["data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/12-Figure8-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure10-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/13-Figure9-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/2-Figure1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/3-Figure2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/4-Figure3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Figure4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/5-Table1-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Figure5-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table2-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/6-Table3-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Figure6-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/7-Table4-1.png", "data/dataset/spiqa/images/d0611891b9e8a7c5731146097b6f201578f47b2f/8-Figure7-1.png"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_spiqa", "eval_kwargs": {"task_type": "testb", "question": "How is normal cell different from reduction cell for NASNets?", "reference_answer": "We learn two separate architectures for reduction and normal cells. During prediction,  the first 5B predictions are for the Normal Cell and the second 5B predictions are for the Reduction Cell. For Reduction cell authors make the initial operation applied to the cell’s inputs have a stride of two to reduce the height and width which is not done for Normal cell."}}, "state": {"gui-gpt-4o-2024-11-20": false}, "annotator": "spiqa_testb"}
