{
    "uuid": "a4a81542-ee41-55f9-8b30-7ef0c6bcd6db",
    "question": "Which paper first shows that it is possible to maintain high LLM reasoning performance with in-context examples that are absurdly wrong?",
    "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.",
    "tags": [
        "retrieval",
        "text",
        "objective"
    ],
    "anchor_pdf": [],
    "reference_pdf": [],
    "conference": [
        "iclr2023"
    ],
    "reasoning_steps": [],
    "evaluator": {
        "eval_func": "eval_paper_relevance_with_reference_answer",
        "eval_kwargs": {
            "question": "Which paper first shows that it is possible to maintain high LLM reasoning performance with in-context examples that are absurdly wrong?",
            "reference_answer": "Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters"
        }
    },
    "state": {},
    "annotator": "litsearch_manual"
}