{
    "uuid": "dcd9e737-6a5f-519f-8357-0a0e6d002c1e",
    "question": "Which two subsets does the benchmark used as evaluation set for BLOOM and BLOOMZ models in the anchor paper merged from?(The anchor paper is named \"An Empirical Study of In-context Learning in LLMs for Machine Translation\")",
    "answer_format": "Your answer should be a single python list, every element of the list is a string of the abbrievation name of the subset, e.g.[\"TAT-Conv\",\"TAT-Web\"].",
    "tags": [
        "objective",
        "multiple",
        "text"
    ],
    "anchor_pdf": ["bffc816d-612c-5fea-83bb-1ac6b290480b"],
    "reference_pdf": ["b40e8ca1-d3e8-5553-ac3c-d6ca0b21c628"],
    "conference": [],
    "reasoning_steps": [
        "Firstly, locate and identify the benchmark used as evaluation set for BLOOM and BLOOMZ models in the anchor paper.",
        "Then find the most relevant reference paper about this benchmark.",
        "Finally, locate the section in the reference paper about the description of the benchmark to extract the information about the merged subsets."
    ],
    "evaluator": {
        "eval_func": "eval_structured_object_exact_match",
        "eval_kwargs": {
            "gold": ["IN22-Wiki", "IN22-Web"],
            "lowercase": true,
            "ignore_blank": true
        }
    },
    "state": {
        "gui-gpt-4o-2024-11-20": false
    },
    "annotator": "human"
}