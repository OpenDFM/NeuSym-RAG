{
    "uuid": "2070b480-446e-52ac-8af1-4cda605d0619",
    "question": "Which paper proposes an alignment framework that steers language models to preferences of individual groups in a few-shot manner through augmenting the LLM with a transformer module?",
    "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.",
    "tags": [
        "retrieval",
        "text",
        "subjective"
    ],
    "anchor_pdf": [],
    "reference_pdf": [],
    "conference": [
        "iclr2024"
    ],
    "reasoning_steps": [],
    "evaluator": {
        "eval_func": "eval_paper_relevance_with_llm",
        "eval_kwargs": {}
    },
    "state": {},
    "annotator": "litsearch"
}