{
    "uuid": "4b276a15-4520-5e37-bec7-9699d6fdcab2",
    "question": "Is there any paper that address attacks on code models by leveraging the semantic information of the source code through attention scores, while also guaranteeing that the generated adversarial examples can always be compiled successfully?",
    "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.",
    "tags": [
        "retrieval",
        "text",
        "subjective"
    ],
    "anchor_pdf": [],
    "reference_pdf": [],
    "conference": [
        "acl2023"
    ],
    "reasoning_steps": [],
    "evaluator": {
        "eval_func": "eval_paper_relevance_with_llm",
        "eval_kwargs": {}
    },
    "state": {},
    "annotator": "litsearch"
}