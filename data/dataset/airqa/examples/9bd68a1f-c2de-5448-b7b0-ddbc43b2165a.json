{
    "uuid": "9bd68a1f-c2de-5448-b7b0-ddbc43b2165a",
    "question": "What is the detailed procedure of progressive learning followed in the instruction tuning section of the anchor pdf?",
    "answer_format": "Your answer should be a python strings.",
    "tags": [
        "multiple",
        "text",
        "subjective"
    ],
    "anchor_pdf": [
        "5a854b33-31c8-50f8-beaa-b3c93e9ae2f8"
    ],
    "reference_pdf": [
        "02f4302f-4f6c-5092-8927-36a0b9cac06a"
    ],
    "conference": [],
    "reasoning_steps": [
        "Find the progressive learning finetuning method in the instruction tuning section of the Anchor PDF.",
        "Locate the relevant paper in the reference PDF.",
        "Identify the detailed procedure of progressive learning in the training section."
    ],
    "evaluator": {
        "eval_func": "eval_reference_answer_with_llm",
        "eval_kwargs": {
            "reference_answer": "The detailed procedure of progressive learning used in Orca 2 starts with LaMA-2-7B or LLaMA-2-13B checkpoint and finetunes it on the train split of FLAN-v2 dataset for one epoch. Then they train on 5 million ChatGPT data from Orca 1 for 3 epochs, and train on the combination of 1 million GPT-4 data from Orca 1 and Orca 2's 817K data for 4 epochs.",
            "question": "What is the detailed procedure of progressive learning followed in the instruction tuning section of the anchor pdf?"
        }
    },
    "state": {
        "gui-gpt-4o-2024-11-20": false
    },
    "annotator": "human"
}