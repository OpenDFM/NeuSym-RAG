{"uuid": "01db3056-b961-59bf-8b58-8b8ee0c70060", "question": "Which paper first published a real-world Chinese-English text image translation dataset?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first published a real-world Chinese-English text image translation dataset?", "reference_answer": "Exploring Better Text Image Translation with Multimodal Codebook"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "05548a18-0a57-54e2-a7d6-58a5a8cdca72", "question": "Is there any paper that performs adversarial training on frame level for audio-visual representation learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that performs adversarial training on frame level for audio-visual representation learning?", "reference_answer": "MIR-GAN: Refining Frame-Level Modality-Invariant Representations with Adversarial Network for Audio-Visual Speech Recognition"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "05729273-17c6-5641-8197-1b1f7ccd4b86", "question": "Which paper first use the attention weights to guide the simultaneous inference of speech translation models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first use the attention weights to guide the simultaneous inference of speech translation models?", "reference_answer": "Attention as a Guide for Simultaneous Speech Translation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "0696ecf8-b39a-5288-b3ee-c6b3dcf2e420", "question": "What paper compares humans' and language models' non-literal interpretations of utterances featuring phenomena like deceit, irony, and humor?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper compares humans' and language models' non-literal interpretations of utterances featuring phenomena like deceit, irony, and humor?", "reference_answer": "A fine-grained comparison of pragmatic language understanding in humans and language models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "079bf850-1cba-5b82-a432-8cfc8e2e28ff", "question": "Which paper presents an easy to implement and high performing method for OOD detection with language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper presents an easy to implement and high performing method for OOD detection with language models?", "reference_answer": "Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for Out-of-Domain Detection"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "085fa0be-3252-59dc-b265-959619c6aa8a", "question": "Could you suggest research that examines the effects of starting language models with weights from pretrained nondiffusion models on the convergence behavior of diffusion losses?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Could you suggest research that examines the effects of starting language models with weights from pretrained nondiffusion models on the convergence behavior of diffusion losses?", "reference_answer": "SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "09c643c6-6a5f-5650-ae54-2bed43a55c17", "question": "What paper first adapted ControlNet to generate continuous videos in a training-free manner?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first adapted ControlNet to generate continuous videos in a training-free manner?", "reference_answer": "ControlVideo: Training-free Controllable Text-to-Video Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "0a202041-de70-55b6-9aa0-6b6486166582", "question": "Which paper was the first to propose combining human spoken language and sign language datasets with gloss annotations to enhance the performance of sign language translation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper was the first to propose combining human spoken language and sign language datasets with gloss annotations to enhance the performance of sign language translation?", "reference_answer": "Neural Machine Translation Methods for Translating Text to Sign Language Glosses"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "0b0ef576-fe34-5e6a-bfd3-eafba60a82d5", "question": "What work first uses LLM to code robotic simulation tasks and show sim-to-real benefits with policy pre-training in simulation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What work first uses LLM to code robotic simulation tasks and show sim-to-real benefits with policy pre-training in simulation?", "reference_answer": "GENSIM: GENERATING ROBOTIC SIMULATION TASKS VIA LARGE LANGUAGE MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "0b1dbace-15fd-53b8-bf52-2bf158ceea33", "question": "Which paper first propose to mask positions to pre-train multi-modal document transformer？", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first propose to mask positions to pre-train multi-modal document transformer？", "reference_answer": "LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training for Document Understanding"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "0d7b0180-0c7e-5eb6-a51f-6d7a473d33f2", "question": "Is there a paper that takes a mixed machine learning and solver based approach to code translation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that takes a mixed machine learning and solver based approach to code translation?", "reference_answer": "GUESS & SKETCH: LANGUAGE MODEL GUIDED TRANSPILATION"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "106570b0-0e1a-5055-9e0d-fcc6eb3a1a1b", "question": "Which paper first combines different methods for uncertainty quantification in one?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first combines different methods for uncertainty quantification in one?", "reference_answer": "Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "11dbd6a6-2eb2-59a2-9ef9-4bdc723ba2c0", "question": "Which paper first proposes a unified framework for black-box and white-box detection of AI-written text with explanations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proposes a unified framework for black-box and white-box detection of AI-written text with explanations?", "reference_answer": "DNA-GPT: DIVERGENT N-GRAM ANALYSIS FOR TRAINING-FREE DETECTION OF GPT-GENERATED TEXT"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "11e16d8d-e642-592e-a8cf-c38bb375630e", "question": "Can you find a research paper that discusses using structured pruning techniques to scale down language models, where the original model being pruned has billions of parameters?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Can you find a research paper that discusses using structured pruning techniques to scale down language models, where the original model being pruned has billions of parameters?", "reference_answer": "SHEARED LLAMA: ACCELERATING LANGUAGE MODEL PRE-TRAINING VIA STRUCTURED PRUNING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "146cb92e-45a7-5146-a88a-7492f9b12047", "question": "What paper proposes breaking down programming problems by predicting the objects that a solution would create?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper proposes breaking down programming problems by predicting the objects that a solution would create?", "reference_answer": "ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "158a0302-d656-5006-9ab8-421c8816faf6", "question": "Is there a paper that shows that language models' error distribution is different for unfamiliar entities that is not apparent when models are evaluated on familiar entities alone?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that shows that language models' error distribution is different for unfamiliar entities that is not apparent when models are evaluated on familiar entities alone?", "reference_answer": "Factual or Contextual? Disentangling Error Types in Entity Description Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "161f8248-8832-5bf9-85e7-7cbe5d89d69b", "question": "Is there any paper that uses prompt tuning in multi-answer QA?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that uses prompt tuning in multi-answer QA?", "reference_answer": "Answering Ambiguous Questions via Iterative Prompting"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "16a194ad-0f62-5048-ab0e-9afa26e75c66", "question": "Is there a method that measures the information provided in a (model generated) rationale beyond what the original context provided?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a method that measures the information provided in a (model generated) rationale beyond what the original context provided?", "reference_answer": "REV: Information-Theoretic Evaluation of Free-Text Rationales"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "17ed4a9d-9711-5799-b02a-6b2cdd366288", "question": "Is there a study that shows how to help the demonstration retriever better integrate feedback from LLMs?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a study that shows how to help the demonstration retriever better integrate feedback from LLMs?", "reference_answer": "Unified Demonstration Retriever for In-Context Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "192f5d76-b256-57c4-a3e7-1df0fffe30b4", "question": "Which paper studies how difficult is a policy learning problem under non-additive rewards in terms of theoretical lower bounds, and what could be a potential strategy to solve it empirically while recovering some specialized guarantees?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper studies how difficult is a policy learning problem under non-additive rewards in terms of theoretical lower bounds, and what could be a potential strategy to solve it empirically while recovering some specialized guarantees?", "reference_answer": "Submodular Reinforcement Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "1a8c2b00-29f9-5a58-83ab-6dbf7061a039", "question": "Which paper considers both weights and activations when pruning large language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper considers both weights and activations when pruning large language models?", "reference_answer": "A SIMPLE AND EFFECTIVE PRUNING APPROACH FOR LARGE LANGUAGE MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "1c0a1908-daee-5d66-95ab-827900fa14c0", "question": "What paper investigated the effect of the relative position (closer or further away) of the most pertinent retrieved code snippets on repository-level code completion performance?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper investigated the effect of the relative position (closer or further away) of the most pertinent retrieved code snippets on repository-level code completion performance?", "reference_answer": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "1ea15b22-ad6d-584d-80f0-3efa819fc91d", "question": "Which paper proposed dictionary-based Bayesian inference to improve the performance of image text matching model?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposed dictionary-based Bayesian inference to improve the performance of image text matching model?", "reference_answer": "Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "1eab7a9f-66b4-5bd3-9870-e4df2e3192dc", "question": "Can we find the solution of the Bilevel optimization when the lower-level problem is nonconvex?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Can we find the solution of the Bilevel optimization when the lower-level problem is nonconvex?", "reference_answer": "On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "1fa16ed9-14d2-5abe-901b-3d34ddceceee", "question": "What research first proposed a new kind of cascaded diffusion of a Markov process?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What research first proposed a new kind of cascaded diffusion of a Markov process?", "reference_answer": "RELAY DIFFUSION: UNIFYING DIFFUSION PROCESS ACROSS RESOLUTIONS FOR IMAGE SYNTHESIS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2214bdec-6cf4-5cce-a5fb-b531bb41e777", "question": "Which paper first proposed shared adapter module across layers?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proposed shared adapter module across layers?", "reference_answer": "One Network, Many Masks: Towards More Parameter-Efficient Transfer Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2351ad69-2ee2-5348-a305-1b7bc5a8fb3a", "question": "Which paper first found that REINFORCE works better than actor critic algorithms like PPO for RL finetuning of pretrained chemistry language models (Transformers and RNNs)?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first found that REINFORCE works better than actor critic algorithms like PPO for RL finetuning of pretrained chemistry language models (Transformers and RNNs)?", "reference_answer": "Searching for High-Value Molecules Using Reinforcement Learning and Transformers"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "23ca6f0a-69de-55f5-9489-c0d7ddd50b18", "question": "Which papers were among the first to explore the task of targeted training data extraction?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which papers were among the first to explore the task of targeted training data extraction?", "reference_answer": "ETHICIST: Targeted Training Data Extraction Through Loss Smoothed Soft Prompting and Calibrated Confidence Estimation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "247b6978-be01-50c8-92fb-e27122c244f0", "question": "Is there any paper that explores using only an encoder-only masked language model for open-ended long text generation (such as story generation)?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that explores using only an encoder-only masked language model for open-ended long text generation (such as story generation)?", "reference_answer": "Open-ended Long Text Generation via Masked Language Modeling"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "259a085d-f5b9-5b80-aa31-a9720bad7047", "question": "Which paper first proved that wide-enough transformer architectures trained with gradient methods on enough data would learn to solve relational reasoning tasks?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proved that wide-enough transformer architectures trained with gradient methods on enough data would learn to solve relational reasoning tasks?", "reference_answer": "When can transformers reason with abstract symbols?"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "25c78c8f-a93c-547a-b06a-b46a60ecba87", "question": "Is there any paper improves adversarial training by forming semantic aware label without extra pre-train time or data?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper improves adversarial training by forming semantic aware label without extra pre-train time or data?", "reference_answer": "Annealing Self-Distillation Rectification Improves Adversarial Training"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "27413ff9-4f7d-5885-a5ea-79e29a534fa9", "question": "Which paper first found that multilingual models can inference cross-lingual supervision in MLM training by themself?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first found that multilingual models can inference cross-lingual supervision in MLM training by themself?", "reference_answer": "On-the-fly Cross-lingual Masking for Multilingual Pre-training"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2819ea5c-0598-511e-a95f-ce3e567a1b10", "question": "Is there a paper that connects the basic elements of storytelling with biased or imbalanced media reporting?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that connects the basic elements of storytelling with biased or imbalanced media reporting?", "reference_answer": "Conflicts, Villains, Resolutions: Towards models of Narrative Media Framing"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2a0aa66e-7f7a-5870-b5a3-935855255b31", "question": "Is there any paper that combines causal inference and finetuning for language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that combines causal inference and finetuning for language models?", "reference_answer": "Preserving Commonsense Knowledge from Pre-trained Language Models via Causal Inference"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2a25d73b-2f10-5623-8dc5-ff64901b0c82", "question": "Which paper first showed that task-specific knowledge embedded in parameters can be extracted from one LLM using seed samples and transferred to another via parameter-efficient fine-tuning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first showed that task-specific knowledge embedded in parameters can be extracted from one LLM using seed samples and transferred to another via parameter-efficient fine-tuning?", "reference_answer": "SEEKING NEURAL NUGGETS: KNOWLEDGE TRANSFER IN LARGE LANGUAGE MODELS FROM A PARAMETRIC PERSPECTIVE"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2a448d7b-073e-5d05-b1ed-4368558ab1d5", "question": "Which paper first investigates the knowledge preferences of LLMs when there are conflicts between the context and the parametric memory?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first investigates the knowledge preferences of LLMs when there are conflicts between the context and the parametric memory?", "reference_answer": "Adaptive Chameleon or Stubborn Sloth: REVEALING THE BEHAVIOR OF LARGE LANGUAGE MODELS IN KNOWLEDGE CONFLICTS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2e8bd79d-01b0-5ee1-accf-eed43dc316da", "question": "Which paper in human motion generation can control the spatial location of any joints of the human with either dense or sparse 3D points?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper in human motion generation can control the spatial location of any joints of the human with either dense or sparse 3D points?", "reference_answer": "OMNICONTROL: CONTROL ANY JOINT AT ANY TIME FOR HUMAN MOTION GENERATION"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "2ee66dfa-7715-5103-8a58-1b372665df07", "question": "Is there any generalizable NeRF paper that disentangles texture and shape?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any generalizable NeRF paper that disentangles texture and shape?", "reference_answer": "TUVF: LEARNING GENERALIZABLE TEXTURE UV RADIANCE FIELDS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "302c67ba-c324-5ae2-9757-0e05956f17cc", "question": "Which paper first explored In-context learning in a cross lingual setup and made use of alignment to better it's performance?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first explored In-context learning in a cross lingual setup and made use of alignment to better it's performance?", "reference_answer": "Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "30335449-a618-5e66-8c7e-dc0eb81bfaae", "question": "Which neural theorem proving paper first attempted to prove theorems in a block-by-block manner?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which neural theorem proving paper first attempted to prove theorems in a block-by-block manner?", "reference_answer": "LEGO-PROVER: NEURAL THEOREM PROVING WITH GROWING LIBRARIES"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3337061c-d350-5522-9c68-f810e017a567", "question": "Can we reduce visual tokens in vision transformers right from the beginning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Can we reduce visual tokens in vision transformers right from the beginning?", "reference_answer": "SparseFormer: Sparse Visual Recognition via Limited Latent Tokens"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "333e0fbf-b322-5998-939c-cada7786f47a", "question": "Which dataset supports narration generation and temporal localization tasks in Chinese movies?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which dataset supports narration generation and temporal localization tasks in Chinese movies?", "reference_answer": "Movie101: A New Movie Understanding Benchmark"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "34fe12fd-640c-506e-86a2-5ab70a15c11a", "question": "Is there any paper that leverages graph neural network by integrating label information for multi-label low-resource intent classification?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that leverages graph neural network by integrating label information for multi-label low-resource intent classification?", "reference_answer": "Dual Class Knowledge Propagation Network for Multi-label Few-shot Intent Detection"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "35b4110d-486c-562f-b488-c8a8b417ef82", "question": "Which paper first apply mixture of experts idea to large language models for domain adaptation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first apply mixture of experts idea to large language models for domain adaptation?", "reference_answer": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models' Memories"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "37877f34-e27f-5de2-a0ee-ffa5a543a374", "question": "Is there a paper that supports the use of automated coherence metrics in topic model evaluations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that supports the use of automated coherence metrics in topic model evaluations?", "reference_answer": "Large-Scale Correlation Analysis of Automated Metrics for Topic Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "37e98c25-68ba-54c4-9068-596ed64b546d", "question": "Is there an evaluation metric for natural language generation that predicts the factual consistency score through a mean-max aggregation method?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there an evaluation metric for natural language generation that predicts the factual consistency score through a mean-max aggregation method?", "reference_answer": "ALIGNSCORE: Evaluating Factual Consistency with A Unified Alignment Function"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "38965ab2-4bc0-562a-98bf-805f7a9fc3ee", "question": "Which pre-trained model is specifically designed for low-resource dialogue summarization tasks?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which pre-trained model is specifically designed for low-resource dialogue summarization tasks?", "reference_answer": "DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "396c566e-ead8-50a4-b00a-d5ca4c432275", "question": "What paper first extends rotary positional encoding (RoPE) for camera-geometry encoding in multi-view transformers?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first extends rotary positional encoding (RoPE) for camera-geometry encoding in multi-view transformers?", "reference_answer": "GTA: A GEOMETRY-AWARE ATTENTION MECHANISM FOR MULTI-VIEW TRANSFORMERS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3a357488-48e9-58d5-ab3f-fdb931ab1db1", "question": "What work proposes to combine video foundation models with vision language models to effective high dimensional robot planning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What work proposes to combine video foundation models with vision language models to effective high dimensional robot planning?", "reference_answer": "VIDEO LANGUAGE PLANNING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3ae37796-7491-5c6f-9d5c-c6f3e358a888", "question": "What work attempts to explore multi-hop reasoning by densifying commonsense knowledge graphs?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What work attempts to explore multi-hop reasoning by densifying commonsense knowledge graphs?", "reference_answer": "Dense-ATOMIC: Towards Densely-connected ATOMIC with High Knowledge Coverage and Massive Multi-hop Paths"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3b007244-9a68-5972-b0a9-04691a2dd6d2", "question": "Which language model distillation paper that first identified the capacity gap in distillation and used the MoE student model to counter the curse of capacity gap?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which language model distillation paper that first identified the capacity gap in distillation and used the MoE student model to counter the curse of capacity gap?", "reference_answer": "Lifting the Curse of Capacity Gap in Distilling Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3b83e010-75b3-5fa9-a5c1-7f786db8d957", "question": "Which paper proposes an alignment framework that steers language models to preferences of individual groups in a few-shot manner through augmenting the LLM with a transformer module?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposes an alignment framework that steers language models to preferences of individual groups in a few-shot manner through augmenting the LLM with a transformer module?", "reference_answer": "GROUP PREFERENCE OPTIMIZATION: FEW-SHOT ALIGNMENT OF LARGE LANGUAGE MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3c712282-2534-5627-84f0-ce1e39212d20", "question": "Is there a paper that uses evolutionary algorithms and neural MT metrics to produce translations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that uses evolutionary algorithms and neural MT metrics to produce translations?", "reference_answer": "Breeding Machine Translations: Evolutionary approach to survive and thrive in the world of automated evaluation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3dc8318e-3f56-5ba9-8542-f845aad5e8a8", "question": "What are some methods for solving the class-incremetal continual learning problems?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What are some methods for solving the class-incremetal continual learning problems?", "reference_answer": "Rehearsal-free Continual Language Learning via Efficient Parameter Isolation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "3fe5526c-b647-51b0-9abb-6edd43c20f79", "question": "Which paper is the first to model the helpfulness and harmlessness alignment of LLMs as a Constrained MDP problem?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper is the first to model the helpfulness and harmlessness alignment of LLMs as a Constrained MDP problem?", "reference_answer": "SAFE RLHF: SAFE REINFORCEMENT LEARNING FROM HUMAN FEEDBACK"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4098e496-9c0b-53b7-acf1-5cde707b8f91", "question": "Which paper proposed decomposing the logit update of each of the attention blocks’ inputs to analyze how the context influences the prediction?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposed decomposing the logit update of each of the attention blocks’ inputs to analyze how the context influences the prediction?", "reference_answer": "Explaining How Transformers Use Context to Build Predictions"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4684de7e-9fc6-5bfe-acd6-0b8d0fc97647", "question": "Which works shows that training large language models with purely mathematical and structural data can exhibit emergence of causal reasoning faster?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which works shows that training large language models with purely mathematical and structural data can exhibit emergence of causal reasoning faster?", "reference_answer": "Learning Multi-Step Reasoning by Solving Arithmetic Tasks"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "46be0f62-9897-5042-b3c4-f67bdd0bed89", "question": "Is there an existing dataset of images with alt-text that also includes the text the image was originally posted with?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there an existing dataset of images with alt-text that also includes the text the image was originally posted with?", "reference_answer": "ALT-TEXT WITH CONTEXT: IMPROVING ACCESSIBILITY FOR IMAGES ON TWITTER"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "46d8670b-3464-5526-b9f9-d5d48dd5bfa1", "question": "Which paper first proposed to combine pretrained masked language models (BERT) and discrete diffusion language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proposed to combine pretrained masked language models (BERT) and discrete diffusion language models?", "reference_answer": "DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "48471601-0130-52f7-8580-d15b057e1bbf", "question": "Is there any paper that constructs augmented training data based on the entity-to-entity correlations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that constructs augmented training data based on the entity-to-entity correlations?", "reference_answer": "PeerDA: Data Augmentation via Modeling Peer Relation for Span Identification Tasks *"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4a99d14d-69e7-55d7-b6fa-2878ad1a8e50", "question": "Which paper did a comprehensive survey of the code large language model (code LLMs)?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper did a comprehensive survey of the code large language model (code LLMs)?", "reference_answer": "Large Language Models Meet NL2Code: A Survey"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4b4877cd-4cdc-5d52-ac20-edfaa6dd7e32", "question": "Is there any paper leverages knowledge distillation of language models for textual out-of-distribution detection or anomaly detection?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper leverages knowledge distillation of language models for textual out-of-distribution detection or anomaly detection?", "reference_answer": "Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4c29808a-cdfa-5e4b-90ee-318b30636e7c", "question": "Which paper studies how current retrieval systems handle queries which contain multiple constraints?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper studies how current retrieval systems handle queries which contain multiple constraints?", "reference_answer": "QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4da68474-8cf2-5077-aa1d-3b7ae74cc70e", "question": "Is there a paper that applies large language models to visual Raven’s Progressive Matrices?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that applies large language models to visual Raven’s Progressive Matrices?", "reference_answer": "In-Context Analogical Reasoning with Pre-Trained Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4dbe770d-1734-5c99-b16d-af3242b8c0ee", "question": "Give me a paper proposing to circumvent a single-truth target in training generative language models.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Give me a paper proposing to circumvent a single-truth target in training generative language models.", "reference_answer": "Soft Alignment Objectives for Robust Adaptation of Language Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4de3ce4f-4b12-59ea-9141-fe765b6e94b3", "question": "Are there sequential learning guarantees for configuring a linear system solver under a distributional assumption on the systems' target vectors?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there sequential learning guarantees for configuring a linear system solver under a distributional assumption on the systems' target vectors?", "reference_answer": "LEARNING TO RELAX: SETTING SOLVER PARAMETERS ACROSS A SEQUENCE OF LINEAR SYSTEM INSTANCES"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4ea66ea8-4a7e-52a2-9c97-c900c9e55da6", "question": "How to faithfully and explicitly measure the helpfulness of human explanations to language models during finetuning and inference?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "How to faithfully and explicitly measure the helpfulness of human explanations to language models during finetuning and inference?", "reference_answer": "Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4f284188-a3d4-5a9a-a723-4f589f221cdd", "question": "Which paper systematically examed the input mismatch between training and sampling in diffusion models", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper systematically examed the input mismatch between training and sampling in diffusion models", "reference_answer": "ELUCIDATING THE EXPOSURE BIAS IN DIFFUSION MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "4fe2e01e-83c6-5121-80fc-7c937e0d73ae", "question": "What paper first uses decoupled workers in distributed RL system?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first uses decoupled workers in distributed RL system?", "reference_answer": "SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "51690cda-38bb-51a8-8c7d-59e8a7f732eb", "question": "Which paper first conducted the positioned error test for the MAUVE metric?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first conducted the positioned error test for the MAUVE metric?", "reference_answer": "On the Blind Spots of Model-Based Evaluation Metrics for Text Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "52bc8a41-b87d-56ad-b253-83e0fd05e698", "question": "Which work proposes an approach to improve candidate responses in the smart reply task by directly optimizing the metric to ensure that a response is selected by the user?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which work proposes an approach to improve candidate responses in the smart reply task by directly optimizing the metric to ensure that a response is selected by the user?", "reference_answer": "Model-Based Simulation for Optimising Smart Reply"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "541382e2-2866-5c2c-9a53-36c96868b9f1", "question": "Which paper proposed the integration of human translators' considerations, such as length control, rhyme type control and suggestion, and enhancing compatibility between translation output and unseen melodies, into the design of machine translation models when translating lyrics?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposed the integration of human translators' considerations, such as length control, rhyme type control and suggestion, and enhancing compatibility between translation output and unseen melodies, into the design of machine translation models when translating lyrics?", "reference_answer": "Songs Across Borders: Singable and Controllable Neural Lyric Translation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "560cb9c7-cd1b-5574-947b-8a3da732d2e3", "question": "Which paper first aggregates statements to represent political actors and learns the mapping from languages to representation via pre-training?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first aggregates statements to represent political actors and learns the mapping from languages to representation via pre-training?", "reference_answer": "UPPAM: A Unified Pre-training Architecture for Political Actor Modeling based on Language"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "56b65fba-a965-5e63-a409-4d834fe2926f", "question": "Is there a tool that can automatically segment speech and the corresponding text transcriptions, to obtain a finer grained alignment?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a tool that can automatically segment speech and the corresponding text transcriptions, to obtain a finer grained alignment?", "reference_answer": "CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "56d50d2a-9ade-583d-a3e9-277363538066", "question": "Which paper shows assessment of training instabilities at different levels for language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper shows assessment of training instabilities at different levels for language models?", "reference_answer": "Measuring the Instability of Fine-Tuning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "5752ba6d-a2f0-5672-90c8-919979dd4edf", "question": "Are there any papers that construct convolutional networks which are equivariant with respect to non-compact/non-abelian Lie groups?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there any papers that construct convolutional networks which are equivariant with respect to non-compact/non-abelian Lie groups?", "reference_answer": "LIE GROUP DECOMPOSITIONS FOR EQUIVARIANT NEURAL NETWORKS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "59369806-b544-5f82-b668-1bd4b943e892", "question": "What research exists on incorporating knowledge graphs into language models to improve their complex question-answering capabilities?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What research exists on incorporating knowledge graphs into language models to improve their complex question-answering capabilities?", "reference_answer": "Knowledge Graph-augmented Language Models for Complex Question Answering"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "5960606a-4a02-5726-8048-bc2c52ad726b", "question": "Is there any paper that applies curriculum learning to various NLG tasks without depending on specific metrics?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that applies curriculum learning to various NLG tasks without depending on specific metrics?", "reference_answer": "In-sample Curriculum Learning by Sequence Completion for Natural Language Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "5c967488-f464-5ab5-aa13-d1dc6be7e4e2", "question": "Is there any paper that proposes a set of criteria to comprehensively evaluate generated conversations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that proposes a set of criteria to comprehensively evaluate generated conversations?", "reference_answer": "Modeling What-to-ask and How-to-ask for Answer-unaware Conversational Question Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "5cae6dda-4a2d-52ec-b511-953f476c3600", "question": "Is there any paper that proposes a new multimodal video dataset that image-level multimodal models do not work well?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that proposes a new multimodal video dataset that image-level multimodal models do not work well?", "reference_answer": "Revealing Single Frame Bias for Video-and-Language Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "60bf1f10-7280-54b7-b364-b7c322b69d51", "question": "Which paper utilized MMD flows with Riesz kernels to solve Bayesian inverse problems?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper utilized MMD flows with Riesz kernels to solve Bayesian inverse problems?", "reference_answer": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "61e20be1-7b19-580f-a86e-2132be450bc3", "question": "Which paper examined the scalability of instruction-tuning with respect to Mixture of Expert models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper examined the scalability of instruction-tuning with respect to Mixture of Expert models?", "reference_answer": "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "63dc113b-0220-5cb4-9bd3-17ba26c310b0", "question": "Which paper introduce a DRO (distribution robust optimization) like training objective for doing adversarial training without constructing adversarial samples.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper introduce a DRO (distribution robust optimization) like training objective for doing adversarial training without constructing adversarial samples.", "reference_answer": "DSRM: Boost Textual Adversarial Training with Distribution Shift Risk Minimization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "655b8b31-8ecd-5b34-9bc4-e9816b314c27", "question": "Could you recommend research that assesses how well language learning models, such as ChatGPT, perform in creating reading comprehension tasks for educational software?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Could you recommend research that assesses how well language learning models, such as ChatGPT, perform in creating reading comprehension tasks for educational software?", "reference_answer": "Evaluating Reading Comprehension Exercises Generated by LLMs: A Showcase of ChatGPT in Education Applications"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "65a648a6-9bea-5467-84fd-2ca01dc52084", "question": "Which paper uses the latent diffusion model for the first time to solve offline reinforcement learning problems based on the sequential modeling framework?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper uses the latent diffusion model for the first time to solve offline reinforcement learning problems based on the sequential modeling framework?", "reference_answer": "Efficient Planning with Latent Diffusion"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "65c9fe88-46f0-579d-ba7b-ca58ee7c55f2", "question": "Which paper introduces the R-GCN technique into document-level joint entity and relation extraction?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper introduces the R-GCN technique into document-level joint entity and relation extraction?", "reference_answer": "A Novel Table-to-Graph Generation Approach for Document-Level Joint Entity and Relation Extraction"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "6af99fe6-5e33-5632-8553-aa9d1daaad86", "question": "Find the NLP paper that focuses on dialogue generation and introduces advancements in the augmentation of one-to-many or one-to-one dialogue data by conducting augmentation within the semantic space.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Find the NLP paper that focuses on dialogue generation and introduces advancements in the augmentation of one-to-many or one-to-one dialogue data by conducting augmentation within the semantic space.", "reference_answer": "DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "6b660c4a-c2a0-538f-b42a-bfe6337add99", "question": "Could you recommend a dataset paper which presents relation extraction performance on translated data and compare it to English data?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Could you recommend a dataset paper which presents relation extraction performance on translated data and compare it to English data?", "reference_answer": "MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "6dc50c47-0782-5277-b10a-e5e427a10223", "question": "What is the first paper that theoretically studies training neural networks under small initialization?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What is the first paper that theoretically studies training neural networks under small initialization?", "reference_answer": "Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "6de72b3a-ac37-5d2d-b870-a61dac353bdb", "question": "Is there any paper that attempts to evaluate the similarity of meaning representations without using annotated data?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that attempts to evaluate the similarity of meaning representations without using annotated data?", "reference_answer": "Evaluate AMR Graph Similarity via Self-supervised Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "6ee75006-72d3-5d81-b85d-ec25b99ed502", "question": "Which vision-language model can demonstrate that visual grounding could facilitate efficient language acquisition? (OctoBERT)", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which vision-language model can demonstrate that visual grounding could facilitate efficient language acquisition? (OctoBERT)", "reference_answer": "World-to-Words: Grounded Open Vocabulary Acquisition through Fast Mapping in Vision-Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7175414d-1ddc-5d5a-b4a6-8a25ba6f2078", "question": "Is there a decoder-only language model that does not use a tokenizer and operates on raw text bytes?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a decoder-only language model that does not use a tokenizer and operates on raw text bytes?", "reference_answer": "ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "71fd543c-b0f5-5631-b97d-0c9f7a996a86", "question": "What paper first used the technique of prompt engineering to generate adversarial prompts that can fool LLMs into making wrong predictions in prompt-based learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first used the technique of prompt engineering to generate adversarial prompts that can fool LLMs into making wrong predictions in prompt-based learning?", "reference_answer": "AN LLM CAN FOOL ITSELF: A PROMPT-BASED ADVERSARIAL ATTACK"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7231e809-3ffe-5fb5-84b6-633ba6c788f5", "question": "Are there datasets and benchmarks available for measuring LLM graph reasoning abilities?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there datasets and benchmarks available for measuring LLM graph reasoning abilities?", "reference_answer": "TALK LIKE A GRAPH: ENCODING GRAPHS FOR LARGE LANGUAGE MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "72c5b793-458d-5af4-86eb-542f839c023a", "question": "What research has been conducted on incorporating visual data into the text summarization process?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What research has been conducted on incorporating visual data into the text summarization process?", "reference_answer": "Summary-Oriented Vision Modeling for Multimodal Abstractive Summarization"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "748c93fa-539a-5f0f-887d-746da0323e23", "question": "Which paper first proposed to only update some original weights of self-attention layers in parameter-efficient fine-tuning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proposed to only update some original weights of self-attention layers in parameter-efficient fine-tuning?", "reference_answer": "HiFi: High-Information Attention Heads Hold for Parameter-Efficient Model Adaptation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "75b9dc7d-abbe-5627-ac3d-649055da6df9", "question": "Which paper proposes to use rewriting based approaches to defending against adversarial attacks in text classification?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposes to use rewriting based approaches to defending against adversarial attacks in text classification?", "reference_answer": "Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "75cd4886-f858-506d-ad37-85cc7c605b3f", "question": "Which paper first introduced document content as an intermediate generation target and utilized textual document identifiers in generative retrieval?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first introduced document content as an intermediate generation target and utilized textual document identifiers in generative retrieval?", "reference_answer": "TOME: A Two-stage Approach for Model-based Retrieval"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "765fc890-3100-5b7f-9068-9460147a99cd", "question": "Which article first proposed shuffled-group-whitening to solve the problem of sentence representation learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which article first proposed shuffled-group-whitening to solve the problem of sentence representation learning?", "reference_answer": "WhitenedCSE: Whitening-based Contrastive Learning of Sentence Embeddings"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "76aee9c9-711d-5c33-9edd-68f80d3dc1ca", "question": "Are there any papers that build dense retrievers with mixture-of-experts architecture where each expert is responsible for different types of queries?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there any papers that build dense retrievers with mixture-of-experts architecture where each expert is responsible for different types of queries?", "reference_answer": "Chain-of-Skills: A Configurable Model for Open-Domain Question Answering"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "79e15976-b650-5e63-847a-8a6ed4c1de02", "question": "If one would like to train (or evaluate) a helpful assistant agent that can converse with humans while the humans traverse an environment, which work has the most suitable resource?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "If one would like to train (or evaluate) a helpful assistant agent that can converse with humans while the humans traverse an environment, which work has the most suitable resource?", "reference_answer": "SIMMC-VR: A Task-oriented Multimodal Dialog Dataset with Situated and Immersive VR Streams"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7a1887ea-4b59-53c5-a860-d6dbd87f0d83", "question": "Can you find a dataset that shows LLM-based evaluation may not be reliable enough?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Can you find a dataset that shows LLM-based evaluation may not be reliable enough?", "reference_answer": "EVALUATING LARGE LANGUAGE MODELS AT EVALUATING INSTRUCTION FOLLOWING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7bd66a0c-2558-572f-8e9c-51c2422a7d1d", "question": "*Could you suggest a dataset with legally or ethically contentious content, and labels for acceptable and non-acceptable questions.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "*Could you suggest a dataset with legally or ethically contentious content, and labels for acceptable and non-acceptable questions.", "reference_answer": "SQUARE: A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created Through Human-Machine Collaboration"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "7c5afdfd-0983-59be-b714-636d275bf7ad", "question": "Which paper used both automatically generated and manual templates with word tuples to adapt language models from one timestamp to another?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper used both automatically generated and manual templates with word tuples to adapt language models from one timestamp to another?", "reference_answer": "Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7ca5b284-3586-51a2-b05f-e6adacb7e072", "question": "Is there any paper that previously proposed to control a risk using prediction sets, based on the literature in conformal prediction?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that previously proposed to control a risk using prediction sets, based on the literature in conformal prediction?", "reference_answer": "Conformal Risk Control"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7d231de8-b8f7-588f-87b0-4fe7b4be0863", "question": "Which knowledge graph completion method focuses on reducing memory usage by pruning features?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which knowledge graph completion method focuses on reducing memory usage by pruning features?", "reference_answer": "GreenKGC: A Lightweight Knowledge Graph Completion Method"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7d856467-aba1-5b39-8ebc-d533b61dc86b", "question": "Which paper highlights the need for leveraging all available resources, including dictionaries, machine translation systems, and language learners, to construct NLP data in low-resource languages?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper highlights the need for leveraging all available resources, including dictionaries, machine translation systems, and language learners, to construct NLP data in low-resource languages?", "reference_answer": "Rethinking Annotation: Can Language Learners Contribute?"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7dbe882d-0adf-5c1b-86f8-71b1a7508bca", "question": "Which paper trains on linear regression to hypothesize how fine-tuning affects language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper trains on linear regression to hypothesize how fine-tuning affects language models?", "reference_answer": "UNDERSTANDING CATASTROPHIC FORGETTING IN LANGUAGE MODELS VIA IMPLICIT INFERENCE"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7dee922c-95de-5d8e-8f03-4c27b84c7919", "question": "Which paper formally defines the problem of model selection in llm agent for multi-modal reasoning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper formally defines the problem of model selection in llm agent for multi-modal reasoning?", "reference_answer": "TOWARDS ROBUST MULTI-MODAL REASONING VIA MODEL SELECTION"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7e8b3e8b-6834-5662-bb05-c05c9b0d38d6", "question": "Is there any research paper that can extract attributes from both a predefined label set and the surrounding context?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any research paper that can extract attributes from both a predefined label set and the surrounding context?", "reference_answer": "AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "7f6dafa1-72c9-5c9b-a4bc-dbddaf15f4de", "question": "Is there a paper illustrating that pre-trained transformers from LLMs can be used to encode visual information in a wide range of scenarios?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper illustrating that pre-trained transformers from LLMs can be used to encode visual information in a wide range of scenarios?", "reference_answer": "FROZEN TRANSFORMERS IN LANGUAGE MODELS ARE EFFECTIVE VISUAL ENCODER LAYERS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "818501f3-3983-598b-903a-9bfc0ec268d6", "question": "Is there any paper that utilizes masked language modeling to defend against word-level adversarial attacks?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that utilizes masked language modeling to defend against word-level adversarial attacks?", "reference_answer": "RMLM: A Flexible Defense Framework for Proactively Mitigating Word-level Adversarial Attacks"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "81a62980-3225-5149-b703-e7c4bc4d48ea", "question": "Is there such a reading comprehension dataset in understanding a snippet from a long story book, while it requires to integrate the necessary long history texts before the snippet to full understand it?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there such a reading comprehension dataset in understanding a snippet from a long story book, while it requires to integrate the necessary long history texts before the snippet to full understand it?", "reference_answer": "Personality Understanding of Fictional Characters during Book Reading"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "82d3067f-1da3-5800-b7ef-a4571d85ccde", "question": "What paper is the first to prove finetuned LLM can be a reliable judge?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper is the first to prove finetuned LLM can be a reliable judge?", "reference_answer": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "837e7da7-5e5c-5cb9-bcb0-c1dc60d97569", "question": "Which paper first used structural information for coherence modeling?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first used structural information for coherence modeling?", "reference_answer": "Modeling Structural Similarities between Documents for Coherence Assessment with Graph Convolutional Networks"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "881d40cb-62f6-57d9-b4bb-75ce6a1c2b89", "question": "Which paper studies the concept of enhancing the coverage of a selective prediction system by re-attempting the questions on which it was not sufficiently confident.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper studies the concept of enhancing the coverage of a selective prediction system by re-attempting the questions on which it was not sufficiently confident.", "reference_answer": "Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances in QA"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "895610a0-b3ae-5623-a8e2-e0731eae53f6", "question": "Is there a paper that uses Explainable AI techniques to investigate how language models represent the expression of morality?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that uses Explainable AI techniques to investigate how language models represent the expression of morality?", "reference_answer": "What does a Text Classifier Learn about Morality? An Explainable Method for Cross-Domain Comparison of Moral Rhetoric"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "8a08dc1f-6e2c-5e4b-9da4-34f5fb3ee073", "question": "Which paper contains quantitative results demonstrating taking VQ tokens as inputs is inferior to pixel images for dense recognition tasks?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper contains quantitative results demonstrating taking VQ tokens as inputs is inferior to pixel images for dense recognition tasks?", "reference_answer": "ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "8b6057cc-77e5-5981-9d3f-5b9b62126d0e", "question": "What work proposes a model to learn a latent regular cell complex from data?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What work proposes a model to learn a latent regular cell complex from data?", "reference_answer": "From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "8b79fc88-0307-532a-bbdb-e8990fb27372", "question": "What paper considers sensitive data issue when prompting large language model APIs?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper considers sensitive data issue when prompting large language model APIs?", "reference_answer": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "8ba9edfd-5a7a-5ec1-9d22-329443311f3b", "question": "Is there any paper that aligns speech and text embeddings better than CTC training?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that aligns speech and text embeddings better than CTC training?", "reference_answer": "WACO: Word-Aligned Contrastive Learning for Speech Translation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "8e1ebc95-7523-5a09-b95c-85748f5825ae", "question": "Which paper is among the earliest to train on extensive collection of signing video and subtitle pairs available from online platforms?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper is among the earliest to train on extensive collection of signing video and subtitle pairs available from online platforms?", "reference_answer": "Gloss-Free End-to-End Sign Language Translation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "8f94a406-ef97-584a-a578-17a8b0380287", "question": "Which paper first derived online occupany estimation technique to get sqrt(T) bound for reinforcement learning in adversarial linear MDP?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first derived online occupany estimation technique to get sqrt(T) bound for reinforcement learning in adversarial linear MDP?", "reference_answer": "Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "90aa9ace-0a80-5867-893b-e342497160a1", "question": "Is there any paper that tries to investigate LLMs’ capabilities in solving elliptical constructions by using a test-dataset based on the psycolinguistic notion of Thematic Fit?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that tries to investigate LLMs’ capabilities in solving elliptical constructions by using a test-dataset based on the psycolinguistic notion of Thematic Fit?", "reference_answer": "We Understand Elliptical Sentences, and Language Models Should Too: A New Dataset for Studying Ellipsis and its Interaction with Thematic Fit"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "92c53685-6c5d-538a-9c62-887598de3301", "question": "Is there a paper that utilizes the characteristics of human evolutionary knowledge to guide language models in generating scientific ideas?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that utilizes the characteristics of human evolutionary knowledge to guide language models in generating scientific ideas?", "reference_answer": "Exploring and Verbalizing Academic Ideas by Concept Co-occurrence"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "92dcdc85-f07b-5980-80c0-474447201940", "question": "Are there any large-scale and open-source text simplification datasets dealing with long passages?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there any large-scale and open-source text simplification datasets dealing with long passages?", "reference_answer": "SWIPE: A Dataset for Document-Level Simplification of Wikipedia Pages"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "93272751-e57b-55e7-a89a-ef2387c4d2be", "question": "Is there any paper that studies a teacher AI inferring mental states of a student role in a role-playing game setup using reinforcement learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that studies a teacher AI inferring mental states of a student role in a role-playing game setup using reinforcement learning?", "reference_answer": "I Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "9388f82d-b44e-52a4-8e0e-4b0e93bd5876", "question": "Which paper proposes the two-stage training method, i.e., task-specific fine-tuning and cross-domain pre-training, to train an open-domain dialogue evaluator using the self-collected dataset.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposes the two-stage training method, i.e., task-specific fine-tuning and cross-domain pre-training, to train an open-domain dialogue evaluator using the self-collected dataset.", "reference_answer": "RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "93cbeec6-18b1-55ba-93f3-8be583414ea9", "question": "Which paper about parameter-efficient finetuning first proposes to feed the pretrained weight instead of the activation to an adapter?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper about parameter-efficient finetuning first proposes to feed the pretrained weight instead of the activation to an adapter?", "reference_answer": "Parameter-Efficient Fine-Tuning without Introducing New Latency"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "948c99f1-12ba-5c05-8cbf-de25811480b1", "question": "Is there a dialogue dataset where a speaker's utterance is grounded in their persona, consisting of image-text pairs representing their episodic memories?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a dialogue dataset where a speaker's utterance is grounded in their persona, consisting of image-text pairs representing their episodic memories?", "reference_answer": "MPCHAT: Towards Multimodal Persona-Grounded Conversation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "94bf4901-caa8-50d8-9626-f34f0226b4e9", "question": "Is there research that investigates embedding multi-bit data into watermarks to improve resilience to text corruption, particularly aimed at safeguarding keywords and syntactic elements from modification?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there research that investigates embedding multi-bit data into watermarks to improve resilience to text corruption, particularly aimed at safeguarding keywords and syntactic elements from modification?", "reference_answer": "Robust Multi-bit Natural Language Watermarking through Invariant Features"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "94ef0706-a58e-556e-b4c4-0dfe3f47ff63", "question": "Is there any work that allows large numbers of model outputs to be encoded and compared by causal language models in a single forward pass?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any work that allows large numbers of model outputs to be encoded and compared by causal language models in a single forward pass?", "reference_answer": "EEL: Efficiently Encoding Lattices for Reranking"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "985616d9-fbc1-5329-824f-15b2d1d79de0", "question": "Is there any dataset that contains minimally-contrasting social situations that lead to different decisions about which behaviors are appropriate in that situation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any dataset that contains minimally-contrasting social situations that lead to different decisions about which behaviors are appropriate in that situation?", "reference_answer": "NORMBANK: A Knowledge Bank of Situational Social Norms"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "98f8113e-ec12-53ee-877c-ed347c655fbd", "question": "Which paper found that using common character encodings and ciphers, or even just convincing the model that it is not communicating in natural language, can bypass the safety guardrails of large models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper found that using common character encodings and ciphers, or even just convincing the model that it is not communicating in natural language, can bypass the safety guardrails of large models?", "reference_answer": "GPT-4 IS TOO SMART TO BE SAFE: STEALTHY CHAT WITH LLMS VIA CIPHER"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "99965706-7450-5c82-9db7-a9f9605c5fc6", "question": "Which research paper leverages event structure information from Abstract Meaning Representation (AMR) graphs to aid in recognizing causal relations between events?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which research paper leverages event structure information from Abstract Meaning Representation (AMR) graphs to aid in recognizing causal relations between events?", "reference_answer": "Semantic Structure Enhanced Event Causality Identification"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "9b05a21b-7190-547c-ae1c-2a4b21a84826", "question": "Is there a paper that uses similarity scores to check knowledge in diffusion models", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that uses similarity scores to check knowledge in diffusion models", "reference_answer": "Multilingual Conceptual Coverage in Text-to-Image Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "9f4464f1-93bd-58ea-9d06-be56dfc0f60b", "question": "Which numerical reasoning paper first published a dataset that considers different types of size of numbers and their representations in arithmetic questions?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which numerical reasoning paper first published a dataset that considers different types of size of numbers and their representations in arithmetic questions?", "reference_answer": "FERMAT: An Alternative to Accuracy for Numerical Reasoning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a06cf968-8d7c-5d7a-b203-91bb312150b7", "question": "Is there any paper that uses data collected from the Dark Web, specifically onion domains, to pretrain a language model?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that uses data collected from the Dark Web, specifically onion domains, to pretrain a language model?", "reference_answer": "DarkBERT: A Language Model for the Dark Side of the Internet"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a3555904-aa5f-5f4d-b823-b51bacf04995", "question": "Which paper introduced the human-evaluated timeliness metric for misinformation detection?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper introduced the human-evaluated timeliness metric for misinformation detection?", "reference_answer": "Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a36db3b8-16d0-5a14-bebb-3e3eea363d27", "question": "What are some evaluation benchmarks for LLM privacy at inference time, targeted towards model input and NOT the training data.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What are some evaluation benchmarks for LLM privacy at inference time, targeted towards model input and NOT the training data.", "reference_answer": "CAN LLMS KEEP A SECRET? TESTING PRIVACY IMPLICATIONS OF LANGUAGE MODELS VIA CONTEXTUAL INTEGRITY THEORY"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a4359833-c1ee-5d01-b18d-1d1a78c749f0", "question": "Is there any work that attacks language models in dialogue generation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any work that attacks language models in dialogue generation?", "reference_answer": "White-Box Multi-Objective Adversarial Attack on Dialogue Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a4ce44e5-a7d3-5043-981c-99695dd766e5", "question": "Which paper first proposed extracting the pair of target and stance from sentences?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proposed extracting the pair of target and stance from sentences?", "reference_answer": "A New Direction in Stance Detection: Target-Stance Extraction in the Wild"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a629b08b-2d1e-5a0e-a39a-007749de7759", "question": "Is there a paper that uses the tree structure of math equations in autoregressive language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that uses the tree structure of math equations in autoregressive language models?", "reference_answer": "Tree-Based Representation and Generation of Natural and Mathematical Language"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a64654b4-b4c5-5167-b58b-529530c1be68", "question": "Is there any paper about style transfer for stories?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper about style transfer for stories?", "reference_answer": "StoryTrans: Non-Parallel Story Author-Style Transfer with Discourse Representations and Content Enhancing"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a69b7df9-1ecd-579e-85ae-17de9f0dfbba", "question": "Are there any examples of using dense phrase retrieval systems in the automatic curation of entity dictionaries?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there any examples of using dense phrase retrieval systems in the automatic curation of entity dictionaries?", "reference_answer": "Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a6e178bd-06c1-58c3-b6f1-e72b0cab6a03", "question": "Which paper first studied differential privacy for in-context learning to prevent prompt leakage attacks?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first studied differential privacy for in-context learning to prevent prompt leakage attacks?", "reference_answer": "PRIVACY-PRESERVING IN-CONTEXT LEARNING FOR LARGE LANGUAGE MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a743e85d-4b2c-5671-a371-578b2f0af908", "question": "Is there any paper that explores and annotates the effectiveness of using testimonials or anecdotes in discussions?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that explores and annotates the effectiveness of using testimonials or anecdotes in discussions?", "reference_answer": "StoryARG: a corpus of narratives and personal experiences in argumentative texts"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a762550d-b54a-5e5f-8fcf-d3be3058cd28", "question": "Could you recommend a contemporary research paper that has advanced natural language watermarking quality through algorithmic methods?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Could you recommend a contemporary research paper that has advanced natural language watermarking quality through algorithmic methods?", "reference_answer": "Robust Multi-bit Natural Language Watermarking through Invariant Features"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "a903623b-95ca-5dc2-a8a8-3c9851d02779", "question": "Is there any paper that employs code LLMs to iteratively generate and refine code with execution results to improve the performance?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that employs code LLMs to iteratively generate and refine code with execution results to improve the performance?", "reference_answer": "Self-Edit: Fault-Aware Code Editor for Code Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a9275d5c-ec5c-5fd2-b8de-0866aaee4fb8", "question": "Which paper combines the advantages of different frameworks for grammar error correction (GEC) and achieves good performance?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper combines the advantages of different frameworks for grammar error correction (GEC) and achieves good performance?", "reference_answer": "TemplateGEC: Improving Grammatical Error Correction with Detection Template"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "a9aba86b-c608-5d87-9039-cc130911a03d", "question": "What molecular representation learning paper introduced a benchmark that focuses on learning over thermodynamically-accessible conformer ensembles across diverse molecular properties and chemical reactions?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What molecular representation learning paper introduced a benchmark that focuses on learning over thermodynamically-accessible conformer ensembles across diverse molecular properties and chemical reactions?", "reference_answer": "Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "aa4ec90c-b162-5319-9a00-ca47101c24f8", "question": "Which paper showed that social relationships were helpful for identifying inappropriate messages?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper showed that social relationships were helpful for identifying inappropriate messages?", "reference_answer": "Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "aa5598d0-e570-5f39-afd6-159fd696bdc6", "question": "What paper mitigates language model sampling errors due to the softmax bottleneck?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper mitigates language model sampling errors due to the softmax bottleneck?", "reference_answer": "CLOSING THE CURIOUS CASE OF NEURAL TEXT DEGENERATION"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ab9138b7-f6f2-5fd0-9430-1d0664ceb5c3", "question": "Which paper first studied the efficiency robustness of multi-exit language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first studied the efficiency robustness of multi-exit language models?", "reference_answer": "Dynamic Transformers Provide a False Sense of Efficiency"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ab9cd1cf-213f-5551-b4fb-104a3ba51266", "question": "Which paper shows that in instruction tuning, the instructions can be compressed to small supporting sets of words that provide useful information?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper shows that in instruction tuning, the instructions can be compressed to small supporting sets of words that provide useful information?", "reference_answer": "Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ac041b6a-467d-53ce-8419-f283f3e0d7aa", "question": "Is there any paper that reveals annotation problems in cross-lingual summarization caused by decomposing the task into translation and summarization?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that reveals annotation problems in cross-lingual summarization caused by decomposing the task into translation and summarization?", "reference_answer": "Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New Benchmark with Improved Annotation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "af63f4bc-4bf0-5521-aa2d-c032a1b947c8", "question": "Is there any paper that address attacks on code models by leveraging the semantic information of the source code through attention scores, while also guaranteeing that the generated adversarial examples can always be compiled successfully?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that address attacks on code models by leveraging the semantic information of the source code through attention scores, while also guaranteeing that the generated adversarial examples can always be compiled successfully?", "reference_answer": "DIP: Dead code Insertion based Black-box Attack for Programming Language Model"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b0b2b9a1-fa76-5027-9ba7-84a9876c07ac", "question": "Is there any paper that uses token-level loss to enhance sentence-level embedding learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that uses token-level loss to enhance sentence-level embedding learning?", "reference_answer": "Dual-Alignment Pre-training for Cross-lingual Sentence Embedding"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b10c0e3a-48e4-5878-bbff-1611969ca685", "question": "What is the first paper that uses the generalized linear model to analyze multi-neural spike train data?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What is the first paper that uses the generalized linear model to analyze multi-neural spike train data?", "reference_answer": "ONE-HOT GENERALIZED LINEAR MODEL FOR SWITCHING BRAIN STATE DISCOVERY"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b1724696-f143-5f5a-a58d-2f4086212016", "question": "Is there any paper that utilizes graph structure to model conversation history?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that utilizes graph structure to model conversation history?", "reference_answer": "History Semantic Graph Enhanced Conversational KBQA with Temporal Information Modeling"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b33b2cf3-a27a-5b2a-a1ca-5f08d8b1e75e", "question": "Which paper makes sure that the questions used in the paper are all from real users that are genuinely curious about a specific topic or concept?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper makes sure that the questions used in the paper are all from real users that are genuinely curious about a specific topic or concept?", "reference_answer": "CREPE: Open-Domain Question Answering with False Presuppositions"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b39cbbdd-8489-53f0-a9ca-d0dbc46c8ead", "question": "What limitations do large language models have in evaluating information-seeking question answering?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What limitations do large language models have in evaluating information-seeking question answering?", "reference_answer": "Evaluating Open-Domain Question Answering in the Era of Large Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b3a5fb63-2a87-5e0c-bd8d-29f25772319c", "question": "What paper first associate the modeling frequency with input human skeletons under the NeRF framework?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first associate the modeling frequency with input human skeletons under the NeRF framework?", "reference_answer": "POSE MODULATED AVATARS FROM VIDEO"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b5307d05-348e-50df-8932-95ccf83020f0", "question": "Which paper investigates the influence of the diversity of source tasks on the performance of target tasks in prompt tuning using CrossFit?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper investigates the influence of the diversity of source tasks on the performance of target tasks in prompt tuning using CrossFit?", "reference_answer": "Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b551c2aa-7d01-5fbf-af59-ae4645fcba85", "question": "Which paper first proposed a cross-domain language model to automatically generate much labeled data for a unlabeled target domain?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first proposed a cross-domain language model to automatically generate much labeled data for a unlabeled target domain?", "reference_answer": "Cross-Domain Data Augmentation with Domain-Adaptive Language Modeling for Aspect-Based Sentiment Analysis"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "b7327d6a-9ab2-5fd7-966d-4250ce72ae00", "question": "Which family of model generally perform the best for the event conceptualization task", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which family of model generally perform the best for the event conceptualization task", "reference_answer": "CAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "bb5aedbf-7683-56e7-a348-0ee986fe0fd2", "question": "Is there any works that explores how to achieve balance between representativeness and diversity in chosen samples for few-shot data selection?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any works that explores how to achieve balance between representativeness and diversity in chosen samples for few-shot data selection?", "reference_answer": "Cold-Start Data Selection for Better Few-shot Language Model Fine-tuning: A Prompt-based Uncertainty Propagation Approach"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "bb6a0f0e-0c0c-5038-b340-3044e9ffefd6", "question": "What paper evaluated the ability of visual few-shot learning models to do in-context learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper evaluated the ability of visual few-shot learning models to do in-context learning?", "reference_answer": "CONTEXT-AWARE META-LEARNING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "bbc522d2-649a-5660-8180-7f67728376bf", "question": "which paper first focuses on addressing the over-smoothing issue for sentence embedding?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "which paper first focuses on addressing the over-smoothing issue for sentence embedding?", "reference_answer": "Alleviating Over-smoothing for Unsupervised Sentence Representation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "be08635a-0dbc-5dab-85d0-40f45c6edfc2", "question": "Which paper enables interactive semantic parsing by training an error correction model with simulated human feedback instead of human annotations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper enables interactive semantic parsing by training an error correction model with simulated human feedback instead of human annotations?", "reference_answer": "Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "bec9b106-831a-5e17-97b6-8af2636194d3", "question": "Which paper proposed a learning-based data augmentation method for improving compositional generalization of language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposed a learning-based data augmentation method for improving compositional generalization of language models?", "reference_answer": "Learning to Substitute Spans towards Improving Compositional Generalization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "befbacf1-d163-5021-bb6c-2ba79257c81c", "question": "Which was the first paper to explore the online adaptation of neural MT metrics for use during the inference stage?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which was the first paper to explore the online adaptation of neural MT metrics for use during the inference stage?", "reference_answer": "Test-time Adaptation for Machine Translation Evaluation by Uncertainty Minimization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "bfa70a42-daa5-52db-aa3f-8ceb0960739a", "question": "Which vision-language model paper in 2023 developed techniques that reduce input tokens to improve model inference speed?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which vision-language model paper in 2023 developed techniques that reduce input tokens to improve model inference speed?", "reference_answer": "PuMer: Pruning and Merging Tokens for Efficient Vision Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "bfb209f1-da03-5d97-a7e8-aa3bd63e257d", "question": "How to better attract readers to news articles by generating personalized headlines?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "How to better attract readers to news articles by generating personalized headlines?", "reference_answer": "Generating User-Engaging News Headlines"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c17c03e2-ea11-5472-be57-c7ead3b8605f", "question": "Which paper employs a two-stage approach in generative models to tackle ABSA tasks across various domains?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper employs a two-stage approach in generative models to tackle ABSA tasks across various domains?", "reference_answer": "Bidirectional Generative Framework for Cross-domain Aspect-based Sentiment Analysis"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c181315e-0268-53f9-a982-60eb5747f0e5", "question": "Which paper first attempts to take potential dependencies among same-level labels into account in Hierarchical Text Classification?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first attempts to take potential dependencies among same-level labels into account in Hierarchical Text Classification?", "reference_answer": "Peer-Label Assisted Hierarchical Text Classification"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c1acd5a0-7a76-5605-996d-0191bda04f6c", "question": "Which is the first multimodal model combining text and speech transformers trained without labelled text-speech pairs?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which is the first multimodal model combining text and speech transformers trained without labelled text-speech pairs?", "reference_answer": "Introducing Semantics into Speech Encoders"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c21e6d8e-865c-5544-8177-49b48d723934", "question": "Is there any paper that applies symbolic distillation on black-box generalist language models to harvest high-quality counterfactual data for out-of-distribution generalization?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that applies symbolic distillation on black-box generalist language models to harvest high-quality counterfactual data for out-of-distribution generalization?", "reference_answer": "DISCO: Distilling Counterfactuals with Large Language Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c40f9463-e7de-5f3e-b3ec-8f64b3289541", "question": "Are there any papers that study whether you can identify if a LLM has been instructed to hide some information?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there any papers that study whether you can identify if a LLM has been instructed to hide some information?", "reference_answer": "HOW TO CATCH AN AI LIAR: LIE DETECTION IN BLACK-BOX LLMS BY ASKING UNRELATED QUESTIONS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c6d527e4-0a3f-5c85-86a7-3b9bf155fa0a", "question": "Is there any paper that investigates backdoor attacks across various types of tasks, not limited to classification, in language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that investigates backdoor attacks across various types of tasks, not limited to classification, in language models?", "reference_answer": "Multi-target Backdoor Attacks for Code Pre-trained Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c7fd4be1-7261-5b8c-bdb8-0da621536182", "question": "Can we learn to represent an image with arbitary numbers of tokens?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Can we learn to represent an image with arbitary numbers of tokens?", "reference_answer": "SparseFormer: Sparse Visual Recognition via Limited Latent Tokens"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "c912d1d0-dced-53f0-9a89-5c982701fbb5", "question": "Is there any paper exploring real speakers and thus performing multimodal emotion recognition task?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper exploring real speakers and thus performing multimodal emotion recognition task?", "reference_answer": "A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ca95aa28-b131-5cea-880a-63b9357ba912", "question": "Is there any paper that utilizes Gaussian processes to analyze the vulnerability of text-conditioned generative models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that utilizes Gaussian processes to analyze the vulnerability of text-conditioned generative models?", "reference_answer": "Query-Efficient Black-Box Red Teaming via Bayesian Optimization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "cb721bd4-b219-50b7-99f9-1f0a5f5da438", "question": "Which paper found that mutual learning benefits multlingual models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper found that mutual learning benefits multlingual models?", "reference_answer": "Towards Higher Pareto Frontier in Multilingual Machine Translation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "cc8b6743-e4fd-5365-b027-f6a70a30187e", "question": "Name a paper which proposes a probabilsitic formulation of retrosynthesis.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Name a paper which proposes a probabilsitic formulation of retrosynthesis.", "reference_answer": "RETRO-FALLBACK: RETROSYNTHETIC PLANNING IN AN UNCERTAIN WORLD"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "cd63b251-d7ef-58a6-83be-75d95099d550", "question": "Is there a Chinese hate speech paper that constructs an insulting lexicon while building the dataset?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a Chinese hate speech paper that constructs an insulting lexicon while building the dataset?", "reference_answer": "Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "cd837558-b900-5448-9c36-9a0c0f29924d", "question": "Which paper proposes a memory-efficient optimizer considering the confidence of each update during the optimization?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposes a memory-efficient optimizer considering the confidence of each update during the optimization?", "reference_answer": "CAME: Confidence-guided Adaptive Memory Efficient Optimization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "cdfcefb3-e2be-515b-aa68-6baf717b17a2", "question": "What paper showed first that one can build a fully differentiable mixture of experts layer with no increase in time complexity?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper showed first that one can build a fully differentiable mixture of experts layer with no increase in time complexity?", "reference_answer": "From Sparse to Soft Mixtures of Experts"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "cff35edd-a526-59ea-a003-787ebabcd2d7", "question": "Which paper first applied the chain-of-thought technique in the text summarization field?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first applied the chain-of-thought technique in the text summarization field?", "reference_answer": "Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d011e781-2e29-52ea-8281-e7bc25c68622", "question": "What paper first proposed a robust perceptual similarity metric with certificates?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first proposed a robust perceptual similarity metric with certificates?", "reference_answer": "LIPSIM: A PROVABLY ROBUST PERCEPTUAL SIMILARITY METRIC"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d0157667-a921-5e91-8948-4e0f31b3010c", "question": "Is there a paper that uses an app for a popular tabletop game to gather real transcripts of gameplay with concrete values for players' and monsters' health?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that uses an app for a popular tabletop game to gather real transcripts of gameplay with concrete values for players' and monsters' health?", "reference_answer": "FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d1df78e0-b32e-5878-b302-ae1d5408e8a7", "question": "What is a paper studying data being collected in bundles in reinforcement learning ?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What is a paper studying data being collected in bundles in reinforcement learning ?", "reference_answer": "Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d2369c7a-ea10-5299-818e-78c80de60a82", "question": "Is there a single GNN model that can inductively generalize to any knowledge graph?;What is the method to generalize knowledge graph reasoning to graphs with new entities and relations?;Is there a foundation model for knowledge graphs that does not learn embeddings for each node and relation type?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a single GNN model that can inductively generalize to any knowledge graph?;What is the method to generalize knowledge graph reasoning to graphs with new entities and relations?;Is there a foundation model for knowledge graphs that does not learn embeddings for each node and relation type?", "reference_answer": "TOWARDS FOUNDATION MODELS FOR KNOWLEDGE GRAPH REASONING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d2ce712c-a887-538c-a0fd-4cf01de110d4", "question": "Is there any paper that leverages syntactic rules to explicitly guide text generation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that leverages syntactic rules to explicitly guide text generation?", "reference_answer": "Explicit Syntactic Guidance for Neural Text Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d2f3c57b-d05d-522b-b8bf-21651c72b837", "question": "What paper mitigates the vocabulary size limitation when pretraining multilingual masked language models using a contrastive loss?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper mitigates the vocabulary size limitation when pretraining multilingual masked language models using a contrastive loss?", "reference_answer": "Headless Language Models: Learning without Predicting with Contrastive Weight Tying"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d4046885-386a-5ea9-a53e-44a4d33ab4b4", "question": "Is there commonsense reasoning dataset which generates diverse sentences to describe the relation between concepts?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there commonsense reasoning dataset which generates diverse sentences to describe the relation between concepts?", "reference_answer": "DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d68e9387-5bbd-5a7d-9091-bc67f849d296", "question": "Which paper first constructed a structured knowledge base to interconnect different human social roles and attributes?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first constructed a structured knowledge base to interconnect different human social roles and attributes?", "reference_answer": "PEACOK: Persona Commonsense Knowledge for Consistent and Engaging Narratives"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "d7aa4317-7e09-53d4-9b5d-61b51995b83f", "question": "Which paper first applied the chain of thought concepts in 3D localization problem?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first applied the chain of thought concepts in 3D localization problem?", "reference_answer": "COT3DREF: CHAIN-OF-THOUGHTS DATA-EFFICIENT 3D VISUAL GROUNDING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "da0eec1f-57e5-5fd8-aff2-cd21493eb60c", "question": "Has any study explored the zero-shot extraction of persona characteristics within conversational dialogues?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Has any study explored the zero-shot extraction of persona characteristics within conversational dialogues?", "reference_answer": "PAED: Zero-Shot Persona Attribute Extraction in Dialogues"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "da8f996b-f289-5718-ac05-36ba34285a28", "question": "Which paper first tried to fine-tune LLMs with chain-of-thoughts and program-of-thoughts for math reasoning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first tried to fine-tune LLMs with chain-of-thoughts and program-of-thoughts for math reasoning?", "reference_answer": "MAMMOTH: BUILDING MATH GENERALIST MODELS THROUGH HYBRID INSTRUCTION TUNING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "db1901ae-ae9a-5f74-9479-c1846458d265", "question": "Is there a paper which applies Bayesian optimization to modular continual learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper which applies Bayesian optimization to modular continual learning?", "reference_answer": "A Probabilistic Framework for Modular Continual Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "db9b0fe4-a8e1-5344-8fab-77bbea36c1f1", "question": "Which paper first construct large-scale corpus to improve in-context learning of large language models in the pre-training stage?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first construct large-scale corpus to improve in-context learning of large language models in the pre-training stage?", "reference_answer": "Pre-Training to Learn in Context"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "dc634e00-e936-527b-b3e1-93565fa0178b", "question": "What are some data-efficient ways to learn text embeddings thru contrastive learning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What are some data-efficient ways to learn text embeddings thru contrastive learning?", "reference_answer": "Composition-contrastive Learning for Sentence Embeddings"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ddd6cf56-5026-5482-b637-f8dd9a20acf6", "question": "Is there a theory paper that explains why sometimes tuning momentum does not boost performance for training a neural network?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a theory paper that explains why sometimes tuning momentum does not boost performance for training a neural network?", "reference_answer": "The Marginal Value of Momentum for Small Learning Rate SGD"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "df46a4db-9a21-55a7-b84a-7764604b47c5", "question": "Is there any paper that uses Lipschitz continuity in learning a dynamics model?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that uses Lipschitz continuity in learning a dynamics model?", "reference_answer": "CCIL: CONTINUITY-BASED DATA AUGMENTATION FOR CORRECTIVE IMITATION LEARNING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "df8afde5-4e93-5e03-86a6-a98bcccdc1e7", "question": "What paper provides generalization bounds for self supervised learning models eg. CLIP", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper provides generalization bounds for self supervised learning models eg. CLIP", "reference_answer": "Understanding prompt engineering may not require rethinking generalization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e03ad6fe-d951-5f49-b4b8-6415e0c8203e", "question": "Which paper produces a dataset for text simplification in over 12 languages and evaluates both finetuning and in context learning approaches to text simplification in those languages?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper produces a dataset for text simplification in over 12 languages and evaluates both finetuning and in context learning approaches to text simplification in those languages?", "reference_answer": "Revisiting non-English Text Simplification: A Unified Multilingual Benchmark"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e0411ac6-86d2-52ff-bcc1-4e9dba8177c5", "question": "Is there any paper that automatically creates a dataset for summarizing text from one language to another for a large collection of languages?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that automatically creates a dataset for summarizing text from one language to another for a large collection of languages?", "reference_answer": "CrossSum: Beyond English-Centric Cross-Lingual Summarization for 1,500+ Language Pairs"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e24d9741-a47e-5f69-8bde-ead5219761be", "question": "In video diffusion models, is there any paper that tried decomposing video instruction into sub instructions of different time?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "In video diffusion models, is there any paper that tried decomposing video instruction into sub instructions of different time?", "reference_answer": "Seer: Language Instructed Video Prediction with Latent Diffusion Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e26fafda-6b5f-5a6c-8fe6-57647a29c7e7", "question": "Is there any paper trying to improve MLE for auto-regressive language modeling through the lens of optimal transport?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper trying to improve MLE for auto-regressive language modeling through the lens of optimal transport?", "reference_answer": "EMO: EARTH MOVER DISTANCE OPTIMIZATION FOR AUTO-REGRESSIVE LANGUAGE MODELING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e2e3bd05-d47f-5602-83a5-06b21a463035", "question": "Which machine learning paper proposed certified robustness in the malware detection domain?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which machine learning paper proposed certified robustness in the malware detection domain?", "reference_answer": "DRSM: DE-RANDOMIZED SMOOTHING ON MALWARE CLASSIFIER PROVIDING CERTIFIED ROBUSTNESS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e30796f1-1fa4-516f-8295-ba45725d32de", "question": "Is there a dataset that allows to perform aspect-based sentiment classification on French news?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a dataset that allows to perform aspect-based sentiment classification on French news?", "reference_answer": "MAD-TSC: A Multilingual Aligned News Dataset for Target-dependent Sentiment Classification"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e3a6b6b4-9899-53e5-b338-c77a80ee71a5", "question": "How to achieve zero-shot lip reading?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "How to achieve zero-shot lip reading?", "reference_answer": "OpenSR: Open-Modality Speech Recognition via Maintaining Multi-Modality Alignment"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e4945000-28d9-5f63-b821-f3def54eb88c", "question": "Has there been any recent work or competitions focused on the development of methods to counteract clickbait through spoiling, such as revealing key information upfront?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Has there been any recent work or competitions focused on the development of methods to counteract clickbait through spoiling, such as revealing key information upfront?", "reference_answer": "SemEval-2023 Task 5: Clickbait Spoiling"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "e6a69aa0-9915-5c51-a2e8-ba90140fe58e", "question": "Which paper first combines rewriting and expansion methods to reformulate a query for conversational search?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first combines rewriting and expansion methods to reformulate a query for conversational search?", "reference_answer": "ConvGQR: Generative Query Reformulation for Conversational Search"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e7356e42-a08e-5c65-abb0-6e00ea2a400a", "question": "What paper first proposes that simply reversing the output can significantly enhance the sample efficiency and the performance of the arithmetic capability of a decoder-only Transformer model?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What paper first proposes that simply reversing the output can significantly enhance the sample efficiency and the performance of the arithmetic capability of a decoder-only Transformer model?", "reference_answer": "Teaching Arithmetic to Small Transformers"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e8654b21-dff6-5447-90f4-afb0974ce94d", "question": "Which backdoor paper first used the CLIP to suppress benign features and enhance poisoning features to design triggers?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which backdoor paper first used the CLIP to suppress benign features and enhance poisoning features to design triggers?", "reference_answer": "Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e910df81-f6bc-5c88-8df2-b99ce1990a47", "question": "Which work discusses an analysis of source and target contributions to output generation based on local interpretation when machine translation models experience hallucinations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which work discusses an analysis of source and target contributions to output generation based on local interpretation when machine translation models experience hallucinations?", "reference_answer": "Local Interpretation of Transformer Based on Linear Decomposition"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "e91cd875-a6a7-540d-80be-279f30dd2e4a", "question": "Which paper first found that when transformers are trained to in-context learn function classes, they might exhibit generalization followed by memorization, in certain settings?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first found that when transformers are trained to in-context learn function classes, they might exhibit generalization followed by memorization, in certain settings?", "reference_answer": "In-Context Learning through the Bayesian Prism"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ea497ecc-8bd7-5954-a3ac-d212432c7feb", "question": "Which paper surveyed the datasets and tasks of asking clarification questions in conversational systems??", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper surveyed the datasets and tasks of asking clarification questions in conversational systems??", "reference_answer": "A Survey on Asking Clarification Questions Datasets in Conversational Systems"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ea965a94-3dc2-58e6-93e6-6da8d839e7e8", "question": "What is a large event-coverage general-domain event argument extraction dataset?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What is a large event-coverage general-domain event argument extraction dataset?", "reference_answer": "GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "edf8b7f4-c386-5053-ac89-00bf27fc0d54", "question": "What techniques exist for incorporating context in detecting emotions within dialogues by leveraging pre-trained language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What techniques exist for incorporating context in detecting emotions within dialogues by leveraging pre-trained language models?", "reference_answer": "Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations"}}, "state": {}, "annotator": "litsearch_automatic"}
{"uuid": "efd9be34-b6b2-5abc-b686-0962c27c350c", "question": "Provide an example of a paper which proposes a method to learn a dynamic (conditioned on the input) sequence tokenizer (segmenter) via standard gradient backpropagation.", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Provide an example of a paper which proposes a method to learn a dynamic (conditioned on the input) sequence tokenizer (segmenter) via standard gradient backpropagation.", "reference_answer": "Efficient Transformers with Dynamic Token Pooling"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f0291d22-9853-5727-b582-349739d89cbe", "question": "What are the key advantages of coupling neural SDEs with neural CDEs for treatment effect estimation over existing baselines?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What are the key advantages of coupling neural SDEs with neural CDEs for treatment effect estimation over existing baselines?", "reference_answer": "BAYESIAN NEURAL CONTROLLED DIFFERENTIAL EQUATIONS FOR TREATMENT EFFECT ESTIMATION"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f06b7b4b-58fd-5450-9c97-00542144b8b2", "question": "Is there a paper exploring the curse of multilinguality for similar languages?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper exploring the curse of multilinguality for similar languages?", "reference_answer": "Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f1429616-9c0c-5f32-b39f-46a63a5f7d03", "question": "What open-source dataset combined knowledge retrieval with constraint satisfaction queries?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What open-source dataset combined knowledge retrieval with constraint satisfaction queries?", "reference_answer": "KITAB: EVALUATING LLMS ON CONSTRAINT SATISFACTION FOR INFORMATION RETRIEVAL"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f1d19f7e-17b7-582f-b9dd-465860422e9e", "question": "Is there a paper which proposes a general data selection method based on information theory?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper which proposes a general data selection method based on information theory?", "reference_answer": "GIO: GRADIENT INFORMATION OPTIMIZATION FOR TRAINING DATASET SELECTION"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f1f24bb5-7f16-5048-86c0-3723a919a07e", "question": "Which foundation model paper first proposed a time series model with proposed financial time series and text data?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which foundation model paper first proposed a time series model with proposed financial time series and text data?", "reference_answer": "TEMPO: PROMPT-BASED GENERATIVE PRE-TRAINED TRANSFORMER FOR TIME SERIES FORECASTING"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f21f555a-1254-59ba-8cbc-11791cdab6b0", "question": "Are there any papers that use a world model for planning to ensure that decisions meet constraints?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Are there any papers that use a world model for planning to ensure that decisions meet constraints?", "reference_answer": "SAFEDREAMER: SAFE REINFORCEMENT LEARNING WITH WORLD MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f22e1e2f-bf4a-579e-a11f-f28e9226693a", "question": "In multimodal (multilingual) abstractive summarization field, is there any paper that propose target-oriented vision modeling method to improve the quality of summaries?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "In multimodal (multilingual) abstractive summarization field, is there any paper that propose target-oriented vision modeling method to improve the quality of summaries?", "reference_answer": "Summary-Oriented Vision Modeling for Multimodal Abstractive Summarization"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f4154375-e94a-5623-a51d-0ae5cf5c4039", "question": "Which paper measured how well the source-translation contribution by the translation model can be used to detect its own hallucinations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper measured how well the source-translation contribution by the translation model can be used to detect its own hallucinations?", "reference_answer": "Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f641587e-0065-54e9-92c4-d2b194535f80", "question": "Which paper first study POMDP with enhanced feedback on observations?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper first study POMDP with enhanced feedback on observations?", "reference_answer": "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "f9866921-b6c0-55f2-874f-8bcb5d1e733b", "question": "Is there a paper that links exposure bias to distillation?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper that links exposure bias to distillation?", "reference_answer": "A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "fa7f68f5-fd2e-5b0b-b099-2c09331b7c25", "question": "Which papers develop methods to make in-context learning more computationally efficient?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which papers develop methods to make in-context learning more computationally efficient?", "reference_answer": "FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "fbca5330-8955-5359-94a5-d91961e2a6d9", "question": "Which paper proposes to integrate black-box LLMs with a pool of smaller but specialized language models?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper proposes to integrate black-box LLMs with a pool of smaller but specialized language models?", "reference_answer": "KNOWLEDGE CARD: FILLING LLMS' KNOWLEDGE GAPS WITH PLUG-IN SPECIALIZED LANGUAGE MODELS"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "fc882b50-9385-5452-a96a-e0e93a9cbd2f", "question": "What is the first paper to address the problem of predicting knowledge graphs whose nodes, links and attributes change with time?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "What is the first paper to address the problem of predicting knowledge graphs whose nodes, links and attributes change with time?", "reference_answer": "Holistic Prediction on a Time-Evolving Attributed Graph"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "fed63d9e-52d3-5a7c-89f4-ac6f37f7e02b", "question": "Which paper explored training a GPT-2 for automatic diagnosis, emphasizing efficient data augmentation for symptom prediction and disease identification?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper explored training a GPT-2 for automatic diagnosis, emphasizing efficient data augmentation for symptom prediction and disease identification?", "reference_answer": "CoAD: Automatic Diagnosis through Symptom and Disease Collaborative Generation"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "fee3ed60-b2ce-55ce-b06d-0f4e9fe1639f", "question": "Is there a paper comparing knowledge distillation and human annotation in terms of cost efficiency?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there a paper comparing knowledge distillation and human annotation in terms of cost efficiency?", "reference_answer": "Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ff1576ee-d2c5-505a-964a-c2fcc94c75ff", "question": "Is there any paper that seamlessly integrates the multigrid structure in operator learning for solving partial differential equations (PDEs)?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["iclr2024"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Is there any paper that seamlessly integrates the multigrid structure in operator learning for solving partial differential equations (PDEs)?", "reference_answer": "MgNO: Efficient Parameterization of Linear Operators via Multigrid"}}, "state": {}, "annotator": "litsearch_manual"}
{"uuid": "ff31ef9b-f07d-59a4-ac9a-4d694ff7bb13", "question": "Which paper is the first to comprehensively review the progress of deep learning in mathematical reasoning?", "answer_format": "Your answer should be the title of the paper WITHOUT ANY EXPLANATION.", "tags": ["retrieval", "text", "subjective"], "anchor_pdf": [], "reference_pdf": [], "conference": ["acl2023"], "reasoning_steps": [], "evaluator": {"eval_func": "eval_paper_relevance_with_llm_and_reference_answer", "eval_kwargs": {"question": "Which paper is the first to comprehensively review the progress of deep learning in mathematical reasoning?", "reference_answer": "A Survey of Deep Learning for Mathematical Reasoning"}}, "state": {}, "annotator": "litsearch_manual"}
