{
    "uuid": "41b46bde-6931-5467-9956-f5f030dd4994",
    "title": "Learn to Not Link: Exploring NIL Prediction in Entity Linking",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zhu-etal-2023-learn,\n    title = \"Learn to Not Link: Exploring {NIL} Prediction in Entity Linking\",\n    author = \"Zhu, Fangwei  and\n      Yu, Jifan  and\n      Jin, Hailong  and\n      Hou, Lei  and\n      Li, Juanzi  and\n      Sui, Zhifang\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.690\",\n    doi = \"10.18653/v1/2023.findings-acl.690\",\n    pages = \"10846--10860\",\n    abstract = \"Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem.NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at \\url{https://github.com/solitaryzero/NIL_EL}.\",\n}\n",
    "authors": [
        "Fangwei Zhu",
        "Jifan Yu",
        "Hailong Jin",
        "Lei Hou",
        "Juanzi Li",
        "Zhifang Sui"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.690.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/41b46bde-6931-5467-9956-f5f030dd4994.pdf",
    "abstract": "Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem.NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at https://github.com/solitaryzero/NIL_EL.",
    "num_pages": 15
}