{
    "uuid": "03661564-6daf-54a3-b057-0f520eebb57c",
    "title": "TEII: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{cheng-etal-2024-teii,\n    title = \"{TEII}: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection\",\n    author = \"Cheng, Long  and\n      Shao, Qihao  and\n      Zhao, Christine  and\n      Bi, Sheng  and\n      Levow, Gina-Anne\",\n    editor = \"De Clercq, Orph{\\'e}e  and\n      Barriere, Valentin  and\n      Barnes, Jeremy  and\n      Klinger, Roman  and\n      Sedoc, Jo{\\~a}o  and\n      Tafreshi, Shabnam\",\n    booktitle = \"Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.wassa-1.49\",\n    doi = \"10.18653/v1/2024.wassa-1.49\",\n    pages = \"495--504\",\n    abstract = \"Cross-lingual emotion detection allows us to analyze global trends, public opinion, and social phenomena at scale. We participated in the Explainability of Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score of 0.6046 on the evaluation set for the emotion detection sub-task. Our system outperformed the baseline by more than 0.16 F1-score absolute, and ranked second amongst competing systems. We conducted experiments using fine-tuning, zero-shot learning, and few-shot learning for Large Language Model (LLM)-based models as well as embedding-based BiLSTM and KNN for non-LLM-based techniques. Additionally, we introduced two novel methods: the Multi-Iteration Agentic Workflow and the Multi-Binary-Classifier Agentic Workflow. We found that LLM-based approaches provided good performance on multilingual emotion detection. Furthermore, ensembles combining all our experimented models yielded higher F1-scores than any single approach alone.\",\n}\n",
    "authors": [
        "Long Cheng",
        "Qihao Shao",
        "Christine Zhao",
        "Sheng Bi",
        "Gina-Anne Levow"
    ],
    "pdf_url": "https://aclanthology.org/2024.wassa-1.49.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/03661564-6daf-54a3-b057-0f520eebb57c.pdf",
    "abstract": "Cross-lingual emotion detection allows us to analyze global trends, public opinion, and social phenomena at scale. We participated in the Explainability of Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score of 0.6046 on the evaluation set for the emotion detection sub-task. Our system outperformed the baseline by more than 0.16 F1-score absolute, and ranked second amongst competing systems. We conducted experiments using fine-tuning, zero-shot learning, and few-shot learning for Large Language Model (LLM)-based models as well as embedding-based BiLSTM and KNN for non-LLM-based techniques. Additionally, we introduced two novel methods: the Multi-Iteration Agentic Workflow and the Multi-Binary-Classifier Agentic Workflow. We found that LLM-based approaches provided good performance on multilingual emotion detection. Furthermore, ensembles combining all our experimented models yielded higher F1-scores than any single approach alone.",
    "num_pages": 10
}