{
    "uuid": "1d362b64-4389-53bd-b919-19ec5d86c706",
    "title": "Thinking about how to extract: Energizing LLMsâ€™ emergence capabilities for document-level event argument extraction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{shuang-etal-2024-thinking,\n    title = \"Thinking about how to extract: Energizing {LLM}s{'} emergence capabilities for document-level event argument extraction\",\n    author = \"Shuang, Kai  and\n      Zhouji, Zhouji  and\n      Qiwei, Wang  and\n      Guo, Jinyu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.328\",\n    doi = \"10.18653/v1/2024.findings-acl.328\",\n    pages = \"5520--5532\",\n    abstract = \"There are two key challenges remaining for the document-level event argument extraction (D-EAE) tasks: key feature forgetting and cross-event argument confusion. The emergence capability of large language models (LLMs) holds promise for solving the above two challenges. In this paper, we propose a document-level event argument extraction method based on guided summarization and reasoning (EAESR), which leverages the emergence capabilities of LLMs to highlight key event information and to clarify the explicit and implicit association between multiple events. Specifically, we generate document summarization information that shorten the length of the event context while preserving the key event features. In addition, we generate inter-event reasoning information, which helps EAESR make sense of the correlations between events and reduces their dependence on the event context, especially to better cope with the few-shot D-EAE task. Then, we obtain named entity information to enable EAESR to learn argument boundary features to improve the sensitivity of its argument boundary recognition. Eventually, we fused the above features and sentence features to make EAESR have summarizing and reasoning capabilities simultaneously. Extensive experiments on WIKIEVENTS and RAMS have shown that EAESR achieves a new state-of-the-art that outperforms the baseline models by 1.3{\\%} F1 and 1.6{\\%} F1, respectively, and averages 11{\\%} F1 in few-shot settings.\",\n}\n",
    "authors": [
        "Kai Shuang",
        "Zhouji Zhouji",
        "Wang Qiwei",
        "Jinyu Guo"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.328.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/1d362b64-4389-53bd-b919-19ec5d86c706.pdf",
    "abstract": "There are two key challenges remaining for the document-level event argument extraction (D-EAE) tasks: key feature forgetting and cross-event argument confusion. The emergence capability of large language models (LLMs) holds promise for solving the above two challenges. In this paper, we propose a document-level event argument extraction method based on guided summarization and reasoning (EAESR), which leverages the emergence capabilities of LLMs to highlight key event information and to clarify the explicit and implicit association between multiple events. Specifically, we generate document summarization information that shorten the length of the event context while preserving the key event features. In addition, we generate inter-event reasoning information, which helps EAESR make sense of the correlations between events and reduces their dependence on the event context, especially to better cope with the few-shot D-EAE task. Then, we obtain named entity information to enable EAESR to learn argument boundary features to improve the sensitivity of its argument boundary recognition. Eventually, we fused the above features and sentence features to make EAESR have summarizing and reasoning capabilities simultaneously. Extensive experiments on WIKIEVENTS and RAMS have shown that EAESR achieves a new state-of-the-art that outperforms the baseline models by 1.3% F1 and 1.6% F1, respectively, and averages 11% F1 in few-shot settings.",
    "num_pages": 13
}