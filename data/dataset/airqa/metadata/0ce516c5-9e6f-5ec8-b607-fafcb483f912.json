{
    "uuid": "0ce516c5-9e6f-5ec8-b607-fafcb483f912",
    "title": "Neural Machine Translation Methods for Translating Text to Sign Language Glosses",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhu-etal-2023-neural,\n    title = \"Neural Machine Translation Methods for Translating Text to Sign Language Glosses\",\n    author = \"Zhu, Dele  and\n      Czehmann, Vera  and\n      Avramidis, Eleftherios\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.700\",\n    doi = \"10.18653/v1/2023.acl-long.700\",\n    pages = \"12523--12541\",\n    abstract = \"State-of-the-art techniques common to low resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses. In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations. Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).\",\n}\n",
    "authors": [
        "Dele Zhu",
        "Vera Czehmann",
        "Eleftherios Avramidis"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.700.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0ce516c5-9e6f-5ec8-b607-fafcb483f912.pdf",
    "abstract": "State-of-the-art techniques common to low resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses. In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations. Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).",
    "num_pages": 19
}