{
    "uuid": "e9badd31-f4a0-544d-a491-aee9e561ddc8",
    "title": "TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
    "bibtex": "@inproceedings{zhao-etal-2023-tencentpretrain,\n    title = \"{T}encent{P}retrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities\",\n    author = \"Zhao, Zhe  and\n      Li, Yudong  and\n      Hou, Cheng  and\n      Zhao, Jing  and\n      Tian, Rong  and\n      Liu, Weijie  and\n      Chen, Yiren  and\n      Sun, Ningyuan  and\n      Liu, Haoyan  and\n      Mao, Weiquan  and\n      Guo, Han  and\n      Gou, Weigang  and\n      Wu, Taiqiang  and\n      Zhu, Tao  and\n      Shi, Wenhang  and\n      Chen, Chen  and\n      Huang, Shan  and\n      Chen, Sihong  and\n      Liu, Liqun  and\n      Li, Feifei  and\n      Chen, Xiaoshuai  and\n      Sun, Xingwu  and\n      Kang, Zhanhui  and\n      Du, Xiaoyong  and\n      Shen, Linlin  and\n      Yan, Kimmo\",\n    editor = \"Bollegala, Danushka  and\n      Huang, Ruihong  and\n      Ritter, Alan\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-demo.20\",\n    doi = \"10.18653/v1/2023.acl-demo.20\",\n    pages = \"217--225\",\n    abstract = \"Recently, the success of pre-training in text domain has been fully extended to vision, audio, and cross-modal scenarios. The proposed pre-training models of different modalities are showing a rising trend of homogeneity in their model structures, which brings the opportunity to implement different pre-training models within a uniform framework. In this paper, we present TencentPretrain, a toolkit supporting pre-training models of different modalities. The core feature of TencentPretrain is the modular design. The toolkit uniformly divides pre-training models into 5 components: embedding, encoder, target embedding, decoder, and target. As almost all of common modules are provided in each component, users can choose the desired modules from different components to build a complete pre-training model. The modular design enables users to efficiently reproduce existing pre-training models or build brand-new one. We test the toolkit on text, vision, and audio benchmarks and show that it can match the performance of the original implementations.\",\n}\n",
    "authors": [
        "Zhe Zhao",
        "Yudong Li",
        "Cheng Hou",
        "Jing Zhao",
        "Rong Tian",
        "Weijie Liu",
        "Yiren Chen",
        "Ningyuan Sun",
        "Haoyan Liu",
        "Weiquan Mao",
        "Han Guo",
        "Weigang Gou",
        "Taiqiang Wu",
        "Tao Zhu",
        "Wenhang Shi",
        "Chen Chen",
        "Shan Huang",
        "Sihong Chen",
        "Liqun Liu",
        "Feifei Li",
        "Xiaoshuai Chen",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Xiaoyong Du",
        "Linlin Shen",
        "Kimmo Yan"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-demo.20.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e9badd31-f4a0-544d-a491-aee9e561ddc8.pdf",
    "abstract": "Recently, the success of pre-training in text domain has been fully extended to vision, audio, and cross-modal scenarios. The proposed pre-training models of different modalities are showing a rising trend of homogeneity in their model structures, which brings the opportunity to implement different pre-training models within a uniform framework. In this paper, we present TencentPretrain, a toolkit supporting pre-training models of different modalities. The core feature of TencentPretrain is the modular design. The toolkit uniformly divides pre-training models into 5 components: embedding, encoder, target embedding, decoder, and target. As almost all of common modules are provided in each component, users can choose the desired modules from different components to build a complete pre-training model. The modular design enables users to efficiently reproduce existing pre-training models or build brand-new one. We test the toolkit on text, vision, and audio benchmarks and show that it can match the performance of the original implementations.",
    "num_pages": 9
}