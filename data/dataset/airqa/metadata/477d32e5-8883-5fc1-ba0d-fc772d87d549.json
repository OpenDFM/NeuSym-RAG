{
    "uuid": "477d32e5-8883-5fc1-ba0d-fc772d87d549",
    "title": "BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhao-etal-2024-bba,\n    title = \"{BBA}: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models\",\n    author = \"Zhao, Xueliang  and\n      Huang, Xinting  and\n      Fu, Tingchen  and\n      Li, Qintong  and\n      Gong, Shansan  and\n      Liu, Lemao  and\n      Bi, Wei  and\n      Kong, Lingpeng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.433\",\n    doi = \"10.18653/v1/2024.findings-acl.433\",\n    pages = \"7255--7279\",\n    abstract = \"Multimodal reasoning stands as a pivotal capability for large vision-language models (LVLMs). The integration with Domain-Specific Languages (DSL), offering precise visual representations, equips these models with the opportunity to execute more accurate reasoning in complex and professional domains. However, the vanilla Chain-of-Thought (CoT) prompting method faces challenges in effectively leveraging the unique strengths of visual and DSL representations, primarily due to their differing reasoning mechanisms. Additionally, it often falls short in addressing critical steps in multi-step reasoning tasks. To mitigate these challenges, we introduce the Bi-Modal Behavioral Alignment (BBA) prompting method, designed to maximize the potential of DSL in augmenting complex multi-modal reasoning tasks. This method initiates by guiding LVLMs to create separate reasoning chains for visual and DSL representations. Subsequently, it aligns these chains by addressing any inconsistencies, thus achieving a cohesive integration of behaviors from different modalities. Our experiments demonstrate that BBA substantially improves the performance of GPT-4V(ision) on geometry problem solving (28.34{\\%} $\\to$ 34.22{\\%}), chess positional advantage prediction (42.08{\\%} $\\to$ 46.99{\\%}) and molecular property prediction (77.47{\\%} $\\to$ 83.52{\\%}).\",\n}\n",
    "authors": [
        "Xueliang Zhao",
        "Xinting Huang",
        "Tingchen Fu",
        "Qintong Li",
        "Shansan Gong",
        "Lemao Liu",
        "Wei Bi",
        "Lingpeng Kong"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.433.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/477d32e5-8883-5fc1-ba0d-fc772d87d549.pdf",
    "abstract": "Multimodal reasoning stands as a pivotal capability for large vision-language models (LVLMs). The integration with Domain-Specific Languages (DSL), offering precise visual representations, equips these models with the opportunity to execute more accurate reasoning in complex and professional domains. However, the vanilla Chain-of-Thought (CoT) prompting method faces challenges in effectively leveraging the unique strengths of visual and DSL representations, primarily due to their differing reasoning mechanisms. Additionally, it often falls short in addressing critical steps in multi-step reasoning tasks. To mitigate these challenges, we introduce the Bi-Modal Behavioral Alignment (BBA) prompting method, designed to maximize the potential of DSL in augmenting complex multi-modal reasoning tasks. This method initiates by guiding LVLMs to create separate reasoning chains for visual and DSL representations. Subsequently, it aligns these chains by addressing any inconsistencies, thus achieving a cohesive integration of behaviors from different modalities. Our experiments demonstrate that BBA substantially improves the performance of GPT-4V(ision) on geometry problem solving (28.34% → 34.22%), chess positional advantage prediction (42.08% → 46.99%) and molecular property prediction (77.47% → 83.52%).",
    "num_pages": 25
}