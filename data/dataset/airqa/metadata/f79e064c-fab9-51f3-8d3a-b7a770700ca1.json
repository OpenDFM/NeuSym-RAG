{
    "uuid": "f79e064c-fab9-51f3-8d3a-b7a770700ca1",
    "title": "Use of NLP in the Context of Belief states of Ethnic Minorities in Latin America",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)",
    "bibtex": "@inproceedings{kellert-zaman-2023-use,\n    title = \"Use of {NLP} in the Context of Belief states of Ethnic Minorities in {L}atin {A}merica\",\n    author = \"Kellert, Olga  and\n      Zaman, Mahmud\",\n    editor = \"Mager, Manuel  and\n      Ebrahimi, Abteen  and\n      Oncevay, Arturo  and\n      Rice, Enora  and\n      Rijhwani, Shruti  and\n      Palmer, Alexis  and\n      Kann, Katharina\",\n    booktitle = \"Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.americasnlp-1.1\",\n    doi = \"10.18653/v1/2023.americasnlp-1.1\",\n    pages = \"1--5\",\n    abstract = \"The major goal of our study is to test methods in NLP in the domain of health care education related to Covid-19 of vulnerable groups such as indigenous people from Latin America. In order to achieve this goal, we asked participants in a survey questionnaire to provide answers about health related topics. We used these answers to measure the health education status ofour participants. In this paper, we summarize the results from our NLP-application on the participants{'} answers. In the first experiment, we use embeddings-based tools to measure the semantic similarity between participants{'} answers and {``}expert{''} or {``}reference{''} answers. In the second experiment, we use synonym-based methods to classify answers under topics. We compare the results from both experiments with human annotations. Our results show that the tested NLP-methods reach a significantly lower accuracy score than human annotations in both experiments. We explain this difference by the assumption that human annotators are much better in pragmatic inferencing necessary to classify the semantic similarity and topic classification of answers.\",\n}\n",
    "authors": [
        "Olga Kellert",
        "Mahmud Zaman"
    ],
    "pdf_url": "https://aclanthology.org/2023.americasnlp-1.1.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f79e064c-fab9-51f3-8d3a-b7a770700ca1.pdf",
    "abstract": "The major goal of our study is to test methods in NLP in the domain of health care education related to Covid-19 of vulnerable groups such as indigenous people from Latin America. In order to achieve this goal, we asked participants in a survey questionnaire to provide answers about health related topics. We used these answers to measure the health education status ofour participants. In this paper, we summarize the results from our NLP-application on the participants’ answers. In the first experiment, we use embeddings-based tools to measure the semantic similarity between participants’ answers and “expert” or “reference” answers. In the second experiment, we use synonym-based methods to classify answers under topics. We compare the results from both experiments with human annotations. Our results show that the tested NLP-methods reach a significantly lower accuracy score than human annotations in both experiments. We explain this difference by the assumption that human annotators are much better in pragmatic inferencing necessary to classify the semantic similarity and topic classification of answers.",
    "num_pages": 5
}