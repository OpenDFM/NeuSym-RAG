{
    "uuid": "ffda5466-8659-558a-928e-91f7701a8325",
    "title": "ON-TRAC Consortium Systems for the IWSLT 2023 Dialectal and Low-resource Speech Translation Tasks",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{laurent-etal-2023-trac,\n    title = \"{ON}-{TRAC} Consortium Systems for the {IWSLT} 2023 Dialectal and Low-resource Speech Translation Tasks\",\n    author = {Laurent, Antoine  and\n      Gahbiche, Souhir  and\n      Nguyen, Ha  and\n      Elleuch, Haroun  and\n      Bougares, Fethi  and\n      Thiol, Antoine  and\n      Riguidel, Hugo  and\n      Mdhaffar, Salima  and\n      Laperri{\\`e}re, Ga{\\\"e}lle  and\n      Maison, Lucas  and\n      Khurana, Sameer  and\n      Est{\\`e}ve, Yannick},\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.18\",\n    doi = \"10.18653/v1/2023.iwslt-1.18\",\n    pages = \"219--226\",\n    abstract = \"This paper describes the ON-TRAC consortium speech translation systems developed for IWSLT 2023 evaluation campaign. Overall, we participated in three speech translation tracks featured in the low-resource and dialect speech translation shared tasks, namely; i) spoken Tamasheq to written French, ii) spoken Pashto to written French, and iii) spoken Tunisian to written English. All our primary submissions are based on the end-to-end speech-to-text neural architecture using a pretrained SAMU-XLSR model as a speech encoder and a mbart model as a decoder. The SAMU-XLSR model is built from the XLS-R 128 in order to generate language agnostic sentence-level embeddings. This building is driven by the LaBSE model trained on multilingual text dataset. This architecture allows us to improve the input speech representations and achieve significant improvements compared to conventional end-to-end speech translation systems.\",\n}\n",
    "authors": [
        "Antoine Laurent",
        "Souhir Gahbiche",
        "Ha Nguyen",
        "Haroun Elleuch",
        "Fethi Bougares",
        "Antoine Thiol",
        "Hugo Riguidel",
        "Salima Mdhaffar",
        "Gaëlle Laperrière",
        "Lucas Maison",
        "Sameer Khurana",
        "Yannick Estève"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.18.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ffda5466-8659-558a-928e-91f7701a8325.pdf",
    "abstract": "This paper describes the ON-TRAC consortium speech translation systems developed for IWSLT 2023 evaluation campaign. Overall, we participated in three speech translation tracks featured in the low-resource and dialect speech translation shared tasks, namely; i) spoken Tamasheq to written French, ii) spoken Pashto to written French, and iii) spoken Tunisian to written English. All our primary submissions are based on the end-to-end speech-to-text neural architecture using a pretrained SAMU-XLSR model as a speech encoder and a mbart model as a decoder. The SAMU-XLSR model is built from the XLS-R 128 in order to generate language agnostic sentence-level embeddings. This building is driven by the LaBSE model trained on multilingual text dataset. This architecture allows us to improve the input speech representations and achieve significant improvements compared to conventional end-to-end speech translation systems.",
    "num_pages": 8
}