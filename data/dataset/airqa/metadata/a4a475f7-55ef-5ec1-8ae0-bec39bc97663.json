{
    "uuid": "a4a475f7-55ef-5ec1-8ae0-bec39bc97663",
    "title": "Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{nourbakhsh-etal-2023-using,\n    title = \"Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning\",\n    author = \"Nourbakhsh, Armineh  and\n      Shah, Sameena  and\n      Ros{\\'e}, Carolyn\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.834\",\n    doi = \"10.18653/v1/2023.acl-long.834\",\n    pages = \"14930--14943\",\n    abstract = \"In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.\",\n}\n",
    "authors": [
        "Armineh Nourbakhsh",
        "Sameena Shah",
        "Carolyn Ros√©"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.834.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a4a475f7-55ef-5ec1-8ae0-bec39bc97663.pdf",
    "abstract": "In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.",
    "num_pages": 14
}