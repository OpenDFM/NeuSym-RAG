{
    "uuid": "6e71b899-ab58-53a4-bbd0-bdf7068017d7",
    "title": "InfoLossQA: Characterizing and Recovering Information Loss in Text Simplification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{trienes-etal-2024-infolossqa,\n    title = \"{I}nfo{L}oss{QA}: Characterizing and Recovering Information Loss in Text Simplification\",\n    author = {Trienes, Jan  and\n      Joseph, Sebastian  and\n      Schl{\\\"o}tterer, J{\\\"o}rg  and\n      Seifert, Christin  and\n      Lo, Kyle  and\n      Xu, Wei  and\n      Wallace, Byron  and\n      Li, Junyi Jessy},\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.234\",\n    doi = \"10.18653/v1/2024.acl-long.234\",\n    pages = \"4263--4294\",\n    abstract = \"Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Questions Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from 104 LLM simplifications of English medical study abstracts. Our analyses of this data reveal that information loss occurs frequently, and that the QA pairs give a high-level overview of what information was lost. Second, we devise two methods for this task: end-to-end prompting of open-source and commercial language models, and a natural language inference pipeline. With a novel evaluation framework considering the correctness of QA pairs and their linguistic suitability, our expert evaluation reveals that models struggle to reliably identify information loss and applying similar standards as humans at what constitutes information loss.\",\n}\n",
    "authors": [
        "Jan Trienes",
        "Sebastian Joseph",
        "Jörg Schlötterer",
        "Christin Seifert",
        "Kyle Lo",
        "Wei Xu",
        "Byron Wallace",
        "Junyi Jessy Li"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.234.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6e71b899-ab58-53a4-bbd0-bdf7068017d7.pdf",
    "abstract": "Text simplification aims to make technical texts more accessible to laypeople but often results in deletion of information and vagueness. This work proposes InfoLossQA, a framework to characterize and recover simplification-induced information loss in form of question-and-answer (QA) pairs. Building on the theory of Questions Under Discussion, the QA pairs are designed to help readers deepen their knowledge of a text. First, we collect a dataset of 1,000 linguist-curated QA pairs derived from 104 LLM simplifications of English medical study abstracts. Our analyses of this data reveal that information loss occurs frequently, and that the QA pairs give a high-level overview of what information was lost. Second, we devise two methods for this task: end-to-end prompting of open-source and commercial language models, and a natural language inference pipeline. With a novel evaluation framework considering the correctness of QA pairs and their linguistic suitability, our expert evaluation reveals that models struggle to reliably identify information loss and applying similar standards as humans at what constitutes information loss.",
    "num_pages": 32
}