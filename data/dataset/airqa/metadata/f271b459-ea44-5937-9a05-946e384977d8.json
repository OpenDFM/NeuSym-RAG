{
    "uuid": "f271b459-ea44-5937-9a05-946e384977d8",
    "title": "Bring More Attention to Syntactic Symmetry for Automatic Postediting of High-Quality Machine Translations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{jung-etal-2023-bring,\n    title = \"Bring More Attention to Syntactic Symmetry for Automatic Postediting of High-Quality Machine Translations\",\n    author = \"Jung, Baikjin  and\n      Lee, Myungji  and\n      Lee, Jong-Hyeok  and\n      Kim, Yunsu\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.122\",\n    doi = \"10.18653/v1/2023.acl-short.122\",\n    pages = \"1433--1441\",\n    abstract = \"Automatic postediting (APE) is an automated process to refine a given machine translation (MT). Recent findings present that existing APE systems are not good at handling high-quality MTs even for a language pair with abundant data resources, English{--}German: the better the given MT is, the harder it is to decide what parts to edit and how to fix these errors. One possible solution to this problem is to instill deeper knowledge about the target language into the model. Thus, we propose a linguistically motivated method of regularization that is expected to enhance APE models{'} understanding of the target language: a loss function that encourages symmetric self-attention on the given MT. Our analysis of experimental results demonstrates that the proposed method helps improving the state-of-the-art architecture{'}s APE quality for high-quality MTs.\",\n}\n",
    "authors": [
        "Baikjin Jung",
        "Myungji Lee",
        "Jong-Hyeok Lee",
        "Yunsu Kim"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.122.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f271b459-ea44-5937-9a05-946e384977d8.pdf",
    "abstract": "Automatic postediting (APE) is an automated process to refine a given machine translation (MT). Recent findings present that existing APE systems are not good at handling high-quality MTs even for a language pair with abundant data resources, English–German: the better the given MT is, the harder it is to decide what parts to edit and how to fix these errors. One possible solution to this problem is to instill deeper knowledge about the target language into the model. Thus, we propose a linguistically motivated method of regularization that is expected to enhance APE models’ understanding of the target language: a loss function that encourages symmetric self-attention on the given MT. Our analysis of experimental results demonstrates that the proposed method helps improving the state-of-the-art architecture’s APE quality for high-quality MTs.",
    "num_pages": 9
}