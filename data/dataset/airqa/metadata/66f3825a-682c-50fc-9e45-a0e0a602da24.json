{
    "uuid": "66f3825a-682c-50fc-9e45-a0e0a602da24",
    "title": "Text-to-Song: Towards Controllable Music Generation Incorporating Vocal and Accompaniment",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{hong-etal-2024-text,\n    title = \"Text-to-Song: Towards Controllable Music Generation Incorporating Vocal and Accompaniment\",\n    author = \"Hong, Zhiqing  and\n      Huang, Rongjie  and\n      Cheng, Xize  and\n      Wang, Yongqi  and\n      Li, Ruiqi  and\n      You, Fuming  and\n      Zhao, Zhou  and\n      Zhang, Zhimeng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.339\",\n    doi = \"10.18653/v1/2024.acl-long.339\",\n    pages = \"6248--6261\",\n    abstract = \"A song is a combination of singing voice and accompaniment. However, existing works focus on singing voice synthesis and music generation independently. Little attention was paid to exploring song synthesis. In this work, we propose a novel task called Text-to-Song synthesis which incorporates both vocal and accompaniment generation. We develop Melodist, a two-stage text-to-song method that consists of singing voice synthesis (SVS) and vocal-to-accompaniment (V2A) synthesis. Melodist leverages tri-tower contrastive pretraining to learn more effective text representation for controllable V2A synthesis. A Chinese song dataset mined from a music website is built to alleviate data scarcity for our research. The evaluation results on our dataset demonstrate that Melodist can synthesize songs with comparable quality and style consistency. Audio samples can be found in https://text2songMelodist.github.io/Sample/.\",\n}\n",
    "authors": [
        "Zhiqing Hong",
        "Rongjie Huang",
        "Xize Cheng",
        "Yongqi Wang",
        "Ruiqi Li",
        "Fuming You",
        "Zhou Zhao",
        "Zhimeng Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.339.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/66f3825a-682c-50fc-9e45-a0e0a602da24.pdf",
    "abstract": "A song is a combination of singing voice and accompaniment. However, existing works focus on singing voice synthesis and music generation independently. Little attention was paid to exploring song synthesis. In this work, we propose a novel task called Text-to-Song synthesis which incorporates both vocal and accompaniment generation. We develop Melodist, a two-stage text-to-song method that consists of singing voice synthesis (SVS) and vocal-to-accompaniment (V2A) synthesis. Melodist leverages tri-tower contrastive pretraining to learn more effective text representation for controllable V2A synthesis. A Chinese song dataset mined from a music website is built to alleviate data scarcity for our research. The evaluation results on our dataset demonstrate that Melodist can synthesize songs with comparable quality and style consistency. Audio samples can be found in https://text2songMelodist.github.io/Sample/.",
    "num_pages": 14
}