{
    "uuid": "db7c1bac-072f-5044-b283-6f65388fcae5",
    "title": "Enhancing Social Media Health Prediction Certainty by Integrating Large Language Models with Transformer Classifiers",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks",
    "bibtex": "@inproceedings{khademi-etal-2024-enhancing,\n    title = \"Enhancing Social Media Health Prediction Certainty by Integrating Large Language Models with Transformer Classifiers\",\n    author = \"Khademi, Sedigh  and\n      Palmer, Christopher  and\n      Javed, Muhammad  and\n      Buttery, Jim  and\n      Dimaguila, Gerardo\",\n    editor = \"Xu, Dongfang  and\n      Gonzalez-Hernandez, Graciela\",\n    booktitle = \"Proceedings of The 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.smm4h-1.16\",\n    pages = \"71--73\",\n    abstract = \"This paper presents our approach for SMM4H 2024 Task 5, focusing on identifying tweets where users discuss their child{'}s health conditions of ADHD, ASD, delayed speech, or asthma. Our approach uses a pipeline that combines transformer-based classifiers and GPT-4 large language models (LLMs). We first address data imbalance in the training set using topic modelling and under-sampling. Next, we train RoBERTa-based classifiers on the adjusted data. Finally, GPT-4 refines the classifier{'}s predictions for uncertain cases (confidence below 0.9). This strategy achieved significant improvement over the baseline RoBERTa models. Our work demonstrates the effectiveness of combining transformer classifiers and LLMs for extracting health insights from social media conversations.\",\n}\n",
    "authors": [
        "Sedigh Khademi",
        "Christopher Palmer",
        "Muhammad Javed",
        "Jim Buttery",
        "Gerardo Dimaguila"
    ],
    "pdf_url": "https://aclanthology.org/2024.smm4h-1.16.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/db7c1bac-072f-5044-b283-6f65388fcae5.pdf",
    "abstract": "This paper presents our approach for SMM4H 2024 Task 5, focusing on identifying tweets where users discuss their child’s health conditions of ADHD, ASD, delayed speech, or asthma. Our approach uses a pipeline that combines transformer-based classifiers and GPT-4 large language models (LLMs). We first address data imbalance in the training set using topic modelling and under-sampling. Next, we train RoBERTa-based classifiers on the adjusted data. Finally, GPT-4 refines the classifier’s predictions for uncertain cases (confidence below 0.9). This strategy achieved significant improvement over the baseline RoBERTa models. Our work demonstrates the effectiveness of combining transformer classifiers and LLMs for extracting health insights from social media conversations.",
    "num_pages": 3
}