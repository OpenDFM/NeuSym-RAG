{
    "uuid": "8b271219-d57e-5982-a193-2a0597c7e2ed",
    "title": "OpenSLU: A Unified, Modularized, and Extensible Toolkit for Spoken Language Understanding",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
    "bibtex": "@inproceedings{qin-etal-2023-openslu,\n    title = \"{O}pen{SLU}: A Unified, Modularized, and Extensible Toolkit for Spoken Language Understanding\",\n    author = \"Qin, Libo  and\n      Chen, Qiguang  and\n      Xu, Xiao  and\n      Feng, Yunlong  and\n      Che, Wanxiang\",\n    editor = \"Bollegala, Danushka  and\n      Huang, Ruihong  and\n      Ritter, Alan\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-demo.9\",\n    doi = \"10.18653/v1/2023.acl-demo.9\",\n    pages = \"95--102\",\n    abstract = \"Spoken Language Understanding (SLU) is one of the core components of a task-oriented dialogue system, which aims to extract the semantic meaning of user queries (e.g., intents and slots). In this work, we introduce OpenSLU, an open-source toolkit to provide a unified, modularized, and extensible toolkit for spoken language understanding. Specifically, OpenSLU unifies 10 SLU models for both single-intent and multi-intent scenarios, which support both non-pretrained and pretrained models simultaneously. Additionally, OpenSLU is highly modularized and extensible by decomposing the model architecture, inference, and learning process into reusable modules, which allows researchers to quickly set up SLU experiments with highly flexible configurations. OpenSLU is implemented based on PyTorch, and released at \\url{https://github.com/LightChen233/OpenSLU}.\",\n}\n",
    "authors": [
        "Libo Qin",
        "Qiguang Chen",
        "Xiao Xu",
        "Yunlong Feng",
        "Wanxiang Che"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-demo.9.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/8b271219-d57e-5982-a193-2a0597c7e2ed.pdf",
    "abstract": "Spoken Language Understanding (SLU) is one of the core components of a task-oriented dialogue system, which aims to extract the semantic meaning of user queries (e.g., intents and slots). In this work, we introduce OpenSLU, an open-source toolkit to provide a unified, modularized, and extensible toolkit for spoken language understanding. Specifically, OpenSLU unifies 10 SLU models for both single-intent and multi-intent scenarios, which support both non-pretrained and pretrained models simultaneously. Additionally, OpenSLU is highly modularized and extensible by decomposing the model architecture, inference, and learning process into reusable modules, which allows researchers to quickly set up SLU experiments with highly flexible configurations. OpenSLU is implemented based on PyTorch, and released at https://github.com/LightChen233/OpenSLU.",
    "num_pages": 8
}