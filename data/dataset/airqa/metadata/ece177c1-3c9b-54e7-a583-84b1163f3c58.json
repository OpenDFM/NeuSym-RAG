{
    "uuid": "ece177c1-3c9b-54e7-a583-84b1163f3c58",
    "title": "Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{li-etal-2024-dynamic,\n    title = \"Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation\",\n    author = \"Li, Yiwei  and\n      Mi, Fei  and\n      Li, Yitong  and\n      Wang, Yasheng  and\n      Sun, Bin  and\n      Feng, Shaoxiong  and\n      Li, Kan\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.688\",\n    doi = \"10.18653/v1/2024.findings-acl.688\",\n    pages = \"11585--11596\",\n    abstract = \"Stochastic sampling strategies such as top-k and top-p have been widely used in dialogue generation task. However, as an open-domain chatting system, there will be two different conversation scenarios, i.e. chit-chat and knowledge-based question answering. In the former situation, responses diversity is essential due to the one-to-many nature in dialogue. The latter, on the other hand, requires less randomness given that stochastic decoding strategy entails the risk of generating incorrect information. As a result, an adaptive and flexible decoding strategy is needed to cope with these two scenarios simultaneously. To this end, we propose the dynamic decoding strategy (DDS), which can adjust the decoding space w.r.t. different contexts. In DDS, both sequence-level and token-level adaptive search can be achieved to adjust the decoding process in a unified framework. Besides, our adaptive algorithm can not only be used during model inference, but it can also be applied during the model training stage to further enhance the performance. Comprehensive experiments indicate that the proposed decoding strategy can consistently improve the performance of pre-trained dialogue models when coupled with four well-used stochastic decoding algorithms.\",\n}\n",
    "authors": [
        "Yiwei Li",
        "Fei Mi",
        "Yitong Li",
        "Yasheng Wang",
        "Bin Sun",
        "Shaoxiong Feng",
        "Kan Li"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.688.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ece177c1-3c9b-54e7-a583-84b1163f3c58.pdf",
    "abstract": "Stochastic sampling strategies such as top-k and top-p have been widely used in dialogue generation task. However, as an open-domain chatting system, there will be two different conversation scenarios, i.e. chit-chat and knowledge-based question answering. In the former situation, responses diversity is essential due to the one-to-many nature in dialogue. The latter, on the other hand, requires less randomness given that stochastic decoding strategy entails the risk of generating incorrect information. As a result, an adaptive and flexible decoding strategy is needed to cope with these two scenarios simultaneously. To this end, we propose the dynamic decoding strategy (DDS), which can adjust the decoding space w.r.t. different contexts. In DDS, both sequence-level and token-level adaptive search can be achieved to adjust the decoding process in a unified framework. Besides, our adaptive algorithm can not only be used during model inference, but it can also be applied during the model training stage to further enhance the performance. Comprehensive experiments indicate that the proposed decoding strategy can consistently improve the performance of pre-trained dialogue models when coupled with four well-used stochastic decoding algorithms.",
    "num_pages": 12
}