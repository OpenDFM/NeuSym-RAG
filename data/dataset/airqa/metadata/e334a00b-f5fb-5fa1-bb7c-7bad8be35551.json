{
    "uuid": "e334a00b-f5fb-5fa1-bb7c-7bad8be35551",
    "title": "Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{mei-etal-2023-foveate,\n    title = \"Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy {AI}\",\n    author = \"Mei, Alex  and\n      Levy, Sharon  and\n      Wang, William Yang\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.701\",\n    doi = \"10.18653/v1/2023.findings-acl.701\",\n    pages = \"11021--11036\",\n    abstract = \"Users{'} physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show that FARM obtains state-of-the-art results on the SafeText dataset, showing absolute improvement in safety classification accuracy by 5.9{\\%}.\",\n}\n",
    "authors": [
        "Alex Mei",
        "Sharon Levy",
        "William Yang Wang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.701.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e334a00b-f5fb-5fa1-bb7c-7bad8be35551.pdf",
    "abstract": "Usersâ€™ physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show that FARM obtains state-of-the-art results on the SafeText dataset, showing absolute improvement in safety classification accuracy by 5.9%.",
    "num_pages": 16
}