{
    "uuid": "3be906ee-359d-5315-94aa-0fd3ecf8f0c9",
    "title": "Continual Dialogue State Tracking via Reason-of-Select Distillation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{feng-etal-2024-continual,\n    title = \"Continual Dialogue State Tracking via Reason-of-Select Distillation\",\n    author = \"Feng, Yujie  and\n      Liu, Bo  and\n      Dong, Xiaoyu  and\n      Lu, Zexin  and\n      Zhan, Li-Ming  and\n      Wu, Xiao-Ming  and\n      Lam, Albert\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.422\",\n    doi = \"10.18653/v1/2024.findings-acl.422\",\n    pages = \"7075--7087\",\n    abstract = \"An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services, confronting catastrophic forgetting and a critical capability loss termed the {``}Value Selection Quandary{''}. To address these challenges, we introduce the Reason-of-Select (RoS) distillation method by enhancing smaller models with a novel {``}meta-reasoning{''} capability. Meta-reasoning, employing an enhanced multi-domain perspective, combines fragments of meta-knowledge from domain-specific dialogues during continual learning, transcending traditional single-perspective reasoning. This domain bootstrapping process enhances the model{'}s ability to dissect intricate dialogues from multiple possible values, and its domain-agnostic property aligns data distribution across different domains, effectively mitigating forgetting. Besides, two novel improvements, {``}multi-value resolution{''} strategy and Semantic Contrastive Reasoning Selection method, significantly enhance RoS by generating DST-specific selection chains and mitigating hallucinations in teachers{'} reasoning, ensuring effective and reliable knowledge transfer. Extensive experiments validate the exceptional performance and robust generalization capabilities of our method.\",\n}\n",
    "authors": [
        "Yujie Feng",
        "Bo Liu",
        "Xiaoyu Dong",
        "Zexin Lu",
        "Li-Ming Zhan",
        "Xiao-Ming Wu",
        "Albert Lam"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.422.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3be906ee-359d-5315-94aa-0fd3ecf8f0c9.pdf",
    "abstract": "An ideal dialogue system requires continuous skill acquisition and adaptation to new tasks while retaining prior knowledge. Dialogue State Tracking (DST), vital in these systems, often involves learning new services, confronting catastrophic forgetting and a critical capability loss termed the “Value Selection Quandary”. To address these challenges, we introduce the Reason-of-Select (RoS) distillation method by enhancing smaller models with a novel “meta-reasoning” capability. Meta-reasoning, employing an enhanced multi-domain perspective, combines fragments of meta-knowledge from domain-specific dialogues during continual learning, transcending traditional single-perspective reasoning. This domain bootstrapping process enhances the model’s ability to dissect intricate dialogues from multiple possible values, and its domain-agnostic property aligns data distribution across different domains, effectively mitigating forgetting. Besides, two novel improvements, “multi-value resolution” strategy and Semantic Contrastive Reasoning Selection method, significantly enhance RoS by generating DST-specific selection chains and mitigating hallucinations in teachers’ reasoning, ensuring effective and reliable knowledge transfer. Extensive experiments validate the exceptional performance and robust generalization capabilities of our method.",
    "num_pages": 13
}