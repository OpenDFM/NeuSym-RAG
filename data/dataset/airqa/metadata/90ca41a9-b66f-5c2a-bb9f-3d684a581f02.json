{
    "uuid": "90ca41a9-b66f-5c2a-bb9f-3d684a581f02",
    "title": "Robust Integration of Contextual Information for Cross-Target Stance Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)",
    "bibtex": "@inproceedings{beck-etal-2023-robust,\n    title = \"Robust Integration of Contextual Information for Cross-Target Stance Detection\",\n    author = \"Beck, Tilman  and\n      Waldis, Andreas  and\n      Gurevych, Iryna\",\n    editor = \"Palmer, Alexis  and\n      Camacho-collados, Jose\",\n    booktitle = \"Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.starsem-1.43\",\n    doi = \"10.18653/v1/2023.starsem-1.43\",\n    pages = \"494--511\",\n    abstract = \"Stance detection deals with identifying an author{'}s stance towards a target. Most existing stance detection models are limited because they do not consider relevant contextual information which allows for inferring the stance correctly. Complementary context can be found in knowledge bases but integrating the context into pretrained language models is non-trivial due to the graph structure of standard knowledge bases. To overcome this, we explore an approach to integrate contextual information as text which allows for integrating contextual information from heterogeneous sources, such as structured knowledge sources and by prompting large language models. Our approach can outperform competitive baselines on a large and diverse stance detection benchmark in a cross-target setup, i.e. for targets unseen during training. We demonstrate that it is more robust to noisy context and can regularize for unwanted correlations between labels and target-specific vocabulary. Finally, it is independent of the pretrained language model in use.\",\n}\n",
    "authors": [
        "Tilman Beck",
        "Andreas Waldis",
        "Iryna Gurevych"
    ],
    "pdf_url": "https://aclanthology.org/2023.starsem-1.43.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/90ca41a9-b66f-5c2a-bb9f-3d684a581f02.pdf",
    "abstract": "Stance detection deals with identifying an authorâ€™s stance towards a target. Most existing stance detection models are limited because they do not consider relevant contextual information which allows for inferring the stance correctly. Complementary context can be found in knowledge bases but integrating the context into pretrained language models is non-trivial due to the graph structure of standard knowledge bases. To overcome this, we explore an approach to integrate contextual information as text which allows for integrating contextual information from heterogeneous sources, such as structured knowledge sources and by prompting large language models. Our approach can outperform competitive baselines on a large and diverse stance detection benchmark in a cross-target setup, i.e. for targets unseen during training. We demonstrate that it is more robust to noisy context and can regularize for unwanted correlations between labels and target-specific vocabulary. Finally, it is independent of the pretrained language model in use.",
    "num_pages": 18
}