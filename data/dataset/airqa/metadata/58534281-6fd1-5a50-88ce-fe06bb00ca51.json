{
    "uuid": "58534281-6fd1-5a50-88ce-fe06bb00ca51",
    "title": "STICKERCONV: Generating Multimodal Empathetic Responses from Scratch",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhang-etal-2024-stickerconv,\n    title = \"{STICKERCONV}: Generating Multimodal Empathetic Responses from Scratch\",\n    author = \"Zhang, Yiqun  and\n      Kong, Fanheng  and\n      Wang, Peidong  and\n      Sun, Shuang  and\n      SWangLing, SWangLing  and\n      Feng, Shi  and\n      Wang, Daling  and\n      Zhang, Yifei  and\n      Song, Kaisong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.417\",\n    doi = \"10.18653/v1/2024.acl-long.417\",\n    pages = \"7707--7733\",\n    abstract = \"Stickers, while widely recognized for enhancing empathetic communication in online interactions, remain underexplored in current empathetic dialogue research, notably due to the challenge of a lack of comprehensive datasets. In this paper, we introduce the Agent for STICKERCONV (Agent4SC), which uses collaborative agent interactions to realistically simulate human behavior with sticker usage, thereby enhancing multimodal empathetic communication. Building on this foundation, we develop a multimodal empathetic dialogue dataset, STICKERCONV, comprising 12.9K dialogue sessions, 5.8K unique stickers, and 2K diverse conversational scenarios. This dataset serves as a benchmark for multimodal empathetic generation. To advance further, we propose PErceive and Generate Stickers (PEGS), a multimodal empathetic response generation framework, complemented by a comprehensive set of empathy evaluation metrics based on LLM. Our experiments demonstrate PEGS{'}s effectiveness in generating contextually relevant and emotionally resonant multimodal empathetic responses, contributing to the advancement of more nuanced and engaging empathetic dialogue systems.\",\n}\n",
    "authors": [
        "Yiqun Zhang",
        "Fanheng Kong",
        "Peidong Wang",
        "Shuang Sun",
        "SWangLing SWangLing",
        "Shi Feng",
        "Daling Wang",
        "Yifei Zhang",
        "Kaisong Song"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.417.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/58534281-6fd1-5a50-88ce-fe06bb00ca51.pdf",
    "abstract": "Stickers, while widely recognized for enhancing empathetic communication in online interactions, remain underexplored in current empathetic dialogue research, notably due to the challenge of a lack of comprehensive datasets. In this paper, we introduce the Agent for STICKERCONV (Agent4SC), which uses collaborative agent interactions to realistically simulate human behavior with sticker usage, thereby enhancing multimodal empathetic communication. Building on this foundation, we develop a multimodal empathetic dialogue dataset, STICKERCONV, comprising 12.9K dialogue sessions, 5.8K unique stickers, and 2K diverse conversational scenarios. This dataset serves as a benchmark for multimodal empathetic generation. To advance further, we propose PErceive and Generate Stickers (PEGS), a multimodal empathetic response generation framework, complemented by a comprehensive set of empathy evaluation metrics based on LLM. Our experiments demonstrate PEGSâ€™s effectiveness in generating contextually relevant and emotionally resonant multimodal empathetic responses, contributing to the advancement of more nuanced and engaging empathetic dialogue systems.",
    "num_pages": 27
}