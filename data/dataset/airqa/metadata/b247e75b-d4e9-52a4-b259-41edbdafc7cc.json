{
    "uuid": "b247e75b-d4e9-52a4-b259-41edbdafc7cc",
    "title": "GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{yang-etal-2023-glue,\n    title = \"{GLUE}-{X}: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective\",\n    author = \"Yang, Linyi  and\n      Zhang, Shuibai  and\n      Qin, Libo  and\n      Li, Yafu  and\n      Wang, Yidong  and\n      Liu, Hanmeng  and\n      Wang, Jindong  and\n      Xie, Xing  and\n      Zhang, Yue\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.806\",\n    doi = \"10.18653/v1/2023.findings-acl.806\",\n    pages = \"12731--12750\",\n    abstract = \"Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named GLUE-X for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.\",\n}\n",
    "authors": [
        "Linyi Yang",
        "Shuibai Zhang",
        "Libo Qin",
        "Yafu Li",
        "Yidong Wang",
        "Hanmeng Liu",
        "Jindong Wang",
        "Xing Xie",
        "Yue Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.806.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b247e75b-d4e9-52a4-b259-41edbdafc7cc.pdf",
    "abstract": "Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named GLUE-X for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.",
    "num_pages": 20
}