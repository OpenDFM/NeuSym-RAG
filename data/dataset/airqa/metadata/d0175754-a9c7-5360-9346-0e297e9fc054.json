{
    "uuid": "d0175754-a9c7-5360-9346-0e297e9fc054",
    "title": "Financial Product Ontology Population with Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of TextGraphs-17: Graph-based Methods for Natural Language Processing",
    "bibtex": "@inproceedings{saetia-etal-2024-financial,\n    title = \"Financial Product Ontology Population with Large Language Models\",\n    author = \"Saetia, Chanatip  and\n      Phruetthiset, Jiratha  and\n      Chalothorn, Tawunrat  and\n      Lertsutthiwong, Monchai  and\n      Taerungruang, Supawat  and\n      Buabthong, Pakpoom\",\n    editor = \"Ustalov, Dmitry  and\n      Gao, Yanjun  and\n      Panchenko, Alexander  and\n      Tutubalina, Elena  and\n      Nikishina, Irina  and\n      Ramesh, Arti  and\n      Sakhovskiy, Andrey  and\n      Usbeck, Ricardo  and\n      Penn, Gerald  and\n      Valentino, Marco\",\n    booktitle = \"Proceedings of TextGraphs-17: Graph-based Methods for Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.textgraphs-1.4\",\n    pages = \"53--60\",\n    abstract = \"Ontology population, which aims to extract structured data to enrich domain-specific ontologies from unstructured text, typically faces challenges in terms of data scarcity and linguistic complexity, particularly in specialized fields such as retail banking. In this study, we investigate the application of large language models (LLMs) to populate domain-specific ontologies of retail banking products from Thai corporate documents. We compare traditional span-based approaches to LLMs-based generative methods, with different prompting techniques. Our findings reveal that while span-based methods struggle with data scarcity and the complex linguistic structure, LLMs-based generative approaches substantially outperform, achieving a 61.05{\\%} F1 score, with the most improvement coming from providing examples in the prompts. This improvement highlights the potential of LLMs for ontology population tasks, offering a scalable and efficient solution for structured information extraction in especially in low-resource language settings.\",\n}\n",
    "authors": [
        "Chanatip Saetia",
        "Jiratha Phruetthiset",
        "Tawunrat Chalothorn",
        "Monchai Lertsutthiwong",
        "Supawat Taerungruang",
        "Pakpoom Buabthong"
    ],
    "pdf_url": "https://aclanthology.org/2024.textgraphs-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d0175754-a9c7-5360-9346-0e297e9fc054.pdf",
    "abstract": "Ontology population, which aims to extract structured data to enrich domain-specific ontologies from unstructured text, typically faces challenges in terms of data scarcity and linguistic complexity, particularly in specialized fields such as retail banking. In this study, we investigate the application of large language models (LLMs) to populate domain-specific ontologies of retail banking products from Thai corporate documents. We compare traditional span-based approaches to LLMs-based generative methods, with different prompting techniques. Our findings reveal that while span-based methods struggle with data scarcity and the complex linguistic structure, LLMs-based generative approaches substantially outperform, achieving a 61.05% F1 score, with the most improvement coming from providing examples in the prompts. This improvement highlights the potential of LLMs for ontology population tasks, offering a scalable and efficient solution for structured information extraction in especially in low-resource language settings.",
    "num_pages": 8
}