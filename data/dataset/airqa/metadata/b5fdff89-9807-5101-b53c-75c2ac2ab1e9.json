{
    "uuid": "b5fdff89-9807-5101-b53c-75c2ac2ab1e9",
    "title": "Automatic Layout Planning for Visually-Rich Documents with Instruction-Following Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR)",
    "bibtex": "@inproceedings{zhu-etal-2024-automatic,\n    title = \"Automatic Layout Planning for Visually-Rich Documents with Instruction-Following Models\",\n    author = \"Zhu, Wanrong  and\n      Zhang, Ruiyi  and\n      Healey, Jennifer  and\n      Wang, William Yang  and\n      Sun, Tong\",\n    editor = \"Gu, Jing  and\n      Fu, Tsu-Jui (Ray)  and\n      Hudson, Drew  and\n      Celikyilmaz, Asli  and\n      Wang, William\",\n    booktitle = \"Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.alvr-1.14\",\n    doi = \"10.18653/v1/2024.alvr-1.14\",\n    pages = \"167--172\",\n    abstract = \"Recent advancements in instruction-following models have made user interactions with models more user-friendly and efficient, broadening their applicability. In graphic design, non-professional users often struggle to create visually appealing layouts due to limited skills and resources. In this work, we introduce a novel multimodal instruction-following framework for layout planning, allowing users to easily arrange visual elements into tailored layouts by specifying canvas size and design purpose, such as for book covers, posters, brochures, or menus. We developed three layout reasoning tasks to train the model in understanding and executing layout instructions. Experiments on two benchmarks show that our method not only simplifies the design process for non-professionals but also surpasses the performance of few-shot GPT-4V models, with mIoU higher by 12{\\%} on Crello. This progress highlights the potential of multimodal instruction-following models to automate and simplify the design process, providing an approachable solution for a wide range of design tasks on visually-rich documents.\",\n}\n",
    "authors": [
        "Wanrong Zhu",
        "Ruiyi Zhang",
        "Jennifer Healey",
        "William Yang Wang",
        "Tong Sun"
    ],
    "pdf_url": "https://aclanthology.org/2024.alvr-1.14.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b5fdff89-9807-5101-b53c-75c2ac2ab1e9.pdf",
    "abstract": "Recent advancements in instruction-following models have made user interactions with models more user-friendly and efficient, broadening their applicability. In graphic design, non-professional users often struggle to create visually appealing layouts due to limited skills and resources. In this work, we introduce a novel multimodal instruction-following framework for layout planning, allowing users to easily arrange visual elements into tailored layouts by specifying canvas size and design purpose, such as for book covers, posters, brochures, or menus. We developed three layout reasoning tasks to train the model in understanding and executing layout instructions. Experiments on two benchmarks show that our method not only simplifies the design process for non-professionals but also surpasses the performance of few-shot GPT-4V models, with mIoU higher by 12% on Crello. This progress highlights the potential of multimodal instruction-following models to automate and simplify the design process, providing an approachable solution for a wide range of design tasks on visually-rich documents.",
    "num_pages": 6
}