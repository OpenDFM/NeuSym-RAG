{
    "uuid": "2cc447bf-ae63-586b-b3a7-f781dad30db7",
    "title": "Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{hu-etal-2023-entity,\n    title = \"Entity-to-Text based Data Augmentation for various Named Entity Recognition Tasks\",\n    author = \"Hu, Xuming  and\n      Jiang, Yong  and\n      Liu, Aiwei  and\n      Huang, Zhongqiang  and\n      Xie, Pengjun  and\n      Huang, Fei  and\n      Wen, Lijie  and\n      Yu, Philip S.\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.578\",\n    doi = \"10.18653/v1/2023.findings-acl.578\",\n    pages = \"9072--9087\",\n    abstract = \"Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks. In this work, we propose a novel Entity-to-Text based data augmentation technique named EnTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that EnTDA could bring more performance improvements compared to the baseline augmentation techniques.\",\n}\n",
    "authors": [
        "Xuming Hu",
        "Yong Jiang",
        "Aiwei Liu",
        "Zhongqiang Huang",
        "Pengjun Xie",
        "Fei Huang",
        "Lijie Wen",
        "Philip S. Yu"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.578.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/2cc447bf-ae63-586b-b3a7-f781dad30db7.pdf",
    "abstract": "Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks. In this work, we propose a novel Entity-to-Text based data augmentation technique named EnTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that EnTDA could bring more performance improvements compared to the baseline augmentation techniques.",
    "num_pages": 16
}