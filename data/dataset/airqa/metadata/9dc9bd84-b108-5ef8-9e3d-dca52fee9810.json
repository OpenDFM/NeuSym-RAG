{
    "uuid": "9dc9bd84-b108-5ef8-9e3d-dca52fee9810",
    "title": "Combating Label Sparsity in Short Text Topic Modeling via Nearest Neighbor Augmentation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{lin-etal-2024-combating,\n    title = \"Combating Label Sparsity in Short Text Topic Modeling via Nearest Neighbor Augmentation\",\n    author = \"Lin, Yang  and\n      Ma, Xinyu  and\n      Gao, Xin  and\n      Li, Ruiqing  and\n      Wang, Yasha  and\n      Chu, Xu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.817\",\n    doi = \"10.18653/v1/2024.findings-acl.817\",\n    pages = \"13762--13774\",\n    abstract = \"Extracting semantic topics from short texts presents a significant challenge in the field of data mining. While efforts have been made to mitigate data sparsity issue, the limited length of short documents also results in the absence of semantically relevant words, causing biased evidence lower bound and incomplete labels for likelihood maximization. We refer to this issue as the label sparsity problem. To combat this problem, we propose kNNTM, a neural short text topic model that incorporates a $k$-Nearest-Neighbor-based label completion algorithm by augmenting the reconstruction label with $k$-nearest documents to complement these relevant but unobserved words. Furthermore, seeking a precise reflection of distances between documents, we propose a fused multi-view distances metric that takes both local word similarities and global topic semantics into consideration. Extensive experiments on multiple public short-text datasets show that kNNTM model outperforms the state-of-the-art baseline models and can derive both high-quality topics and document representations.\",\n}\n",
    "authors": [
        "Yang Lin",
        "Xinyu Ma",
        "Xin Gao",
        "Ruiqing Li",
        "Yasha Wang",
        "Xu Chu"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.817.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9dc9bd84-b108-5ef8-9e3d-dca52fee9810.pdf",
    "abstract": "Extracting semantic topics from short texts presents a significant challenge in the field of data mining. While efforts have been made to mitigate data sparsity issue, the limited length of short documents also results in the absence of semantically relevant words, causing biased evidence lower bound and incomplete labels for likelihood maximization. We refer to this issue as the label sparsity problem. To combat this problem, we propose kNNTM, a neural short text topic model that incorporates a k-Nearest-Neighbor-based label completion algorithm by augmenting the reconstruction label with k-nearest documents to complement these relevant but unobserved words. Furthermore, seeking a precise reflection of distances between documents, we propose a fused multi-view distances metric that takes both local word similarities and global topic semantics into consideration. Extensive experiments on multiple public short-text datasets show that kNNTM model outperforms the state-of-the-art baseline models and can derive both high-quality topics and document representations.",
    "num_pages": 13
}