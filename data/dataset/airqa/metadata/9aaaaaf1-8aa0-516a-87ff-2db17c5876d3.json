{
    "uuid": "9aaaaaf1-8aa0-516a-87ff-2db17c5876d3",
    "title": "3MVRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{ding-etal-2024-3mvrd,\n    title = \"3{MVRD}: Multimodal Multi-task Multi-teacher Visually-Rich Form Document Understanding\",\n    author = \"Ding, Yihao  and\n      Vaiani, Lorenzo  and\n      Han, Caren  and\n      Lee, Jean  and\n      Garza, Paolo  and\n      Poon, Josiah  and\n      Cagliero, Luca\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.903\",\n    doi = \"10.18653/v1/2024.findings-acl.903\",\n    pages = \"15233--15244\",\n    abstract = \"This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation between token and entity representations, addressing the complexities inherent in form documents. Additionally, we introduce new inter-grained and cross-grained loss functions to further refine diverse multi-teacher knowledge distillation transfer process, presenting distribution gaps and a harmonised understanding of form documents. Through a comprehensive evaluation across publicly available form document understanding datasets, our proposed model consistently outperforms existing baselines, showcasing its efficacy in handling the intricate structures and content of visually complex form documents.\",\n}\n",
    "authors": [
        "Yihao Ding",
        "Lorenzo Vaiani",
        "Caren Han",
        "Jean Lee",
        "Paolo Garza",
        "Josiah Poon",
        "Luca Cagliero"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.903.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9aaaaaf1-8aa0-516a-87ff-2db17c5876d3.pdf",
    "abstract": "This paper presents a groundbreaking multimodal, multi-task, multi-teacher joint-grained knowledge distillation model for visually-rich form document understanding. The model is designed to leverage insights from both fine-grained and coarse-grained levels by facilitating a nuanced correlation between token and entity representations, addressing the complexities inherent in form documents. Additionally, we introduce new inter-grained and cross-grained loss functions to further refine diverse multi-teacher knowledge distillation transfer process, presenting distribution gaps and a harmonised understanding of form documents. Through a comprehensive evaluation across publicly available form document understanding datasets, our proposed model consistently outperforms existing baselines, showcasing its efficacy in handling the intricate structures and content of visually complex form documents.",
    "num_pages": 12
}