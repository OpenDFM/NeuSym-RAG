{
    "uuid": "aee1dccd-6dda-5d10-9c02-08076fe333f1",
    "title": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
    "bibtex": "@inproceedings{manakul-etal-2023-cued,\n    title = \"{CUED} at {P}rob{S}um 2023: Hierarchical Ensemble of Summarization Models\",\n    author = \"Manakul, Potsawee  and\n      Fathullah, Yassir  and\n      Liusie, Adian  and\n      Raina, Vyas  and\n      Raina, Vatsal  and\n      Gales, Mark\",\n    editor = \"Demner-fushman, Dina  and\n      Ananiadou, Sophia  and\n      Cohen, Kevin\",\n    booktitle = \"The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bionlp-1.51\",\n    doi = \"10.18653/v1/2023.bionlp-1.51\",\n    pages = \"516--523\",\n    abstract = \"In this paper, we consider the challenge of summarizing patients medical progress notes in a limited data setting. For the Problem List Summarization (shared task 1A) at the BioNLP Workshop 2023, we demonstrate that ClinicalT5 fine-tuned to 765 medical clinic notes outperforms other extractive, abstractive and zero-shot baselines, yielding reasonable baseline systems for medical note summarization. Further, we introduce Hierarchical Ensemble of Summarization Models (HESM), consisting of token-level ensembles of diverse fine-tuned ClinicalT5 models, followed by Minimum Bayes Risk (MBR) decoding. Our HESM approach lead to a considerable summarization performance boost, and when evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which was the best-performing system at the top of the shared task leaderboard.\",\n}\n",
    "authors": [
        "Potsawee Manakul",
        "Yassir Fathullah",
        "Adian Liusie",
        "Vyas Raina",
        "Vatsal Raina",
        "Mark Gales"
    ],
    "pdf_url": "https://aclanthology.org/2023.bionlp-1.51.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/aee1dccd-6dda-5d10-9c02-08076fe333f1.pdf",
    "abstract": "In this paper, we consider the challenge of summarizing patients medical progress notes in a limited data setting. For the Problem List Summarization (shared task 1A) at the BioNLP Workshop 2023, we demonstrate that ClinicalT5 fine-tuned to 765 medical clinic notes outperforms other extractive, abstractive and zero-shot baselines, yielding reasonable baseline systems for medical note summarization. Further, we introduce Hierarchical Ensemble of Summarization Models (HESM), consisting of token-level ensembles of diverse fine-tuned ClinicalT5 models, followed by Minimum Bayes Risk (MBR) decoding. Our HESM approach lead to a considerable summarization performance boost, and when evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which was the best-performing system at the top of the shared task leaderboard.",
    "num_pages": 8
}