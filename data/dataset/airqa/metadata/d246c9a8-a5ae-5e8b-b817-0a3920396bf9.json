{
    "uuid": "d246c9a8-a5ae-5e8b-b817-0a3920396bf9",
    "title": "ASOS at KSAA-CAD 2024: One Embedding is All You Need for Your Dictionary",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The Second Arabic Natural Language Processing Conference",
    "bibtex": "@inproceedings{sibaee-etal-2024-asos-ksaa,\n    title = \"{ASOS} at {KSAA}-{CAD} 2024: One Embedding is All You Need for Your Dictionary\",\n    author = \"Sibaee, Serry  and\n      Alharbi, Abdullah  and\n      Ahmad, Samar  and\n      Nacar, Omer  and\n      Koubaa, Anis  and\n      Ghouti, Lahouari\",\n    editor = \"Habash, Nizar  and\n      Bouamor, Houda  and\n      Eskander, Ramy  and\n      Tomeh, Nadi  and\n      Abu Farha, Ibrahim  and\n      Abdelali, Ahmed  and\n      Touileb, Samia  and\n      Hamed, Injy  and\n      Onaizan, Yaser  and\n      Alhafni, Bashar  and\n      Antoun, Wissam  and\n      Khalifa, Salam  and\n      Haddad, Hatem  and\n      Zitouni, Imed  and\n      AlKhamissi, Badr  and\n      Almatham, Rawan  and\n      Mrini, Khalil\",\n    booktitle = \"Proceedings of The Second Arabic Natural Language Processing Conference\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.arabicnlp-1.77\",\n    doi = \"10.18653/v1/2024.arabicnlp-1.77\",\n    pages = \"697--703\",\n    abstract = \"Semantic search tasks have grown extremely fast following the advancements in large language models, including the Reverse Dictionary and Word Sense Disambiguation in Arabic. This paper describes our participation in the Contemporary Arabic Dictionary Shared Task. We propose two models that achieved first place in both tasks. We conducted comprehensive experiments on the latest five multilingual sentence transformers and the Arabic BERT model for semantic embedding extraction. We achieved a ranking score of 0.06 for the reverse dictionary task, which is double than last year{'}s winner. We had an accuracy score of 0.268 for the Word Sense Disambiguation task.\",\n}\n",
    "authors": [
        "Serry Sibaee",
        "Abdullah Alharbi",
        "Samar Ahmad",
        "Omer Nacar",
        "Anis Koubaa",
        "Lahouari Ghouti"
    ],
    "pdf_url": "https://aclanthology.org/2024.arabicnlp-1.77.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d246c9a8-a5ae-5e8b-b817-0a3920396bf9.pdf",
    "abstract": "Semantic search tasks have grown extremely fast following the advancements in large language models, including the Reverse Dictionary and Word Sense Disambiguation in Arabic. This paper describes our participation in the Contemporary Arabic Dictionary Shared Task. We propose two models that achieved first place in both tasks. We conducted comprehensive experiments on the latest five multilingual sentence transformers and the Arabic BERT model for semantic embedding extraction. We achieved a ranking score of 0.06 for the reverse dictionary task, which is double than last yearâ€™s winner. We had an accuracy score of 0.268 for the Word Sense Disambiguation task.",
    "num_pages": 7
}