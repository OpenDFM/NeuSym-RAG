{
    "uuid": "1460185f-a26d-5883-8cf9-817fd6f3e1df",
    "title": "Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for Ancient Indian Philosophy",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 1st Workshop on Machine Learning for Ancient Languages (ML4AL 2024)",
    "bibtex": "@inproceedings{mandikal-2024-ancient,\n    title = \"Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented {LLM}s for {A}ncient {I}ndian Philosophy\",\n    author = \"Mandikal, Priyanka\",\n    editor = \"Pavlopoulos, John  and\n      Sommerschield, Thea  and\n      Assael, Yannis  and\n      Gordin, Shai  and\n      Cho, Kyunghyun  and\n      Passarotti, Marco  and\n      Sprugnoli, Rachele  and\n      Liu, Yudong  and\n      Li, Bin  and\n      Anderson, Adam\",\n    booktitle = \"Proceedings of the 1st Workshop on Machine Learning for Ancient Languages (ML4AL 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Hybrid in Bangkok, Thailand and online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.ml4al-1.23\",\n    doi = \"10.18653/v1/2024.ml4al-1.23\",\n    pages = \"224--250\",\n    abstract = \"LLMs have revolutionized the landscape of information retrieval and knowledge dissemination. However, their application in specialized areas is often hindered by limitations such as factual inaccuracies and hallucinations, especially in long-tail knowledge distributions. In this work, we explore the potential of retrieval-augmented generation (RAG) models in performing long-form question answering (LFQA) on a specially curated niche and custom knowledge domain. We present VedantaNY-10M, a dataset curated from extensive public discourses on the ancient Indian philosophy of Advaita Vedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM, focusing on transcription, retrieval, and generation performance. A human evaluation involving computational linguists and domain experts, shows that the RAG model significantly outperforms the standard model in producing factual, comprehensive responses having fewer hallucinations. In addition, we find that a keyword-based hybrid retriever that focuses on unique low-frequency words further improves results. Our study provides insights into the future development of real-world RAG models for custom and niche areas of knowledge.\",\n}\n",
    "authors": [
        "Priyanka Mandikal"
    ],
    "pdf_url": "https://aclanthology.org/2024.ml4al-1.23.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/1460185f-a26d-5883-8cf9-817fd6f3e1df.pdf",
    "abstract": "LLMs have revolutionized the landscape of information retrieval and knowledge dissemination. However, their application in specialized areas is often hindered by limitations such as factual inaccuracies and hallucinations, especially in long-tail knowledge distributions. In this work, we explore the potential of retrieval-augmented generation (RAG) models in performing long-form question answering (LFQA) on a specially curated niche and custom knowledge domain. We present VedantaNY-10M, a dataset curated from extensive public discourses on the ancient Indian philosophy of Advaita Vedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM, focusing on transcription, retrieval, and generation performance. A human evaluation involving computational linguists and domain experts, shows that the RAG model significantly outperforms the standard model in producing factual, comprehensive responses having fewer hallucinations. In addition, we find that a keyword-based hybrid retriever that focuses on unique low-frequency words further improves results. Our study provides insights into the future development of real-world RAG models for custom and niche areas of knowledge.",
    "num_pages": 27
}