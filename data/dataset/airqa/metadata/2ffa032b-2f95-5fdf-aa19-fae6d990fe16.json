{
    "uuid": "2ffa032b-2f95-5fdf-aa19-fae6d990fe16",
    "title": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{suzgun-etal-2023-challenging,\n    title = \"Challenging {BIG}-Bench Tasks and Whether Chain-of-Thought Can Solve Them\",\n    author = {Suzgun, Mirac  and\n      Scales, Nathan  and\n      Sch{\\\"a}rli, Nathanael  and\n      Gehrmann, Sebastian  and\n      Tay, Yi  and\n      Chung, Hyung Won  and\n      Chowdhery, Aakanksha  and\n      Le, Quoc  and\n      Chi, Ed  and\n      Zhou, Denny  and\n      Wei, Jason},\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.824\",\n    doi = \"10.18653/v1/2023.findings-acl.824\",\n    pages = \"13003--13051\",\n    abstract = \"BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65{\\%} of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models? In this work, we focus on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the tasks for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.\",\n}\n",
    "authors": [
        "Mirac Suzgun",
        "Nathan Scales",
        "Nathanael Sch√§rli",
        "Sebastian Gehrmann",
        "Yi Tay",
        "Hyung Won Chung",
        "Aakanksha Chowdhery",
        "Quoc Le",
        "Ed Chi",
        "Denny Zhou",
        "Jason Wei"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.824.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/2ffa032b-2f95-5fdf-aa19-fae6d990fe16.pdf",
    "abstract": "BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65% of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models? In this work, we focus on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the tasks for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.",
    "num_pages": 49
}