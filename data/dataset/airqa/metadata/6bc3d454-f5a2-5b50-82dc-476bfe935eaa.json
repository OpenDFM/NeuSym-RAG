{
    "uuid": "6bc3d454-f5a2-5b50-82dc-476bfe935eaa",
    "title": "HellaSwag: Can a Machine Really Finish Your Sentence?",
    "conference": "ACL",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "volume": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "year": 2019,
    "authors": [
        "Rowan Zellers",
        "Ari Holtzman",
        "Yonatan Bisk",
        "Ali Farhadi",
        "Yejin Choi"
    ],
    "pdf_url": "https://aclanthology.org/P19-1472.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2019/6bc3d454-f5a2-5b50-82dc-476bfe935eaa.pdf",
    "bibtex": "@inproceedings{DBLP:conf/acl/ZellersHBFC19,\n  author       = {Rowan Zellers and\n                  Ari Holtzman and\n                  Yonatan Bisk and\n                  Ali Farhadi and\n                  Yejin Choi},\n  editor       = {Anna Korhonen and\n                  David R. Traum and\n                  Llu{\\'{\\i}}s M{\\`{a}}rquez},\n  title        = {HellaSwag: Can a Machine Really Finish Your Sentence?},\n  booktitle    = {Proceedings of the 57th Conference of the Association for Computational\n                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,\n                  Volume 1: Long Papers},\n  pages        = {4791--4800},\n  publisher    = {Association for Computational Linguistics},\n  year         = {2019},\n  url          = {https://doi.org/10.18653/v1/p19-1472},\n  doi          = {10.18653/V1/P19-1472},\n  timestamp    = {Sat, 29 Apr 2023 10:09:26 +0200},\n  biburl       = {https://dblp.org/rec/conf/acl/ZellersHBFC19.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n\n",
    "abstract": "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as “A woman sits at a piano,” a machine must select the most likely followup: “She sets her ﬁngers on the keys.” With the introduction of BERT (Devlin et al., 2018), near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves diﬃcult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (°95% accuracy), state-of-the-art models struggle (†48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical ‘Goldilocks’ zone wherein generated text is ridiculous to humans, yet often misclassiﬁed by state-of-the-art models. Our construction of HellaSwag, and its resulting diﬃculty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
    "num_pages": 10,
    "tldr": "HellaSwag reveals limitations in AI commonsense inference with adversarial data.",
    "tags": [
        "commonsense inference",
        "adversarial filtering",
        "deep learning",
        "NLP benchmarks",
        "machine-generated text"
    ]
}
