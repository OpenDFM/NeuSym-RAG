{
    "uuid": "7924fba6-45fd-583f-9c2c-9340aaf84384",
    "title": "Selective “Selective Prediction”: Reducing Unnecessary Abstention in Vision-Language Reasoning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{srinivasan-etal-2024-selective,\n    title = \"Selective {``}Selective Prediction{''}: Reducing Unnecessary Abstention in Vision-Language Reasoning\",\n    author = \"Srinivasan, Tejas  and\n      Hessel, Jack  and\n      Gupta, Tanmay  and\n      Lin, Bill Yuchen  and\n      Choi, Yejin  and\n      Thomason, Jesse  and\n      Chandu, Khyathi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.767\",\n    doi = \"10.18653/v1/2024.findings-acl.767\",\n    pages = \"12935--12948\",\n    abstract = \"Selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain too frequently, even on many correct predictions. We introduce ReCoVERR, an inference-time algorithm to reduce the over-abstention of a selective vision-language system without increasing the error rate of the system{'}s predictions. When the VLM makes a low-confidence prediction, instead of abstaining ReCoVERR tries to find relevant clues in the image that provide additional evidence for the prediction. ReCoVERR uses an LLM to pose related questions to the VLM, collects high-confidence evidences, and if enough evidence confirms the prediction the system makes a prediction instead of abstaining. ReCoVERR enables three VLMs (BLIP2, InstructBLIP and LLaVA-1.5) to answer up to 20{\\%} more questions on the VQAv2 and A-OKVQA tasks without decreasing system accuracy, thus improving overall system reliability. Our code is available at https://github.com/tejas1995/ReCoVERR.\",\n}\n",
    "authors": [
        "Tejas Srinivasan",
        "Jack Hessel",
        "Tanmay Gupta",
        "Bill Yuchen Lin",
        "Yejin Choi",
        "Jesse Thomason",
        "Khyathi Chandu"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.767.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/7924fba6-45fd-583f-9c2c-9340aaf84384.pdf",
    "abstract": "Selective prediction minimizes incorrect predictions from vision-language models (VLMs) by allowing them to abstain from answering when uncertain. However, when deploying a vision-language system with low tolerance for inaccurate predictions, selective prediction may be over-cautious and abstain too frequently, even on many correct predictions. We introduce ReCoVERR, an inference-time algorithm to reduce the over-abstention of a selective vision-language system without increasing the error rate of the system’s predictions. When the VLM makes a low-confidence prediction, instead of abstaining ReCoVERR tries to find relevant clues in the image that provide additional evidence for the prediction. ReCoVERR uses an LLM to pose related questions to the VLM, collects high-confidence evidences, and if enough evidence confirms the prediction the system makes a prediction instead of abstaining. ReCoVERR enables three VLMs (BLIP2, InstructBLIP and LLaVA-1.5) to answer up to 20% more questions on the VQAv2 and A-OKVQA tasks without decreasing system accuracy, thus improving overall system reliability. Our code is available at https://github.com/tejas1995/ReCoVERR.",
    "num_pages": 14
}