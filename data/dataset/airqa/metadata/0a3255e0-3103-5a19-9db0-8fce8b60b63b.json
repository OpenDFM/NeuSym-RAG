{
    "uuid": "0a3255e0-3103-5a19-9db0-8fce8b60b63b",
    "title": "Reassess Summary Factual Inconsistency Detection with Large Language Model",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)",
    "bibtex": "@inproceedings{yang-etal-2024-reassess,\n    title = \"Reassess Summary Factual Inconsistency Detection with Large Language Model\",\n    author = \"Yang, Jiuding  and\n      Liu, Hui  and\n      Guo, Weidong  and\n      Rao, Zhuwei  and\n      Xu, Yu  and\n      Niu, Di\",\n    editor = \"Li, Sha  and\n      Li, Manling  and\n      Zhang, Michael JQ  and\n      Choi, Eunsol  and\n      Geva, Mor  and\n      Hase, Peter  and\n      Ji, Heng\",\n    booktitle = \"Proceedings of the 1st Workshop on Towards Knowledgeable Language Models (KnowLLM 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.knowllm-1.3\",\n    doi = \"10.18653/v1/2024.knowllm-1.3\",\n    pages = \"27--31\",\n    abstract = \"Ensuring factual consistency between the summary and the original document is paramount in summarization tasks. Consequently, considerable effort has been dedicated to detecting inconsistencies. With the advent of Large Language Models (LLMs), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection. However, early attempts have shown that LLMs underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology. In this study, we reassess summary inconsistency detection with LLMs, comparing the performances of GPT-3.5 and GPT-4. To advance research in LLM-based inconsistency detection, we propose SIFiD (Summary Inconsistency Detection with Filtered Document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.\",\n}\n",
    "authors": [
        "Jiuding Yang",
        "Hui Liu",
        "Weidong Guo",
        "Zhuwei Rao",
        "Yu Xu",
        "Di Niu"
    ],
    "pdf_url": "https://aclanthology.org/2024.knowllm-1.3.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/0a3255e0-3103-5a19-9db0-8fce8b60b63b.pdf",
    "abstract": "Ensuring factual consistency between the summary and the original document is paramount in summarization tasks. Consequently, considerable effort has been dedicated to detecting inconsistencies. With the advent of Large Language Models (LLMs), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection. However, early attempts have shown that LLMs underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology. In this study, we reassess summary inconsistency detection with LLMs, comparing the performances of GPT-3.5 and GPT-4. To advance research in LLM-based inconsistency detection, we propose SIFiD (Summary Inconsistency Detection with Filtered Document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.",
    "num_pages": 5
}