{
    "uuid": "9cb847a5-f20b-5812-9fcf-40b7a1c87855",
    "title": "Tailoring with Targeted Precision: Edit-Based Agents for Open-Domain Procedure Customization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{lal-etal-2024-tailoring,\n    title = \"Tailoring with Targeted Precision: Edit-Based Agents for Open-Domain Procedure Customization\",\n    author = \"Lal, Yash Kumar  and\n      Zhang, Li  and\n      Brahman, Faeze  and\n      Majumder, Bodhisattwa Prasad  and\n      Clark, Peter  and\n      Tandon, Niket\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.921\",\n    doi = \"10.18653/v1/2024.findings-acl.921\",\n    pages = \"15597--15611\",\n    abstract = \"How-to procedures, such as how to plant a garden, are now used by millions of users, but sometimes need customizing to meet a user{'}s specific needs, e.g., planting a garden without pesticides. Our goal is to measure and improve an LLM{'}s ability to perform such customization. Our approach is to test several simple multi-LLM-agent architectures for customization, as well as an end-to-end LLM, using a new evaluation set, called CustomPlans, of over 200 WikiHow procedures each with a customization need. We find that a simple architecture with two LLM agents used sequentially performs best, one that edits a generic how-to procedure and one that verifies its executability, significantly outperforming (10.5{\\%} absolute) an end-to-end prompted LLM. This suggests that LLMs can be configured reasonably effectively for procedure customization. This also suggests that multi-agent editing architectures may be worth exploring further for other customization applications (e.g. coding, creative writing) in the future.\",\n}\n",
    "authors": [
        "Yash Kumar Lal",
        "Li Zhang",
        "Faeze Brahman",
        "Bodhisattwa Prasad Majumder",
        "Peter Clark",
        "Niket Tandon"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.921.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9cb847a5-f20b-5812-9fcf-40b7a1c87855.pdf",
    "abstract": "How-to procedures, such as how to plant a garden, are now used by millions of users, but sometimes need customizing to meet a user’s specific needs, e.g., planting a garden without pesticides. Our goal is to measure and improve an LLM’s ability to perform such customization. Our approach is to test several simple multi-LLM-agent architectures for customization, as well as an end-to-end LLM, using a new evaluation set, called CustomPlans, of over 200 WikiHow procedures each with a customization need. We find that a simple architecture with two LLM agents used sequentially performs best, one that edits a generic how-to procedure and one that verifies its executability, significantly outperforming (10.5% absolute) an end-to-end prompted LLM. This suggests that LLMs can be configured reasonably effectively for procedure customization. This also suggests that multi-agent editing architectures may be worth exploring further for other customization applications (e.g. coding, creative writing) in the future.",
    "num_pages": 15
}