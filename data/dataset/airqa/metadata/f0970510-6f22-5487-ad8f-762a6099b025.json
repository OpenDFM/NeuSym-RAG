{
    "uuid": "f0970510-6f22-5487-ad8f-762a6099b025",
    "title": "Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{song-etal-2024-revisiting,\n    title = \"Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance\",\n    author = \"Song, Yewei  and\n      Lothritz, Cedric  and\n      Tang, Xunzhu  and\n      Bissyand{\\'e}, Tegawend{\\'e}  and\n      Klein, Jacques\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-short.3\",\n    doi = \"10.18653/v1/2024.acl-short.3\",\n    pages = \"38--46\",\n    abstract = \"This paper revisits recent code similarity evaluation metrics, particularly focusing on the application of Abstract Syntax Tree (AST) editing distance in diverse programming languages. In particular, we explore the usefulness of these metrics and compare them to traditional sequence similarity metrics. Our experiments showcase the effectiveness of AST editing distance in capturing intricate code structures, revealing a high correlation with established metrics. Furthermore, we explore the strengths and weaknesses of AST editing distance and prompt-based GPT similarity scores in comparison to BLEU score, execution match, and Jaccard Similarity. We propose, optimize, and publish an adaptable metric that demonstrates effectiveness across all tested languages, representing an enhanced version of Tree Similarity of Edit Distance (TSED).\",\n}\n",
    "authors": [
        "Yewei Song",
        "Cedric Lothritz",
        "Xunzhu Tang",
        "Tegawendé Bissyandé",
        "Jacques Klein"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-short.3.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/f0970510-6f22-5487-ad8f-762a6099b025.pdf",
    "abstract": "This paper revisits recent code similarity evaluation metrics, particularly focusing on the application of Abstract Syntax Tree (AST) editing distance in diverse programming languages. In particular, we explore the usefulness of these metrics and compare them to traditional sequence similarity metrics. Our experiments showcase the effectiveness of AST editing distance in capturing intricate code structures, revealing a high correlation with established metrics. Furthermore, we explore the strengths and weaknesses of AST editing distance and prompt-based GPT similarity scores in comparison to BLEU score, execution match, and Jaccard Similarity. We propose, optimize, and publish an adaptable metric that demonstrates effectiveness across all tested languages, representing an enhanced version of Tree Similarity of Edit Distance (TSED).",
    "num_pages": 9
}