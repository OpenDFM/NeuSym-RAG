{
    "uuid": "b155ce80-2cd8-5f12-9892-c9c59e6da392",
    "title": "Direct Metric Optimization for Image Captioning through Reward-Weighted Augmented Data Utilization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{takada-etal-2024-direct,\n    title = \"Direct Metric Optimization for Image Captioning through Reward-Weighted Augmented Data Utilization\",\n    author = \"Takada, Takumi  and\n      Suzuki, Yuma  and\n      Takushima, Hiroki  and\n      Tanoue, Hayato  and\n      Sato, Haruki  and\n      Kumar, Aiswariya  and\n      Nishihara, Hiroki  and\n      Hori, Takayuki  and\n      Ueki, Kazuya\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.453\",\n    doi = \"10.18653/v1/2024.acl-long.453\",\n    pages = \"8333--8346\",\n    abstract = \"While image captioning is an essential field of vision language models (VLM), a lack of continuity between the learning objective and final performance metrics of VLMs complicates their training and optimization. Reinforcement learning (RL) can directly optimize such metrics, but it is accompanied by a significant computational cost, making it difficult to apply to recent large-scale VLMs. In this paper, we propose Direct Metric Optimization (DMO), which is a lightweight final-metric-optimizing training method. We replace the computationally expensive exploration process in RL with an offline, diverse text data augmentation and show that self-supervised training on reward-weighted augmented data leads to direct and stable metric optimization. Our experiments demonstrate that DMO achieves performance comparable to those of the state-of-the-art RL method while saving hundreds of times more model forwarding iterations and greater amounts of computation time. This suggests that DMO constitutes a promising alternative for metric optimization in the era of large-scale VLMs.\",\n}\n",
    "authors": [
        "Takumi Takada",
        "Yuma Suzuki",
        "Hiroki Takushima",
        "Hayato Tanoue",
        "Haruki Sato",
        "Aiswariya Kumar",
        "Hiroki Nishihara",
        "Takayuki Hori",
        "Kazuya Ueki"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.453.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b155ce80-2cd8-5f12-9892-c9c59e6da392.pdf",
    "abstract": "While image captioning is an essential field of vision language models (VLM), a lack of continuity between the learning objective and final performance metrics of VLMs complicates their training and optimization. Reinforcement learning (RL) can directly optimize such metrics, but it is accompanied by a significant computational cost, making it difficult to apply to recent large-scale VLMs. In this paper, we propose Direct Metric Optimization (DMO), which is a lightweight final-metric-optimizing training method. We replace the computationally expensive exploration process in RL with an offline, diverse text data augmentation and show that self-supervised training on reward-weighted augmented data leads to direct and stable metric optimization. Our experiments demonstrate that DMO achieves performance comparable to those of the state-of-the-art RL method while saving hundreds of times more model forwarding iterations and greater amounts of computation time. This suggests that DMO constitutes a promising alternative for metric optimization in the era of large-scale VLMs.",
    "num_pages": 14
}