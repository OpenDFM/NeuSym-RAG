{
    "uuid": "2c3b6bab-9511-5292-ac54-35ec57be6c5c",
    "title": "Ctyun AI at BioLaySumm: Enhancing Lay Summaries of Biomedical Articles Through Large Language Models and Data Augmentation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{bao-etal-2024-ctyun,\n    title = \"Ctyun {AI} at {B}io{L}ay{S}umm: Enhancing Lay Summaries of Biomedical Articles Through Large Language Models and Data Augmentation\",\n    author = \"Bao, Siyu  and\n      Zhao, Ruijing  and\n      Zhang, Siqin  and\n      Zhang, Jinghui  and\n      Wang, Weiyin  and\n      Ru, Yunian\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.79\",\n    doi = \"10.18653/v1/2024.bionlp-1.79\",\n    pages = \"837--844\",\n    abstract = \"Lay summaries play a crucial role in making scientific research accessible to a wider audience. However, generating lay summaries from lengthy articles poses significant challenges. We consider two approaches to address this issue: Hard Truncation, which preserves the most informative initial portion of the article, and Text Chunking, which segments articles into smaller, manageable chunks. Our workflow encompasses data preprocessing, augmentation, prompt engineering, and fine-tuning large language models. We explore the influence of pretrained model selection, inference prompt design, and hyperparameter tuning on summarization performance. Our methods demonstrate effectiveness in generating high-quality, informative lay summaries, achieving the second-best performance in the BioLaySumm shared task at BioNLP 2024.\",\n}\n",
    "authors": [
        "Siyu Bao",
        "Ruijing Zhao",
        "Siqin Zhang",
        "Jinghui Zhang",
        "Weiyin Wang",
        "Yunian Ru"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.79.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/2c3b6bab-9511-5292-ac54-35ec57be6c5c.pdf",
    "abstract": "Lay summaries play a crucial role in making scientific research accessible to a wider audience. However, generating lay summaries from lengthy articles poses significant challenges. We consider two approaches to address this issue: Hard Truncation, which preserves the most informative initial portion of the article, and Text Chunking, which segments articles into smaller, manageable chunks. Our workflow encompasses data preprocessing, augmentation, prompt engineering, and fine-tuning large language models. We explore the influence of pretrained model selection, inference prompt design, and hyperparameter tuning on summarization performance. Our methods demonstrate effectiveness in generating high-quality, informative lay summaries, achieving the second-best performance in the BioLaySumm shared task at BioNLP 2024.",
    "num_pages": 8
}