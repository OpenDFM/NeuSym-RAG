{
    "uuid": "8a7e2e59-1c78-5cbd-a60e-2b0b34ab55b9",
    "title": "Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{wei-etal-2024-unveiling,\n    title = \"Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models\",\n    author = \"Wei, Sheng-Lun  and\n      Wu, Cheng-Kuang  and\n      Huang, Hen-Hsen  and\n      Chen, Hsin-Hsi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.333\",\n    doi = \"10.18653/v1/2024.findings-acl.333\",\n    pages = \"5598--5621\",\n    abstract = \"In this paper, we investigate the phenomena of {``}selection biases{''} in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option order and token usage, which significantly impact LLMs{'} decision-making processes. We also quantify the impact of these biases through an extensive empirical analysis across multiple models and tasks. Furthermore, we propose mitigation strategies to enhance model performance. Our key contributions are threefold: 1) Precisely quantifying the influence of option order and token on LLMs, 2) Developing strategies to mitigate the impact of token and order sensitivity to enhance robustness, and 3) Offering a detailed analysis of sensitivity across models and tasks, which informs the creation of more stable and reliable LLM applications for selection problems.\",\n}\n",
    "authors": [
        "Sheng-Lun Wei",
        "Cheng-Kuang Wu",
        "Hen-Hsen Huang",
        "Hsin-Hsi Chen"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.333.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8a7e2e59-1c78-5cbd-a60e-2b0b34ab55b9.pdf",
    "abstract": "In this paper, we investigate the phenomena of “selection biases” in Large Language Models (LLMs), focusing on problems where models are tasked with choosing the optimal option from an ordered sequence. We delve into biases related to option order and token usage, which significantly impact LLMs’ decision-making processes. We also quantify the impact of these biases through an extensive empirical analysis across multiple models and tasks. Furthermore, we propose mitigation strategies to enhance model performance. Our key contributions are threefold: 1) Precisely quantifying the influence of option order and token on LLMs, 2) Developing strategies to mitigate the impact of token and order sensitivity to enhance robustness, and 3) Offering a detailed analysis of sensitivity across models and tasks, which informs the creation of more stable and reliable LLM applications for selection problems.",
    "num_pages": 24
}