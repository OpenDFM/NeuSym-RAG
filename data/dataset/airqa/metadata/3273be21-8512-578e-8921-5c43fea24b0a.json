{
    "uuid": "3273be21-8512-578e-8921-5c43fea24b0a",
    "title": "PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{xu-etal-2024-pathreasoner,\n    title = \"{P}ath{R}easoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering\",\n    author = \"Xu, Fangzhi  and\n      Lin, Qika  and\n      Zhao, Tianzhe  and\n      JiaweiHan, JiaweiHan  and\n      Liu, Jun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.724\",\n    doi = \"10.18653/v1/2024.acl-long.724\",\n    pages = \"13413--13429\",\n    abstract = \"Logical reasoning task has attracted great interest since it was proposed. Faced with such a task, current competitive models, even large language models (e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs struggle in logical consistency modeling and logical structure perception. To this end, we model the logical reasoning task by transforming each logical sample into reasoning paths and propose an architecture PathReasoner. It addresses the task from the views of both data and model. To expand the diversity of the logical samples, we propose an atom extension strategy supported by equivalent logical formulas, to form new reasoning paths. From the model perspective, we design a stack of transformer-style blocks. In particular, we propose a path-attention module to joint model in-atom and cross-atom relations with the high-order diffusion strategy. Experiments show that PathReasoner achieves competitive performances on two logical reasoning benchmarks and great generalization abilities.\",\n}\n",
    "authors": [
        "Fangzhi Xu",
        "Qika Lin",
        "Tianzhe Zhao",
        "JiaweiHan JiaweiHan",
        "Jun Liu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.724.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3273be21-8512-578e-8921-5c43fea24b0a.pdf",
    "abstract": "Logical reasoning task has attracted great interest since it was proposed. Faced with such a task, current competitive models, even large language models (e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs struggle in logical consistency modeling and logical structure perception. To this end, we model the logical reasoning task by transforming each logical sample into reasoning paths and propose an architecture PathReasoner. It addresses the task from the views of both data and model. To expand the diversity of the logical samples, we propose an atom extension strategy supported by equivalent logical formulas, to form new reasoning paths. From the model perspective, we design a stack of transformer-style blocks. In particular, we propose a path-attention module to joint model in-atom and cross-atom relations with the high-order diffusion strategy. Experiments show that PathReasoner achieves competitive performances on two logical reasoning benchmarks and great generalization abilities.",
    "num_pages": 17
}