{
    "uuid": "ee86cf08-48e7-5c46-a591-bc7a23977dc6",
    "title": "Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{li-etal-2023-shot-data,\n    title = \"Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning\",\n    author = \"Li, Alexander Hanbo  and\n      Shang, Mingyue  and\n      Spiliopoulou, Evangelia  and\n      Ma, Jie  and\n      Ng, Patrick  and\n      Wang, Zhiguo  and\n      Min, Bonan  and\n      Wang, William Yang  and\n      McKeown, Kathleen  and\n      Castelli, Vittorio  and\n      Roth, Dan  and\n      Xiang, Bing\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.894\",\n    doi = \"10.18653/v1/2023.acl-long.894\",\n    pages = \"16171--16189\",\n    abstract = \"In this paper, we present a novel approach for data-to-text generation that addresses the limitations of current methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multi-task training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66{\\%} improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework.\",\n}\n",
    "authors": [
        "Alexander Hanbo Li",
        "Mingyue Shang",
        "Evangelia Spiliopoulou",
        "Jie Ma",
        "Patrick Ng",
        "Zhiguo Wang",
        "Bonan Min",
        "William Yang Wang",
        "Kathleen McKeown",
        "Vittorio Castelli",
        "Dan Roth",
        "Bing Xiang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.894.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ee86cf08-48e7-5c46-a591-bc7a23977dc6.pdf",
    "abstract": "In this paper, we present a novel approach for data-to-text generation that addresses the limitations of current methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multi-task training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66% improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework.",
    "num_pages": 19
}