{
    "uuid": "92f5e846-cfbf-53ee-addd-25b3763055a2",
    "title": "DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 3rd Workshop on Knowledge Augmented Methods for NLP",
    "bibtex": "@inproceedings{hwang-etal-2024-dslr,\n    title = \"{DSLR}: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation\",\n    author = \"Hwang, Taeho  and\n      Jeong, Soyeong  and\n      Cho, Sukmin  and\n      Han, SeungYoon  and\n      Park, Jong\",\n    editor = \"Yu, Wenhao  and\n      Shi, Weijia  and\n      Yasunaga, Michihiro  and\n      Jiang, Meng  and\n      Zhu, Chenguang  and\n      Hajishirzi, Hannaneh  and\n      Zettlemoyer, Luke  and\n      Zhang, Zhihan\",\n    booktitle = \"Proceedings of the 3rd Workshop on Knowledge Augmented Methods for NLP\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.knowledgenlp-1.6\",\n    doi = \"10.18653/v1/2024.knowledgenlp-1.6\",\n    pages = \"73--92\",\n    abstract = \"Recent advancements in Large Language Models (LLMs) have significantly improved their performance across various Natural Language Processing (NLP) tasks.However, LLMs still struggle with generating non-factual responses due to limitations in their parametric memory.Retrieval-Augmented Generation (RAG) systems address this issue by incorporating external knowledge with a retrieval module.Despite their successes, however, current RAG systems face challenges with retrieval failures and the limited ability of LLMs to filter out irrelevant information.Therefore, in this work, we propose \\textit{ \\textbf{DSLR}} (\\textbf{D}ocument Refinement with \\textbf{S}entence-\\textbf{L}evel \\textbf{R}e-ranking and Reconstruction), an unsupervised framework that decomposes retrieved documents into sentences, filters out irrelevant sentences, and reconstructs them again into coherent passages.We experimentally validate \\textit{DSLR} on multiple open-domain QA datasets and the results demonstrate that \\textit{DSLR} significantly enhances the RAG performance over conventional fixed-size passage.Furthermore, our \\textit{DSLR} enhances performance in specific, yet realistic scenarios without the need for additional training, providing an effective and efficient solution for refining retrieved documents in RAG systems.\",\n}\n",
    "authors": [
        "Taeho Hwang",
        "Soyeong Jeong",
        "Sukmin Cho",
        "SeungYoon Han",
        "Jong Park"
    ],
    "pdf_url": "https://aclanthology.org/2024.knowledgenlp-1.6.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/92f5e846-cfbf-53ee-addd-25b3763055a2.pdf",
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly improved their performance across various Natural Language Processing (NLP) tasks.However, LLMs still struggle with generating non-factual responses due to limitations in their parametric memory.Retrieval-Augmented Generation (RAG) systems address this issue by incorporating external knowledge with a retrieval module.Despite their successes, however, current RAG systems face challenges with retrieval failures and the limited ability of LLMs to filter out irrelevant information.Therefore, in this work, we propose DSLR (Document Refinement with Sentence-Level Re-ranking and Reconstruction), an unsupervised framework that decomposes retrieved documents into sentences, filters out irrelevant sentences, and reconstructs them again into coherent passages.We experimentally validate DSLR on multiple open-domain QA datasets and the results demonstrate that DSLR significantly enhances the RAG performance over conventional fixed-size passage.Furthermore, our DSLR enhances performance in specific, yet realistic scenarios without the need for additional training, providing an effective and efficient solution for refining retrieved documents in RAG systems.",
    "num_pages": 20
}