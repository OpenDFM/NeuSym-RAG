{
    "uuid": "2b767776-e1be-5c2b-af10-cfec9564dc62",
    "title": "SBAAM! Eliminating Transcript Dependency in Automatic Subtitling",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{gaido-etal-2024-sbaam,\n    title = \"{SBAAM}! Eliminating Transcript Dependency in Automatic Subtitling\",\n    author = \"Gaido, Marco  and\n      Papi, Sara  and\n      Negri, Matteo  and\n      Cettolo, Mauro  and\n      Bentivogli, Luisa\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.201\",\n    doi = \"10.18653/v1/2024.acl-long.201\",\n    pages = \"3673--3691\",\n    abstract = \"Subtitling plays a crucial role in enhancing the accessibility of audiovisual content and encompasses three primary subtasks: translating spoken dialogue, segmenting translations into concise textual units, and estimating timestamps that govern their on-screen duration. Past attempts to automate this process rely, to varying degrees, on automatic transcripts, employed diversely for the three subtasks. In response to the acknowledged limitations associated with this reliance on transcripts, recent research has shifted towards transcription-free solutions for translation and segmentation, leaving the direct generation of timestamps as uncharted territory. To fill this gap, we introduce the first direct model capable of producing automatic subtitles, entirely eliminating any dependence on intermediate transcripts also for timestamp prediction. Experimental results, backed by manual evaluation, showcase our solution{'}s new state-of-the-art performance across multiple language pairs and diverse conditions.\",\n}\n",
    "authors": [
        "Marco Gaido",
        "Sara Papi",
        "Matteo Negri",
        "Mauro Cettolo",
        "Luisa Bentivogli"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.201.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/2b767776-e1be-5c2b-af10-cfec9564dc62.pdf",
    "abstract": "Subtitling plays a crucial role in enhancing the accessibility of audiovisual content and encompasses three primary subtasks: translating spoken dialogue, segmenting translations into concise textual units, and estimating timestamps that govern their on-screen duration. Past attempts to automate this process rely, to varying degrees, on automatic transcripts, employed diversely for the three subtasks. In response to the acknowledged limitations associated with this reliance on transcripts, recent research has shifted towards transcription-free solutions for translation and segmentation, leaving the direct generation of timestamps as uncharted territory. To fill this gap, we introduce the first direct model capable of producing automatic subtitles, entirely eliminating any dependence on intermediate transcripts also for timestamp prediction. Experimental results, backed by manual evaluation, showcase our solutionâ€™s new state-of-the-art performance across multiple language pairs and diverse conditions.",
    "num_pages": 19
}