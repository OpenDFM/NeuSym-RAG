{
    "uuid": "a21ceae1-4c66-5400-b0e0-383bda11d0d6",
    "title": "Biasly: An Expert-Annotated Dataset for Subtle Misogyny Detection and Mitigation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{sheppard-etal-2024-biasly,\n    title = \"Biasly: An Expert-Annotated Dataset for Subtle Misogyny Detection and Mitigation\",\n    author = \"Sheppard, Brooklyn  and\n      Richter, Anna  and\n      Cohen, Allison  and\n      Smith, Elizabeth  and\n      Kneese, Tamara  and\n      Pelletier, Carolyne  and\n      Baldini, Ioana  and\n      Dong, Yue\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.24\",\n    doi = \"10.18653/v1/2024.findings-acl.24\",\n    pages = \"427--452\",\n    abstract = \"Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles, capturing colloquial expressions of misogyny in North American film. The open-source dataset can be used for a range of NLP tasks, including binary and multi-label classification, severity score regression, and text generation for rewrites. In this paper, we discuss the methodology used, analyze the annotations obtained, provide baselines for each task using common NLP algorithms, and furnish error analyses to give insight into model behaviour when fine-tuned on the Biasly dataset.\",\n}\n",
    "authors": [
        "Brooklyn Sheppard",
        "Anna Richter",
        "Allison Cohen",
        "Elizabeth Smith",
        "Tamara Kneese",
        "Carolyne Pelletier",
        "Ioana Baldini",
        "Yue Dong"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.24.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a21ceae1-4c66-5400-b0e0-383bda11d0d6.pdf",
    "abstract": "Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles, capturing colloquial expressions of misogyny in North American film. The open-source dataset can be used for a range of NLP tasks, including binary and multi-label classification, severity score regression, and text generation for rewrites. In this paper, we discuss the methodology used, analyze the annotations obtained, provide baselines for each task using common NLP algorithms, and furnish error analyses to give insight into model behaviour when fine-tuned on the Biasly dataset.",
    "num_pages": 26
}