{
    "uuid": "e66567ac-6b48-5983-a87d-5bab697e738c",
    "title": "Sam Miller at SemEval-2023 Task 5: Classification and Type-specific Spoiler Extraction Using XLNET and Other Transformer Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{stormer-etal-2023-sam,\n    title = \"{S}am Miller at {S}em{E}val-2023 Task 5: Classification and Type-specific Spoiler Extraction Using {XLNET} and Other Transformer Models\",\n    author = {St{\\\"o}rmer, Pia  and\n      Esser, Tobias  and\n      Thomasius, Patrick},\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.169\",\n    doi = \"10.18653/v1/2023.semeval-1.169\",\n    pages = \"1217--1224\",\n    abstract = \"This paper proposes an approach to classify andan approach to generate spoilers for clickbaitarticles and posts. For the spoiler classification,XLNET was trained to fine-tune a model. Withan accuracy of 0.66, 2 out of 3 spoilers arepredicted accurately. The spoiler generationapproach involves preprocessing the clickbaittext and post-processing the output to fit thespoiler type. The approach is evaluated on atest dataset of 1000 posts, with the best resultfor spoiler generation achieved by fine-tuninga RoBERTa Large model with a small learningrate and sample size, reaching a BLEU scoreof 0.311. The paper provides an overview ofthe models and techniques used and discussesthe experimental setup.\",\n}\n",
    "authors": [
        "Pia St√∂rmer",
        "Tobias Esser",
        "Patrick Thomasius"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.169.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e66567ac-6b48-5983-a87d-5bab697e738c.pdf",
    "abstract": "This paper proposes an approach to classify andan approach to generate spoilers for clickbaitarticles and posts. For the spoiler classification,XLNET was trained to fine-tune a model. Withan accuracy of 0.66, 2 out of 3 spoilers arepredicted accurately. The spoiler generationapproach involves preprocessing the clickbaittext and post-processing the output to fit thespoiler type. The approach is evaluated on atest dataset of 1000 posts, with the best resultfor spoiler generation achieved by fine-tuninga RoBERTa Large model with a small learningrate and sample size, reaching a BLEU scoreof 0.311. The paper provides an overview ofthe models and techniques used and discussesthe experimental setup.",
    "num_pages": 8
}