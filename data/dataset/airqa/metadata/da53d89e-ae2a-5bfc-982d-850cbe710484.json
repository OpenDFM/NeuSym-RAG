{
    "uuid": "da53d89e-ae2a-5bfc-982d-850cbe710484",
    "title": "Coarse-to-fine Few-shot Learning for Named Entity Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{ma-etal-2023-coarse,\n    title = \"Coarse-to-fine Few-shot Learning for Named Entity Recognition\",\n    author = \"Ma, Ruotian  and\n      Lin, Zhang  and\n      Chen, Xuanting  and\n      Zhou, Xin  and\n      Wang, Junzhe  and\n      Gui, Tao  and\n      Zhang, Qi  and\n      Gao, Xiang  and\n      Chen, Yun Wen\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.253\",\n    doi = \"10.18653/v1/2023.findings-acl.253\",\n    pages = \"4115--4129\",\n    abstract = \"Recently, Few-shot Named Entity Recognition has received wide attention with the growing need for NER models to learn new classes with minimized annotation costs. However, one common yet understudied situation is to transfer a model trained with coarse-grained classes to recognize fine-grained classes, such as separating a product category into sub-classes. We find that existing few-shot NER solutions are not suitable for such a situation since they do not consider the sub-class discrimination during coarse training and various granularity of new classes during few-shot learning. In this work, we introduce the Coarse-to-fine Few-shot NER (C2FNER) task and propose an effective solution. Specifically, during coarse training, we propose a cluster-based prototype margin loss to learn group-wise discriminative representations, so as to benefit fine-grained learning. Targeting various granularity of new classes, we separate the coarse classes into extra-fine clusters and propose a novel prototype retrieval and bootstrapping algorithm to retrieve representative clusters for each fine class. We then adopt a mixture prototype loss to efficiently learn the representations of fine classes. We conduct experiments on both in-domain and cross-domain C2FNER settings with various target granularity, and the proposed method shows superior performance over the baseline methods.\",\n}\n",
    "authors": [
        "Ruotian Ma",
        "Zhang Lin",
        "Xuanting Chen",
        "Xin Zhou",
        "Junzhe Wang",
        "Tao Gui",
        "Qi Zhang",
        "Xiang Gao",
        "Yun Wen Chen"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.253.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/da53d89e-ae2a-5bfc-982d-850cbe710484.pdf",
    "abstract": "Recently, Few-shot Named Entity Recognition has received wide attention with the growing need for NER models to learn new classes with minimized annotation costs. However, one common yet understudied situation is to transfer a model trained with coarse-grained classes to recognize fine-grained classes, such as separating a product category into sub-classes. We find that existing few-shot NER solutions are not suitable for such a situation since they do not consider the sub-class discrimination during coarse training and various granularity of new classes during few-shot learning. In this work, we introduce the Coarse-to-fine Few-shot NER (C2FNER) task and propose an effective solution. Specifically, during coarse training, we propose a cluster-based prototype margin loss to learn group-wise discriminative representations, so as to benefit fine-grained learning. Targeting various granularity of new classes, we separate the coarse classes into extra-fine clusters and propose a novel prototype retrieval and bootstrapping algorithm to retrieve representative clusters for each fine class. We then adopt a mixture prototype loss to efficiently learn the representations of fine classes. We conduct experiments on both in-domain and cross-domain C2FNER settings with various target granularity, and the proposed method shows superior performance over the baseline methods.",
    "num_pages": 15
}