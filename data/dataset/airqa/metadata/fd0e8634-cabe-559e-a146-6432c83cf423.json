{
    "uuid": "fd0e8634-cabe-559e-a146-6432c83cf423",
    "title": "Early Exit with Disentangled Representation and Equiangular Tight Frame",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{ji-etal-2023-early,\n    title = \"Early Exit with Disentangled Representation and Equiangular Tight Frame\",\n    author = \"Ji, Yixin  and\n      Wang, Jikai  and\n      Li, Juntao  and\n      Chen, Qiang  and\n      Chen, Wenliang  and\n      Zhang, Min\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.889\",\n    doi = \"10.18653/v1/2023.findings-acl.889\",\n    pages = \"14128--14142\",\n    abstract = \"Dynamic early exit has demonstrated great potential in coping with the sharply increasing number of pre-trained language model parameters, which can achieve a good trade-off between performance and efficiency. The existing early exit paradigm relies on training parametrical internal classifiers at each intermediate layer to complete specific tasks. Based on the predictions of these internal classifiers, different methods are designed to decide when to exit. Under this circumstance, each intermediate layer takes on both generic language representation learning and task-specific feature extraction, which makes each intermediate layer struggle to balance two types of backward loss signals during training. To break this dilemma, we propose an adapter method to decouple the two distinct types of representation and further introduce a non-parametric simplex equiangular tight frame classifier (ETF) for improvement. Extensive experiments on monolingual and multilingual tasks demonstrate that our method gains significant improvements over strong PLM backbones and early exit methods.\",\n}\n",
    "authors": [
        "Yixin Ji",
        "Jikai Wang",
        "Juntao Li",
        "Qiang Chen",
        "Wenliang Chen",
        "Min Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.889.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/fd0e8634-cabe-559e-a146-6432c83cf423.pdf",
    "abstract": "Dynamic early exit has demonstrated great potential in coping with the sharply increasing number of pre-trained language model parameters, which can achieve a good trade-off between performance and efficiency. The existing early exit paradigm relies on training parametrical internal classifiers at each intermediate layer to complete specific tasks. Based on the predictions of these internal classifiers, different methods are designed to decide when to exit. Under this circumstance, each intermediate layer takes on both generic language representation learning and task-specific feature extraction, which makes each intermediate layer struggle to balance two types of backward loss signals during training. To break this dilemma, we propose an adapter method to decouple the two distinct types of representation and further introduce a non-parametric simplex equiangular tight frame classifier (ETF) for improvement. Extensive experiments on monolingual and multilingual tasks demonstrate that our method gains significant improvements over strong PLM backbones and early exit methods.",
    "num_pages": 15
}