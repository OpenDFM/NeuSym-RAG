{
    "uuid": "21be2c54-3e56-5aea-a3be-5beff38fde34",
    "title": "Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
    "bibtex": "@inproceedings{baffour-etal-2023-analyzing,\n    title = \"Analyzing Bias in Large Language Model Solutions for Assisted Writing Feedback Tools: Lessons from the Feedback Prize Competition Series\",\n    author = \"Baffour, Perpetual  and\n      Saxberg, Tor  and\n      Crossley, Scott\",\n    editor = {Kochmar, Ekaterina  and\n      Burstein, Jill  and\n      Horbach, Andrea  and\n      Laarmann-Quante, Ronja  and\n      Madnani, Nitin  and\n      Tack, Ana{\\\"\\i}s  and\n      Yaneva, Victoria  and\n      Yuan, Zheng  and\n      Zesch, Torsten},\n    booktitle = \"Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bea-1.21\",\n    doi = \"10.18653/v1/2023.bea-1.21\",\n    pages = \"242--246\",\n    abstract = \"This paper analyzes winning solutions from the Feedback Prize competition series hosted from 2021-2022. The competition sought to improve Assisted Writing Feedback Tools (AWFTs) by crowdsourcing Large Language Model (LLM) solutions for evaluating student writing. The winning models are freely available for incorporation into educational applications, but the models need to be assessed for performance and other factors. This study reports the performance accuracy of Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status. Two competitions are analyzed. The first, which focused on identifying discourse elements, demonstrated minimal bias based on students{'} demographic factors. However, the second competition, which aimed to predict discourse effectiveness, exhibited moderate bias.\",\n}\n",
    "authors": [
        "Perpetual Baffour",
        "Tor Saxberg",
        "Scott Crossley"
    ],
    "pdf_url": "https://aclanthology.org/2023.bea-1.21.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/21be2c54-3e56-5aea-a3be-5beff38fde34.pdf",
    "abstract": "This paper analyzes winning solutions from the Feedback Prize competition series hosted from 2021-2022. The competition sought to improve Assisted Writing Feedback Tools (AWFTs) by crowdsourcing Large Language Model (LLM) solutions for evaluating student writing. The winning models are freely available for incorporation into educational applications, but the models need to be assessed for performance and other factors. This study reports the performance accuracy of Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status. Two competitions are analyzed. The first, which focused on identifying discourse elements, demonstrated minimal bias based on studentsâ€™ demographic factors. However, the second competition, which aimed to predict discourse effectiveness, exhibited moderate bias.",
    "num_pages": 5
}