{
    "uuid": "29f509d4-f011-5e4f-8e6e-c0434b792e8c",
    "title": "PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{dong-etal-2023-promptattack,\n    title = \"{P}rompt{A}ttack: Probing Dialogue State Trackers with Adversarial Prompts\",\n    author = \"Dong, Xiangjue  and\n      He, Yun  and\n      Zhu, Ziwei  and\n      Caverlee, James\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.677\",\n    doi = \"10.18653/v1/2023.findings-acl.677\",\n    pages = \"10651--10666\",\n    abstract = \"A key component of modern conversational systems is the Dialogue State Tracker (or DST), which models a user{'}s goals and needs. Toward building more robust and reliable DSTs, we introduce a prompt-based learning approach to automatically generate effective adversarial examples to probe DST models. Two key characteristics of this approach are: (i) it only needs the output of the DST with no need for model parameters, and (ii) it can learn to generate natural language utterances that can target any DST. Through experiments over state-of-the-art DSTs, the proposed framework leads to the greatest reduction in accuracy and the best attack success rate while maintaining good fluency and a low perturbation ratio. We also show how much the generated adversarial examples can bolster a DST through adversarial training. These results indicate the strength of prompt-based attacks on DSTs and leave open avenues for continued refinement.\",\n}\n",
    "authors": [
        "Xiangjue Dong",
        "Yun He",
        "Ziwei Zhu",
        "James Caverlee"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.677.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/29f509d4-f011-5e4f-8e6e-c0434b792e8c.pdf",
    "abstract": "A key component of modern conversational systems is the Dialogue State Tracker (or DST), which models a userâ€™s goals and needs. Toward building more robust and reliable DSTs, we introduce a prompt-based learning approach to automatically generate effective adversarial examples to probe DST models. Two key characteristics of this approach are: (i) it only needs the output of the DST with no need for model parameters, and (ii) it can learn to generate natural language utterances that can target any DST. Through experiments over state-of-the-art DSTs, the proposed framework leads to the greatest reduction in accuracy and the best attack success rate while maintaining good fluency and a low perturbation ratio. We also show how much the generated adversarial examples can bolster a DST through adversarial training. These results indicate the strength of prompt-based attacks on DSTs and leave open avenues for continued refinement.",
    "num_pages": 16
}