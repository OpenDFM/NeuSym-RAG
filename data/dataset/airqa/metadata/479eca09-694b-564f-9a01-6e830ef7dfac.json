{
    "uuid": "479eca09-694b-564f-9a01-6e830ef7dfac",
    "title": "Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 1st Human-Centered Large Language Modeling Workshop",
    "bibtex": "@inproceedings{chingacham-etal-2024-human,\n    title = \"Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?\",\n    author = \"Chingacham, Anupama  and\n      Zhang, Miaoran  and\n      Demberg, Vera  and\n      Klakow, Dietrich\",\n    editor = \"Soni, Nikita  and\n      Flek, Lucie  and\n      Sharma, Ashish  and\n      Yang, Diyi  and\n      Hooker, Sara  and\n      Schwartz, H. Andrew\",\n    booktitle = \"Proceedings of the 1st Human-Centered Large Language Modeling Workshop\",\n    month = aug,\n    year = \"2024\",\n    address = \"TBD\",\n    publisher = \"ACL\",\n    url = \"https://aclanthology.org/2024.hucllm-1.1\",\n    doi = \"10.18653/v1/2024.hucllm-1.1\",\n    pages = \"1--15\",\n    abstract = \"Large Language Models (LLMs) can generate text by transferring style attributes like formality resulting in formal or informal text.However, instructing LLMs to generate text that when spoken, is more intelligible in an acoustically difficult environment, is an under-explored topic.We conduct the first study to evaluate LLMs on a novel task of generating acoustically intelligible paraphrases for better human speech perception in noise.Our experiments in English demonstrated that with standard prompting, LLMs struggle to control the non-textual attribute, i.e., acoustic intelligibility, while efficiently capturing the desired textual attributes like semantic equivalence. To remedy this issue, we propose a simple prompting approach, prompt-and-select, which generates paraphrases by decoupling the desired textual and non-textual attributes in the text generation pipeline.Our approach resulted in a 40{\\%} relative improvement in human speech perception, by paraphrasing utterances that are highly distorted in a listening condition with babble noise at signal-to-noise ratio (SNR) -5 dB. This study reveals the limitation of LLMs in capturing non-textual attributes, and our proposed method showcases the potential of using LLMs for better human speech perception in noise.\",\n}\n",
    "authors": [
        "Anupama Chingacham",
        "Miaoran Zhang",
        "Vera Demberg",
        "Dietrich Klakow"
    ],
    "pdf_url": "https://aclanthology.org/2024.hucllm-1.1.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/479eca09-694b-564f-9a01-6e830ef7dfac.pdf",
    "abstract": "Large Language Models (LLMs) can generate text by transferring style attributes like formality resulting in formal or informal text.However, instructing LLMs to generate text that when spoken, is more intelligible in an acoustically difficult environment, is an under-explored topic.We conduct the first study to evaluate LLMs on a novel task of generating acoustically intelligible paraphrases for better human speech perception in noise.Our experiments in English demonstrated that with standard prompting, LLMs struggle to control the non-textual attribute, i.e., acoustic intelligibility, while efficiently capturing the desired textual attributes like semantic equivalence. To remedy this issue, we propose a simple prompting approach, prompt-and-select, which generates paraphrases by decoupling the desired textual and non-textual attributes in the text generation pipeline.Our approach resulted in a 40% relative improvement in human speech perception, by paraphrasing utterances that are highly distorted in a listening condition with babble noise at signal-to-noise ratio (SNR) -5 dB. This study reveals the limitation of LLMs in capturing non-textual attributes, and our proposed method showcases the potential of using LLMs for better human speech perception in noise.",
    "num_pages": 15
}