{
    "uuid": "4d339d9b-3cbf-5a74-9df2-3eb1426b3fdc",
    "title": "Unveiling the Spectrum of Data Contamination in Language Model: A Survey from Detection to Remediation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{deng-etal-2024-unveiling,\n    title = \"Unveiling the Spectrum of Data Contamination in Language Model: A Survey from Detection to Remediation\",\n    author = \"Deng, Chunyuan  and\n      Zhao, Yilun  and\n      Heng, Yuzhao  and\n      Li, Yitong  and\n      Cao, Jiannan  and\n      Tang, Xiangru  and\n      Cohan, Arman\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.951\",\n    doi = \"10.18653/v1/2024.findings-acl.951\",\n    pages = \"16078--16092\",\n    abstract = \"Data contamination has garnered increased attention in the era of Large language models (LLMs) due to the reliance on extensive internet-derived training corpora. The issue of training corpus overlap with evaluation benchmarks{---}referred to as contamination{---}has been the focus of significant recent research. This body of work aims to identify contamination, understand its impacts, and explore mitigation strategies from diverse perspectives. However, comprehensive studies that provide a clear pathway from foundational concepts to advanced insights are lacking in this nascent field. Therefore, we present the first survey in the field of data contamination. We begin by examining the effects of data contamination across various stages and forms. We then provide a detailed analysis of current contamination detection methods, categorizing them to highlight their focus, assumptions, strengths, and limitations. We also discuss mitigation strategies, offering a clear guide for future research. This survey serves as a succinct overview of the most recent advancements in data contamination research, providing a straightforward guide for the benefit of future research endeavors.\",\n}\n",
    "authors": [
        "Chunyuan Deng",
        "Yilun Zhao",
        "Yuzhao Heng",
        "Yitong Li",
        "Jiannan Cao",
        "Xiangru Tang",
        "Arman Cohan"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.951.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4d339d9b-3cbf-5a74-9df2-3eb1426b3fdc.pdf",
    "abstract": "Data contamination has garnered increased attention in the era of Large language models (LLMs) due to the reliance on extensive internet-derived training corpora. The issue of training corpus overlap with evaluation benchmarks—referred to as contamination—has been the focus of significant recent research. This body of work aims to identify contamination, understand its impacts, and explore mitigation strategies from diverse perspectives. However, comprehensive studies that provide a clear pathway from foundational concepts to advanced insights are lacking in this nascent field. Therefore, we present the first survey in the field of data contamination. We begin by examining the effects of data contamination across various stages and forms. We then provide a detailed analysis of current contamination detection methods, categorizing them to highlight their focus, assumptions, strengths, and limitations. We also discuss mitigation strategies, offering a clear guide for future research. This survey serves as a succinct overview of the most recent advancements in data contamination research, providing a straightforward guide for the benefit of future research endeavors.",
    "num_pages": 15
}