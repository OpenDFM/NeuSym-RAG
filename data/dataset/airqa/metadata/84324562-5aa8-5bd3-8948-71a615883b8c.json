{
    "uuid": "84324562-5aa8-5bd3-8948-71a615883b8c",
    "title": "Stanford MLab at SemEval-2023 Task 10: Exploring GloVe- and Transformer-Based Methods for the Explainable Detection of Online Sexism",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{wan-etal-2023-stanford,\n    title = \"{S}tanford {ML}ab at {S}em{E}val-2023 Task 10: Exploring {G}lo{V}e- and Transformer-Based Methods for the Explainable Detection of Online Sexism\",\n    author = \"Wan, Aaron  and\n      Yam, Hong Meng  and\n      Yogeswaran, Swetha  and\n      Zhou, Beining  and\n      Choi, Hee Jung  and\n      Chow, Trevor\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.248\",\n    doi = \"10.18653/v1/2023.semeval-1.248\",\n    pages = \"1791--1797\",\n    abstract = \"In this paper, we discuss the methods we applied at SemEval-2023 Task 10: Towards the Explainable Detection of Online Sexism. Given an input text, we perform three classification tasks to predict whether the text is sexist and classify the sexist text into subcategories in order to provide an additional explanation as to why the text is sexist. We explored many different types of models, including GloVe embeddings as the baseline approach, transformer-based deep learning models like BERT, RoBERTa, and DeBERTa, ensemble models, and model blending. We explored various data cleaning and augmentation methods to improve model performance. Pre-training transformer models yielded significant improvements in performance, and ensembles and blending slightly improved robustness in the F1 score.\",\n}\n",
    "authors": [
        "Aaron Wan",
        "Hong Meng Yam",
        "Swetha Yogeswaran",
        "Beining Zhou",
        "Hee Jung Choi",
        "Trevor Chow"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.248.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/84324562-5aa8-5bd3-8948-71a615883b8c.pdf",
    "abstract": "In this paper, we discuss the methods we applied at SemEval-2023 Task 10: Towards the Explainable Detection of Online Sexism. Given an input text, we perform three classification tasks to predict whether the text is sexist and classify the sexist text into subcategories in order to provide an additional explanation as to why the text is sexist. We explored many different types of models, including GloVe embeddings as the baseline approach, transformer-based deep learning models like BERT, RoBERTa, and DeBERTa, ensemble models, and model blending. We explored various data cleaning and augmentation methods to improve model performance. Pre-training transformer models yielded significant improvements in performance, and ensembles and blending slightly improved robustness in the F1 score.",
    "num_pages": 7
}