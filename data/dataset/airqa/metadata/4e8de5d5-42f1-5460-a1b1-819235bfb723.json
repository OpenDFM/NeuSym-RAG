{
    "uuid": "4e8de5d5-42f1-5460-a1b1-819235bfb723",
    "title": "Towards Reasoning in Large Language Models: A Survey",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{huang-chang-2023-towards,\n    title = \"Towards Reasoning in Large Language Models: A Survey\",\n    author = \"Huang, Jie  and\n      Chang, Kevin Chen-Chuan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.67\",\n    doi = \"10.18653/v1/2023.findings-acl.67\",\n    pages = \"1049--1065\",\n    abstract = \"Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.\",\n}\n",
    "authors": [
        "Jie Huang",
        "Kevin Chen-Chuan Chang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.67.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4e8de5d5-42f1-5460-a1b1-819235bfb723.pdf",
    "abstract": "Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.",
    "num_pages": 17
}