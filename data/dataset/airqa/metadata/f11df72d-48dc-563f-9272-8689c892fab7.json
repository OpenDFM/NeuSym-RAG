{
    "uuid": "f11df72d-48dc-563f-9272-8689c892fab7",
    "title": "An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhou-etal-2024-empirical,\n    title = \"An Empirical Study on Parameter-Efficient Fine-Tuning for {M}ulti{M}odal Large Language Models\",\n    author = \"Zhou, Xiongtao  and\n      He, Jie  and\n      Ke, Yuhua  and\n      Zhu, Guangyao  and\n      Gutierrez Basulto, Victor  and\n      Pan, Jeff\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.598\",\n    doi = \"10.18653/v1/2024.findings-acl.598\",\n    pages = \"10057--10084\",\n    abstract = \"Multimodal Large Language Models (MLLMs) fine-tuned with multimodal instruction-following data have demonstrated formidable capabilities in multimodal tasks. However, fine-tuning all parameters of MLLMs has become challenging due to the rapid growth of the overall model{'}s parameters. To address this issue, we study Parameter-Efficient Fine-Tuning (PEFT) methods for MLLMs. We aim to identify effective methods for enhancing performance in scenarios where only a limited number of parameters are trained. This paper conducts empirical studies that employ four widely used PEFT methods to fine-tune the LLM component of open-source MLLMs. We present a comprehensive analysis that encompasses various aspects, including the impact of PEFT methods on various models, parameters and location of PEFT module, fine-tuning data scale, model stability based on PEFT method, MLLM{'}s generalization, and hallucination. We evaluated four PEFT methods on seven datasets from two different categories, unseen and seen datasets. Across all experiments, we show that the adapter is the best-performing PEFT method in various aspects. At the same time, fine-tuning the connector layers leads to improved performance in most MLLMs.\",\n}\n",
    "authors": [
        "Xiongtao Zhou",
        "Jie He",
        "Yuhua Ke",
        "Guangyao Zhu",
        "Victor Gutierrez Basulto",
        "Jeff Pan"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.598.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/f11df72d-48dc-563f-9272-8689c892fab7.pdf",
    "abstract": "Multimodal Large Language Models (MLLMs) fine-tuned with multimodal instruction-following data have demonstrated formidable capabilities in multimodal tasks. However, fine-tuning all parameters of MLLMs has become challenging due to the rapid growth of the overall model’s parameters. To address this issue, we study Parameter-Efficient Fine-Tuning (PEFT) methods for MLLMs. We aim to identify effective methods for enhancing performance in scenarios where only a limited number of parameters are trained. This paper conducts empirical studies that employ four widely used PEFT methods to fine-tune the LLM component of open-source MLLMs. We present a comprehensive analysis that encompasses various aspects, including the impact of PEFT methods on various models, parameters and location of PEFT module, fine-tuning data scale, model stability based on PEFT method, MLLM’s generalization, and hallucination. We evaluated four PEFT methods on seven datasets from two different categories, unseen and seen datasets. Across all experiments, we show that the adapter is the best-performing PEFT method in various aspects. At the same time, fine-tuning the connector layers leads to improved performance in most MLLMs.",
    "num_pages": 28
}