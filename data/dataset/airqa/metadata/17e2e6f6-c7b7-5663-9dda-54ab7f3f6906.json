{
    "uuid": "17e2e6f6-c7b7-5663-9dda-54ab7f3f6906",
    "title": "XrayGPT: Chest Radiographs Summarization using Large Medical Vision-Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{thawakar-etal-2024-xraygpt,\n    title = \"{X}ray{GPT}: Chest Radiographs Summarization using Large Medical Vision-Language Models\",\n    author = \"Thawakar, Omkar Chakradhar  and\n      Shaker, Abdelrahman M.  and\n      Mullappilly, Sahal Shaji  and\n      Cholakkal, Hisham  and\n      Anwer, Rao Muhammad  and\n      Khan, Salman  and\n      Laaksonen, Jorma  and\n      Khan, Fahad\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.35\",\n    doi = \"10.18653/v1/2024.bionlp-1.35\",\n    pages = \"440--448\",\n    abstract = \"The latest breakthroughs in large language models (LLMs) and vision-language models (VLMs) have showcased promising capabilities toward performing a wide range of tasks. Such models are typically trained on massive datasets comprising billions of image-text pairs with diverse tasks. However, their performance on task-specific domains, such as radiology, is still under-explored. While few works have recently explored LLMs-based conversational medical models, they mainly focus on text-based analysis. In this paper, we introduce XrayGPT, a conversational medical vision-language (VLMs) model that can analyze and answer open-ended questions about chest radiographs. Specifically, we align both medical visual encoder with a fine-tuned LLM to possess visual conversation abilities, grounded in an understanding of radiographs and medical knowledge. For improved alignment of chest radiograph data, we generate {\\textasciitilde}217k interactive and high-quality summaries from free-text radiology reports. Extensive experiments are conducted to validate the merits of XrayGPT. To conduct an expert evaluation, certified medical doctors evaluated the output of our XrayGPT on a test subset and the results reveal that more than 70{\\%} of the responses are scientifically accurate, with an average score of 4/5. We hope our simple and effective method establishes a solid baseline, facilitating future research toward automated analysis and summarization of chest radiographs. Code, models, and instruction sets will be publicly released.\",\n}\n",
    "authors": [
        "Omkar Chakradhar Thawakar",
        "Abdelrahman M. Shaker",
        "Sahal Shaji Mullappilly",
        "Hisham Cholakkal",
        "Rao Muhammad Anwer",
        "Salman Khan",
        "Jorma Laaksonen",
        "Fahad Khan"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.35.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/17e2e6f6-c7b7-5663-9dda-54ab7f3f6906.pdf",
    "abstract": "The latest breakthroughs in large language models (LLMs) and vision-language models (VLMs) have showcased promising capabilities toward performing a wide range of tasks. Such models are typically trained on massive datasets comprising billions of image-text pairs with diverse tasks. However, their performance on task-specific domains, such as radiology, is still under-explored. While few works have recently explored LLMs-based conversational medical models, they mainly focus on text-based analysis. In this paper, we introduce XrayGPT, a conversational medical vision-language (VLMs) model that can analyze and answer open-ended questions about chest radiographs. Specifically, we align both medical visual encoder with a fine-tuned LLM to possess visual conversation abilities, grounded in an understanding of radiographs and medical knowledge. For improved alignment of chest radiograph data, we generate ~217k interactive and high-quality summaries from free-text radiology reports. Extensive experiments are conducted to validate the merits of XrayGPT. To conduct an expert evaluation, certified medical doctors evaluated the output of our XrayGPT on a test subset and the results reveal that more than 70% of the responses are scientifically accurate, with an average score of 4/5. We hope our simple and effective method establishes a solid baseline, facilitating future research toward automated analysis and summarization of chest radiographs. Code, models, and instruction sets will be publicly released.",
    "num_pages": 9
}