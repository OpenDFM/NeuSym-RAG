{
    "uuid": "fafdd995-7192-5012-8200-ad584c3d8562",
    "title": "Score It All Together: A Multi-Task Learning Study on Automatic Scoring of Argumentative Essays",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{ding-etal-2023-score,\n    title = \"Score It All Together: A Multi-Task Learning Study on Automatic Scoring of Argumentative Essays\",\n    author = \"Ding, Yuning  and\n      Bexte, Marie  and\n      Horbach, Andrea\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.825\",\n    doi = \"10.18653/v1/2023.findings-acl.825\",\n    pages = \"13052--13063\",\n    abstract = \"When scoring argumentative essays in an educational context, not only the presence or absence of certain argumentative elements but also their quality is important. On the recently published student essay dataset PERSUADE, we first show that the automatic scoring of argument quality benefits from additional information about context, writing prompt and argument type. We then explore the different combinations of three tasks: automated span detection, type and quality prediction. Results show that a multi-task learning approach combining the three tasks outperforms sequential approaches that first learn to segment and then predict the quality/type of a segment.\",\n}\n",
    "authors": [
        "Yuning Ding",
        "Marie Bexte",
        "Andrea Horbach"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.825.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/fafdd995-7192-5012-8200-ad584c3d8562.pdf",
    "abstract": "When scoring argumentative essays in an educational context, not only the presence or absence of certain argumentative elements but also their quality is important. On the recently published student essay dataset PERSUADE, we first show that the automatic scoring of argument quality benefits from additional information about context, writing prompt and argument type. We then explore the different combinations of three tasks: automated span detection, type and quality prediction. Results show that a multi-task learning approach combining the three tasks outperforms sequential approaches that first learn to segment and then predict the quality/type of a segment.",
    "num_pages": 12
}