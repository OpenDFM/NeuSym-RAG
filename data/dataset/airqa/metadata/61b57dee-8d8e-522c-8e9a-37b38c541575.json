{
    "uuid": "61b57dee-8d8e-522c-8e9a-37b38c541575",
    "title": "Neural Machine Translation for Mathematical Formulae",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{petersen-etal-2023-neural,\n    title = \"Neural Machine Translation for Mathematical Formulae\",\n    author = \"Petersen, Felix  and\n      Schubotz, Moritz  and\n      Greiner-Petter, Andre  and\n      Gipp, Bela\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.645\",\n    doi = \"10.18653/v1/2023.acl-long.645\",\n    pages = \"11534--11550\",\n    abstract = \"We tackle the problem of neural machine translation of mathematical formulae between ambiguous presentation languages and unambiguous content languages. Compared to neural machine translation on natural language, mathematical formulae have a much smaller vocabulary and much longer sequences of symbols, while their translation requires extreme precision to satisfy mathematical information needs. In this work, we perform the tasks of translating from LaTeX to Mathematica as well as from LaTeX to semantic LaTeX. While recurrent, recursive, and transformer networks struggle with preserving all contained information, we find that convolutional sequence-to-sequence networks achieve 95.1{\\%} and 90.7{\\%} exact matches, respectively.\",\n}\n",
    "authors": [
        "Felix Petersen",
        "Moritz Schubotz",
        "Andre Greiner-Petter",
        "Bela Gipp"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.645.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/61b57dee-8d8e-522c-8e9a-37b38c541575.pdf",
    "abstract": "We tackle the problem of neural machine translation of mathematical formulae between ambiguous presentation languages and unambiguous content languages. Compared to neural machine translation on natural language, mathematical formulae have a much smaller vocabulary and much longer sequences of symbols, while their translation requires extreme precision to satisfy mathematical information needs. In this work, we perform the tasks of translating from LaTeX to Mathematica as well as from LaTeX to semantic LaTeX. While recurrent, recursive, and transformer networks struggle with preserving all contained information, we find that convolutional sequence-to-sequence networks achieve 95.1% and 90.7% exact matches, respectively.",
    "num_pages": 17
}