{
    "uuid": "73ec5a1f-f737-502f-8dac-c68b8feccaf4",
    "title": "Controllable Mixed-Initiative Dialogue Generation through Prompting",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{chen-etal-2023-controllable,\n    title = \"Controllable Mixed-Initiative Dialogue Generation through Prompting\",\n    author = \"Chen, Maximillian  and\n      Yu, Xiao  and\n      Shi, Weiyan  and\n      Awasthi, Urvi  and\n      Yu, Zhou\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.82\",\n    doi = \"10.18653/v1/2023.acl-short.82\",\n    pages = \"951--966\",\n    abstract = \"Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.\",\n}\n",
    "authors": [
        "Maximillian Chen",
        "Xiao Yu",
        "Weiyan Shi",
        "Urvi Awasthi",
        "Zhou Yu"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.82.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/73ec5a1f-f737-502f-8dac-c68b8feccaf4.pdf",
    "abstract": "Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.",
    "num_pages": 16
}