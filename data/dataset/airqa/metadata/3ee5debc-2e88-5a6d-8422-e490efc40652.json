{
    "uuid": "3ee5debc-2e88-5a6d-8422-e490efc40652",
    "title": "Multimodal Prompt Learning with Missing Modalities for Sentiment Analysis and Emotion Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{guo-etal-2024-multimodal,\n    title = \"Multimodal Prompt Learning with Missing Modalities for Sentiment Analysis and Emotion Recognition\",\n    author = \"Guo, Zirun  and\n      Jin, Tao  and\n      Zhao, Zhou\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.94\",\n    doi = \"10.18653/v1/2024.acl-long.94\",\n    pages = \"1726--1736\",\n    abstract = \"The development of multimodal models has significantly advanced multimodal sentiment analysis and emotion recognition. However, in real-world applications, the presence of various missing modality cases often leads to a degradation in the model{'}s performance. In this work, we propose a novel multimodal Transformer framework using prompt learning to address the issue of missing modalities. Our method introduces three types of prompts: generative prompts, missing-signal prompts, and missing-type prompts. These prompts enable the generation of missing modality features and facilitate the learning of intra- and inter-modality information. Through prompt learning, we achieve a substantial reduction in the number of trainable parameters. Our proposed method outperforms other methods significantly across all evaluation metrics. Extensive experiments and ablation studies are conducted to demonstrate the effectiveness and robustness of our method, showcasing its ability to effectively handle missing modalities. Codes are available at https://github.com/zrguo/MPLMM.\",\n}\n",
    "authors": [
        "Zirun Guo",
        "Tao Jin",
        "Zhou Zhao"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.94.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3ee5debc-2e88-5a6d-8422-e490efc40652.pdf",
    "abstract": "The development of multimodal models has significantly advanced multimodal sentiment analysis and emotion recognition. However, in real-world applications, the presence of various missing modality cases often leads to a degradation in the modelâ€™s performance. In this work, we propose a novel multimodal Transformer framework using prompt learning to address the issue of missing modalities. Our method introduces three types of prompts: generative prompts, missing-signal prompts, and missing-type prompts. These prompts enable the generation of missing modality features and facilitate the learning of intra- and inter-modality information. Through prompt learning, we achieve a substantial reduction in the number of trainable parameters. Our proposed method outperforms other methods significantly across all evaluation metrics. Extensive experiments and ablation studies are conducted to demonstrate the effectiveness and robustness of our method, showcasing its ability to effectively handle missing modalities. Codes are available at https://github.com/zrguo/MPLMM.",
    "num_pages": 11
}