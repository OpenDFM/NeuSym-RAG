{
    "uuid": "792aa4f7-770c-5bfb-9873-19bc4b36e694",
    "title": "A Hierarchical Explanation Generation Method Based on Feature Interaction Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{ju-etal-2023-hierarchical,\n    title = \"A Hierarchical Explanation Generation Method Based on Feature Interaction Detection\",\n    author = \"Ju, Yiming  and\n      Zhang, Yuanzhe  and\n      Liu, Kang  and\n      Zhao, Jun\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.798\",\n    doi = \"10.18653/v1/2023.findings-acl.798\",\n    pages = \"12600--12611\",\n    abstract = \"The opaqueness of deep NLP models has motivated efforts to explain how deep models predict. Recently, work has introduced hierarchical attribution explanations, which calculate attribution scores for compositional text hierarchically to capture compositional semantics. Existing work on hierarchical attributions tends to limit the text groups to a continuous text span, which we call the connecting rule. While easy for humans to read, limiting the attribution unit to a continuous span might lose important long-distance feature interactions for reflecting model predictions. In this work, we introduce a novel strategy for capturing feature interactions and employ it to build hierarchical explanations without the connecting rule. The proposed method can convert ubiquitous non-hierarchical explanations (e.g., LIME) into their corresponding hierarchical versions. Experimental results show the effectiveness of our approach in building high-quality hierarchical explanations.\",\n}\n",
    "authors": [
        "Yiming Ju",
        "Yuanzhe Zhang",
        "Kang Liu",
        "Jun Zhao"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.798.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/792aa4f7-770c-5bfb-9873-19bc4b36e694.pdf",
    "abstract": "The opaqueness of deep NLP models has motivated efforts to explain how deep models predict. Recently, work has introduced hierarchical attribution explanations, which calculate attribution scores for compositional text hierarchically to capture compositional semantics. Existing work on hierarchical attributions tends to limit the text groups to a continuous text span, which we call the connecting rule. While easy for humans to read, limiting the attribution unit to a continuous span might lose important long-distance feature interactions for reflecting model predictions. In this work, we introduce a novel strategy for capturing feature interactions and employ it to build hierarchical explanations without the connecting rule. The proposed method can convert ubiquitous non-hierarchical explanations (e.g., LIME) into their corresponding hierarchical versions. Experimental results show the effectiveness of our approach in building high-quality hierarchical explanations.",
    "num_pages": 12
}