{
    "uuid": "3c849d4f-8159-5963-a391-ac2efdf4089e",
    "title": "The HW-TSCâ€™s Simultaneous Speech-to-Text Translation System for IWSLT 2023 Evaluation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{guo-etal-2023-hw,\n    title = \"The {HW}-{TSC}{'}s Simultaneous Speech-to-Text Translation System for {IWSLT} 2023 Evaluation\",\n    author = \"Guo, Jiaxin  and\n      Wei, Daimeng  and\n      Wu, Zhanglin  and\n      Li, Zongyao  and\n      Rao, Zhiqiang  and\n      Wang, Minghan  and\n      Shang, Hengchao  and\n      Chen, Xiaoyu  and\n      Yu, Zhengzhe  and\n      Li, Shaojun  and\n      Xie, Yuhao  and\n      Lei, Lizhi  and\n      Yang, Hao\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.35\",\n    doi = \"10.18653/v1/2023.iwslt-1.35\",\n    pages = \"376--382\",\n    abstract = \"In this paper, we present our submission to the IWSLT 2023 Simultaneous Speech-to-Text Translation competition. Our participation involves three language directions: English-German, English-Chinese, and English-Japanese. Our proposed solution is a cascaded incremental decoding system that comprises an ASR model and an MT model. The ASR model is based on the U2++ architecture and can handle both streaming and offline speech scenarios with ease. Meanwhile, the MT model adopts the Deep-Transformer architecture. To improve performance, we explore methods to generate a confident partial target text output that guides the next MT incremental decoding process. In our experiments, we demonstrate that our simultaneous strategies achieve low latency while maintaining a loss of no more than 2 BLEU points when compared to offline systems.\",\n}\n",
    "authors": [
        "Jiaxin Guo",
        "Daimeng Wei",
        "Zhanglin Wu",
        "Zongyao Li",
        "Zhiqiang Rao",
        "Minghan Wang",
        "Hengchao Shang",
        "Xiaoyu Chen",
        "Zhengzhe Yu",
        "Shaojun Li",
        "Yuhao Xie",
        "Lizhi Lei",
        "Hao Yang"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.35.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/3c849d4f-8159-5963-a391-ac2efdf4089e.pdf",
    "abstract": "In this paper, we present our submission to the IWSLT 2023 Simultaneous Speech-to-Text Translation competition. Our participation involves three language directions: English-German, English-Chinese, and English-Japanese. Our proposed solution is a cascaded incremental decoding system that comprises an ASR model and an MT model. The ASR model is based on the U2++ architecture and can handle both streaming and offline speech scenarios with ease. Meanwhile, the MT model adopts the Deep-Transformer architecture. To improve performance, we explore methods to generate a confident partial target text output that guides the next MT incremental decoding process. In our experiments, we demonstrate that our simultaneous strategies achieve low latency while maintaining a loss of no more than 2 BLEU points when compared to offline systems.",
    "num_pages": 7
}