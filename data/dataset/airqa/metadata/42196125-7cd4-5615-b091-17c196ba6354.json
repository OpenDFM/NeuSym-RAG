{
    "uuid": "42196125-7cd4-5615-b091-17c196ba6354",
    "title": "An Analysis of Tasks and Datasets in Peer Reviewing",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Fourth Workshop on Scholarly Document Processing (SDP 2024)",
    "bibtex": "@inproceedings{staudinger-etal-2024-analysis,\n    title = \"An Analysis of Tasks and Datasets in Peer Reviewing\",\n    author = \"Staudinger, Moritz  and\n      Kusa, Wojciech  and\n      Piroi, Florina  and\n      Hanbury, Allan\",\n    editor = \"Ghosal, Tirthankar  and\n      Singh, Amanpreet  and\n      Waard, Anita  and\n      Mayr, Philipp  and\n      Naik, Aakanksha  and\n      Weller, Orion  and\n      Lee, Yoonjoo  and\n      Shen, Shannon  and\n      Qin, Yanxia\",\n    booktitle = \"Proceedings of the Fourth Workshop on Scholarly Document Processing (SDP 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sdp-1.24\",\n    pages = \"257--268\",\n    abstract = \"Taking note of the current challenges of the peer review system, this paper inventories the research tasks for analysing and possibly automating parts of the reviewing process, like matching submissions with a reviewer{'}s domain of expertise. For each of these tasks we list their associated datasets, analysing their quality in terms of available documentation of creation and use. Building up on this, we give a set of recommendations to take into account when collecting and releasing data.\",\n}\n",
    "authors": [
        "Moritz Staudinger",
        "Wojciech Kusa",
        "Florina Piroi",
        "Allan Hanbury"
    ],
    "pdf_url": "https://aclanthology.org/2024.sdp-1.24.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/42196125-7cd4-5615-b091-17c196ba6354.pdf",
    "abstract": "Taking note of the current challenges of the peer review system, this paper inventories the research tasks for analysing and possibly automating parts of the reviewing process, like matching submissions with a reviewerâ€™s domain of expertise. For each of these tasks we list their associated datasets, analysing their quality in terms of available documentation of creation and use. Building up on this, we give a set of recommendations to take into account when collecting and releasing data.",
    "num_pages": 12
}