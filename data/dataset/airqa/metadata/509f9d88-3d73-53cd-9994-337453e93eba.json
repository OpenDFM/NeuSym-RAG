{
    "uuid": "509f9d88-3d73-53cd-9994-337453e93eba",
    "title": "BUCA: A Binary Classification Approach to Unsupervised Commonsense Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{he-etal-2023-buca,\n    title = \"{BUCA}: A Binary Classification Approach to Unsupervised Commonsense Question Answering\",\n    author = \"He, Jie  and\n      U, Simon  and\n      Gutierrez-Basulto, Victor  and\n      Pan, Jeff\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.33\",\n    doi = \"10.18653/v1/2023.acl-short.33\",\n    pages = \"376--387\",\n    abstract = \"Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as the construction of commonsense reasoning datasets is expensive, and they are inevitably limited in their scope. A popular approach to UCR is to fine-tune language models with external knowledge (e.g., knowledge graphs), but this usually requires a large number of training examples. In this paper, we propose to transform the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. To this end, for training the model, we convert the knowledge graph triples into reasonable and unreasonable texts. Extensive experimental results show the effectiveness of our approach on various multiple choice question answering benchmarks. Furthermore, compared with existing UCR approaches using KGs, ours is less data hungry.\",\n}\n",
    "authors": [
        "Jie He",
        "Simon U",
        "Victor Gutierrez-Basulto",
        "Jeff Pan"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.33.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/509f9d88-3d73-53cd-9994-337453e93eba.pdf",
    "abstract": "Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as the construction of commonsense reasoning datasets is expensive, and they are inevitably limited in their scope. A popular approach to UCR is to fine-tune language models with external knowledge (e.g., knowledge graphs), but this usually requires a large number of training examples. In this paper, we propose to transform the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. To this end, for training the model, we convert the knowledge graph triples into reasonable and unreasonable texts. Extensive experimental results show the effectiveness of our approach on various multiple choice question answering benchmarks. Furthermore, compared with existing UCR approaches using KGs, ours is less data hungry.",
    "num_pages": 12
}