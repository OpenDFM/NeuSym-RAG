{
    "uuid": "e6b2c116-402e-548a-976e-8f2f891056eb",
    "title": "Search-Oriented Conversational Query Editing",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{mao-etal-2023-search,\n    title = \"Search-Oriented Conversational Query Editing\",\n    author = \"Mao, Kelong  and\n      Dou, Zhicheng  and\n      Liu, Bang  and\n      Qian, Hongjin  and\n      Mo, Fengran  and\n      Wu, Xiangli  and\n      Cheng, Xiaohua  and\n      Cao, Zhao\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.256\",\n    doi = \"10.18653/v1/2023.findings-acl.256\",\n    pages = \"4160--4172\",\n    abstract = \"Conversational query rewriting (CQR) realizes conversational search by reformulating the search dialogue into a standalone rewrite. However, existing CQR models either are not learned toward improving the downstream search performance or inefficiently generate the rewrite token-by-token from scratch while neglecting the fact that the search dialogue often has a large overlap with the rewrite. In this paper, we propose EdiRCS, a new text editing-based CQR model tailored for conversational search. In EdiRCS, most of the rewrite tokens are selected from the dialogue in a non-autoregressive fashion and only a few new tokens are generated to supplement the final rewrite, which makes EdiRCS highly efficient. In particular, the learning of EdiRCS is augmented with two search-oriented objectives, including contrastive ranking augmentation and contextualization knowledge transfer, which effectively improve it to select and generate more useful tokens from the view of retrieval. We show that EdiRCS outperforms state-of-the-art CQR models on three conversational search benchmarks while having low rewriting latency, and is robust to out-of-domain search dialogues and long dialogue contexts.\",\n}\n",
    "authors": [
        "Kelong Mao",
        "Zhicheng Dou",
        "Bang Liu",
        "Hongjin Qian",
        "Fengran Mo",
        "Xiangli Wu",
        "Xiaohua Cheng",
        "Zhao Cao"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.256.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e6b2c116-402e-548a-976e-8f2f891056eb.pdf",
    "abstract": "Conversational query rewriting (CQR) realizes conversational search by reformulating the search dialogue into a standalone rewrite. However, existing CQR models either are not learned toward improving the downstream search performance or inefficiently generate the rewrite token-by-token from scratch while neglecting the fact that the search dialogue often has a large overlap with the rewrite. In this paper, we propose EdiRCS, a new text editing-based CQR model tailored for conversational search. In EdiRCS, most of the rewrite tokens are selected from the dialogue in a non-autoregressive fashion and only a few new tokens are generated to supplement the final rewrite, which makes EdiRCS highly efficient. In particular, the learning of EdiRCS is augmented with two search-oriented objectives, including contrastive ranking augmentation and contextualization knowledge transfer, which effectively improve it to select and generate more useful tokens from the view of retrieval. We show that EdiRCS outperforms state-of-the-art CQR models on three conversational search benchmarks while having low rewriting latency, and is robust to out-of-domain search dialogues and long dialogue contexts.",
    "num_pages": 13
}