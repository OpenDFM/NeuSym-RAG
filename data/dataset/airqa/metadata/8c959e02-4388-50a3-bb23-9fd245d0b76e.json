{
    "uuid": "8c959e02-4388-50a3-bb23-9fd245d0b76e",
    "title": "Deloitte at #SMM4H 2024: Can GPT-4 Detect COVID-19 Tweets Annotated by Itself?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks",
    "bibtex": "@inproceedings{abburi-etal-2024-deloitte,\n    title = \"Deloitte at {\\#}{SMM}4{H} 2024: Can {GPT}-4 Detect {COVID}-19 Tweets Annotated by Itself?\",\n    author = \"Abburi, Harika  and\n      Pudota, Nirmala  and\n      Veeramani, Balaji  and\n      Bowen, Edward  and\n      Bhattacharya, Sanmitra\",\n    editor = \"Xu, Dongfang  and\n      Gonzalez-Hernandez, Graciela\",\n    booktitle = \"Proceedings of The 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.smm4h-1.18\",\n    pages = \"79--82\",\n    abstract = \"The advent of Large Language Models (LLMs) such as Generative Pre-trained Transformers (GPT-4) mark a transformative era in Natural Language Generation (NLG). These models demonstrate the ability to generate coherent text that closely resembles human-authored content. They are easily accessible and have become invaluable tools in handling various text-based tasks, such as data annotation, report generation, and question answering. In this paper, we investigate GPT-4{'}s ability to discern between data it has annotated and data annotated by humans, specifically within the context of tweets in the medical domain. Through experimental analysis, we observe GPT-4 outperform other state-of-the-art models. The dataset used in this study was provided by the SMM4H (Social Media Mining for Health Research and Applications) shared task. Our model achieved an accuracy of 0.51, securing a second rank in the shared task.\",\n}\n",
    "authors": [
        "Harika Abburi",
        "Nirmala Pudota",
        "Balaji Veeramani",
        "Edward Bowen",
        "Sanmitra Bhattacharya"
    ],
    "pdf_url": "https://aclanthology.org/2024.smm4h-1.18.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8c959e02-4388-50a3-bb23-9fd245d0b76e.pdf",
    "abstract": "The advent of Large Language Models (LLMs) such as Generative Pre-trained Transformers (GPT-4) mark a transformative era in Natural Language Generation (NLG). These models demonstrate the ability to generate coherent text that closely resembles human-authored content. They are easily accessible and have become invaluable tools in handling various text-based tasks, such as data annotation, report generation, and question answering. In this paper, we investigate GPT-4â€™s ability to discern between data it has annotated and data annotated by humans, specifically within the context of tweets in the medical domain. Through experimental analysis, we observe GPT-4 outperform other state-of-the-art models. The dataset used in this study was provided by the SMM4H (Social Media Mining for Health Research and Applications) shared task. Our model achieved an accuracy of 0.51, securing a second rank in the shared task.",
    "num_pages": 4
}