{
    "uuid": "63bea4bc-5cbf-5dcc-9dab-db52fced82ab",
    "title": "What the DAAM: Interpreting Stable Diffusion Using Cross Attention",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{tang-etal-2023-daam,\n    title = \"What the {DAAM}: Interpreting Stable Diffusion Using Cross Attention\",\n    author = \"Tang, Raphael  and\n      Liu, Linqing  and\n      Pandey, Akshat  and\n      Jiang, Zhiying  and\n      Yang, Gefei  and\n      Kumar, Karun  and\n      Stenetorp, Pontus  and\n      Lin, Jimmy  and\n      Ture, Ferhan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.310\",\n    doi = \"10.18653/v1/2023.acl-long.310\",\n    pages = \"5644--5659\",\n    abstract = \"Diffusion models are a milestone in text-to-image generation, but they remain poorly understood, lacking interpretability analyses. In this paper, we perform a text-image attribution analysis on Stable Diffusion, a recently open-sourced model. To produce attribution maps, we upscale and aggregate cross-attention maps in the denoising module, naming our method DAAM. We validate it by testing its segmentation ability on nouns, as well as its generalized attribution quality on all parts of speech, rated by humans. On two generated datasets, we attain a competitive 58.8-64.8 mIoU on noun segmentation and fair to good mean opinion scores (3.4-4.2) on generalized attribution. Then, we apply DAAM to study the role of syntax in the pixel space across head{--}dependent heat map interaction patterns for ten common dependency relations. We show that, for some relations, the head map consistently subsumes the dependent, while the opposite is true for others. Finally, we study several semantic phenomena, focusing on feature entanglement; we find that the presence of cohyponyms worsens generation quality by 9{\\%}, and descriptive adjectives attend too broadly. We are the first to interpret large diffusion models from a visuolinguistic perspective, which enables future research. Our code is at \\url{https://github.com/castorini/daam}.\",\n}\n",
    "authors": [
        "Raphael Tang",
        "Linqing Liu",
        "Akshat Pandey",
        "Zhiying Jiang",
        "Gefei Yang",
        "Karun Kumar",
        "Pontus Stenetorp",
        "Jimmy Lin",
        "Ferhan Ture"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.310.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/63bea4bc-5cbf-5dcc-9dab-db52fced82ab.pdf",
    "abstract": "Diffusion models are a milestone in text-to-image generation, but they remain poorly understood, lacking interpretability analyses. In this paper, we perform a text-image attribution analysis on Stable Diffusion, a recently open-sourced model. To produce attribution maps, we upscale and aggregate cross-attention maps in the denoising module, naming our method DAAM. We validate it by testing its segmentation ability on nouns, as well as its generalized attribution quality on all parts of speech, rated by humans. On two generated datasets, we attain a competitive 58.8-64.8 mIoU on noun segmentation and fair to good mean opinion scores (3.4-4.2) on generalized attribution. Then, we apply DAAM to study the role of syntax in the pixel space across headâ€“dependent heat map interaction patterns for ten common dependency relations. We show that, for some relations, the head map consistently subsumes the dependent, while the opposite is true for others. Finally, we study several semantic phenomena, focusing on feature entanglement; we find that the presence of cohyponyms worsens generation quality by 9%, and descriptive adjectives attend too broadly. We are the first to interpret large diffusion models from a visuolinguistic perspective, which enables future research. Our code is at https://github.com/castorini/daam.",
    "num_pages": 16
}