{
    "uuid": "9a4cceb0-9520-50ec-9b9e-ce2fa93512ca",
    "title": "„Mann“ is to “Donna” as「国王」is to « Reine » Adapting the Analogy Task for Multilingual and Contextual Embeddings",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)",
    "bibtex": "@inproceedings{mickus-etal-2023-mann,\n    title = \"âMann{``} is to {``}Donna{''} asãå½çãis to Â« Reine Â» Adapting the Analogy Task for Multilingual and Contextual Embeddings\",\n    author = \"Mickus, Timothee  and\n      Cal{\\`o}, Eduardo  and\n      Jacqmin, L{\\'e}o  and\n      Paperno, Denis  and\n      Constant, Mathieu\",\n    editor = \"Palmer, Alexis  and\n      Camacho-collados, Jose\",\n    booktitle = \"Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.starsem-1.25\",\n    doi = \"10.18653/v1/2023.starsem-1.25\",\n    pages = \"270--283\",\n    abstract = \"How does the word analogy task fit in the modern NLP landscape? Given the rarity of comparable multilingual benchmarks and the lack of a consensual evaluation protocol for contextual models, this remains an open question. In this paper, we introduce MATS: a multilingual analogy dataset, covering forty analogical relations in six languages, and evaluate human as well as static and contextual embedding performances on the task. We find that not all analogical relations are equally straightforward for humans, static models remain competitive with contextual embeddings, and optimal settings vary across languages and analogical relations. Several key challenges remain, including creating benchmarks that align with human reasoning and understanding what drives differences across methodologies.\",\n}\n",
    "authors": [
        "Timothee Mickus",
        "Eduardo Calò",
        "Léo Jacqmin",
        "Denis Paperno",
        "Mathieu Constant"
    ],
    "pdf_url": "https://aclanthology.org/2023.starsem-1.25.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/9a4cceb0-9520-50ec-9b9e-ce2fa93512ca.pdf",
    "abstract": "How does the word analogy task fit in the modern NLP landscape? Given the rarity of comparable multilingual benchmarks and the lack of a consensual evaluation protocol for contextual models, this remains an open question. In this paper, we introduce MATS: a multilingual analogy dataset, covering forty analogical relations in six languages, and evaluate human as well as static and contextual embedding performances on the task. We find that not all analogical relations are equally straightforward for humans, static models remain competitive with contextual embeddings, and optimal settings vary across languages and analogical relations. Several key challenges remain, including creating benchmarks that align with human reasoning and understanding what drives differences across methodologies.",
    "num_pages": 14
}