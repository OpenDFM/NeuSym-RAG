{
    "uuid": "d9c34620-7b35-5371-a380-7578079cc38a",
    "title": "RideKE: Leveraging Low-resource Twitter User-generated Content for Sentiment and Emotion Detection on Code-switched RHS Dataset.",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{etori-gini-2024-rideke,\n    title = \"{R}ide{KE}: Leveraging Low-resource {T}witter User-generated Content for Sentiment and Emotion Detection on Code-switched {RHS} Dataset.\",\n    author = \"Etori, Naome  and\n      Gini, Maria\",\n    editor = \"De Clercq, Orph{\\'e}e  and\n      Barriere, Valentin  and\n      Barnes, Jeremy  and\n      Klinger, Roman  and\n      Sedoc, Jo{\\~a}o  and\n      Tafreshi, Shabnam\",\n    booktitle = \"Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.wassa-1.19\",\n    doi = \"10.18653/v1/2024.wassa-1.19\",\n    pages = \"234--249\",\n    abstract = \"Social media has become a crucial open-access platform enabling individuals to freely express opinions and share experiences. These platforms contain user-generated content facilitating instantaneous communication and feedback. However, leveraging low-resource language data from Twitter can be challenging due to the scarcity and poor quality of content with significant variations in language use, such as slang and code-switching. Automatically identifying tweets in low-resource languages can also be challenging because Twitter primarily supports high-resource languages; low-resource languages often lack robust linguistic and contextual support. This paper analyzes Kenyan code-switched data from Twitter using four transformer-based pretrained models for sentiment and emotion classification tasks using supervised and semi-supervised methods. We detail the methodology behind data collection, the annotation procedure, and the challenges encountered during the data curation phase. Our results show that XLM-R outperforms other models; for sentiment analysis, XLM-R supervised model achieves the highest accuracy (69.2{\\%}) and F1 score (66.1{\\%}), XLM-R semi-supervised (67.2{\\%} accuracy, 64.1{\\%} F1 score). In emotion analysis, DistilBERT supervised leads in accuracy (59.8{\\%}) and F1 score (31{\\%}), mBERT semi-supervised (accuracy (59{\\%} and F1 score 26.5{\\%}). AfriBERTa models show the lowest accuracy and F1 scores. This indicates that the semi-supervised method{'}s performance is constrained by the small labeled dataset.\",\n}\n",
    "authors": [
        "Naome Etori",
        "Maria Gini"
    ],
    "pdf_url": "https://aclanthology.org/2024.wassa-1.19.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d9c34620-7b35-5371-a380-7578079cc38a.pdf",
    "abstract": "Social media has become a crucial open-access platform enabling individuals to freely express opinions and share experiences. These platforms contain user-generated content facilitating instantaneous communication and feedback. However, leveraging low-resource language data from Twitter can be challenging due to the scarcity and poor quality of content with significant variations in language use, such as slang and code-switching. Automatically identifying tweets in low-resource languages can also be challenging because Twitter primarily supports high-resource languages; low-resource languages often lack robust linguistic and contextual support. This paper analyzes Kenyan code-switched data from Twitter using four transformer-based pretrained models for sentiment and emotion classification tasks using supervised and semi-supervised methods. We detail the methodology behind data collection, the annotation procedure, and the challenges encountered during the data curation phase. Our results show that XLM-R outperforms other models; for sentiment analysis, XLM-R supervised model achieves the highest accuracy (69.2%) and F1 score (66.1%), XLM-R semi-supervised (67.2% accuracy, 64.1% F1 score). In emotion analysis, DistilBERT supervised leads in accuracy (59.8%) and F1 score (31%), mBERT semi-supervised (accuracy (59% and F1 score 26.5%). AfriBERTa models show the lowest accuracy and F1 scores. This indicates that the semi-supervised methodâ€™s performance is constrained by the small labeled dataset.",
    "num_pages": 16
}