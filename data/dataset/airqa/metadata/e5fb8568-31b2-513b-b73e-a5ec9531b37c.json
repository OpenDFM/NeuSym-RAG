{
    "uuid": "e5fb8568-31b2-513b-b73e-a5ec9531b37c",
    "title": "HealthMavericks@MEDIQA-Chat 2023: Benchmarking different Transformer based models for Clinical Dialogue Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{suri-etal-2023-healthmavericks,\n    title = \"{H}ealth{M}avericks@{MEDIQA}-Chat 2023: Benchmarking different Transformer based models for Clinical Dialogue Summarization\",\n    author = \"Suri, Kunal  and\n      Saha, Saumajit  and\n      Singh, Atul\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.50\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.50\",\n    pages = \"472--489\",\n    abstract = \"In recent years, we have seen many Transformer based models being created to address Dialog Summarization problem. While there has been a lot of work on understanding how these models stack against each other in summarizing regular conversations such as the ones found in DialogSum dataset, there haven{'}t been many analysis of these models on Clinical Dialog Summarization. In this article, we describe our solution to MEDIQA-Chat 2023 Shared Tasks as part of ACL-ClinicalNLP 2023 workshop which benchmarks some of the popular Transformer Architectures such as BioBart, Flan-T5, DialogLED, and OpenAI GPT3 on the problem of Clinical Dialog Summarization. We analyse their performance on two tasks - summarizing short conversations and long conversations. In addition to this, we also benchmark two popular summarization ensemble methods and report their performance.\",\n}\n",
    "authors": [
        "Kunal Suri",
        "Saumajit Saha",
        "Atul Singh"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.50.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e5fb8568-31b2-513b-b73e-a5ec9531b37c.pdf",
    "abstract": "In recent years, we have seen many Transformer based models being created to address Dialog Summarization problem. While there has been a lot of work on understanding how these models stack against each other in summarizing regular conversations such as the ones found in DialogSum dataset, there havenâ€™t been many analysis of these models on Clinical Dialog Summarization. In this article, we describe our solution to MEDIQA-Chat 2023 Shared Tasks as part of ACL-ClinicalNLP 2023 workshop which benchmarks some of the popular Transformer Architectures such as BioBart, Flan-T5, DialogLED, and OpenAI GPT3 on the problem of Clinical Dialog Summarization. We analyse their performance on two tasks - summarizing short conversations and long conversations. In addition to this, we also benchmark two popular summarization ensemble methods and report their performance.",
    "num_pages": 18
}