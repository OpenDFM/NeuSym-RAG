{
    "uuid": "f095ce67-6429-5ddc-9792-05f34dcec9fc",
    "title": "Towards Boosting the Open-Domain Chatbot with Human Feedback",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{lu-etal-2023-towards,\n    title = \"Towards Boosting the Open-Domain Chatbot with Human Feedback\",\n    author = \"Lu, Hua  and\n      Bao, Siqi  and\n      He, Huang  and\n      Wang, Fan  and\n      Wu, Hua  and\n      Wang, Haifeng\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.224\",\n    doi = \"10.18653/v1/2023.acl-long.224\",\n    pages = \"4060--4078\",\n    abstract = \"Many open-domain dialogue models pre-trained with social media comments can generate coherent replies but have difficulties producing engaging responses. This phenomenon might mainly result from the deficiency of annotated human-human conversations and the misalignment with human preference. In this paper, we propose a novel and efficient framework Diamante to boost the open-domain chatbot, where two kinds of human feedback (including explicit demonstration and implicit preference) are collected and leveraged. By asking annotators to select or amend the model-generated candidate responses, Diamante efficiently collects the human demonstrated responses and constructs a Chinese chit-chat dataset. To enhance the alignment with human preference, Diamante leverages the implicit preference in the data collection process and introduces the generation-evaluation joint training. Comprehensive experiments indicate that the Diamante dataset and joint training paradigm can significantly boost the performance of pre-trained dialogue models. The overall engagingness of the previous state-of-the-art model has been improved remarkably by 50{\\%} in Chinese open-domain conversations.\",\n}\n",
    "authors": [
        "Hua Lu",
        "Siqi Bao",
        "Huang He",
        "Fan Wang",
        "Hua Wu",
        "Haifeng Wang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.224.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f095ce67-6429-5ddc-9792-05f34dcec9fc.pdf",
    "abstract": "Many open-domain dialogue models pre-trained with social media comments can generate coherent replies but have difficulties producing engaging responses. This phenomenon might mainly result from the deficiency of annotated human-human conversations and the misalignment with human preference. In this paper, we propose a novel and efficient framework Diamante to boost the open-domain chatbot, where two kinds of human feedback (including explicit demonstration and implicit preference) are collected and leveraged. By asking annotators to select or amend the model-generated candidate responses, Diamante efficiently collects the human demonstrated responses and constructs a Chinese chit-chat dataset. To enhance the alignment with human preference, Diamante leverages the implicit preference in the data collection process and introduces the generation-evaluation joint training. Comprehensive experiments indicate that the Diamante dataset and joint training paradigm can significantly boost the performance of pre-trained dialogue models. The overall engagingness of the previous state-of-the-art model has been improved remarkably by 50% in Chinese open-domain conversations.",
    "num_pages": 19
}