{
    "uuid": "fae1bc4c-2236-5764-89d4-727529c2fa3e",
    "title": "Data Augmentation for Speech-Based Diacritic Restoration",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The Second Arabic Natural Language Processing Conference",
    "bibtex": "@inproceedings{shatnawi-etal-2024-data,\n    title = \"Data Augmentation for Speech-Based Diacritic Restoration\",\n    author = \"Shatnawi, Sara  and\n      Alqahtani, Sawsan  and\n      Shehata, Shady  and\n      Aldarmaki, Hanan\",\n    editor = \"Habash, Nizar  and\n      Bouamor, Houda  and\n      Eskander, Ramy  and\n      Tomeh, Nadi  and\n      Abu Farha, Ibrahim  and\n      Abdelali, Ahmed  and\n      Touileb, Samia  and\n      Hamed, Injy  and\n      Onaizan, Yaser  and\n      Alhafni, Bashar  and\n      Antoun, Wissam  and\n      Khalifa, Salam  and\n      Haddad, Hatem  and\n      Zitouni, Imed  and\n      AlKhamissi, Badr  and\n      Almatham, Rawan  and\n      Mrini, Khalil\",\n    booktitle = \"Proceedings of The Second Arabic Natural Language Processing Conference\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.arabicnlp-1.15\",\n    doi = \"10.18653/v1/2024.arabicnlp-1.15\",\n    pages = \"160--169\",\n    abstract = \"This paper describes a data augmentation technique for boosting the performance of speech-based diacritic restoration. Our experiments demonstrate the utility of this appraoch, resulting in improved generalization of all models across different test sets. In addition, we describe the first multi-modal diacritic restoration model, utilizing both speech and text as input modalities. This type of model can be used to diacritize speech transcripts. Unlike previous work that relies on an external ASR model, the proposed model is far more compact and efficient. While the multi-modal framework does not surpass the ASR-based model for this task, it offers a promising approach for improving the efficiency of speech-based diacritization, with a potential for improvement using data augmentation and other methods.\",\n}\n",
    "authors": [
        "Sara Shatnawi",
        "Sawsan Alqahtani",
        "Shady Shehata",
        "Hanan Aldarmaki"
    ],
    "pdf_url": "https://aclanthology.org/2024.arabicnlp-1.15.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/fae1bc4c-2236-5764-89d4-727529c2fa3e.pdf",
    "abstract": "This paper describes a data augmentation technique for boosting the performance of speech-based diacritic restoration. Our experiments demonstrate the utility of this appraoch, resulting in improved generalization of all models across different test sets. In addition, we describe the first multi-modal diacritic restoration model, utilizing both speech and text as input modalities. This type of model can be used to diacritize speech transcripts. Unlike previous work that relies on an external ASR model, the proposed model is far more compact and efficient. While the multi-modal framework does not surpass the ASR-based model for this task, it offers a promising approach for improving the efficiency of speech-based diacritization, with a potential for improvement using data augmentation and other methods.",
    "num_pages": 10
}