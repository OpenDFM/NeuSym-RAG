{
    "uuid": "4fb6e46e-201a-533c-a97b-f4bc50fff31e",
    "title": "A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{verma-etal-2024-community,\n    title = \"A Community-Centric Perspective for Characterizing and Detecting Anti-{A}sian Violence-Provoking Speech\",\n    author = \"Verma, Gaurav  and\n      Grover, Rynaa  and\n      Zhou, Jiawei  and\n      Mathew, Binny  and\n      Kraemer, Jordan  and\n      Choudhury, Munmun  and\n      Kumar, Srijan\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.684\",\n    doi = \"10.18653/v1/2024.acl-long.684\",\n    pages = \"12672--12684\",\n    abstract = \"Violence-provoking speech {--} speech that implicitly or explicitly promotes violence against the members of the targeted community, contributed to a massive surge in anti-Asian crimes during the COVID-19 pandemic. While previous works have characterized and built tools for detecting other forms of harmful speech, like fear speech and hate speech, our work takes a community-centric approach to studying anti-Asian violence-provoking speech. Using data from {\\textasciitilde}420k Twitter posts spanning a 3-year duration (January 1, 2020 to February 1, 2023), we develop a codebook to characterize anti-Asian violence-provoking speech and collect a community-crowdsourced dataset to facilitate its large-scale detection using state-of-the-art classifiers. We contrast the capabilities of natural language processing classifiers, ranging from BERT-based to LLM-based classifiers, in detecting violence-provoking speech with their capabilities to detect anti-Asian hateful speech. In contrast to prior work that has demonstrated the effectiveness of such classifiers in detecting hateful speech ($F_1$ = 0.89), our work shows that accurate and reliable detection of violence-provoking speech is a challenging task ($F_1$ = 0.69). We discuss the implications of our findings, particularly the need for proactive interventions to support Asian communities during public health crises.\",\n}\n",
    "authors": [
        "Gaurav Verma",
        "Rynaa Grover",
        "Jiawei Zhou",
        "Binny Mathew",
        "Jordan Kraemer",
        "Munmun Choudhury",
        "Srijan Kumar"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.684.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4fb6e46e-201a-533c-a97b-f4bc50fff31e.pdf",
    "abstract": "Violence-provoking speech â€“ speech that implicitly or explicitly promotes violence against the members of the targeted community, contributed to a massive surge in anti-Asian crimes during the COVID-19 pandemic. While previous works have characterized and built tools for detecting other forms of harmful speech, like fear speech and hate speech, our work takes a community-centric approach to studying anti-Asian violence-provoking speech. Using data from ~420k Twitter posts spanning a 3-year duration (January 1, 2020 to February 1, 2023), we develop a codebook to characterize anti-Asian violence-provoking speech and collect a community-crowdsourced dataset to facilitate its large-scale detection using state-of-the-art classifiers. We contrast the capabilities of natural language processing classifiers, ranging from BERT-based to LLM-based classifiers, in detecting violence-provoking speech with their capabilities to detect anti-Asian hateful speech. In contrast to prior work that has demonstrated the effectiveness of such classifiers in detecting hateful speech (F1 = 0.89), our work shows that accurate and reliable detection of violence-provoking speech is a challenging task (F1 = 0.69). We discuss the implications of our findings, particularly the need for proactive interventions to support Asian communities during public health crises.",
    "num_pages": 13
}