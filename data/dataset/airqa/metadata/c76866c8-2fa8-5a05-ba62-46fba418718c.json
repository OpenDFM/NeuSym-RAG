{
    "uuid": "c76866c8-2fa8-5a05-ba62-46fba418718c",
    "title": "Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhu-etal-2024-generative,\n    title = \"Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer\",\n    author = \"Zhu, Yongxin  and\n      Su, Dan  and\n      He, Liqiang  and\n      Xu, Linli  and\n      Yu, Dong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.97\",\n    doi = \"10.18653/v1/2024.acl-long.97\",\n    pages = \"1764--1775\",\n    abstract = \"While recent advancements in speech language models have achieved significant progress, they face remarkable challenges in modeling the long acoustic sequences of neural audio codecs. In this paper, we introduce \\textbf{G}enerative \\textbf{P}re-trained \\textbf{S}peech \\textbf{T}ransformer (GPST), a hierarchical transformer designed for efficient speech language modeling. GPST quantizes audio waveforms into two distinct types of discrete speech representations and integrates them within a hierarchical transformer architecture, allowing for a unified one-stage generation process and enhancing Hi-Res audio generation capabilities. By training on large corpora of speeches in an end-to-end unsupervised manner, GPST can generate syntactically consistent speech with diverse speaker identities. Given a brief 3-second prompt, GPST can produce natural and coherent personalized speech, demonstrating in-context learning abilities. Moreover, our approach can be easily extended to spoken cross-lingual speech generation by incorporating multi-lingual semantic tokens and universal acoustic tokens. Experimental results indicate that GPST significantly outperforms the existing speech language models in terms of word error rate, speech quality, and speaker similarity. See \\url{https://youngsheen.github.io/GPST/demo} for demo samples.\",\n}\n",
    "authors": [
        "Yongxin Zhu",
        "Dan Su",
        "Liqiang He",
        "Linli Xu",
        "Dong Yu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.97.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/c76866c8-2fa8-5a05-ba62-46fba418718c.pdf",
    "abstract": "While recent advancements in speech language models have achieved significant progress, they face remarkable challenges in modeling the long acoustic sequences of neural audio codecs. In this paper, we introduce Generative Pre-trained Speech Transformer (GPST), a hierarchical transformer designed for efficient speech language modeling. GPST quantizes audio waveforms into two distinct types of discrete speech representations and integrates them within a hierarchical transformer architecture, allowing for a unified one-stage generation process and enhancing Hi-Res audio generation capabilities. By training on large corpora of speeches in an end-to-end unsupervised manner, GPST can generate syntactically consistent speech with diverse speaker identities. Given a brief 3-second prompt, GPST can produce natural and coherent personalized speech, demonstrating in-context learning abilities. Moreover, our approach can be easily extended to spoken cross-lingual speech generation by incorporating multi-lingual semantic tokens and universal acoustic tokens. Experimental results indicate that GPST significantly outperforms the existing speech language models in terms of word error rate, speech quality, and speaker similarity. See https://youngsheen.github.io/GPST/demo for demo samples.",
    "num_pages": 12
}