{
    "uuid": "dc4e42a0-fb69-5be9-beb7-6a82ce0b5303",
    "title": "GMNLP at SemEval-2023 Task 12: Sentiment Analysis with Phylogeny-Based Adapters",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{alam-etal-2023-gmnlp,\n    title = \"{GMNLP} at {S}em{E}val-2023 Task 12: Sentiment Analysis with Phylogeny-Based Adapters\",\n    author = \"Alam, Md Mahfuz Ibn  and\n      Xie, Ruoyu  and\n      Faisal, Fahim  and\n      Anastasopoulos, Antonios\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.163\",\n    doi = \"10.18653/v1/2023.semeval-1.163\",\n    pages = \"1172--1182\",\n    abstract = \"This report describes GMU{'}s sentiment analysis system for the SemEval-2023 shared task AfriSenti-SemEval. We participated in all three sub-tasks: Monolingual, Multilingual, and Zero-Shot. Our approach uses models initialized with AfroXLMR-large, a pre-trained multilingual language model trained on African languages and fine-tuned correspondingly. We also introduce augmented training data along with original training data. Alongside finetuning, we perform phylogeny-based adapter-tuning to create several models and ensemble the best models for the final submission. Our system achieves the best F1-score on track 5: Amharic, with 6.2 points higher F1-score than the second-best performing system on this track. Overall, our system ranks 5th among the 10 systems participating in all 15 tracks.\",\n}\n",
    "authors": [
        "Md Mahfuz Ibn Alam",
        "Ruoyu Xie",
        "Fahim Faisal",
        "Antonios Anastasopoulos"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.163.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/dc4e42a0-fb69-5be9-beb7-6a82ce0b5303.pdf",
    "abstract": "This report describes GMUâ€™s sentiment analysis system for the SemEval-2023 shared task AfriSenti-SemEval. We participated in all three sub-tasks: Monolingual, Multilingual, and Zero-Shot. Our approach uses models initialized with AfroXLMR-large, a pre-trained multilingual language model trained on African languages and fine-tuned correspondingly. We also introduce augmented training data along with original training data. Alongside finetuning, we perform phylogeny-based adapter-tuning to create several models and ensemble the best models for the final submission. Our system achieves the best F1-score on track 5: Amharic, with 6.2 points higher F1-score than the second-best performing system on this track. Overall, our system ranks 5th among the 10 systems participating in all 15 tracks.",
    "num_pages": 11
}