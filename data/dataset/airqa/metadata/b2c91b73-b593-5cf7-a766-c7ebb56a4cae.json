{
    "uuid": "b2c91b73-b593-5cf7-a766-c7ebb56a4cae",
    "title": "Epicurus at SemEval-2023 Task 4: Improving Prediction of Human Values behind Arguments by Leveraging Their Definitions",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{fang-etal-2023-epicurus,\n    title = \"Epicurus at {S}em{E}val-2023 Task 4: Improving Prediction of Human Values behind Arguments by Leveraging Their Definitions\",\n    author = \"Fang, Christian  and\n      Fang, Qixiang  and\n      Nguyen, Dong\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.31\",\n    doi = \"10.18653/v1/2023.semeval-1.31\",\n    pages = \"221--229\",\n    abstract = \"We describe our experiments for SemEval-2023 Task 4 on the identification of human values behind arguments (ValueEval). Because human values are subjective concepts which require precise definitions, we hypothesize that incorporating the definitions of human values (in the form of annotation instructions and validated survey items) during model training can yield better prediction performance. We explore this idea and show that our proposed models perform better than the challenge organizers{'} baselines, with improvements in macro F1 scores of up to 18{\\%}.\",\n}\n",
    "authors": [
        "Christian Fang",
        "Qixiang Fang",
        "Dong Nguyen"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.31.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b2c91b73-b593-5cf7-a766-c7ebb56a4cae.pdf",
    "abstract": "We describe our experiments for SemEval-2023 Task 4 on the identification of human values behind arguments (ValueEval). Because human values are subjective concepts which require precise definitions, we hypothesize that incorporating the definitions of human values (in the form of annotation instructions and validated survey items) during model training can yield better prediction performance. We explore this idea and show that our proposed models perform better than the challenge organizersâ€™ baselines, with improvements in macro F1 scores of up to 18%.",
    "num_pages": 9
}