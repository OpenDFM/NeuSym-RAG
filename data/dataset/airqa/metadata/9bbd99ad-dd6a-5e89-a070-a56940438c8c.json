{
    "uuid": "9bbd99ad-dd6a-5e89-a070-a56940438c8c",
    "title": "HAUSER: Towards Holistic and Automatic Evaluation of Simile Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{he-etal-2023-hauser,\n    title = \"{HAUSER}: Towards Holistic and Automatic Evaluation of Simile Generation\",\n    author = \"He, Qianyu  and\n      Zhang, Yikai  and\n      Liang, Jiaqing  and\n      Huang, Yuncheng  and\n      Xiao, Yanghua  and\n      Chen, Yunwen\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.702\",\n    doi = \"10.18653/v1/2023.acl-long.702\",\n    pages = \"12557--12572\",\n    abstract = \"Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation. To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion. Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics. Resources of HAUSER are publicly available at \\url{https://github.com/Abbey4799/HAUSER}.\",\n}\n",
    "authors": [
        "Qianyu He",
        "Yikai Zhang",
        "Jiaqing Liang",
        "Yuncheng Huang",
        "Yanghua Xiao",
        "Yunwen Chen"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.702.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/9bbd99ad-dd6a-5e89-a070-a56940438c8c.pdf",
    "abstract": "Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation. To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion. Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics. Resources of HAUSER are publicly available at https://github.com/Abbey4799/HAUSER.",
    "num_pages": 16
}