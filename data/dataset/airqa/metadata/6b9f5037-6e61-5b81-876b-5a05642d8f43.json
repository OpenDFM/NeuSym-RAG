{
    "uuid": "6b9f5037-6e61-5b81-876b-5a05642d8f43",
    "title": "Teddysum at MEDIQA-Chat 2023: an analysis of fine-tuning strategy for long dialog summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{jeong-etal-2023-teddysum,\n    title = \"Teddysum at {MEDIQA}-Chat 2023: an analysis of fine-tuning strategy for long dialog summarization\",\n    author = \"Jeong, Yongbin  and\n      Han, Ju-Hyuck  and\n      Chae, Kyung Min  and\n      Cho, Yousang  and\n      Seo, Hyunbin  and\n      Lim, KyungTae  and\n      Choi, Key-Sun  and\n      Hahm, Younggyun\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.42\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.42\",\n    pages = \"394--402\",\n    abstract = \"In this paper, we introduce the design and various attempts for TaskB of MEDIQA-Chat 2023. The goal of TaskB in MEDIQA-Chat 2023 is to generate full clinical note from doctor-patient consultation dialogues. This task has several challenging issues, such as lack of training data, handling long dialogue inputs, and generating semi-structured clinical note which have section heads. To address these issues, we conducted various experiments and analyzed their results. We utilized the DialogLED model pre-trained on long dialogue data to handle long inputs, and we pre-trained on other dialogue datasets to address the lack of training data. We also attempted methods such as using prompts and contrastive learning for handling sections. This paper provides insights into clinical note generation through analyzing experimental methods and results, and it suggests future research directions.\",\n}\n",
    "authors": [
        "Yongbin Jeong",
        "Ju-Hyuck Han",
        "Kyung Min Chae",
        "Yousang Cho",
        "Hyunbin Seo",
        "KyungTae Lim",
        "Key-Sun Choi",
        "Younggyun Hahm"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.42.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/6b9f5037-6e61-5b81-876b-5a05642d8f43.pdf",
    "abstract": "In this paper, we introduce the design and various attempts for TaskB of MEDIQA-Chat 2023. The goal of TaskB in MEDIQA-Chat 2023 is to generate full clinical note from doctor-patient consultation dialogues. This task has several challenging issues, such as lack of training data, handling long dialogue inputs, and generating semi-structured clinical note which have section heads. To address these issues, we conducted various experiments and analyzed their results. We utilized the DialogLED model pre-trained on long dialogue data to handle long inputs, and we pre-trained on other dialogue datasets to address the lack of training data. We also attempted methods such as using prompts and contrastive learning for handling sections. This paper provides insights into clinical note generation through analyzing experimental methods and results, and it suggests future research directions.",
    "num_pages": 9
}