{
    "uuid": "24cd0ee2-4375-52a9-b455-e3d64e9494dd",
    "title": "KEEP CHATTING! An Attractive Dataset for Continuous Conversation Agents",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{wang-etal-2024-keep,\n    title = \"{KEEP} {CHATTING}! An Attractive Dataset for Continuous Conversation Agents\",\n    author = \"Wang, Yihe  and\n      Liu, Jin  and\n      Wan, Yao  and\n      Li, Yitong  and\n      Liu, Zifeng  and\n      Chen, Weipeng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.972\",\n    doi = \"10.18653/v1/2024.findings-acl.972\",\n    pages = \"16408--16414\",\n    abstract = \"Ongoing chatting is an important step for conversational agents to build long-term connections with people. However, people tend to quickly lose interest in chatting if the conversational agent{'}s words are not engaging enough. In this paper, we present a novel task of increasing users{'} willingness to continue talking to the agent.We collect a dataset named ContinuousChat by: (i) collecting personas and revising them, and then expanding the personas to detailed-personas through experiences, daily life, future plans, or interesting stories; (ii) expanding detailed-personas into the dialogues, and inject emotions and feelings into them; (iii) rewriting the dialogues in specific styles through few-shot prompt, conditioning on handwritten style-specific examples.We benchmark LLMs on ContinuousChat Dataset using both fine-tuning and in-context learning settings. Experiments over publicly available models demonstrate that although there is substantial room for improvement in generating style-specific dialogues, our ContinuousChat dataset is valuable in guiding conversational agents to generate more attractive dialogues and increase users{'} willingness to continue the conversations.\",\n}\n",
    "authors": [
        "Yihe Wang",
        "Jin Liu",
        "Yao Wan",
        "Yitong Li",
        "Zifeng Liu",
        "Weipeng Chen"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.972.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/24cd0ee2-4375-52a9-b455-e3d64e9494dd.pdf",
    "abstract": "Ongoing chatting is an important step for conversational agents to build long-term connections with people. However, people tend to quickly lose interest in chatting if the conversational agent’s words are not engaging enough. In this paper, we present a novel task of increasing users’ willingness to continue talking to the agent.We collect a dataset named ContinuousChat by: (i) collecting personas and revising them, and then expanding the personas to detailed-personas through experiences, daily life, future plans, or interesting stories; (ii) expanding detailed-personas into the dialogues, and inject emotions and feelings into them; (iii) rewriting the dialogues in specific styles through few-shot prompt, conditioning on handwritten style-specific examples.We benchmark LLMs on ContinuousChat Dataset using both fine-tuning and in-context learning settings. Experiments over publicly available models demonstrate that although there is substantial room for improvement in generating style-specific dialogues, our ContinuousChat dataset is valuable in guiding conversational agents to generate more attractive dialogues and increase users’ willingness to continue the conversations.",
    "num_pages": 7
}