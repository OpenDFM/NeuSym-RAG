{
    "uuid": "9df1b99d-a352-58ea-b1b7-d0780730f87a",
    "title": "SumSurvey: An Abstractive Dataset of Scientific Survey Papers for Long Document Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{liu-etal-2024-sumsurvey,\n    title = \"{S}um{S}urvey: An Abstractive Dataset of Scientific Survey Papers for Long Document Summarization\",\n    author = \"Liu, Ran  and\n      Liu, Ming  and\n      Yu, Min  and\n      Zhang, He  and\n      Jiang, Jianguo  and\n      Li, Gang  and\n      Huang, Weiqing\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.574\",\n    doi = \"10.18653/v1/2024.findings-acl.574\",\n    pages = \"9632--9651\",\n    abstract = \"With the popularity of large language models (LLMs) and their ability to handle longer input documents, there is a growing need for high-quality long document summarization datasets. Although many models already support 16k input, current lengths of summarization datasets are inadequate, and salient information is not evenly distributed. To bridge these gaps, we collect a new summarization dataset called SumSurvey, consisting of more than 18k scientific survey papers. With an average document length exceeding 12k and a quarter exceeding 16k, as well as the uniformity metric outperforming current mainstream long document summarization datasets, SumSurvey brings new challenges and expectations to both fine-tuned models and LLMs. The informativeness of summaries and the models supporting the evaluation of long document summarization warrant further attention. Automatic and human evaluation results on this abstractive dataset confirm this view. Our dataset and code are available at https://github.com/Oswald1997/SumSurvey.\",\n}\n",
    "authors": [
        "Ran Liu",
        "Ming Liu",
        "Min Yu",
        "He Zhang",
        "Jianguo Jiang",
        "Gang Li",
        "Weiqing Huang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.574.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9df1b99d-a352-58ea-b1b7-d0780730f87a.pdf",
    "abstract": "With the popularity of large language models (LLMs) and their ability to handle longer input documents, there is a growing need for high-quality long document summarization datasets. Although many models already support 16k input, current lengths of summarization datasets are inadequate, and salient information is not evenly distributed. To bridge these gaps, we collect a new summarization dataset called SumSurvey, consisting of more than 18k scientific survey papers. With an average document length exceeding 12k and a quarter exceeding 16k, as well as the uniformity metric outperforming current mainstream long document summarization datasets, SumSurvey brings new challenges and expectations to both fine-tuned models and LLMs. The informativeness of summaries and the models supporting the evaluation of long document summarization warrant further attention. Automatic and human evaluation results on this abstractive dataset confirm this view. Our dataset and code are available at https://github.com/Oswald1997/SumSurvey.",
    "num_pages": 20
}