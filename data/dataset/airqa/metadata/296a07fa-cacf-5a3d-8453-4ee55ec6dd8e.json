{
    "uuid": "296a07fa-cacf-5a3d-8453-4ee55ec6dd8e",
    "title": "WangLab at MEDIQA-Chat 2023: Clinical Note Generation from Doctor-Patient Conversations using Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{giorgi-etal-2023-wanglab,\n    title = \"{W}ang{L}ab at {MEDIQA}-Chat 2023: Clinical Note Generation from Doctor-Patient Conversations using Large Language Models\",\n    author = \"Giorgi, John  and\n      Toma, Augustin  and\n      Xie, Ronald  and\n      Chen, Sondra  and\n      An, Kevin  and\n      Zheng, Grace  and\n      Wang, Bo\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.36\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.36\",\n    pages = \"323--334\",\n    abstract = \"This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.\",\n}\n",
    "authors": [
        "John Giorgi",
        "Augustin Toma",
        "Ronald Xie",
        "Sondra Chen",
        "Kevin An",
        "Grace Zheng",
        "Bo Wang"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.36.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/296a07fa-cacf-5a3d-8453-4ee55ec6dd8e.pdf",
    "abstract": "This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.",
    "num_pages": 12
}