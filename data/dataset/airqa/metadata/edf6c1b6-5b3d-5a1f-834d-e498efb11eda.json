{
    "uuid": "edf6c1b6-5b3d-5a1f-834d-e498efb11eda",
    "title": "Linguistic Properties of Truthful Response",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)",
    "bibtex": "@inproceedings{lee-etal-2023-linguistic,\n    title = \"Linguistic Properties of Truthful Response\",\n    author = \"Lee, Bruce W.  and\n      Arockiaraj, Benedict Florance  and\n      Jin, Helen\",\n    editor = \"Ovalle, Anaelia  and\n      Chang, Kai-Wei  and\n      Mehrabi, Ninareh  and\n      Pruksachatkun, Yada  and\n      Galystan, Aram  and\n      Dhamala, Jwala  and\n      Verma, Apurv  and\n      Cao, Trista  and\n      Kumar, Anoop  and\n      Gupta, Rahul\",\n    booktitle = \"Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.trustnlp-1.12\",\n    doi = \"10.18653/v1/2023.trustnlp-1.12\",\n    pages = \"135--140\",\n    abstract = \"We investigate the phenomenon of an LLM{'}s untruthful response using a large set of 220 handcrafted linguistic features. We focus on GPT-3 models and find that the linguistic profiles of responses are similar across model sizes. That is, how varying-sized LLMs respond to given prompts stays similar on the linguistic properties level. We expand upon this finding by training support vector machines that rely only upon the stylistic components of model responses to classify the truthfulness of statements. Though the dataset size limits our current findings, we present promising evidence that truthfulness detection is possible without evaluating the content itself. We release our code and raw data.\",\n}\n",
    "authors": [
        "Bruce W. Lee",
        "Benedict Florance Arockiaraj",
        "Helen Jin"
    ],
    "pdf_url": "https://aclanthology.org/2023.trustnlp-1.12.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/edf6c1b6-5b3d-5a1f-834d-e498efb11eda.pdf",
    "abstract": "We investigate the phenomenon of an LLMâ€™s untruthful response using a large set of 220 handcrafted linguistic features. We focus on GPT-3 models and find that the linguistic profiles of responses are similar across model sizes. That is, how varying-sized LLMs respond to given prompts stays similar on the linguistic properties level. We expand upon this finding by training support vector machines that rely only upon the stylistic components of model responses to classify the truthfulness of statements. Though the dataset size limits our current findings, we present promising evidence that truthfulness detection is possible without evaluating the content itself. We release our code and raw data.",
    "num_pages": 6
}