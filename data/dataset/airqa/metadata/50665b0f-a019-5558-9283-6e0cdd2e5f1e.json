{
    "uuid": "50665b0f-a019-5558-9283-6e0cdd2e5f1e",
    "title": "Computer says “No”: The Case Against Empathetic Conversational AI",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{cercas-curry-cercas-curry-2023-computer,\n    title = \"Computer says {``}No{''}: The Case Against Empathetic Conversational {AI}\",\n    author = \"Curry, Alba  and\n      Cercas Curry, Amanda\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.515\",\n    doi = \"10.18653/v1/2023.findings-acl.515\",\n    pages = \"8123--8130\",\n    abstract = \"Emotions are an integral part of human cognition and they guide not only our understanding of the world but also our actions within it. As such, whether we soothe or flame an emotion is not inconsequential. Recent work in conversational AI has focused on responding empathetically to users, validating and soothing their emotions without a real basis. This AI-aided emotional regulation can have negative consequences for users and society, tending towards a one-noted happiness defined as only the absence of {``}negative{''} emotions. We argue that we must carefully consider whether and how to respond to users{'} emotions.\",\n}\n",
    "authors": [
        "Alba Curry",
        "Amanda Cercas Curry"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.515.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/50665b0f-a019-5558-9283-6e0cdd2e5f1e.pdf",
    "abstract": "Emotions are an integral part of human cognition and they guide not only our understanding of the world but also our actions within it. As such, whether we soothe or flame an emotion is not inconsequential. Recent work in conversational AI has focused on responding empathetically to users, validating and soothing their emotions without a real basis. This AI-aided emotional regulation can have negative consequences for users and society, tending towards a one-noted happiness defined as only the absence of “negative” emotions. We argue that we must carefully consider whether and how to respond to users’ emotions.",
    "num_pages": 8
}