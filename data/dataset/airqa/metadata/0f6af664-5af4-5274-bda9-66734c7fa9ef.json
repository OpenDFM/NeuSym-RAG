{
    "uuid": "0f6af664-5af4-5274-bda9-66734c7fa9ef",
    "title": "TeamEC at SemEval-2023 Task 4: Transformers vs. Low-Resource Dictionaries, Expert Dictionary vs. Learned Dictionary",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{stefanovitch-etal-2023-teamec,\n    title = \"{T}eam{EC} at {S}em{E}val-2023 Task 4: Transformers vs. Low-Resource Dictionaries, Expert Dictionary vs. Learned Dictionary\",\n    author = \"Stefanovitch, Nicolas  and\n      De Longueville, Bertrand  and\n      Scharfbillig, Mario\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.290\",\n    doi = \"10.18653/v1/2023.semeval-1.290\",\n    pages = \"2107--2111\",\n    abstract = \"This paper describes the system we used to participate in the shared task, as well as additional experiments beyond the scope of the shared task, but using its data. Our primary goal is to compare the effectiveness of transformers model compared to low-resource dictionaries. Secondly, we compare the difference in performance of a learned dictionary and of a dictionary designed by experts in the field of values. Our findings surprisingly show that transformers perform on par with a dictionary containing less than 1k words, when evaluated with 19 fine-grained categories, and only outperform a dictionary-based approach in a coarse setting with 10 categories. Interestingly, the expert dictionary has a precision on par with the learned one, while its recall is clearly lower, potentially an indication of overfitting of topics to values in the shared task{'}s dataset. Our findings should be of interest to both the NLP and Value scientific communities on the use of automated approaches for value classification\",\n}\n",
    "authors": [
        "Nicolas Stefanovitch",
        "Bertrand De Longueville",
        "Mario Scharfbillig"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.290.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0f6af664-5af4-5274-bda9-66734c7fa9ef.pdf",
    "abstract": "This paper describes the system we used to participate in the shared task, as well as additional experiments beyond the scope of the shared task, but using its data. Our primary goal is to compare the effectiveness of transformers model compared to low-resource dictionaries. Secondly, we compare the difference in performance of a learned dictionary and of a dictionary designed by experts in the field of values. Our findings surprisingly show that transformers perform on par with a dictionary containing less than 1k words, when evaluated with 19 fine-grained categories, and only outperform a dictionary-based approach in a coarse setting with 10 categories. Interestingly, the expert dictionary has a precision on par with the learned one, while its recall is clearly lower, potentially an indication of overfitting of topics to values in the shared taskâ€™s dataset. Our findings should be of interest to both the NLP and Value scientific communities on the use of automated approaches for value classification",
    "num_pages": 5
}