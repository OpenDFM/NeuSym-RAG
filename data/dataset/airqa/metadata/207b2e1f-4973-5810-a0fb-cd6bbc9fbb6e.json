{
    "uuid": "207b2e1f-4973-5810-a0fb-cd6bbc9fbb6e",
    "title": "Team:PULSAR at ProbSum 2023:PULSAR: Pre-training with Extracted Healthcare Terms for Summarising Patients’ Problems and Data Augmentation with Black-box Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
    "bibtex": "@inproceedings{li-etal-2023-team,\n    title = \"Team:{PULSAR} at {P}rob{S}um 2023:{PULSAR}: Pre-training with Extracted Healthcare Terms for Summarising Patients{'} Problems and Data Augmentation with Black-box Large Language Models\",\n    author = \"Li, Hao  and\n      Wu, Yuping  and\n      Schlegel, Viktor  and\n      Batista-Navarro, Riza  and\n      Nguyen, Thanh-Tung  and\n      Ramesh Kashyap, Abhinav  and\n      Zeng, Xiao-Jun  and\n      Beck, Daniel  and\n      Winkler, Stefan  and\n      Nenadic, Goran\",\n    editor = \"Demner-fushman, Dina  and\n      Ananiadou, Sophia  and\n      Cohen, Kevin\",\n    booktitle = \"The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bionlp-1.49\",\n    doi = \"10.18653/v1/2023.bionlp-1.49\",\n    pages = \"503--509\",\n    abstract = \"Medical progress notes play a crucial role in documenting a patient{'}s hospital journey, including his or her condition, treatment plan, and any updates for healthcare providers. Automatic summarisation of a patient{'}s problems in the form of a {``}problem list{''} can aid stakeholders in understanding a patient{'}s condition, reducing workload and cognitive bias. BioNLP 2023 Shared Task 1A focusses on generating a list of diagnoses and problems from the provider{'}s progress notes during hospitalisation. In this paper, we introduce our proposed approach to this task, which integrates two complementary components. One component employs large language models (LLMs) for data augmentation; the other is an abstractive summarisation LLM with a novel pre-training objective for generating the patients{'} problems summarised as a list. Our approach was ranked second among all submissions to the shared task. The performance of our model on the development and test datasets shows that our approach is more robust on unknown data, with an improvement of up to 3.1 points over the same size of the larger model.\",\n}\n",
    "authors": [
        "Hao Li",
        "Yuping Wu",
        "Viktor Schlegel",
        "Riza Batista-Navarro",
        "Thanh-Tung Nguyen",
        "Abhinav Ramesh Kashyap",
        "Xiao-Jun Zeng",
        "Daniel Beck",
        "Stefan Winkler",
        "Goran Nenadic"
    ],
    "pdf_url": "https://aclanthology.org/2023.bionlp-1.49.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/207b2e1f-4973-5810-a0fb-cd6bbc9fbb6e.pdf",
    "abstract": "Medical progress notes play a crucial role in documenting a patient’s hospital journey, including his or her condition, treatment plan, and any updates for healthcare providers. Automatic summarisation of a patient’s problems in the form of a “problem list” can aid stakeholders in understanding a patient’s condition, reducing workload and cognitive bias. BioNLP 2023 Shared Task 1A focusses on generating a list of diagnoses and problems from the provider’s progress notes during hospitalisation. In this paper, we introduce our proposed approach to this task, which integrates two complementary components. One component employs large language models (LLMs) for data augmentation; the other is an abstractive summarisation LLM with a novel pre-training objective for generating the patients’ problems summarised as a list. Our approach was ranked second among all submissions to the shared task. The performance of our model on the development and test datasets shows that our approach is more robust on unknown data, with an improvement of up to 3.1 points over the same size of the larger model.",
    "num_pages": 7
}