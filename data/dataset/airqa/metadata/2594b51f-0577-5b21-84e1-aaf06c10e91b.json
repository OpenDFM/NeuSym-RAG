{
    "uuid": "2594b51f-0577-5b21-84e1-aaf06c10e91b",
    "title": "MAPO: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{she-etal-2024-mapo,\n    title = \"{MAPO}: Advancing Multilingual Reasoning through Multilingual-Alignment-as-Preference Optimization\",\n    author = \"She, Shuaijie  and\n      Zou, Wei  and\n      Huang, Shujian  and\n      Zhu, Wenhao  and\n      Liu, Xiang  and\n      Geng, Xiang  and\n      Chen, Jiajun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.539\",\n    doi = \"10.18653/v1/2024.acl-long.539\",\n    pages = \"10015--10027\",\n    abstract = \"Intuitively, reasoning abilities are considered language-agnostic. However, existing LLMs exhibit inconsistent reasoning abilities across different languages, e.g., reasoning in the dominant language like English is superior to other languages due to the imbalance of multilingual training data. To enhance reasoning abilities in non-dominant languages, we propose a Multilingual-Alignment-as-Preference Optimization framework (MAPO) to align the reasoning processes in other languages with the dominant language. Specifically, we harness an off-the-shelf translation model for the consistency between answers in non-dominant and dominant languages, which we adopt as the preference for optimization, e.g., Direct Preference Optimization(DPO) or Proximal Policy Optimization (PPO). Experiments show that MAPO stably achieves significant improvements in the multilingual reasoning of various models on all three benchmarks (MSVAMP +16.2{\\%}, MGSM +6.1{\\%}, and MNumGLUESub +13.3{\\%}), with improved reasoning consistency across languages. The project is available at https://github.com/NJUNLP/MAPO.\",\n}\n",
    "authors": [
        "Shuaijie She",
        "Wei Zou",
        "Shujian Huang",
        "Wenhao Zhu",
        "Xiang Liu",
        "Xiang Geng",
        "Jiajun Chen"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.539.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/2594b51f-0577-5b21-84e1-aaf06c10e91b.pdf",
    "abstract": "Intuitively, reasoning abilities are considered language-agnostic. However, existing LLMs exhibit inconsistent reasoning abilities across different languages, e.g., reasoning in the dominant language like English is superior to other languages due to the imbalance of multilingual training data. To enhance reasoning abilities in non-dominant languages, we propose a Multilingual-Alignment-as-Preference Optimization framework (MAPO) to align the reasoning processes in other languages with the dominant language. Specifically, we harness an off-the-shelf translation model for the consistency between answers in non-dominant and dominant languages, which we adopt as the preference for optimization, e.g., Direct Preference Optimization(DPO) or Proximal Policy Optimization (PPO). Experiments show that MAPO stably achieves significant improvements in the multilingual reasoning of various models on all three benchmarks (MSVAMP +16.2%, MGSM +6.1%, and MNumGLUESub +13.3%), with improved reasoning consistency across languages. The project is available at https://github.com/NJUNLP/MAPO.",
    "num_pages": 13
}