{
    "uuid": "346590a3-f637-5387-85a2-55a8cd01360f",
    "title": "TOREE: Evaluating Topic Relevance of Student Essays for Chinese Primary and Middle School Education",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhuang-etal-2024-toree,\n    title = \"{TOREE}: Evaluating Topic Relevance of Student Essays for {C}hinese Primary and Middle School Education\",\n    author = \"Zhuang, Xinlin  and\n      Wu, Hongyi  and\n      Shen, Xinshu  and\n      Yu, Peimin  and\n      Yi, Gaowei  and\n      Chen, Xinhao  and\n      Hu, Tu  and\n      Chen, Yang  and\n      Ren, Yupei  and\n      Zhang, Yadong  and\n      Song, Youqi  and\n      Liu, Binxuan  and\n      Lan, Man\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.342\",\n    doi = \"10.18653/v1/2024.findings-acl.342\",\n    pages = \"5749--5765\",\n    abstract = \"Topic relevance of an essay demands that the composition adheres to a clear theme and aligns well with the essay prompt requirements, a critical aspect of essay quality evaluation. However, existing research of Automatic Essay Scoring (AES) for Chinese essays has overlooked topic relevance and lacks detailed feedback, while Automatic Essay Comment Generation (AECG) faces much complexity and difficulty. Additionally, current Large Language Models, including GPT-4, often make incorrect judgments and provide overly impractical feedback when evaluating topic relevance. This paper introduces \\textbf{TOREE} (\\textbf{To}pic \\textbf{Re}levance \\textbf{E}valuation), a comprehensive dataset developed to assess topic relevance in Chinese primary and middle school students{'} essays, which is beneficial for AES, AECG and other applications. Moreover, our proposed two-step method utilizes TOREE through a combination of Supervised Fine-tuning and Preference Learning. Experimental results demonstrate that TOREE is of high quality, and our method significantly enhances models{'} performance on two designed tasks for topic relevance evaluation, improving both automatic and human evaluations across four diverse LLMs.\",\n}\n",
    "authors": [
        "Xinlin Zhuang",
        "Hongyi Wu",
        "Xinshu Shen",
        "Peimin Yu",
        "Gaowei Yi",
        "Xinhao Chen",
        "Tu Hu",
        "Yang Chen",
        "Yupei Ren",
        "Yadong Zhang",
        "Youqi Song",
        "Binxuan Liu",
        "Man Lan"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.342.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/346590a3-f637-5387-85a2-55a8cd01360f.pdf",
    "abstract": "Topic relevance of an essay demands that the composition adheres to a clear theme and aligns well with the essay prompt requirements, a critical aspect of essay quality evaluation. However, existing research of Automatic Essay Scoring (AES) for Chinese essays has overlooked topic relevance and lacks detailed feedback, while Automatic Essay Comment Generation (AECG) faces much complexity and difficulty. Additionally, current Large Language Models, including GPT-4, often make incorrect judgments and provide overly impractical feedback when evaluating topic relevance. This paper introduces TOREE (Topic Relevance Evaluation), a comprehensive dataset developed to assess topic relevance in Chinese primary and middle school students’ essays, which is beneficial for AES, AECG and other applications. Moreover, our proposed two-step method utilizes TOREE through a combination of Supervised Fine-tuning and Preference Learning. Experimental results demonstrate that TOREE is of high quality, and our method significantly enhances models’ performance on two designed tasks for topic relevance evaluation, improving both automatic and human evaluations across four diverse LLMs.",
    "num_pages": 17
}