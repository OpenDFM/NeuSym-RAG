{
    "uuid": "7e2d0d2c-01f3-5f01-8b12-ab3642a520c7",
    "title": "Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{dutt-etal-2024-leveraging,\n    title = \"Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations\",\n    author = \"Dutt, Ritam  and\n      Wu, Zhen  and\n      Shi, Jiaxin  and\n      Sheth, Divyanshu  and\n      Gupta, Prakhar  and\n      Rose, Carolyn\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.373\",\n    doi = \"10.18653/v1/2024.acl-long.373\",\n    pages = \"6901--6929\",\n    abstract = \"We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of implicitly encoded social meaning in conversations. We design a multi-faceted prompt to extract a textual explanation of the reasoning that connects visible cues to underlying social meanings. These extracted explanations or rationales serve as augmentations to the conversational text to facilitate dialogue understanding and transfer. Our empirical results over 2,340 experimental settings demonstrate the significant positive impact of adding these rationales. Our findings hold true for in-domain classification, zero-shot, and few-shot domain transfer for two different social meaning detection tasks, each spanning two different corpora.\",\n}\n",
    "authors": [
        "Ritam Dutt",
        "Zhen Wu",
        "Jiaxin Shi",
        "Divyanshu Sheth",
        "Prakhar Gupta",
        "Carolyn Rose"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.373.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/7e2d0d2c-01f3-5f01-8b12-ab3642a520c7.pdf",
    "abstract": "We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of implicitly encoded social meaning in conversations. We design a multi-faceted prompt to extract a textual explanation of the reasoning that connects visible cues to underlying social meanings. These extracted explanations or rationales serve as augmentations to the conversational text to facilitate dialogue understanding and transfer. Our empirical results over 2,340 experimental settings demonstrate the significant positive impact of adding these rationales. Our findings hold true for in-domain classification, zero-shot, and few-shot domain transfer for two different social meaning detection tasks, each spanning two different corpora.",
    "num_pages": 29
}