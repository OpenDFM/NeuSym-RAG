{
    "uuid": "128e2c4f-82f0-5d56-9316-5e37bb1c5307",
    "title": "Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 7th Workshop on Online Abuse and Harms (WOAH)",
    "bibtex": "@inproceedings{plaza-del-arco-etal-2023-respectful,\n    title = \"Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech\",\n    author = \"Plaza-del-arco, Flor Miriam  and\n      Nozza, Debora  and\n      Hovy, Dirk\",\n    editor = {Chung, Yi-ling  and\n      R{{\\textbackslash}\"ottger}, Paul  and\n      Nozza, Debora  and\n      Talat, Zeerak  and\n      Mostafazadeh Davani, Aida},\n    booktitle = \"The 7th Workshop on Online Abuse and Harms (WOAH)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.woah-1.6\",\n    doi = \"10.18653/v1/2023.woah-1.6\",\n    pages = \"60--68\",\n    abstract = \"Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.\",\n}\n",
    "authors": [
        "Flor Miriam Plaza-del-arco",
        "Debora Nozza",
        "Dirk Hovy"
    ],
    "pdf_url": "https://aclanthology.org/2023.woah-1.6.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/128e2c4f-82f0-5d56-9316-5e37bb1c5307.pdf",
    "abstract": "Hate speech detection faces two significant challenges: 1) the limited availability of labeled data and 2) the high variability of hate speech across different contexts and languages. Prompting brings a ray of hope to these challenges. It allows injecting a model with task-specific knowledge without relying on labeled data. This paper explores zero-shot learning with prompting for hate speech detection. We investigate how well zero-shot learning can detect hate speech in 3 languages with limited labeled data. We experiment with various large language models and verbalizers on 8 benchmark datasets. Our findings highlight the impact of prompt selection on the results. They also suggest that prompting, specifically with recent large language models, can achieve performance comparable to and surpass fine-tuned models, making it a promising alternative for under-resourced languages. Our findings highlight the potential of prompting for hate speech detection and show how both the prompt and the model have a significant impact on achieving more accurate predictions in this task.",
    "num_pages": 9
}