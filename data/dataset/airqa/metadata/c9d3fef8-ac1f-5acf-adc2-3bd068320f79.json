{
    "uuid": "c9d3fef8-ac1f-5acf-adc2-3bd068320f79",
    "title": "CR-LLM: A Dataset and Optimization for Concept Reasoning of Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{li-etal-2024-cr,\n    title = \"{CR}-{LLM}: A Dataset and Optimization for Concept Reasoning of Large Language Models\",\n    author = \"Li, Nianqi  and\n      Liu, Jingping  and\n      Jiang, Sihang  and\n      Jiang, Haiyun  and\n      Xiao, Yanghua  and\n      Liang, Jiaqing  and\n      Liang, Zujie  and\n      Wei, Feng  and\n      Chen, Jinglei  and\n      Hao, Zhenghong  and\n      Han, Bing\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.815\",\n    doi = \"10.18653/v1/2024.findings-acl.815\",\n    pages = \"13737--13747\",\n    abstract = \"Concept reasoning is an important capability for models to understand the world. However, the existing datasets, such as concept extraction and concept generation, suffer from modeledge leakage and context leakage. To address these limitations, we construct a dataset of concept reasoning for large language models (CR-LLM) with modeledge leakage prevention and context leakage prevention, which consists of 2,167 samples and covers different concept types. In addition, we propose a hybrid reasoning method, consisting of inductive reasoning, deductive reasoning and a controller. This method allows large language models to adaptively select the optimal reasoning method for each input sample. Finally, we conduct extensive experiments on CR-LLM using different models and methods. The results show that existing large language models and reasoning methods perform sub-optimally in the concept reasoning task. In contrast, our proposed method significantly improves the capabilities, achieving a 7{\\%} increase in accuracy compared to CoT and demonstrating better granularity. We release CR-LLM and code at https://github.com/Nianqi-Li/Concept-Reasoning-for-LLMs.\",\n}\n",
    "authors": [
        "Nianqi Li",
        "Jingping Liu",
        "Sihang Jiang",
        "Haiyun Jiang",
        "Yanghua Xiao",
        "Jiaqing Liang",
        "Zujie Liang",
        "Feng Wei",
        "Jinglei Chen",
        "Zhenghong Hao",
        "Bing Han"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.815.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/c9d3fef8-ac1f-5acf-adc2-3bd068320f79.pdf",
    "abstract": "Concept reasoning is an important capability for models to understand the world. However, the existing datasets, such as concept extraction and concept generation, suffer from modeledge leakage and context leakage. To address these limitations, we construct a dataset of concept reasoning for large language models (CR-LLM) with modeledge leakage prevention and context leakage prevention, which consists of 2,167 samples and covers different concept types. In addition, we propose a hybrid reasoning method, consisting of inductive reasoning, deductive reasoning and a controller. This method allows large language models to adaptively select the optimal reasoning method for each input sample. Finally, we conduct extensive experiments on CR-LLM using different models and methods. The results show that existing large language models and reasoning methods perform sub-optimally in the concept reasoning task. In contrast, our proposed method significantly improves the capabilities, achieving a 7% increase in accuracy compared to CoT and demonstrating better granularity. We release CR-LLM and code at https://github.com/Nianqi-Li/Concept-Reasoning-for-LLMs.",
    "num_pages": 11
}