{
    "uuid": "722396a4-6971-5864-a55b-843c66451afb",
    "title": "Cited Text Spans for Scientific Citation Text Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Fourth Workshop on Scholarly Document Processing (SDP 2024)",
    "bibtex": "@inproceedings{li-etal-2024-cited,\n    title = \"Cited Text Spans for Scientific Citation Text Generation\",\n    author = \"Li, Xiangci  and\n      Lee, Yi-Hui  and\n      Ouyang, Jessica\",\n    editor = \"Ghosal, Tirthankar  and\n      Singh, Amanpreet  and\n      Waard, Anita  and\n      Mayr, Philipp  and\n      Naik, Aakanksha  and\n      Weller, Orion  and\n      Lee, Yoonjoo  and\n      Shen, Shannon  and\n      Qin, Yanxia\",\n    booktitle = \"Proceedings of the Fourth Workshop on Scholarly Document Processing (SDP 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sdp-1.9\",\n    pages = \"90--104\",\n    abstract = \"An automatic citation generation system aims to concisely and accurately describe the relationship between two scientific articles. To do so, such a system must ground its outputs to the content of the cited paper to avoid non-factual hallucinations. Due to the length of scientific documents, existing abstractive approaches have conditioned only on cited paper \\textit{abstracts}. We demonstrate empirically that the abstract is not always the most appropriate input for citation generation and that models trained in this way learn to hallucinate. We propose to condition instead on the \\textit{cited text span} (CTS) as an alternative to the abstract. Because manual CTS annotation is extremely time- and labor-intensive, we experiment with distant labeling of candidate CTS sentences, achieving sufficiently strong performance to substitute for expensive human annotations in model training, and we propose a human-in-the-loop, keyword-based CTS retrieval approach that makes generating citation texts grounded in the full text of cited papers both promising and practical.\",\n}\n",
    "authors": [
        "Xiangci Li",
        "Yi-Hui Lee",
        "Jessica Ouyang"
    ],
    "pdf_url": "https://aclanthology.org/2024.sdp-1.9.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/722396a4-6971-5864-a55b-843c66451afb.pdf",
    "abstract": "An automatic citation generation system aims to concisely and accurately describe the relationship between two scientific articles. To do so, such a system must ground its outputs to the content of the cited paper to avoid non-factual hallucinations. Due to the length of scientific documents, existing abstractive approaches have conditioned only on cited paper abstracts. We demonstrate empirically that the abstract is not always the most appropriate input for citation generation and that models trained in this way learn to hallucinate. We propose to condition instead on the cited text span (CTS) as an alternative to the abstract. Because manual CTS annotation is extremely time- and labor-intensive, we experiment with distant labeling of candidate CTS sentences, achieving sufficiently strong performance to substitute for expensive human annotations in model training, and we propose a human-in-the-loop, keyword-based CTS retrieval approach that makes generating citation texts grounded in the full text of cited papers both promising and practical.",
    "num_pages": 15
}