{
    "uuid": "9e4f3b3e-1d0c-58ae-b796-4ecd4961c3aa",
    "title": "Exploration of Contrastive Learning Strategies toward more Robust Stance Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{rajendran-trabelsi-2023-exploration,\n    title = \"Exploration of Contrastive Learning Strategies toward more Robust Stance Detection\",\n    author = \"Rajendran, Udhaya Kumar  and\n      Trabelsi, Amine\",\n    editor = \"Barnes, Jeremy  and\n      De Clercq, Orph{\\'e}e  and\n      Klinger, Roman\",\n    booktitle = \"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wassa-1.37\",\n    doi = \"10.18653/v1/2023.wassa-1.37\",\n    pages = \"431--440\",\n    abstract = \"Stance Detection is the task of identifying the position of an author of a text towards an issue or a target. Previous studies on Stance Detection indicate that the existing systems are non-robust to the variations and errors in input sentences. Our proposed methodology uses Contrastive Learning to learn sentence representations by bringing semantically similar sentences and sentences implying the same stance closer to each other in the embedding space. We compare our approach to a pretrained transformer model directly finetuned with the stance datasets. We use char-level and word-level adversarial perturbation attacks to measure the resilience of the models and we show that our approach achieves better performances and is more robust to the different adversarial perturbations introduced to the test data. The results indicate that our approach performs better on small-sized and class-imbalanced stance datasets.\",\n}\n",
    "authors": [
        "Udhaya Kumar Rajendran",
        "Amine Trabelsi"
    ],
    "pdf_url": "https://aclanthology.org/2023.wassa-1.37.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/9e4f3b3e-1d0c-58ae-b796-4ecd4961c3aa.pdf",
    "abstract": "Stance Detection is the task of identifying the position of an author of a text towards an issue or a target. Previous studies on Stance Detection indicate that the existing systems are non-robust to the variations and errors in input sentences. Our proposed methodology uses Contrastive Learning to learn sentence representations by bringing semantically similar sentences and sentences implying the same stance closer to each other in the embedding space. We compare our approach to a pretrained transformer model directly finetuned with the stance datasets. We use char-level and word-level adversarial perturbation attacks to measure the resilience of the models and we show that our approach achieves better performances and is more robust to the different adversarial perturbations introduced to the test data. The results indicate that our approach performs better on small-sized and class-imbalanced stance datasets.",
    "num_pages": 10
}