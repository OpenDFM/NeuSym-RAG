{
    "uuid": "33344abf-e5ee-5e2c-b606-fe49943d3af1",
    "title": "From Moments to Milestones: Incremental Timeline Summarization Leveraging Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{hu-etal-2024-moments,\n    title = \"From Moments to Milestones: Incremental Timeline Summarization Leveraging Large Language Models\",\n    author = \"Hu, Qisheng  and\n      Moon, Geonsik  and\n      Ng, Hwee Tou\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.390\",\n    doi = \"10.18653/v1/2024.acl-long.390\",\n    pages = \"7232--7246\",\n    abstract = \"Timeline summarization (TLS) is essential for distilling coherent narratives from a vast collection of texts, tracing the progression of events and topics over time. Prior research typically focuses on either event or topic timeline summarization, neglecting the potential synergy of these two forms. In this study, we bridge this gap by introducing a novel approach that leverages large language models (LLMs) for generating both event and topic timelines. Our approach diverges from conventional TLS by prioritizing event detection, leveraging LLMs as pseudo-oracles for incremental event clustering and the construction of timelines from a text stream. As a result, it produces a more interpretable pipeline. Empirical evaluation across four TLS benchmarks reveals that our approach outperforms the best prior published approaches, highlighting the potential of LLMs in timeline summarization for real-world applications.\",\n}\n",
    "authors": [
        "Qisheng Hu",
        "Geonsik Moon",
        "Hwee Tou Ng"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.390.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/33344abf-e5ee-5e2c-b606-fe49943d3af1.pdf",
    "abstract": "Timeline summarization (TLS) is essential for distilling coherent narratives from a vast collection of texts, tracing the progression of events and topics over time. Prior research typically focuses on either event or topic timeline summarization, neglecting the potential synergy of these two forms. In this study, we bridge this gap by introducing a novel approach that leverages large language models (LLMs) for generating both event and topic timelines. Our approach diverges from conventional TLS by prioritizing event detection, leveraging LLMs as pseudo-oracles for incremental event clustering and the construction of timelines from a text stream. As a result, it produces a more interpretable pipeline. Empirical evaluation across four TLS benchmarks reveals that our approach outperforms the best prior published approaches, highlighting the potential of LLMs in timeline summarization for real-world applications.",
    "num_pages": 15
}