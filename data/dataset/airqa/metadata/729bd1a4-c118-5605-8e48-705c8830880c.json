{
    "uuid": "729bd1a4-c118-5605-8e48-705c8830880c",
    "title": "TAME-RD: Text Assisted Replication of Image Multi-Adjustments for Reverse Designing",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{guhan-etal-2024-tame,\n    title = \"{TAME}-{RD}: Text Assisted Replication of Image Multi-Adjustments for Reverse Designing\",\n    author = \"Guhan, Pooja  and\n      Bhattacharya, Uttaran  and\n      Sarkhel, Somdeb  and\n      Azizi, Vahid  and\n      Chen, Xiang  and\n      Mitra, Saayan  and\n      Bera, Aniket  and\n      Manocha, Dinesh\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.637\",\n    doi = \"10.18653/v1/2024.findings-acl.637\",\n    pages = \"10710--10727\",\n    abstract = \"Given a source and its edited version performed based on human instructions in natural language, how do we extract the underlying edit operations, to automatically replicate similar edits on other images? This is the problem of reverse designing, and we present TAME-RD, a model to solve this problem. TAME-RD automatically learns from the complex interplay of image editing operations and the natural language instructions to learn fully specified edit operations. It predicts both the underlying image edit operations as discrete categories and their corresponding parameter values in the continuous space.We accomplish this by mapping together the contextual information from the natural language text and the structural differences between the corresponding source and edited images using the concept of pre-post effect. We demonstrate the efficiency of our network through quantitative evaluations on multiple datasets. We observe improvements of 6-10{\\%} on various accuracy metrics and 1.01X-4X on the RMSE score and the concordance correlation coefficient for the corresponding parameter values on the benchmark GIER dataset. We also introduce I-MAD, a new two-part dataset: I-MAD-Dense, a collection of approximately 100K source and edited images, together with automatically generated text instructions and annotated edit operations, and I-MAD-Pro, consisting of about 1.6K source and edited images, together with text instructions and annotated edit operations provided by professional editors. On our dataset, we observe absolute improvements of 1-10{\\%} on the accuracy metrics and 1.14X{--}5X on the RMSE score.\",\n}\n",
    "authors": [
        "Pooja Guhan",
        "Uttaran Bhattacharya",
        "Somdeb Sarkhel",
        "Vahid Azizi",
        "Xiang Chen",
        "Saayan Mitra",
        "Aniket Bera",
        "Dinesh Manocha"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.637.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/729bd1a4-c118-5605-8e48-705c8830880c.pdf",
    "abstract": "Given a source and its edited version performed based on human instructions in natural language, how do we extract the underlying edit operations, to automatically replicate similar edits on other images? This is the problem of reverse designing, and we present TAME-RD, a model to solve this problem. TAME-RD automatically learns from the complex interplay of image editing operations and the natural language instructions to learn fully specified edit operations. It predicts both the underlying image edit operations as discrete categories and their corresponding parameter values in the continuous space.We accomplish this by mapping together the contextual information from the natural language text and the structural differences between the corresponding source and edited images using the concept of pre-post effect. We demonstrate the efficiency of our network through quantitative evaluations on multiple datasets. We observe improvements of 6-10% on various accuracy metrics and 1.01X-4X on the RMSE score and the concordance correlation coefficient for the corresponding parameter values on the benchmark GIER dataset. We also introduce I-MAD, a new two-part dataset: I-MAD-Dense, a collection of approximately 100K source and edited images, together with automatically generated text instructions and annotated edit operations, and I-MAD-Pro, consisting of about 1.6K source and edited images, together with text instructions and annotated edit operations provided by professional editors. On our dataset, we observe absolute improvements of 1-10% on the accuracy metrics and 1.14Xâ€“5X on the RMSE score.",
    "num_pages": 18
}