{
    "uuid": "dff5618a-c9ee-585b-bf2b-eebc0c60f3c4",
    "title": "Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{lee-kim-2023-recursion,\n    title = \"Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models\",\n    author = \"Lee, Soochan  and\n      Kim, Gunhee\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.40\",\n    doi = \"10.18653/v1/2023.findings-acl.40\",\n    pages = \"623--658\",\n    abstract = \"Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models{'} (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs{'} inference capability to solve problems, whose solution consists of hundreds of thousands of tokens.\",\n}\n",
    "authors": [
        "Soochan Lee",
        "Gunhee Kim"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.40.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/dff5618a-c9ee-585b-bf2b-eebc0c60f3c4.pdf",
    "abstract": "Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models’ (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs’ inference capability to solve problems, whose solution consists of hundreds of thousands of tokens.",
    "num_pages": 36
}