{
    "uuid": "51dbf89a-2e10-5f34-a4c4-4635e987fbd2",
    "title": "Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{hallinan-etal-2023-detoxifying,\n    title = \"Detoxifying Text with {M}a{RC}o: Controllable Revision with Experts and Anti-Experts\",\n    author = \"Hallinan, Skyler  and\n      Liu, Alisa  and\n      Choi, Yejin  and\n      Sap, Maarten\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.21\",\n    doi = \"10.18653/v1/2023.acl-short.21\",\n    pages = \"228--242\",\n    abstract = \"Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCo{'}s rewrites are preferred 2.1 times more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.\",\n}\n",
    "authors": [
        "Skyler Hallinan",
        "Alisa Liu",
        "Yejin Choi",
        "Maarten Sap"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.21.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/51dbf89a-2e10-5f34-a4c4-4635e987fbd2.pdf",
    "abstract": "Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCoâ€™s rewrites are preferred 2.1 times more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.",
    "num_pages": 15
}