{
    "uuid": "675c71e9-20f9-5314-82ba-e5c39bab6c4b",
    "title": "Type Enhanced BERT for Correcting NER Errors",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{li-etal-2023-type,\n    title = \"Type Enhanced {BERT} for Correcting {NER} Errors\",\n    author = \"Li, Kuai  and\n      Chen, Chen  and\n      Yang, Tao  and\n      Du, Tianming  and\n      Yu, Peijie  and\n      Du, Dong  and\n      Zhang, Feng\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.445\",\n    doi = \"10.18653/v1/2023.findings-acl.445\",\n    pages = \"7124--7131\",\n    abstract = \"We introduce the task of correcting named entity recognition (NER) errors without re-training model. After an NER model is trained and deployed in production,it makes prediction errors, which usually need to be fixed quickly. To address this problem, we firstly construct a gazetteer containing named entities and corresponding possible entity types. And then, we propose type enhanced BERT (TyBERT),a method that integrates the named entity{'}s type information into BERT by an adapter layer. When errors are identified, we can repair the model by updating the gazetteer. In other words, the gazetteer becomes a trigger to control NER model{'}s output. The experiment results in multiple corpus show the effectiveness of our method, which outperforms strong baselines.x\",\n}\n",
    "authors": [
        "Kuai Li",
        "Chen Chen",
        "Tao Yang",
        "Tianming Du",
        "Peijie Yu",
        "Dong Du",
        "Feng Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.445.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/675c71e9-20f9-5314-82ba-e5c39bab6c4b.pdf",
    "abstract": "We introduce the task of correcting named entity recognition (NER) errors without re-training model. After an NER model is trained and deployed in production,it makes prediction errors, which usually need to be fixed quickly. To address this problem, we firstly construct a gazetteer containing named entities and corresponding possible entity types. And then, we propose type enhanced BERT (TyBERT),a method that integrates the named entity’s type information into BERT by an adapter layer. When errors are identified, we can repair the model by updating the gazetteer. In other words, the gazetteer becomes a trigger to control NER model’s output. The experiment results in multiple corpus show the effectiveness of our method, which outperforms strong baselines.x",
    "num_pages": 8
}