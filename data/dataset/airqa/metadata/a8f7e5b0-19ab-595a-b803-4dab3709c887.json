{
    "uuid": "a8f7e5b0-19ab-595a-b803-4dab3709c887",
    "title": "Revisiting Interpolation Augmentation for Speech-to-Text Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{xu-etal-2024-revisiting,\n    title = \"Revisiting Interpolation Augmentation for Speech-to-Text Generation\",\n    author = \"Xu, Chen  and\n      Wang, Jie  and\n      Liu, Xiaoqian  and\n      Dong, Qian  and\n      Zhang, Chunliang  and\n      Xiao, Tong  and\n      Zhu, JingBo  and\n      Man, Dapeng  and\n      Yang, Wu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.565\",\n    doi = \"10.18653/v1/2024.findings-acl.565\",\n    pages = \"9488--9499\",\n    abstract = \"Speech-to-text (S2T) generation systems frequently face challenges in low-resource scenarios, primarily due to the lack of extensive labeled datasets. One emerging solution is constructing virtual training samples by interpolating inputs and labels, which has notably enhanced system generalization in other domains. Despite its potential, this technique{'}s application in S2T tasks has remained under-explored. In this paper, we delve into the utility of interpolation augmentation, guided by several pivotal questions. Our findings reveal that employing an appropriate strategy in interpolation augmentation significantly enhances performance across diverse tasks, architectures, and data scales, offering a promising avenue for more robust S2T systems in resource-constrained settings.\",\n}\n",
    "authors": [
        "Chen Xu",
        "Jie Wang",
        "Xiaoqian Liu",
        "Qian Dong",
        "Chunliang Zhang",
        "Tong Xiao",
        "JingBo Zhu",
        "Dapeng Man",
        "Wu Yang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.565.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a8f7e5b0-19ab-595a-b803-4dab3709c887.pdf",
    "abstract": "Speech-to-text (S2T) generation systems frequently face challenges in low-resource scenarios, primarily due to the lack of extensive labeled datasets. One emerging solution is constructing virtual training samples by interpolating inputs and labels, which has notably enhanced system generalization in other domains. Despite its potential, this techniqueâ€™s application in S2T tasks has remained under-explored. In this paper, we delve into the utility of interpolation augmentation, guided by several pivotal questions. Our findings reveal that employing an appropriate strategy in interpolation augmentation significantly enhances performance across diverse tasks, architectures, and data scales, offering a promising avenue for more robust S2T systems in resource-constrained settings.",
    "num_pages": 12
}