{
    "uuid": "aefa5954-ffdf-5031-bc54-4fa848d53520",
    "title": "Understanding Emotion Valence is a Joint Deep Learning Task",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{roccabruna-etal-2023-understanding,\n    title = \"Understanding Emotion Valence is a Joint Deep Learning Task\",\n    author = \"Roccabruna, Gabriel  and\n      Mousavi, Seyed Mahed  and\n      Riccardi, Giuseppe\",\n    editor = \"Barnes, Jeremy  and\n      De Clercq, Orph{\\'e}e  and\n      Klinger, Roman\",\n    booktitle = \"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wassa-1.9\",\n    doi = \"10.18653/v1/2023.wassa-1.9\",\n    pages = \"85--95\",\n    abstract = \"The valence analysis of speakers{'} utterances or written posts helps to understand the activation and variations of the emotional state throughout the conversation. More recently, the concept of Emotion Carriers (EC) has been introduced to explain the emotion felt by the speaker and its manifestations. In this work, we investigate the natural inter-dependency of valence and ECs via a multi-task learning approach. We experiment with Pre-trained Language Models (PLM) for single-task, two-step, and joint settings for the valence and EC prediction tasks. We compare and evaluate the performance of generative (GPT-2) and discriminative (BERT) architectures in each setting. We observed that providing the ground truth label of one task improves the prediction performance of the models in the other task. We further observed that the discriminative model achieves the best trade-off of valence and EC prediction tasks in the joint prediction setting. As a result, we attain a single model that performs both tasks, thus, saving computation resources at training and inference times.\",\n}\n",
    "authors": [
        "Gabriel Roccabruna",
        "Seyed Mahed Mousavi",
        "Giuseppe Riccardi"
    ],
    "pdf_url": "https://aclanthology.org/2023.wassa-1.9.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/aefa5954-ffdf-5031-bc54-4fa848d53520.pdf",
    "abstract": "The valence analysis of speakersâ€™ utterances or written posts helps to understand the activation and variations of the emotional state throughout the conversation. More recently, the concept of Emotion Carriers (EC) has been introduced to explain the emotion felt by the speaker and its manifestations. In this work, we investigate the natural inter-dependency of valence and ECs via a multi-task learning approach. We experiment with Pre-trained Language Models (PLM) for single-task, two-step, and joint settings for the valence and EC prediction tasks. We compare and evaluate the performance of generative (GPT-2) and discriminative (BERT) architectures in each setting. We observed that providing the ground truth label of one task improves the prediction performance of the models in the other task. We further observed that the discriminative model achieves the best trade-off of valence and EC prediction tasks in the joint prediction setting. As a result, we attain a single model that performs both tasks, thus, saving computation resources at training and inference times.",
    "num_pages": 11
}