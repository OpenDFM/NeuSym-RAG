{
    "uuid": "5c400ff8-759b-5e0b-9ab8-8c86e7056251",
    "title": "Enhancing Language Representation with Constructional Information for Natural Language Understanding",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{xu-etal-2023-enhancing,\n    title = \"Enhancing Language Representation with Constructional Information for Natural Language Understanding\",\n    author = \"Xu, Lvxiaowei  and\n      Wu, Jianwang  and\n      Peng, Jiawei  and\n      Gong, Zhilin  and\n      Cai, Ming  and\n      Wang, Tianxiang\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.258\",\n    doi = \"10.18653/v1/2023.acl-long.258\",\n    pages = \"4685--4705\",\n    abstract = \"Natural language understanding (NLU) is an essential branch of natural language processing, which relies on representations generated by pre-trained language models (PLMs). However, PLMs primarily focus on acquiring lexico-semantic information, while they may be unable to adequately handle the meaning of constructions. To address this issue, we introduce construction grammar (CxG), which highlights the pairings of form and meaning, to enrich language representation. We adopt usage-based construction grammar as the basis of our work, which is highly compatible with statistical models such as PLMs. Then a HyCxG framework is proposed to enhance language representation through a three-stage solution. First, all constructions are extracted from sentences via a slot-constraints approach. As constructions can overlap with each other, bringing redundancy and imbalance, we formulate the conditional max coverage problem for selecting the discriminative constructions. Finally, we propose a relational hypergraph attention network to acquire representation from constructional information by capturing high-order word interactions among constructions. Extensive experiments demonstrate the superiority of the proposed model on a variety of NLU tasks.\",\n}\n",
    "authors": [
        "Lvxiaowei Xu",
        "Jianwang Wu",
        "Jiawei Peng",
        "Zhilin Gong",
        "Ming Cai",
        "Tianxiang Wang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.258.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/5c400ff8-759b-5e0b-9ab8-8c86e7056251.pdf",
    "abstract": "Natural language understanding (NLU) is an essential branch of natural language processing, which relies on representations generated by pre-trained language models (PLMs). However, PLMs primarily focus on acquiring lexico-semantic information, while they may be unable to adequately handle the meaning of constructions. To address this issue, we introduce construction grammar (CxG), which highlights the pairings of form and meaning, to enrich language representation. We adopt usage-based construction grammar as the basis of our work, which is highly compatible with statistical models such as PLMs. Then a HyCxG framework is proposed to enhance language representation through a three-stage solution. First, all constructions are extracted from sentences via a slot-constraints approach. As constructions can overlap with each other, bringing redundancy and imbalance, we formulate the conditional max coverage problem for selecting the discriminative constructions. Finally, we propose a relational hypergraph attention network to acquire representation from constructional information by capturing high-order word interactions among constructions. Extensive experiments demonstrate the superiority of the proposed model on a variety of NLU tasks.",
    "num_pages": 21
}