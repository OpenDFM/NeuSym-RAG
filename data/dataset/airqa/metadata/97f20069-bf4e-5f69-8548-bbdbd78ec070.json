{
    "uuid": "97f20069-bf4e-5f69-8548-bbdbd78ec070",
    "title": "Do LLMs Speak Kazakh? A Pilot Evaluation of Seven Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the First Workshop on Natural Language Processing for Turkic Languages (SIGTURK 2024)",
    "bibtex": "@inproceedings{maxutov-etal-2024-llms,\n    title = \"Do {LLM}s Speak {K}azakh? A Pilot Evaluation of Seven Models\",\n    author = \"Maxutov, Akylbek  and\n      Myrzakhmet, Ayan  and\n      Braslavski, Pavel\",\n    editor = {Ataman, Duygu  and\n      Derin, Mehmet Oguz  and\n      Ivanova, Sardana  and\n      K{\\\"o}ksal, Abdullatif  and\n      S{\\\"a}lev{\\\"a}, Jonne  and\n      Zeyrek, Deniz},\n    booktitle = \"Proceedings of the First Workshop on Natural Language Processing for Turkic Languages (SIGTURK 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand and Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sigturk-1.8\",\n    pages = \"81--91\",\n    abstract = \"We conducted a systematic evaluation of seven large language models (LLMs) on tasks in Kazakh, a Turkic language spoken by approximately 13 million native speakers in Kazakhstan and abroad. We used six datasets corresponding to different tasks {--} questions answering, causal reasoning, middle school math problems, machine translation, and spelling correction. Three of the datasets were prepared for this study. As expected, the quality of the LLMs on the Kazakh tasks is lower than on the parallel English tasks. GPT-4 shows the best results, followed by Gemini and . In general, LLMs perform better on classification tasks and struggle with generative tasks. Our results provide valuable insights into the applicability of currently available LLMs for Kazakh. We made the data collected for this study publicly available: https://github.com/akylbekmaxutov/LLM-eval-using-Kazakh.\",\n}\n",
    "authors": [
        "Akylbek Maxutov",
        "Ayan Myrzakhmet",
        "Pavel Braslavski"
    ],
    "pdf_url": "https://aclanthology.org/2024.sigturk-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/97f20069-bf4e-5f69-8548-bbdbd78ec070.pdf",
    "abstract": "We conducted a systematic evaluation of seven large language models (LLMs) on tasks in Kazakh, a Turkic language spoken by approximately 13 million native speakers in Kazakhstan and abroad. We used six datasets corresponding to different tasks â€“ questions answering, causal reasoning, middle school math problems, machine translation, and spelling correction. Three of the datasets were prepared for this study. As expected, the quality of the LLMs on the Kazakh tasks is lower than on the parallel English tasks. GPT-4 shows the best results, followed by Gemini and . In general, LLMs perform better on classification tasks and struggle with generative tasks. Our results provide valuable insights into the applicability of currently available LLMs for Kazakh. We made the data collected for this study publicly available: https://github.com/akylbekmaxutov/LLM-eval-using-Kazakh.",
    "num_pages": 11
}