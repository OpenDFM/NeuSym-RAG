{
    "uuid": "b6cabac2-fb7f-56bd-a3e2-daff67342d03",
    "title": "Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{xu-etal-2023-contrastive,\n    title = \"Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models\",\n    author = \"Xu, Albert  and\n      Ren, Xiang  and\n      Jia, Robin\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.658\",\n    doi = \"10.18653/v1/2023.acl-long.658\",\n    pages = \"11778--11801\",\n    abstract = \"In many task settings, text classification models are likely to encounter examples from novel classes on which they cannot predict correctly. Selective prediction, in which models abstain on low-confidence examples, provides a possible solution, but existing models are often overly confident on unseen classes. To remedy this overconfidence, we introduce Contrastive Novelty-Augmented Learning (CoNAL), a two-step method that generates OOD examples representative of novel classes, then trains to decrease confidence on them. First, we generate OOD examples by prompting a large language model twice: we prompt it to enumerate relevant novel classes, then generate examples from each novel class matching the task format. Second, we train a classifier with a novel contrastive objective that encourages lower confidence on generated OOD examples than training examples. When trained with CoNAL, classifiers improve in their ability to detect and abstain on novel class examples over prior methods by an average of 2.3{\\%} in terms of accuracy under the accuracy-coverage curve (AUAC) and 5.5{\\%} AUROC across 4 NLP datasets, with no cost to in-distribution accuracy.\",\n}\n",
    "authors": [
        "Albert Xu",
        "Xiang Ren",
        "Robin Jia"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.658.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b6cabac2-fb7f-56bd-a3e2-daff67342d03.pdf",
    "abstract": "In many task settings, text classification models are likely to encounter examples from novel classes on which they cannot predict correctly. Selective prediction, in which models abstain on low-confidence examples, provides a possible solution, but existing models are often overly confident on unseen classes. To remedy this overconfidence, we introduce Contrastive Novelty-Augmented Learning (CoNAL), a two-step method that generates OOD examples representative of novel classes, then trains to decrease confidence on them. First, we generate OOD examples by prompting a large language model twice: we prompt it to enumerate relevant novel classes, then generate examples from each novel class matching the task format. Second, we train a classifier with a novel contrastive objective that encourages lower confidence on generated OOD examples than training examples. When trained with CoNAL, classifiers improve in their ability to detect and abstain on novel class examples over prior methods by an average of 2.3% in terms of accuracy under the accuracy-coverage curve (AUAC) and 5.5% AUROC across 4 NLP datasets, with no cost to in-distribution accuracy.",
    "num_pages": 24
}