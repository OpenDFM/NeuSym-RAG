{
    "uuid": "83e7afb1-de2d-55f2-b47a-8b78d28f0fde",
    "title": "ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{huang-etal-2024-araida,\n    title = \"{ARAIDA}: Analogical Reasoning-Augmented Interactive Data Annotation\",\n    author = \"Huang, Chen  and\n      Jin, Yiping  and\n      Ilievski, Ilija  and\n      Lei, Wenqiang  and\n      Lv, Jiancheng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.574\",\n    doi = \"10.18653/v1/2024.acl-long.574\",\n    pages = \"10660--10675\",\n    abstract = \"Human annotation is a time-consuming task that requires a significant amount of effort. To address this issue, interactive data annotation utilizes an annotation model to provide suggestions for humans to approve or correct. However, annotation models trained with limited labeled data are prone to generating incorrect suggestions, leading to extra human correction effort. To tackle this challenge, we propose Araida, an analogical reasoning-based approach that enhances automatic annotation accuracy in the interactive data annotation setting and reduces the need for human corrections. Araida involves an error-aware integration strategy that dynamically coordinates an annotation model and a k-nearest neighbors (KNN) model, giving more importance to KNN{'}s predictions when predictions from the annotation model are deemed inaccurate. Empirical studies demonstrate that Araida is adaptable to different annotation tasks and models. On average, it reduces human correction labor by 11.02{\\%} compared to vanilla interactive data annotation methods.\",\n}\n",
    "authors": [
        "Chen Huang",
        "Yiping Jin",
        "Ilija Ilievski",
        "Wenqiang Lei",
        "Jiancheng Lv"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.574.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/83e7afb1-de2d-55f2-b47a-8b78d28f0fde.pdf",
    "abstract": "Human annotation is a time-consuming task that requires a significant amount of effort. To address this issue, interactive data annotation utilizes an annotation model to provide suggestions for humans to approve or correct. However, annotation models trained with limited labeled data are prone to generating incorrect suggestions, leading to extra human correction effort. To tackle this challenge, we propose Araida, an analogical reasoning-based approach that enhances automatic annotation accuracy in the interactive data annotation setting and reduces the need for human corrections. Araida involves an error-aware integration strategy that dynamically coordinates an annotation model and a k-nearest neighbors (KNN) model, giving more importance to KNNâ€™s predictions when predictions from the annotation model are deemed inaccurate. Empirical studies demonstrate that Araida is adaptable to different annotation tasks and models. On average, it reduces human correction labor by 11.02% compared to vanilla interactive data annotation methods.",
    "num_pages": 16
}