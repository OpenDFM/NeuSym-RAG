{
    "uuid": "f5055f5b-3109-5bae-96a5-2faa0a43293d",
    "title": "Reducing Knowledge Noise for Improved Semantic Analysis in Biomedical Natural Language Processing Applications",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{naseem-etal-2023-reducing,\n    title = \"Reducing Knowledge Noise for Improved Semantic Analysis in Biomedical Natural Language Processing Applications\",\n    author = \"Naseem, Usman  and\n      Thapa, Surendrabikram  and\n      Zhang, Qi  and\n      Hu, Liang  and\n      Masood, Anum  and\n      Nasim, Mehwish\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.32\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.32\",\n    pages = \"272--277\",\n    abstract = \"Graph-based techniques have gained traction for representing and analyzing data in various natural language processing (NLP) tasks. Knowledge graph-based language representation models have shown promising results in leveraging domain-specific knowledge for NLP tasks, particularly in the biomedical NLP field. However, such models have limitations, including knowledge noise and neglect of contextual relationships, leading to potential semantic errors and reduced accuracy. To address these issues, this paper proposes two novel methods. The first method combines knowledge graph-based language model with nearest-neighbor models to incorporate semantic and category information from neighboring instances. The second method involves integrating knowledge graph-based language model with graph neural networks (GNNs) to leverage feature information from neighboring nodes in the graph. Experiments on relation extraction (RE) and classification tasks in English and Chinese language datasets demonstrate significant performance improvements with both methods, highlighting their potential for enhancing the performance of language models and improving NLP applications in the biomedical domain.\",\n}\n",
    "authors": [
        "Usman Naseem",
        "Surendrabikram Thapa",
        "Qi Zhang",
        "Liang Hu",
        "Anum Masood",
        "Mehwish Nasim"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.32.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f5055f5b-3109-5bae-96a5-2faa0a43293d.pdf",
    "abstract": "Graph-based techniques have gained traction for representing and analyzing data in various natural language processing (NLP) tasks. Knowledge graph-based language representation models have shown promising results in leveraging domain-specific knowledge for NLP tasks, particularly in the biomedical NLP field. However, such models have limitations, including knowledge noise and neglect of contextual relationships, leading to potential semantic errors and reduced accuracy. To address these issues, this paper proposes two novel methods. The first method combines knowledge graph-based language model with nearest-neighbor models to incorporate semantic and category information from neighboring instances. The second method involves integrating knowledge graph-based language model with graph neural networks (GNNs) to leverage feature information from neighboring nodes in the graph. Experiments on relation extraction (RE) and classification tasks in English and Chinese language datasets demonstrate significant performance improvements with both methods, highlighting their potential for enhancing the performance of language models and improving NLP applications in the biomedical domain.",
    "num_pages": 6
}