{
    "uuid": "d8c22ef1-4551-54a9-b3b0-8d8821676317",
    "title": "Exploring Chain-of-Thought for Multi-modal Metaphor Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{xu-etal-2024-exploring,\n    title = \"Exploring Chain-of-Thought for Multi-modal Metaphor Detection\",\n    author = \"Xu, Yanzhi  and\n      Hua, Yueying  and\n      Li, Shichen  and\n      Wang, Zhongqing\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.6\",\n    doi = \"10.18653/v1/2024.acl-long.6\",\n    pages = \"91--101\",\n    abstract = \"Metaphors are commonly found in advertising and internet memes. However, the free form of internet memes often leads to a lack of high-quality textual data. Metaphor detection demands a deep interpretation of both textual and visual elements, requiring extensive common-sense knowledge, which poses a challenge to language models. To address these challenges, we propose a compact framework called C4MMD, which utilizes a \\textbf{C}hain-of-Thought(CoT) method \\textbf{for} \\textbf{M}ulti-modal \\textbf{M}etaphor \\textbf{D}etection. Specifically, our approach designs a three-step process inspired by CoT that extracts and integrates knowledge from Multi-modal Large Language Models(MLLMs) into smaller ones. We also developed a modality fusion architecture to transform knowledge from large models into metaphor features, supplemented by auxiliary tasks to improve model performance. Experimental results on the MET-MEME dataset demonstrate that our method not only effectively enhances the metaphor detection capabilities of small models but also outperforms existing models. To our knowledge, this is the first systematic study leveraging MLLMs in metaphor detection tasks. The code for our method is publicly available at \\url{https://github.com/xyz189411yt/C4MMD}.\",\n}\n",
    "authors": [
        "Yanzhi Xu",
        "Yueying Hua",
        "Shichen Li",
        "Zhongqing Wang"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.6.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d8c22ef1-4551-54a9-b3b0-8d8821676317.pdf",
    "abstract": "Metaphors are commonly found in advertising and internet memes. However, the free form of internet memes often leads to a lack of high-quality textual data. Metaphor detection demands a deep interpretation of both textual and visual elements, requiring extensive common-sense knowledge, which poses a challenge to language models. To address these challenges, we propose a compact framework called C4MMD, which utilizes a Chain-of-Thought(CoT) method for Multi-modal Metaphor Detection. Specifically, our approach designs a three-step process inspired by CoT that extracts and integrates knowledge from Multi-modal Large Language Models(MLLMs) into smaller ones. We also developed a modality fusion architecture to transform knowledge from large models into metaphor features, supplemented by auxiliary tasks to improve model performance. Experimental results on the MET-MEME dataset demonstrate that our method not only effectively enhances the metaphor detection capabilities of small models but also outperforms existing models. To our knowledge, this is the first systematic study leveraging MLLMs in metaphor detection tasks. The code for our method is publicly available at https://github.com/xyz189411yt/C4MMD.",
    "num_pages": 11
}