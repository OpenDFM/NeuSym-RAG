{
    "uuid": "0daaf284-550d-5261-bcfe-7fba222ddf0f",
    "title": "Relevance-aware Diverse Query Generation for Out-of-domain Text Ranking",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)",
    "bibtex": "@inproceedings{ju-etal-2024-relevance,\n    title = \"Relevance-aware Diverse Query Generation for Out-of-domain Text Ranking\",\n    author = \"Ju, Jia-Huei  and\n      Yang, Chao-Han  and\n      Fu, Szu-Wei  and\n      Tsai, Ming-Feng  and\n      Wang, Chuan-Ju\",\n    editor = \"Zhao, Chen  and\n      Mosbach, Marius  and\n      Atanasova, Pepa  and\n      Goldfarb-Tarrent, Seraphina  and\n      Hase, Peter  and\n      Hosseini, Arian  and\n      Elbayad, Maha  and\n      Pezzelle, Sandro  and\n      Mozes, Maximilian\",\n    booktitle = \"Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.repl4nlp-1.3\",\n    pages = \"26--36\",\n    abstract = \"Domain adaptation presents significant challenges for out-of-domain text ranking, especially when supervised data is limited. In this paper, we present ReadQG (Relevance-Aware Diverse Query Generation), a method to generate informative synthetic queries to facilitate the adaptation process of text ranking models. Unlike previous approaches focusing solely on relevant query generation, our ReadQG generates diverse queries with continuous relevance scores. Specifically, we propose leveraging soft-prompt tuning and diverse generation objectives to control query generation according to the given relevance. Our experiments show that integrating negative queries into the learning process enhances the effectiveness of text ranking models in out-of-domain information retrieval (IR) benchmarks. Furthermore, we measure the quality of query generation, highlighting the underlying beneficial characteristics of negative queries. Our empirical results and analysis also shed light on potential directions for more advanced data augmentation in IR. The data and code have been released.\",\n}\n",
    "authors": [
        "Jia-Huei Ju",
        "Chao-Han Yang",
        "Szu-Wei Fu",
        "Ming-Feng Tsai",
        "Chuan-Ju Wang"
    ],
    "pdf_url": "https://aclanthology.org/2024.repl4nlp-1.3.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/0daaf284-550d-5261-bcfe-7fba222ddf0f.pdf",
    "abstract": "Domain adaptation presents significant challenges for out-of-domain text ranking, especially when supervised data is limited. In this paper, we present ReadQG (Relevance-Aware Diverse Query Generation), a method to generate informative synthetic queries to facilitate the adaptation process of text ranking models. Unlike previous approaches focusing solely on relevant query generation, our ReadQG generates diverse queries with continuous relevance scores. Specifically, we propose leveraging soft-prompt tuning and diverse generation objectives to control query generation according to the given relevance. Our experiments show that integrating negative queries into the learning process enhances the effectiveness of text ranking models in out-of-domain information retrieval (IR) benchmarks. Furthermore, we measure the quality of query generation, highlighting the underlying beneficial characteristics of negative queries. Our empirical results and analysis also shed light on potential directions for more advanced data augmentation in IR. The data and code have been released.",
    "num_pages": 11
}