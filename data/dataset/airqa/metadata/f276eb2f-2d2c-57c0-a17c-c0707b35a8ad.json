{
    "uuid": "f276eb2f-2d2c-57c0-a17c-c0707b35a8ad",
    "title": "Aristoxenus at SemEval-2023 Task 4: A Domain-Adapted Ensemble Approach to the Identification of Human Values behind Arguments",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{zaikis-etal-2023-aristoxenus,\n    title = \"Aristoxenus at {S}em{E}val-2023 Task 4: A Domain-Adapted Ensemble Approach to the Identification of Human Values behind Arguments\",\n    author = \"Zaikis, Dimitrios  and\n      Stefanidis, Stefanos D.  and\n      Anagnostopoulos, Konstantinos  and\n      Vlahavas, Ioannis\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.142\",\n    doi = \"10.18653/v1/2023.semeval-1.142\",\n    pages = \"1037--1043\",\n    abstract = \"This paper presents our system for the SemEval-2023 Task 4, which aims to identify human values behind arguments by classifying whether or not an argument draws on a specific category. Our approach leverages a second-phase pre-training method to adapt a RoBERTa Language Model (LM) and tackles the problem using a One-Versus-All strategy. Final predictions are determined by a majority voting module that combines the outputs of an ensemble of three sets of per-label models. We conducted experiments to evaluate the impact of different pre-trained LMs on the task, comparing their performance in both pre-trained and task-adapted settings. Our findings show that fine-tuning the RoBERTa LM on the task-specific dataset improves its performance, outperforming the best-performing baseline BERT approach. Overall, our approach achieved a macro-F1 score of 0.47 on the official test set, demonstrating its potential in identifying human values behind arguments.\",\n}\n",
    "authors": [
        "Dimitrios Zaikis",
        "Stefanos D. Stefanidis",
        "Konstantinos Anagnostopoulos",
        "Ioannis Vlahavas"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.142.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f276eb2f-2d2c-57c0-a17c-c0707b35a8ad.pdf",
    "abstract": "This paper presents our system for the SemEval-2023 Task 4, which aims to identify human values behind arguments by classifying whether or not an argument draws on a specific category. Our approach leverages a second-phase pre-training method to adapt a RoBERTa Language Model (LM) and tackles the problem using a One-Versus-All strategy. Final predictions are determined by a majority voting module that combines the outputs of an ensemble of three sets of per-label models. We conducted experiments to evaluate the impact of different pre-trained LMs on the task, comparing their performance in both pre-trained and task-adapted settings. Our findings show that fine-tuning the RoBERTa LM on the task-specific dataset improves its performance, outperforming the best-performing baseline BERT approach. Overall, our approach achieved a macro-F1 score of 0.47 on the official test set, demonstrating its potential in identifying human values behind arguments.",
    "num_pages": 7
}