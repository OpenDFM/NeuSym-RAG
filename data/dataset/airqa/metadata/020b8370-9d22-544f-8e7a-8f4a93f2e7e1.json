{
    "uuid": "020b8370-9d22-544f-8e7a-8f4a93f2e7e1",
    "title": "From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{ermis-etal-2024-one,\n    title = \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models\",\n    author = \"Ermis, Beyza  and\n      Pozzobon, Luiza  and\n      Hooker, Sara  and\n      Lewis, Patrick\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.893\",\n    doi = \"10.18653/v1/2024.findings-acl.893\",\n    pages = \"15041--15058\",\n    abstract = \"To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it{'}s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic families and levels of resource availability, ranging from high to mid-resource languages. Through comprehensive experiments, we provide insights into the complexities of multilingual toxicity mitigation, offering valuable insights and paving the way for future research in this increasingly important field.\",\n}\n",
    "authors": [
        "Beyza Ermis",
        "Luiza Pozzobon",
        "Sara Hooker",
        "Patrick Lewis"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.893.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/020b8370-9d22-544f-8e7a-8f4a93f2e7e1.pdf",
    "abstract": "To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, itâ€™s crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic families and levels of resource availability, ranging from high to mid-resource languages. Through comprehensive experiments, we provide insights into the complexities of multilingual toxicity mitigation, offering valuable insights and paving the way for future research in this increasingly important field.",
    "num_pages": 18
}