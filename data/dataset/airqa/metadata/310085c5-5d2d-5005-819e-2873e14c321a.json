{
    "uuid": "310085c5-5d2d-5005-819e-2873e14c321a",
    "title": "Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{chaudhury-etal-2023-learning,\n    title = \"Learning Symbolic Rules over {A}bstract {M}eaning {R}epresentations for Textual Reinforcement Learning\",\n    author = \"Chaudhury, Subhajit  and\n      Swaminathan, Sarathkrishna  and\n      Kimura, Daiki  and\n      Sen, Prithviraj  and\n      Murugesan, Keerthiram  and\n      Uceda-Sosa, Rosario  and\n      Tatsubori, Michiaki  and\n      Fokoue, Achille  and\n      Kapanipathi, Pavan  and\n      Munawar, Asim  and\n      Gray, Alexander\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.373\",\n    doi = \"10.18653/v1/2023.acl-long.373\",\n    pages = \"6764--6776\",\n    abstract = \"Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data. Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies. Our experiments on established text-based game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.\",\n}\n",
    "authors": [
        "Subhajit Chaudhury",
        "Sarathkrishna Swaminathan",
        "Daiki Kimura",
        "Prithviraj Sen",
        "Keerthiram Murugesan",
        "Rosario Uceda-Sosa",
        "Michiaki Tatsubori",
        "Achille Fokoue",
        "Pavan Kapanipathi",
        "Asim Munawar",
        "Alexander Gray"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.373.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/310085c5-5d2d-5005-819e-2873e14c321a.pdf",
    "abstract": "Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data. Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies. Our experiments on established text-based game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.",
    "num_pages": 13
}