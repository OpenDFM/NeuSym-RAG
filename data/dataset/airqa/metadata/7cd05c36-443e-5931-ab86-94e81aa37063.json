{
    "uuid": "7cd05c36-443e-5931-ab86-94e81aa37063",
    "title": "MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{saha-etal-2023-murmur,\n    title = \"{MURMUR}: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation\",\n    author = \"Saha, Swarnadeep  and\n      Yu, Xinyan  and\n      Bansal, Mohit  and\n      Pasunuru, Ramakanth  and\n      Celikyilmaz, Asli\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.704\",\n    doi = \"10.18653/v1/2023.findings-acl.704\",\n    pages = \"11069--11090\",\n    abstract = \"Prompting large language models has enabled significant recent progress in multi-step reasoning over text. However, when applied to text generation from semi-structured data (e.g., graphs or tables), these methods typically suffer from low semantic coverage, hallucination, and logical inconsistency. We propose MURMUR a neuro-symbolic modular approach to text generation from semi-structured data with multi-step reasoning. MURMUR is a best-first search method that generates reasoning paths using: (1) neural and symbolic modules with specific linguistic and logical skills, (2) a grammar whose production rules define valid compositions of modules, and (3) value functions that assess the quality of each reasoning step. We conduct experiments on two diverse data-to-text generation tasks like WebNLG and LogicNLG. The tasks differ in their data representations (graphs and tables) and span multiple linguistic and logical skills. MURMUR obtains significant improvements over recent few-shot baselines like direct prompting and chain-of-thought prompting, while also achieving comparable performance to fine-tuned GPT-2 on out-of-domain data. Moreover, human evaluation shows that MURMUR generates highly faithful and correct reasoning paths that lead to 26{\\%} more logically consistent summaries on LogicNLG, compared to direct prompting.\",\n}\n",
    "authors": [
        "Swarnadeep Saha",
        "Xinyan Yu",
        "Mohit Bansal",
        "Ramakanth Pasunuru",
        "Asli Celikyilmaz"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.704.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/7cd05c36-443e-5931-ab86-94e81aa37063.pdf",
    "abstract": "Prompting large language models has enabled significant recent progress in multi-step reasoning over text. However, when applied to text generation from semi-structured data (e.g., graphs or tables), these methods typically suffer from low semantic coverage, hallucination, and logical inconsistency. We propose MURMUR a neuro-symbolic modular approach to text generation from semi-structured data with multi-step reasoning. MURMUR is a best-first search method that generates reasoning paths using: (1) neural and symbolic modules with specific linguistic and logical skills, (2) a grammar whose production rules define valid compositions of modules, and (3) value functions that assess the quality of each reasoning step. We conduct experiments on two diverse data-to-text generation tasks like WebNLG and LogicNLG. The tasks differ in their data representations (graphs and tables) and span multiple linguistic and logical skills. MURMUR obtains significant improvements over recent few-shot baselines like direct prompting and chain-of-thought prompting, while also achieving comparable performance to fine-tuned GPT-2 on out-of-domain data. Moreover, human evaluation shows that MURMUR generates highly faithful and correct reasoning paths that lead to 26% more logically consistent summaries on LogicNLG, compared to direct prompting.",
    "num_pages": 22
}