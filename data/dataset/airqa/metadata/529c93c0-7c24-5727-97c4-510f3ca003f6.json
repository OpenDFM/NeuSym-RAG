{
    "uuid": "529c93c0-7c24-5727-97c4-510f3ca003f6",
    "title": "SINAI at RadSum23: Radiology Report Summarization Based on Domain-Specific Sequence-To-Sequence Transformer Model",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
    "bibtex": "@inproceedings{chizhikova-etal-2023-sinai,\n    title = \"{SINAI} at {R}ad{S}um23: Radiology Report Summarization Based on Domain-Specific Sequence-To-Sequence Transformer Model\",\n    author = \"Chizhikova, Mariia  and\n      Diaz-Galiano, Manuel  and\n      Urena-Lopez, L. Alfonso  and\n      Martin-Valdivia, M. Teresa\",\n    editor = \"Demner-fushman, Dina  and\n      Ananiadou, Sophia  and\n      Cohen, Kevin\",\n    booktitle = \"The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bionlp-1.53\",\n    doi = \"10.18653/v1/2023.bionlp-1.53\",\n    pages = \"530--534\",\n    abstract = \"This paper covers participation of the SINAI team in the shared task 1B: Radiology Report Summarization at the BioNLP workshop held on ACL 2023. Our proposal follows a sequence-to-sequence approach which leverages pre-trained multilingual general domain and monolingual biomedical domain pre-trained language models. The best performing system based on domain-specific model reached 33.96 F1RadGraph score which is the fourth best result among the challenge participants. This model was made publicly available on HuggingFace. We also describe an attempt of Proximal Policy Optimization Reinforcement Learning that was made in order to improve the factual correctness measured with F1RadGraph but did not lead to satisfactory results.\",\n}\n",
    "authors": [
        "Mariia Chizhikova",
        "Manuel Diaz-Galiano",
        "L. Alfonso Urena-Lopez",
        "M. Teresa Martin-Valdivia"
    ],
    "pdf_url": "https://aclanthology.org/2023.bionlp-1.53.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/529c93c0-7c24-5727-97c4-510f3ca003f6.pdf",
    "abstract": "This paper covers participation of the SINAI team in the shared task 1B: Radiology Report Summarization at the BioNLP workshop held on ACL 2023. Our proposal follows a sequence-to-sequence approach which leverages pre-trained multilingual general domain and monolingual biomedical domain pre-trained language models. The best performing system based on domain-specific model reached 33.96 F1RadGraph score which is the fourth best result among the challenge participants. This model was made publicly available on HuggingFace. We also describe an attempt of Proximal Policy Optimization Reinforcement Learning that was made in order to improve the factual correctness measured with F1RadGraph but did not lead to satisfactory results.",
    "num_pages": 5
}