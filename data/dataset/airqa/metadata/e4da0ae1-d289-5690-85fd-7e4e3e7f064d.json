{
    "uuid": "e4da0ae1-d289-5690-85fd-7e4e3e7f064d",
    "title": "STARLING: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{basavatia-etal-2024-starling,\n    title = \"{STARLING}: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models\",\n    author = \"Basavatia, Shreyas  and\n      Murugesan, Keerthiram  and\n      Ratnakar, Shivam\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.935\",\n    doi = \"10.18653/v1/2024.findings-acl.935\",\n    pages = \"15804--15819\",\n    abstract = \"Interactive fiction games have emerged as an important application to improve the generalization capabilities of language-based reinforcement learning (RL) agents. Existing environments for interactive fiction games are domain-specific or time-consuming to generate and do not train the RL agents to master a specific set of skills. In this work, we introduce an interactive environment for self-supervised RL, STARLING, for text-based games that bootstraps the text-based RL agents with automatically generated games (based on the seed set of game ideas) to boost the performance and generalization capabilities to reach a goal of the target environment. These games let the agent hone their skills on a predefined set of tasks. We create and test an environment with 100 games, generated using this automated framework that uses large language models (GPT3) and an interactive fiction game engine (based on Inform7) to provide the user with the ability to generate more games under minimal human supervision. Experimental results based on both the human participants and baseline text-based RL agents reveal that current state-of-the-art text-based RL agents cannot use previously learned skills in new situations at the level humans can. These results enforce STARLING{'}s potential to serve as a sandbox environment for further research in self-supervised text-based RL.\",\n}\n",
    "authors": [
        "Shreyas Basavatia",
        "Keerthiram Murugesan",
        "Shivam Ratnakar"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.935.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/e4da0ae1-d289-5690-85fd-7e4e3e7f064d.pdf",
    "abstract": "Interactive fiction games have emerged as an important application to improve the generalization capabilities of language-based reinforcement learning (RL) agents. Existing environments for interactive fiction games are domain-specific or time-consuming to generate and do not train the RL agents to master a specific set of skills. In this work, we introduce an interactive environment for self-supervised RL, STARLING, for text-based games that bootstraps the text-based RL agents with automatically generated games (based on the seed set of game ideas) to boost the performance and generalization capabilities to reach a goal of the target environment. These games let the agent hone their skills on a predefined set of tasks. We create and test an environment with 100 games, generated using this automated framework that uses large language models (GPT3) and an interactive fiction game engine (based on Inform7) to provide the user with the ability to generate more games under minimal human supervision. Experimental results based on both the human participants and baseline text-based RL agents reveal that current state-of-the-art text-based RL agents cannot use previously learned skills in new situations at the level humans can. These results enforce STARLINGâ€™s potential to serve as a sandbox environment for further research in self-supervised text-based RL.",
    "num_pages": 16
}