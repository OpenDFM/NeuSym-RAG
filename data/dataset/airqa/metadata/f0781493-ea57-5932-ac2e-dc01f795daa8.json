{
    "uuid": "f0781493-ea57-5932-ac2e-dc01f795daa8",
    "title": "University of Hildesheim at SemEval-2023 Task 1: Combining Pre-trained Multimodal and Generative Models for Image Disambiguation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{diem-etal-2023-university,\n    title = \"{U}niversity of {H}ildesheim at {S}em{E}val-2023 Task 1: Combining Pre-trained Multimodal and Generative Models for Image Disambiguation\",\n    author = \"Diem, Sebastian  and\n      Im, Chan Jong  and\n      Mandl, Thomas\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.18\",\n    doi = \"10.18653/v1/2023.semeval-1.18\",\n    pages = \"130--135\",\n    abstract = \"Multimodal ambiguity is a challenge for understanding text and images. Large pre-trained models have reached a high level of quality already. This paper presents an implementation for solving a image disambiguation task relying solely on the knowledge captured in multimodal and language models. Within the task 1 of SemEval 2023 (Visual Word Sense Disambiguation), this approach managed to achieve an MRR of 0.738 using CLIP-Large and the OPT model for generating text. Applying a generative model to create more text given a phrase with an ambiguous word leads to an improvement of our results. The performance gain from a bigger language model is larger than the performance gain from using the lager CLIP model.\",\n}\n",
    "authors": [
        "Sebastian Diem",
        "Chan Jong Im",
        "Thomas Mandl"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.18.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f0781493-ea57-5932-ac2e-dc01f795daa8.pdf",
    "abstract": "Multimodal ambiguity is a challenge for understanding text and images. Large pre-trained models have reached a high level of quality already. This paper presents an implementation for solving a image disambiguation task relying solely on the knowledge captured in multimodal and language models. Within the task 1 of SemEval 2023 (Visual Word Sense Disambiguation), this approach managed to achieve an MRR of 0.738 using CLIP-Large and the OPT model for generating text. Applying a generative model to create more text given a phrase with an ambiguous word leads to an improvement of our results. The performance gain from a bigger language model is larger than the performance gain from using the lager CLIP model.",
    "num_pages": 6
}