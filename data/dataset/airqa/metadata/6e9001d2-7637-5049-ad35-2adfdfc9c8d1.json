{
    "uuid": "6e9001d2-7637-5049-ad35-2adfdfc9c8d1",
    "title": "SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{cheng-etal-2024-seeclick,\n    title = \"{S}ee{C}lick: Harnessing {GUI} Grounding for Advanced Visual {GUI} Agents\",\n    author = \"Cheng, Kanzhi  and\n      Sun, Qiushi  and\n      Chu, Yougang  and\n      Xu, Fangzhi  and\n      YanTao, Li  and\n      Zhang, Jianbing  and\n      Wu, Zhiyong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.505\",\n    doi = \"10.18653/v1/2024.acl-long.505\",\n    pages = \"9313--9332\",\n    abstract = \"Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a novel visual GUI agent {--} SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key challenge in developing visual GUI agents: GUI grounding {--} the capacity to accurately locate screen elements based on instructions. To tackle this challenge, we propose to enhance SeeClick with GUI grounding pre-training and devise a method to automate the curation of GUI grounding data. Along with the efforts above, we have also created ScreenSpot, the first realistic GUI grounding benchmark that encompasses mobile, desktop, and web environments. After pre-training, SeeClick demonstrates significant improvement in ScreenSpot over various baselines. Moreover, comprehensive evaluations on three widely used benchmarks consistently support our finding that advancements in GUI grounding directly correlate with enhanced performance in downstream GUI agent tasks. The model, data and code will be open-sourced.\",\n}\n",
    "authors": [
        "Kanzhi Cheng",
        "Qiushi Sun",
        "Yougang Chu",
        "Fangzhi Xu",
        "Li YanTao",
        "Jianbing Zhang",
        "Zhiyong Wu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.505.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6e9001d2-7637-5049-ad35-2adfdfc9c8d1.pdf",
    "abstract": "Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a novel visual GUI agent – SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key challenge in developing visual GUI agents: GUI grounding – the capacity to accurately locate screen elements based on instructions. To tackle this challenge, we propose to enhance SeeClick with GUI grounding pre-training and devise a method to automate the curation of GUI grounding data. Along with the efforts above, we have also created ScreenSpot, the first realistic GUI grounding benchmark that encompasses mobile, desktop, and web environments. After pre-training, SeeClick demonstrates significant improvement in ScreenSpot over various baselines. Moreover, comprehensive evaluations on three widely used benchmarks consistently support our finding that advancements in GUI grounding directly correlate with enhanced performance in downstream GUI agent tasks. The model, data and code will be open-sourced.",
    "num_pages": 20
}