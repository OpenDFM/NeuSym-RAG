{
    "uuid": "202c2f65-9575-55f7-ad29-e66dc387a9f2",
    "title": "Language Models Don’t Learn the Physical Manifestation of Language",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{lee-lim-2024-language,\n    title = \"Language Models Don{'}t Learn the Physical Manifestation of Language\",\n    author = \"Lee, Bruce  and\n      Lim, Jaehyuk\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.195\",\n    doi = \"10.18653/v1/2024.acl-long.195\",\n    pages = \"3554--3579\",\n    abstract = \"We argue that language-only models don{'}t learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test.These tasks highlight a fundamental gap between human linguistic understanding and the sensory-deprived linguistic understanding of LLMs. In support of our hypothesis, 1. deliberate reasoning (Chain-of-Thought), 2. few-shot examples, or 3. stronger LLM from the same model family (LLaMA 2 13B -{\\textgreater} LLaMA 2 70B) has no significant effect on H-Test performance. We bring in the philosophical case of Mary, who learns about the world in a sensory-deprived environment as a useful conceptual framework to understand how language-only models learn about the world (Jackson, 1986). Our experiments show that some of the strongest proprietary LLMs stay near random chance baseline accuracy of 50{\\%}, highlighting the limitations of linguistic knowledge acquired in the absence of sensory experience. Our code and data are available at {\\textless}github.com/brucewlee/h-test{\\textgreater}.\",\n}\n",
    "authors": [
        "Bruce Lee",
        "Jaehyuk Lim"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.195.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/202c2f65-9575-55f7-ad29-e66dc387a9f2.pdf",
    "abstract": "We argue that language-only models don’t learn the physical manifestation of language. We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-Test.These tasks highlight a fundamental gap between human linguistic understanding and the sensory-deprived linguistic understanding of LLMs. In support of our hypothesis, 1. deliberate reasoning (Chain-of-Thought), 2. few-shot examples, or 3. stronger LLM from the same model family (LLaMA 2 13B -> LLaMA 2 70B) has no significant effect on H-Test performance. We bring in the philosophical case of Mary, who learns about the world in a sensory-deprived environment as a useful conceptual framework to understand how language-only models learn about the world (Jackson, 1986). Our experiments show that some of the strongest proprietary LLMs stay near random chance baseline accuracy of 50%, highlighting the limitations of linguistic knowledge acquired in the absence of sensory experience. Our code and data are available at <github.com/brucewlee/h-test>.",
    "num_pages": 26
}