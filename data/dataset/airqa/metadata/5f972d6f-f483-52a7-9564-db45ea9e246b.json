{
    "uuid": "5f972d6f-f483-52a7-9564-db45ea9e246b",
    "title": "The Power of Summary-Source Alignments",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{ernst-etal-2024-power,\n    title = \"The Power of Summary-Source Alignments\",\n    author = \"Ernst, Ori  and\n      Shapira, Ori  and\n      Slobodkin, Aviv  and\n      Adar, Sharon  and\n      Bansal, Mohit  and\n      Goldberger, Jacob  and\n      Levy, Ran  and\n      Dagan, Ido\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.389\",\n    doi = \"10.18653/v1/2024.findings-acl.389\",\n    pages = \"6527--6548\",\n    abstract = \"Multi-document summarization (MDS) is a challenging task, often decomposed to subtasks of salience and redundancy detection, followed by text generation.In this context, alignment of corresponding sentences between a reference summary and its source documents has been leveraged to generate training data for some of the component tasks. Yet, this enabling alignment step has usually been applied heuristically on the sentence level on a limited number of subtasks.In this paper, we propose extending the summary-source alignment framework by (1) applying it at the more fine-grained proposition span level, (2) annotating alignment manually in a multi-document setup, and (3) revealing the great potential of summary-source alignments to yield several datasets for at least six different tasks. Specifically, for each of the tasks, we release a manually annotated test set that was derived automatically from the alignment annotation. We also release development and train sets in the same way, but from automatically derived alignments.Using the datasets, each task is demonstrated with baseline models and corresponding evaluation metrics to spur future research on this broad challenge.\",\n}\n",
    "authors": [
        "Ori Ernst",
        "Ori Shapira",
        "Aviv Slobodkin",
        "Sharon Adar",
        "Mohit Bansal",
        "Jacob Goldberger",
        "Ran Levy",
        "Ido Dagan"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.389.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/5f972d6f-f483-52a7-9564-db45ea9e246b.pdf",
    "abstract": "Multi-document summarization (MDS) is a challenging task, often decomposed to subtasks of salience and redundancy detection, followed by text generation.In this context, alignment of corresponding sentences between a reference summary and its source documents has been leveraged to generate training data for some of the component tasks. Yet, this enabling alignment step has usually been applied heuristically on the sentence level on a limited number of subtasks.In this paper, we propose extending the summary-source alignment framework by (1) applying it at the more fine-grained proposition span level, (2) annotating alignment manually in a multi-document setup, and (3) revealing the great potential of summary-source alignments to yield several datasets for at least six different tasks. Specifically, for each of the tasks, we release a manually annotated test set that was derived automatically from the alignment annotation. We also release development and train sets in the same way, but from automatically derived alignments.Using the datasets, each task is demonstrated with baseline models and corresponding evaluation metrics to spur future research on this broad challenge.",
    "num_pages": 22
}