{
    "uuid": "17795ccb-5050-57cb-b35e-1666f7b336ec",
    "title": "Composition and Deformance: Measuring Imageability with a Text-to-Image Model",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Workshop on Narrative Understanding",
    "bibtex": "@inproceedings{wu-smith-2023-composition,\n    title = \"Composition and Deformance: Measuring Imageability with a Text-to-Image Model\",\n    author = \"Wu, Si  and\n      Smith, David\",\n    editor = \"Akoury, Nader  and\n      Clark, Elizabeth  and\n      Iyyer, Mohit  and\n      Chaturvedi, Snigdha  and\n      Brahman, Faeze  and\n      Chandu, Khyathi\",\n    booktitle = \"Proceedings of the 5th Workshop on Narrative Understanding\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wnu-1.16\",\n    doi = \"10.18653/v1/2023.wnu-1.16\",\n    pages = \"106--117\",\n    abstract = \"Although psycholinguists and psychologists have long studied the tendency of linguistic strings to evoke mental images in hearers or readers, most computational studies have applied this concept of imageability only to isolated words. Using recent developments in text-to-image generation models, such as DALLE mini, we propose computational methods that use generated images to measure the imageability of both single English words and connected text. We sample text prompts for image generation from three corpora: human-generated image captions, news article sentences, and poem lines. We subject these prompts to different deformances to examine the model{'}s ability to detect changes in imageability caused by compositional change. We find high correlation between the proposed computational measures of imageability and human judgments of individual words. We also find the proposed measures more consistently respond to changes in compositionality than baseline approaches. We discuss possible effects of model training and implications for the study of compositionality in text-to-image models.\",\n}\n",
    "authors": [
        "Si Wu",
        "David Smith"
    ],
    "pdf_url": "https://aclanthology.org/2023.wnu-1.16.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/17795ccb-5050-57cb-b35e-1666f7b336ec.pdf",
    "abstract": "Although psycholinguists and psychologists have long studied the tendency of linguistic strings to evoke mental images in hearers or readers, most computational studies have applied this concept of imageability only to isolated words. Using recent developments in text-to-image generation models, such as DALLE mini, we propose computational methods that use generated images to measure the imageability of both single English words and connected text. We sample text prompts for image generation from three corpora: human-generated image captions, news article sentences, and poem lines. We subject these prompts to different deformances to examine the modelâ€™s ability to detect changes in imageability caused by compositional change. We find high correlation between the proposed computational measures of imageability and human judgments of individual words. We also find the proposed measures more consistently respond to changes in compositionality than baseline approaches. We discuss possible effects of model training and implications for the study of compositionality in text-to-image models.",
    "num_pages": 12
}