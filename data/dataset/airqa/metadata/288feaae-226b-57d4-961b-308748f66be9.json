{
    "uuid": "288feaae-226b-57d4-961b-308748f66be9",
    "title": "Disambiguated Lexically Constrained Neural Machine Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zhang-etal-2023-disambiguated,\n    title = \"Disambiguated Lexically Constrained Neural Machine Translation\",\n    author = \"Zhang, Jinpeng  and\n      Xiao, Nini  and\n      Wang, Ke  and\n      Dong, Chuanqi  and\n      Duan, Xiangyu  and\n      Zhang, Yuqi  and\n      Zhang, Min\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.673\",\n    doi = \"10.18653/v1/2023.findings-acl.673\",\n    pages = \"10583--10596\",\n    abstract = \"Lexically constrained neural machine translation (LCNMT), which controls the translation generation with pre-specified constraints, is important in many practical applications. Current approaches to LCNMT typically assume that the pre-specified lexicon constraints are contextually appropriate. This assumption limits their application to real-world scenarios where a source lexicon may have multiple target constraints, and disambiguation is needed to select the most suitable one. In this paper, we propose disambiguated LCNMT (D-LCNMT) to solve the problem. D-LCNMT is a robust and effective two-stage framework that disambiguates the constraints based on contexts at first, then integrates the disambiguated constraints into LCNMT. Experimental results show that our approach outperforms strong baselines including existing data argumentation based approaches on benchmark datasets, and comprehensive experiments in scenarios where a source lexicon corresponds to multiple target constraints demonstrate the constraint disambiguation superiority of our approach.\",\n}\n",
    "authors": [
        "Jinpeng Zhang",
        "Nini Xiao",
        "Ke Wang",
        "Chuanqi Dong",
        "Xiangyu Duan",
        "Yuqi Zhang",
        "Min Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.673.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/288feaae-226b-57d4-961b-308748f66be9.pdf",
    "abstract": "Lexically constrained neural machine translation (LCNMT), which controls the translation generation with pre-specified constraints, is important in many practical applications. Current approaches to LCNMT typically assume that the pre-specified lexicon constraints are contextually appropriate. This assumption limits their application to real-world scenarios where a source lexicon may have multiple target constraints, and disambiguation is needed to select the most suitable one. In this paper, we propose disambiguated LCNMT (D-LCNMT) to solve the problem. D-LCNMT is a robust and effective two-stage framework that disambiguates the constraints based on contexts at first, then integrates the disambiguated constraints into LCNMT. Experimental results show that our approach outperforms strong baselines including existing data argumentation based approaches on benchmark datasets, and comprehensive experiments in scenarios where a source lexicon corresponds to multiple target constraints demonstrate the constraint disambiguation superiority of our approach.",
    "num_pages": 14
}