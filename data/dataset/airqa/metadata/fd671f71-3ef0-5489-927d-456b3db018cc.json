{
    "uuid": "fd671f71-3ef0-5489-927d-456b3db018cc",
    "title": "Aggregating Multiple Heuristic Signals as Supervision for Unsupervised Automated Essay Scoring",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{wang-etal-2023-aggregating,\n    title = \"Aggregating Multiple Heuristic Signals as Supervision for Unsupervised Automated Essay Scoring\",\n    author = \"Wang, Cong  and\n      Jiang, Zhiwei  and\n      Yin, Yafeng  and\n      Cheng, Zifeng  and\n      Ge, Shiping  and\n      Gu, Qing\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.782\",\n    doi = \"10.18653/v1/2023.acl-long.782\",\n    pages = \"13999--14013\",\n    abstract = \"Automated Essay Scoring (AES) aims to evaluate the quality score for input essays. In this work, we propose a novel unsupervised AES approach ULRA, which does not require groundtruth scores of essays for training. The core idea of our ULRA is to use multiple heuristic quality signals as the pseudo-groundtruth, and then train a neural AES model by learning from the aggregation of these quality signals. To aggregate these inconsistent quality signals into a unified supervision, we view the AES task as a ranking problem, and design a special Deep Pairwise Rank Aggregation (DPRA) loss for training. In the DPRA loss, we set a learnable confidence weight for each signal to address the conflicts among signals, and train the neural AES model in a pairwise way to disentangle the cascade effect among partial-order pairs. Experiments on eight prompts of ASPA dataset show that ULRA achieves the state-of-the-art performance compared with previous unsupervised methods in terms of both transductive and inductive settings. Further, our approach achieves comparable performance with many existing domain-adapted supervised models, showing the effectiveness of ULRA. The code is available at \\url{https://github.com/tenvence/ulra}.\",\n}\n",
    "authors": [
        "Cong Wang",
        "Zhiwei Jiang",
        "Yafeng Yin",
        "Zifeng Cheng",
        "Shiping Ge",
        "Qing Gu"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.782.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/fd671f71-3ef0-5489-927d-456b3db018cc.pdf",
    "abstract": "Automated Essay Scoring (AES) aims to evaluate the quality score for input essays. In this work, we propose a novel unsupervised AES approach ULRA, which does not require groundtruth scores of essays for training. The core idea of our ULRA is to use multiple heuristic quality signals as the pseudo-groundtruth, and then train a neural AES model by learning from the aggregation of these quality signals. To aggregate these inconsistent quality signals into a unified supervision, we view the AES task as a ranking problem, and design a special Deep Pairwise Rank Aggregation (DPRA) loss for training. In the DPRA loss, we set a learnable confidence weight for each signal to address the conflicts among signals, and train the neural AES model in a pairwise way to disentangle the cascade effect among partial-order pairs. Experiments on eight prompts of ASPA dataset show that ULRA achieves the state-of-the-art performance compared with previous unsupervised methods in terms of both transductive and inductive settings. Further, our approach achieves comparable performance with many existing domain-adapted supervised models, showing the effectiveness of ULRA. The code is available at https://github.com/tenvence/ulra.",
    "num_pages": 15
}