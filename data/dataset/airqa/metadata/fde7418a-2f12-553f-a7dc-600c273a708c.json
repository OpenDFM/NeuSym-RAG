{
    "uuid": "fde7418a-2f12-553f-a7dc-600c273a708c",
    "title": "Temporal and Second Language Influence on Intra-Annotator Agreement and Stability in Hate Speech Labelling",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)",
    "bibtex": "@inproceedings{abercrombie-etal-2023-temporal,\n    title = \"Temporal and Second Language Influence on Intra-Annotator Agreement and Stability in Hate Speech Labelling\",\n    author = \"Abercrombie, Gavin  and\n      Hovy, Dirk  and\n      Prabhakaran, Vinodkumar\",\n    editor = \"Prange, Jakob  and\n      Friedrich, Annemarie\",\n    booktitle = \"Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.law-1.10\",\n    doi = \"10.18653/v1/2023.law-1.10\",\n    pages = \"96--103\",\n    abstract = \"Much work in natural language processing (NLP) relies on human annotation. The majority of this implicitly assumes that annotator{'}s labels are temporally stable, although the reality is that human judgements are rarely consistent over time. As a subjective annotation task, hate speech labels depend on annotator{'}s emotional and moral reactions to the language used to convey the message. Studies in Cognitive Science reveal a {`}foreign language effect{'}, whereby people take differing moral positions and perceive offensive phrases to be weaker in their second languages. Does this affect annotations as well? We conduct an experiment to investigate the impacts of (1) time and (2) different language conditions (English and German) on measurements of intra-annotator agreement in a hate speech labelling task. While we do not observe the expected lower stability in the different language condition, we find that overall agreement is significantly lower than is implicitly assumed in annotation tasks, which has important implications for dataset reproducibility in NLP.\",\n}\n",
    "authors": [
        "Gavin Abercrombie",
        "Dirk Hovy",
        "Vinodkumar Prabhakaran"
    ],
    "pdf_url": "https://aclanthology.org/2023.law-1.10.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/fde7418a-2f12-553f-a7dc-600c273a708c.pdf",
    "abstract": "Much work in natural language processing (NLP) relies on human annotation. The majority of this implicitly assumes that annotator’s labels are temporally stable, although the reality is that human judgements are rarely consistent over time. As a subjective annotation task, hate speech labels depend on annotator’s emotional and moral reactions to the language used to convey the message. Studies in Cognitive Science reveal a ‘foreign language effect’, whereby people take differing moral positions and perceive offensive phrases to be weaker in their second languages. Does this affect annotations as well? We conduct an experiment to investigate the impacts of (1) time and (2) different language conditions (English and German) on measurements of intra-annotator agreement in a hate speech labelling task. While we do not observe the expected lower stability in the different language condition, we find that overall agreement is significantly lower than is implicitly assumed in annotation tasks, which has important implications for dataset reproducibility in NLP.",
    "num_pages": 8
}