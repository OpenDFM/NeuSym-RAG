{
    "uuid": "40e5e19e-1a7d-5be0-9416-8e7eb0738a25",
    "title": "Follow the Knowledge: Structural Biases and Artefacts in Knowledge Grounded Dialog Datasets",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering",
    "bibtex": "@inproceedings{lotfi-etal-2023-follow,\n    title = \"Follow the Knowledge: Structural Biases and Artefacts in Knowledge Grounded Dialog Datasets\",\n    author = \"Lotfi, Ehsan  and\n      De Bruyn, Maxime  and\n      Jeska.buhmann@uantwerpen.be, Jeska.buhmann@uantwerpen.be  and\n      Daelemans, Walter\",\n    editor = \"Muresan, Smaranda  and\n      Chen, Vivian  and\n      Casey, Kennington  and\n      David, Vandyke  and\n      Nina, Dethlefs  and\n      Koji, Inoue  and\n      Erik, Ekstedt  and\n      Stefan, Ultes\",\n    booktitle = \"Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.dialdoc-1.12\",\n    doi = \"10.18653/v1/2023.dialdoc-1.12\",\n    pages = \"109--121\",\n    abstract = \"Crowd-sourcing has been one of the primary ways to curate conversational data, specially for certain scenarios like grounding in knowledge. In this setting, using online platforms like AMT, non-expert participants are hired to converse with each other, following instructions which try to guide the outcome towards the desired format. The resulting data then is used for different parts of dialog modelling like knowledge selection and response selection/generation. In this work, we take a closer look into two of the most popular knowledge grounded dialog (KGD) datasets. Investigating potential biases and artefacts in knowledge selection labels, we observe that in many cases the {`}knowledge selection flow{'} simply follows the order of presented knowledge pieces. In Wizard of Wikipedia (the most popular KGD dataset) we use simple content-agnostic models based on this bias to get significant knowledge selection performance. In Topical-Chat we see a similar correlation between the knowledge selection sequence and the order of entities and their segments, as provided to crowd-source workers. We believe that the observed results, question the significance and origin of the presumed dialog-level attributes like {`}knowledge flow{'} in these crowd-sourced datasets.\",\n}\n",
    "authors": [
        "Ehsan Lotfi",
        "Maxime De Bruyn",
        "Jeska.buhmann@uantwerpen.be Jeska.buhmann@uantwerpen.be",
        "Walter Daelemans"
    ],
    "pdf_url": "https://aclanthology.org/2023.dialdoc-1.12.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/40e5e19e-1a7d-5be0-9416-8e7eb0738a25.pdf",
    "abstract": "Crowd-sourcing has been one of the primary ways to curate conversational data, specially for certain scenarios like grounding in knowledge. In this setting, using online platforms like AMT, non-expert participants are hired to converse with each other, following instructions which try to guide the outcome towards the desired format. The resulting data then is used for different parts of dialog modelling like knowledge selection and response selection/generation. In this work, we take a closer look into two of the most popular knowledge grounded dialog (KGD) datasets. Investigating potential biases and artefacts in knowledge selection labels, we observe that in many cases the ‘knowledge selection flow’ simply follows the order of presented knowledge pieces. In Wizard of Wikipedia (the most popular KGD dataset) we use simple content-agnostic models based on this bias to get significant knowledge selection performance. In Topical-Chat we see a similar correlation between the knowledge selection sequence and the order of entities and their segments, as provided to crowd-source workers. We believe that the observed results, question the significance and origin of the presumed dialog-level attributes like ‘knowledge flow’ in these crowd-sourced datasets.",
    "num_pages": 13
}