{
    "uuid": "d0f87965-1f79-503b-a0b3-55ea742a310e",
    "title": "M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{wang-etal-2024-m4gt,\n    title = \"{M}4{GT}-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection\",\n    author = \"Wang, Yuxia  and\n      Mansurov, Jonibek  and\n      Ivanov, Petar  and\n      Su, Jinyan  and\n      Shelmanov, Artem  and\n      Tsvigun, Akim  and\n      Mohammed Afzal, Osama  and\n      Mahmoud, Tarek  and\n      Puccetti, Giovanni  and\n      Arnold, Thomas  and\n      Aji, Alham  and\n      Habash, Nizar  and\n      Gurevych, Iryna  and\n      Nakov, Preslav\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.218\",\n    doi = \"10.18653/v1/2024.acl-long.218\",\n    pages = \"3964--3992\",\n    abstract = \"The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine human-generated text is critical in combating disinformation, preserving the integrity of education and scientific fields, and maintaining trust in communication. In this work, we address this problem by introducing a new benchmark based on a multilingual, multi-domain and multi-generator corpus of MGTs {---} M4GT-Bench. The benchmark is compiled of three tasks: (1) mono-lingual and multi-lingual binary MGT detection; (2) multi-way detection where one need to identify, which particular model generated the text; and (3) mixed human-machine text detection, where a word boundary delimiting MGT from human-written content should be determined. On the developed benchmark, we have tested several MGT detection baselines and also conducted an evaluation of human performance. We see that obtaining good performance in MGT detection usually requires an access to the training data from the same domain and generators. The benchmark is available at https://github.com/mbzuai-nlp/M4GT-Bench.\",\n}\n",
    "authors": [
        "Yuxia Wang",
        "Jonibek Mansurov",
        "Petar Ivanov",
        "Jinyan Su",
        "Artem Shelmanov",
        "Akim Tsvigun",
        "Osama Mohammed Afzal",
        "Tarek Mahmoud",
        "Giovanni Puccetti",
        "Thomas Arnold",
        "Alham Aji",
        "Nizar Habash",
        "Iryna Gurevych",
        "Preslav Nakov"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.218.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d0f87965-1f79-503b-a0b3-55ea742a310e.pdf",
    "abstract": "The advent of Large Language Models (LLMs) has brought an unprecedented surge in machine-generated text (MGT) across diverse channels. This raises legitimate concerns about its potential misuse and societal implications. The need to identify and differentiate such content from genuine human-generated text is critical in combating disinformation, preserving the integrity of education and scientific fields, and maintaining trust in communication. In this work, we address this problem by introducing a new benchmark based on a multilingual, multi-domain and multi-generator corpus of MGTs â€” M4GT-Bench. The benchmark is compiled of three tasks: (1) mono-lingual and multi-lingual binary MGT detection; (2) multi-way detection where one need to identify, which particular model generated the text; and (3) mixed human-machine text detection, where a word boundary delimiting MGT from human-written content should be determined. On the developed benchmark, we have tested several MGT detection baselines and also conducted an evaluation of human performance. We see that obtaining good performance in MGT detection usually requires an access to the training data from the same domain and generators. The benchmark is available at https://github.com/mbzuai-nlp/M4GT-Bench.",
    "num_pages": 29
}