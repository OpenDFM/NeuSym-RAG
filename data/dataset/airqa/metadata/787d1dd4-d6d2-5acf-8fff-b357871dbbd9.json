{
    "uuid": "787d1dd4-d6d2-5acf-8fff-b357871dbbd9",
    "title": "Prosody-TTS: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{huang-etal-2023-prosody,\n    title = \"Prosody-{TTS}: Improving Prosody with Masked Autoencoder and Conditional Diffusion Model For Expressive Text-to-Speech\",\n    author = \"Huang, Rongjie  and\n      Zhang, Chunlei  and\n      Ren, Yi  and\n      Zhao, Zhou  and\n      Yu, Dong\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.508\",\n    doi = \"10.18653/v1/2023.findings-acl.508\",\n    pages = \"8018--8034\",\n    abstract = \"Expressive text-to-speech aims to generate high-quality samples with rich and diverse prosody, which is hampered by \\textbf{dual challenges}: 1) prosodic attributes in highly dynamic voices are difficult to capture and model without intonation; and 2) highly multimodal prosodic representations cannot be well learned by simple regression (e.g., MSE) objectives, which causes blurry and over-smoothing predictions. This paper proposes Prosody-TTS, a two-stage pipeline that enhances \\textbf{prosody modeling and sampling} by introducing several components: 1) a self-supervised masked autoencoder to model the prosodic representation without relying on text transcriptions or local prosody attributes, which ensures to cover diverse speaking voices with superior generalization; and 2) a diffusion model to sample diverse prosodic patterns within the latent space, which prevents TTS models from generating samples with dull prosodic performance. Experimental results show that Prosody-TTS achieves new state-of-the-art in text-to-speech with natural and expressive synthesis. Both subjective and objective evaluation demonstrate that it exhibits superior audio quality and prosody naturalness with rich and diverse prosodic attributes. Audio samples are available at \\url{https://improved_prosody.github.io}\",\n}\n",
    "authors": [
        "Rongjie Huang",
        "Chunlei Zhang",
        "Yi Ren",
        "Zhou Zhao",
        "Dong Yu"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.508.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/787d1dd4-d6d2-5acf-8fff-b357871dbbd9.pdf",
    "abstract": "Expressive text-to-speech aims to generate high-quality samples with rich and diverse prosody, which is hampered by dual challenges: 1) prosodic attributes in highly dynamic voices are difficult to capture and model without intonation; and 2) highly multimodal prosodic representations cannot be well learned by simple regression (e.g., MSE) objectives, which causes blurry and over-smoothing predictions. This paper proposes Prosody-TTS, a two-stage pipeline that enhances prosody modeling and sampling by introducing several components: 1) a self-supervised masked autoencoder to model the prosodic representation without relying on text transcriptions or local prosody attributes, which ensures to cover diverse speaking voices with superior generalization; and 2) a diffusion model to sample diverse prosodic patterns within the latent space, which prevents TTS models from generating samples with dull prosodic performance. Experimental results show that Prosody-TTS achieves new state-of-the-art in text-to-speech with natural and expressive synthesis. Both subjective and objective evaluation demonstrate that it exhibits superior audio quality and prosody naturalness with rich and diverse prosodic attributes. Audio samples are available at https://improved_prosody.github.io",
    "num_pages": 17
}