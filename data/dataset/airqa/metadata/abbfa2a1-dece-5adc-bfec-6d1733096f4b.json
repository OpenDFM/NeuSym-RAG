{
    "uuid": "abbfa2a1-dece-5adc-bfec-6d1733096f4b",
    "title": "Recent Highlights in Multilingual and Multimodal Speech Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
    "bibtex": "@inproceedings{liu-niehues-2024-recent,\n    title = \"Recent Highlights in Multilingual and Multimodal Speech Translation\",\n    author = \"Liu, Danni  and\n      Niehues, Jan\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.iwslt-1.29\",\n    doi = \"10.18653/v1/2024.iwslt-1.29\",\n    pages = \"235--253\",\n    abstract = \"Speech translation has witnessed significant progress driven by advancements in modeling techniques and the growing availability of training data. In this paper, we highlight recent advances in two ongoing research directions in ST: scaling the models to 1) many translation directions (multilingual ST) and 2) beyond the text output modality (multimodal ST). We structure this review by examining the sequential stages of a model{'}s development lifecycle: determining training resources, selecting model architecture, training procedures, evaluation metrics, and deployment considerations. We aim to highlight recent developments in each stage, with a particular focus on model architectures (dedicated speech translation models and LLM-based general-purpose model) and training procedures (task-specific vs. task-invariant approaches). Based on the reviewed advancements, we identify and discuss ongoing challenges within the field of speech translation.\",\n}\n",
    "authors": [
        "Danni Liu",
        "Jan Niehues"
    ],
    "pdf_url": "https://aclanthology.org/2024.iwslt-1.29.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/abbfa2a1-dece-5adc-bfec-6d1733096f4b.pdf",
    "abstract": "Speech translation has witnessed significant progress driven by advancements in modeling techniques and the growing availability of training data. In this paper, we highlight recent advances in two ongoing research directions in ST: scaling the models to 1) many translation directions (multilingual ST) and 2) beyond the text output modality (multimodal ST). We structure this review by examining the sequential stages of a modelâ€™s development lifecycle: determining training resources, selecting model architecture, training procedures, evaluation metrics, and deployment considerations. We aim to highlight recent developments in each stage, with a particular focus on model architectures (dedicated speech translation models and LLM-based general-purpose model) and training procedures (task-specific vs. task-invariant approaches). Based on the reviewed advancements, we identify and discuss ongoing challenges within the field of speech translation.",
    "num_pages": 19
}