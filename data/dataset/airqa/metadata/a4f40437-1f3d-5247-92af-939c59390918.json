{
    "uuid": "a4f40437-1f3d-5247-92af-939c59390918",
    "title": "ECBD: Evidence-Centered Benchmark Design for NLP",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{liu-etal-2024-ecbd,\n    title = \"{ECBD}: Evidence-Centered Benchmark Design for {NLP}\",\n    author = \"Liu, Yu Lu  and\n      Blodgett, Su Lin  and\n      Cheung, Jackie  and\n      Liao, Q. Vera  and\n      Olteanu, Alexandra  and\n      Xiao, Ziang\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.861\",\n    doi = \"10.18653/v1/2024.acl-long.861\",\n    pages = \"16349--16365\",\n    abstract = \"Benchmarking is seen as critical to assessing progress in NLP. However, creating a benchmark involves many design decisions (e.g., which datasets to include, which metrics to use) that often rely on tacit, untested assumptions about what the benchmark is intended to measure or is actually measuring. There is currently no principled way of analyzing these decisions and how they impact the validity of the benchmark{'}s measurements. To address this gap, we draw on evidence-centered design in educational assessments and propose Evidence-Centered Benchmark Design (ECBD), a framework which formalizes the benchmark design process into five modules. ECBD specifies the role each module plays in helping practitioners collect evidence about capabilities of interest. Specifically, each module requires benchmark designers to describe, justify, and support benchmark design choices{---}e.g., clearly specifying the capabilities the benchmark aims to measure or how evidence about those capabilities is collected from model responses. To demonstrate the use of ECBD, we conduct case studies with three benchmarks: BoolQ, SuperGLUE, and HELM. Our analysis reveals common trends in benchmark design and documentation that could threaten the validity of benchmarks{'} measurements.\",\n}\n",
    "authors": [
        "Yu Lu Liu",
        "Su Lin Blodgett",
        "Jackie Cheung",
        "Q. Vera Liao",
        "Alexandra Olteanu",
        "Ziang Xiao"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.861.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a4f40437-1f3d-5247-92af-939c59390918.pdf",
    "abstract": "Benchmarking is seen as critical to assessing progress in NLP. However, creating a benchmark involves many design decisions (e.g., which datasets to include, which metrics to use) that often rely on tacit, untested assumptions about what the benchmark is intended to measure or is actually measuring. There is currently no principled way of analyzing these decisions and how they impact the validity of the benchmark’s measurements. To address this gap, we draw on evidence-centered design in educational assessments and propose Evidence-Centered Benchmark Design (ECBD), a framework which formalizes the benchmark design process into five modules. ECBD specifies the role each module plays in helping practitioners collect evidence about capabilities of interest. Specifically, each module requires benchmark designers to describe, justify, and support benchmark design choices—e.g., clearly specifying the capabilities the benchmark aims to measure or how evidence about those capabilities is collected from model responses. To demonstrate the use of ECBD, we conduct case studies with three benchmarks: BoolQ, SuperGLUE, and HELM. Our analysis reveals common trends in benchmark design and documentation that could threaten the validity of benchmarks’ measurements.",
    "num_pages": 17
}