{
    "uuid": "8c60f550-ceb9-59ff-8410-2f82cf4a97ab",
    "title": "Are Generative Language Models Multicultural? A Study on Hausa Culture and Emotions using ChatGPT",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP",
    "bibtex": "@inproceedings{ahmad-etal-2024-generative,\n    title = \"Are Generative Language Models Multicultural? A Study on {H}ausa Culture and Emotions using {C}hat{GPT}\",\n    author = \"Ahmad, Ibrahim  and\n      Dudy, Shiran  and\n      Ramachandranpillai, Resmi  and\n      Church, Kenneth\",\n    editor = \"Prabhakaran, Vinodkumar  and\n      Dev, Sunipa  and\n      Benotti, Luciana  and\n      Hershcovich, Daniel  and\n      Cabello, Laura  and\n      Cao, Yong  and\n      Adebara, Ife  and\n      Zhou, Li\",\n    booktitle = \"Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.c3nlp-1.8\",\n    doi = \"10.18653/v1/2024.c3nlp-1.8\",\n    pages = \"98--106\",\n    abstract = \"Large Language Models (LLMs), such as ChatGPT, are widely used to generate content for various purposes and audiences. However, these models may not reflect the cultural and emotional diversity of their users, especially for low-resource languages. In this paper, we investigate how ChatGPT represents Hausa{'}s culture and emotions. We compare responses generated by ChatGPT with those provided by native Hausa speakers on 37 culturally relevant questions. We conducted experiments using emotion analysis. We also used two similarity metrics to measure the alignment between human and ChatGPT responses. We also collect human participants ratings and feedback on ChatGPT responses. Our results show that ChatGPT has some level of similarity to human responses, but also exhibits some gaps and biases in its knowledge and awareness of Hausa culture and emotions. We discuss the implications and limitations of our methodology and analysis and suggest ways to improve the performance and evaluation of LLMs for low-resource languages.\",\n}\n",
    "authors": [
        "Ibrahim Ahmad",
        "Shiran Dudy",
        "Resmi Ramachandranpillai",
        "Kenneth Church"
    ],
    "pdf_url": "https://aclanthology.org/2024.c3nlp-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8c60f550-ceb9-59ff-8410-2f82cf4a97ab.pdf",
    "abstract": "Large Language Models (LLMs), such as ChatGPT, are widely used to generate content for various purposes and audiences. However, these models may not reflect the cultural and emotional diversity of their users, especially for low-resource languages. In this paper, we investigate how ChatGPT represents Hausaâ€™s culture and emotions. We compare responses generated by ChatGPT with those provided by native Hausa speakers on 37 culturally relevant questions. We conducted experiments using emotion analysis. We also used two similarity metrics to measure the alignment between human and ChatGPT responses. We also collect human participants ratings and feedback on ChatGPT responses. Our results show that ChatGPT has some level of similarity to human responses, but also exhibits some gaps and biases in its knowledge and awareness of Hausa culture and emotions. We discuss the implications and limitations of our methodology and analysis and suggest ways to improve the performance and evaluation of LLMs for low-resource languages.",
    "num_pages": 9
}