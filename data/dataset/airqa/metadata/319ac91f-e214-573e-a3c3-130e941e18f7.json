{
    "uuid": "319ac91f-e214-573e-a3c3-130e941e18f7",
    "title": "QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{huang-etal-2024-queryagent,\n    title = \"{Q}uery{A}gent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction\",\n    author = \"Huang, Xiang  and\n      Cheng, Sitao  and\n      Huang, Shanshan  and\n      Shen, Jiayu  and\n      Xu, Yong  and\n      Zhang, Chaoyun  and\n      Qu, Yuzhong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.274\",\n    doi = \"10.18653/v1/2024.acl-long.274\",\n    pages = \"5014--5035\",\n    abstract = \"Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which solves a question step-by-step and performs stepwise self-correction. We introduce an environmental feedback-based self-correction method called ERASER. Unlike traditional approaches, ERASER leverages rich environmental feedback in the intermediate steps to perform selective and differentiated self-correction only when necessary. Experimental results demonstrate that QueryAgent notably outperforms all previous few-shot methods using only one example on GrailQA and GraphQ by 5.7 and 15.0 points. Furthermore, our approach exhibits superiority in terms of efficiency, including run-time, query overhead, and API invocation costs. By leveraging ERASER, we further improve another baseline (i.e., AgentBench) by approximately 10 points, validating the strong transferability of our approach.\",\n}\n",
    "authors": [
        "Xiang Huang",
        "Sitao Cheng",
        "Shanshan Huang",
        "Jiayu Shen",
        "Yong Xu",
        "Chaoyun Zhang",
        "Yuzhong Qu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.274.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/319ac91f-e214-573e-a3c3-130e941e18f7.pdf",
    "abstract": "Employing Large Language Models (LLMs) for semantic parsing has achieved remarkable success. However, we find existing methods fall short in terms of reliability and efficiency when hallucinations are encountered. In this paper, we address these challenges with a framework called QueryAgent, which solves a question step-by-step and performs stepwise self-correction. We introduce an environmental feedback-based self-correction method called ERASER. Unlike traditional approaches, ERASER leverages rich environmental feedback in the intermediate steps to perform selective and differentiated self-correction only when necessary. Experimental results demonstrate that QueryAgent notably outperforms all previous few-shot methods using only one example on GrailQA and GraphQ by 5.7 and 15.0 points. Furthermore, our approach exhibits superiority in terms of efficiency, including run-time, query overhead, and API invocation costs. By leveraging ERASER, we further improve another baseline (i.e., AgentBench) by approximately 10 points, validating the strong transferability of our approach.",
    "num_pages": 22
}