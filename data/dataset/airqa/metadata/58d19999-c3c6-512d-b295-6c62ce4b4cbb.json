{
    "uuid": "58d19999-c3c6-512d-b295-6c62ce4b4cbb",
    "title": "Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{dong-etal-2024-rich,\n    title = \"Rich Semantic Knowledge Enhanced Large Language Models for Few-shot {C}hinese Spell Checking\",\n    author = \"Dong, Ming  and\n      Chen, Yujing  and\n      Zhang, Miao  and\n      Sun, Hao  and\n      He, Tingting\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.439\",\n    doi = \"10.18653/v1/2024.findings-acl.439\",\n    pages = \"7372--7383\",\n}\n",
    "authors": [
        "Ming Dong",
        "Yujing Chen",
        "Miao Zhang",
        "Hao Sun",
        "Tingting He"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.439.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/58d19999-c3c6-512d-b295-6c62ce4b4cbb.pdf",
    "abstract": "Chinese Spell Checking (CSC) is a widely used technology, which plays a vital role in speech to text (STT) and optical character recognition (OCR). Most of the existing CSC approaches relying on BERT architecture achieve excellent performance. However, limited by the scale of the foundation model, BERT-based method does not work well in few-shot scenarios, showing certain limitations in practical applications. In this paper, we explore using an incontext learning method named RS-LLM (Rich Semantic based LLMs) to introduce large language models (LLMs) as the foundation model. Besides, we study the impact of introducing various Chinese rich semantic information in our framework. We found that by introducing a small number of specific Chinese rich semantic structures, LLMs achieve better performance than most of the BERT-based model on few-shot CSC task. Furthermore, we conduct experiments on multiple datasets, and the experimental results verified the superiority of our proposed framework.",
    "num_pages": 12
}