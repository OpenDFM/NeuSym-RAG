{
    "uuid": "43b37b98-0659-5620-9eca-51bbe8067772",
    "title": "ProLex: A Benchmark for Language Proficiency-oriented Lexical Substitution",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhang-etal-2024-prolex,\n    title = \"{P}ro{L}ex: A Benchmark for Language Proficiency-oriented Lexical Substitution\",\n    author = \"Zhang, Xuanming  and\n      Chen, Zixun  and\n      Yu, Zhou\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.502\",\n    doi = \"10.18653/v1/2024.findings-acl.502\",\n    pages = \"8475--8493\",\n    abstract = \"Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing. To bridge this gap, we propose a new task {---} language proficiency-oriented lexical substitution. We also introduce ProLex, a novel benchmark designed to assess systems{'} ability to generate not only appropriate substitutes but also substitutes that demonstrate better language proficiency. Besides the benchmark, we propose models that can automatically perform the new task. We show that our best model, a Llama2-13B model fine-tuned with task-specific synthetic data, outperforms ChatGPT by an average of 3.2{\\%} in F-score and achieves comparable results with GPT-4 on ProLex.\",\n}\n",
    "authors": [
        "Xuanming Zhang",
        "Zixun Chen",
        "Zhou Yu"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.502.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/43b37b98-0659-5620-9eca-51bbe8067772.pdf",
    "abstract": "Lexical Substitution discovers appropriate substitutes for a given target word in a context sentence. However, the task fails to consider substitutes that are of equal or higher proficiency than the target, an aspect that could be beneficial for language learners looking to improve their writing. To bridge this gap, we propose a new task — language proficiency-oriented lexical substitution. We also introduce ProLex, a novel benchmark designed to assess systems’ ability to generate not only appropriate substitutes but also substitutes that demonstrate better language proficiency. Besides the benchmark, we propose models that can automatically perform the new task. We show that our best model, a Llama2-13B model fine-tuned with task-specific synthetic data, outperforms ChatGPT by an average of 3.2% in F-score and achieves comparable results with GPT-4 on ProLex.",
    "num_pages": 19
}