{
    "uuid": "a1f42535-0f44-5018-8663-ec1a7056241e",
    "title": "Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{nguyen-etal-2024-direct,\n    title = \"Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs\",\n    author = \"Nguyen, Thi  and\n      Luo, Linhao  and\n      Shiri, Fatemeh  and\n      Phung, Dinh  and\n      Li, Yuan-Fang  and\n      Vu, Thuy-Trang  and\n      Haffari, Gholamreza\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.168\",\n    doi = \"10.18653/v1/2024.findings-acl.168\",\n    pages = \"2862--2883\",\n    abstract = \"Large language models (LLMs) have demonstrated strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation paradigm to assess LLMs{'} knowledge of reasoning and the accuracy of the generated CoT. Through experiments conducted on 5 different families of LLMs across 2 multi-hop question-answering datasets, we find that LLMs possess sufficient knowledge to perform reasoning. However, there exists a significant disparity between answer accuracy and faithfulness of the CoT generated by LLMs, indicating that they often arrive at correct answers through incorrect reasoning.\",\n}\n",
    "authors": [
        "Thi Nguyen",
        "Linhao Luo",
        "Fatemeh Shiri",
        "Dinh Phung",
        "Yuan-Fang Li",
        "Thuy-Trang Vu",
        "Gholamreza Haffari"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.168.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a1f42535-0f44-5018-8663-ec1a7056241e.pdf",
    "abstract": "Large language models (LLMs) have demonstrated strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation paradigm to assess LLMsâ€™ knowledge of reasoning and the accuracy of the generated CoT. Through experiments conducted on 5 different families of LLMs across 2 multi-hop question-answering datasets, we find that LLMs possess sufficient knowledge to perform reasoning. However, there exists a significant disparity between answer accuracy and faithfulness of the CoT generated by LLMs, indicating that they often arrive at correct answers through incorrect reasoning.",
    "num_pages": 22
}