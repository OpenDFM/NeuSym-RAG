{
    "uuid": "b2488a67-763f-5b6e-b9b3-4419267b0234",
    "title": "Dragonfly_captain at SemEval-2023 Task 11: Unpacking Disagreement with Investigation of Annotator Demographics and Task Difficulty",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{wan-badillo-urquiola-2023-dragonfly,\n    title = \"Dragonfly{\\_}captain at {S}em{E}val-2023 Task 11: Unpacking Disagreement with Investigation of Annotator Demographics and Task Difficulty\",\n    author = \"Wan, Ruyuan  and\n      Badillo-Urquiola, Karla\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.272\",\n    doi = \"10.18653/v1/2023.semeval-1.272\",\n    pages = \"1978--1982\",\n    abstract = \"This study investigates learning with disagreement in NLP tasks and evaluates its performance on four datasets. The results suggest that the model performs best on the experimental dataset and faces challenges in minority languages. Furthermore, the analysis indicates that annotator demographics play a significant role in the interpretation of such tasks. This study suggests the need for greater consideration of demographic differences in annotators and more comprehensive evaluation metrics for NLP models.\",\n}\n",
    "authors": [
        "Ruyuan Wan",
        "Karla Badillo-Urquiola"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.272.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b2488a67-763f-5b6e-b9b3-4419267b0234.pdf",
    "abstract": "This study investigates learning with disagreement in NLP tasks and evaluates its performance on four datasets. The results suggest that the model performs best on the experimental dataset and faces challenges in minority languages. Furthermore, the analysis indicates that annotator demographics play a significant role in the interpretation of such tasks. This study suggests the need for greater consideration of demographic differences in annotators and more comprehensive evaluation metrics for NLP models.",
    "num_pages": 5
}