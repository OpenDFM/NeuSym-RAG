{
    "uuid": "7b2d8dac-4db0-5b6c-b67d-3b80fe97b410",
    "title": "ArgAnalysis35K : A large-scale dataset for Argument Quality Analysis",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{joshi-etal-2023-arganalysis35k,\n    title = \"{A}rg{A}nalysis35{K} : A large-scale dataset for Argument Quality Analysis\",\n    author = \"Joshi, Omkar  and\n      Pitre, Priya  and\n      Haribhakta, Yashodhara\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.778\",\n    doi = \"10.18653/v1/2023.acl-long.778\",\n    pages = \"13916--13931\",\n    abstract = \"Argument Quality Detection is an emerging field in NLP which has seen significant recent development. However, existing datasets in this field suffer from a lack of quality, quantity and diversity of topics and arguments, specifically the presence of vague arguments that are not persuasive in nature. In this paper, we leverage a combined experience of 10+ years of Parliamentary Debating to create a dataset that covers significantly more topics and has a wide range of sources to capture more diversity of opinion. With 34,890 high-quality argument-analysis pairs (a term we introduce in this paper), this is also the largest dataset of its kind to our knowledge. In addition to this contribution, we introduce an innovative argument scoring system based on instance-level annotator reliability and propose a quantitative model of scoring the relevance of arguments to a range of topics.\",\n}\n",
    "authors": [
        "Omkar Joshi",
        "Priya Pitre",
        "Yashodhara Haribhakta"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.778.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/7b2d8dac-4db0-5b6c-b67d-3b80fe97b410.pdf",
    "abstract": "Argument Quality Detection is an emerging field in NLP which has seen significant recent development. However, existing datasets in this field suffer from a lack of quality, quantity and diversity of topics and arguments, specifically the presence of vague arguments that are not persuasive in nature. In this paper, we leverage a combined experience of 10+ years of Parliamentary Debating to create a dataset that covers significantly more topics and has a wide range of sources to capture more diversity of opinion. With 34,890 high-quality argument-analysis pairs (a term we introduce in this paper), this is also the largest dataset of its kind to our knowledge. In addition to this contribution, we introduce an innovative argument scoring system based on instance-level annotator reliability and propose a quantitative model of scoring the relevance of arguments to a range of topics.",
    "num_pages": 16
}