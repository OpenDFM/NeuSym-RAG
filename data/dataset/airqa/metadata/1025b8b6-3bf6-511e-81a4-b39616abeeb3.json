{
    "uuid": "1025b8b6-3bf6-511e-81a4-b39616abeeb3",
    "title": "Identifying Slurs and Lexical Hate Speech via Light-Weight Dimension Projection in Embedding Space",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{hoeken-etal-2023-identifying,\n    title = \"Identifying Slurs and Lexical Hate Speech via Light-Weight Dimension Projection in Embedding Space\",\n    author = \"Hoeken, Sanne  and\n      Zarrie{\\ss}, Sina  and\n      Alacam, Ozge\",\n    editor = \"Barnes, Jeremy  and\n      De Clercq, Orph{\\'e}e  and\n      Klinger, Roman\",\n    booktitle = \"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wassa-1.25\",\n    doi = \"10.18653/v1/2023.wassa-1.25\",\n    pages = \"278--289\",\n    abstract = \"The prevalence of hate speech on online platforms has become a pressing concern for society, leading to increased attention towards detecting hate speech. Prior work in this area has primarily focused on identifying hate speech at the utterance level that reflects the complex nature of hate speech. In this paper, we propose a targeted and efficient approach to identifying hate speech by detecting slurs at the lexical level using contextualized word embeddings. We hypothesize that slurs have a systematically different representation than their neutral counterparts, making them identifiable through existing methods for discovering semantic dimensions in word embeddings. The results demonstrate the effectiveness of our approach in predicting slurs, confirming linguistic theory that the meaning of slurs is stable across contexts. Our robust hate dimension approach for slur identification offers a promising solution to tackle a smaller yet crucial piece of the complex puzzle of hate speech detection.\",\n}\n",
    "authors": [
        "Sanne Hoeken",
        "Sina Zarrie√ü",
        "Ozge Alacam"
    ],
    "pdf_url": "https://aclanthology.org/2023.wassa-1.25.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/1025b8b6-3bf6-511e-81a4-b39616abeeb3.pdf",
    "abstract": "The prevalence of hate speech on online platforms has become a pressing concern for society, leading to increased attention towards detecting hate speech. Prior work in this area has primarily focused on identifying hate speech at the utterance level that reflects the complex nature of hate speech. In this paper, we propose a targeted and efficient approach to identifying hate speech by detecting slurs at the lexical level using contextualized word embeddings. We hypothesize that slurs have a systematically different representation than their neutral counterparts, making them identifiable through existing methods for discovering semantic dimensions in word embeddings. The results demonstrate the effectiveness of our approach in predicting slurs, confirming linguistic theory that the meaning of slurs is stable across contexts. Our robust hate dimension approach for slur identification offers a promising solution to tackle a smaller yet crucial piece of the complex puzzle of hate speech detection.",
    "num_pages": 12
}