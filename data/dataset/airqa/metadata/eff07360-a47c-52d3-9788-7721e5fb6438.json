{
    "uuid": "eff07360-a47c-52d3-9788-7721e5fb6438",
    "title": "An Extensive Exploration of Back-Translation in 60 Languages",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{mcnamee-duh-2023-extensive,\n    title = \"An Extensive Exploration of Back-Translation in 60 Languages\",\n    author = \"McNamee, Paul  and\n      Duh, Kevin\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.518\",\n    doi = \"10.18653/v1/2023.findings-acl.518\",\n    pages = \"8166--8183\",\n    abstract = \"Back-translation is a data augmentation technique that has been shown to improve model quality through the creation of synthetic training bitext. Early studies showed the promise of the technique and follow on studies have produced additional refinements. We have undertaken a broad investigation using back-translation to train models from 60 languages into English; the majority of these languages are considered moderate- or low-resource languages. We observed consistent gains, though compared to prior work we saw conspicuous gains in quite a number of lower-resourced languages. We analyzed differences in translations between baseline and back-translation models, and observed many indications of improved translation quality. Translation of both rare and common terms is improved, and these improvements occur despite the less natural synthetic source-language text used in training.\",\n}\n",
    "authors": [
        "Paul McNamee",
        "Kevin Duh"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.518.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/eff07360-a47c-52d3-9788-7721e5fb6438.pdf",
    "abstract": "Back-translation is a data augmentation technique that has been shown to improve model quality through the creation of synthetic training bitext. Early studies showed the promise of the technique and follow on studies have produced additional refinements. We have undertaken a broad investigation using back-translation to train models from 60 languages into English; the majority of these languages are considered moderate- or low-resource languages. We observed consistent gains, though compared to prior work we saw conspicuous gains in quite a number of lower-resourced languages. We analyzed differences in translations between baseline and back-translation models, and observed many indications of improved translation quality. Translation of both rare and common terms is improved, and these improvements occur despite the less natural synthetic source-language text used in training.",
    "num_pages": 18
}