{
    "uuid": "8868e9a4-28d1-5eb6-bc8b-76d56eeb62a6",
    "title": "SafetyBench: Evaluating the Safety of Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhang-etal-2024-safetybench,\n    title = \"{S}afety{B}ench: Evaluating the Safety of Large Language Models\",\n    author = \"Zhang, Zhexin  and\n      Lei, Leqi  and\n      Wu, Lindong  and\n      Sun, Rui  and\n      Huang, Yongkang  and\n      Long, Chong  and\n      Liu, Xiao  and\n      Lei, Xuanyu  and\n      Tang, Jie  and\n      Huang, Minlie\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.830\",\n    doi = \"10.18653/v1/2024.acl-long.830\",\n    pages = \"15537--15553\",\n    abstract = \"With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We also demonstrate that the measured safety understanding abilities in SafetyBench are correlated with safety generation abilities. Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench. Submission entrance and leaderboard are available at https://llmbench.ai/safety.\",\n}\n",
    "authors": [
        "Zhexin Zhang",
        "Leqi Lei",
        "Lindong Wu",
        "Rui Sun",
        "Yongkang Huang",
        "Chong Long",
        "Xiao Liu",
        "Xuanyu Lei",
        "Jie Tang",
        "Minlie Huang"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.830.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8868e9a4-28d1-5eb6-bc8b-76d56eeb62a6.pdf",
    "abstract": "With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We also demonstrate that the measured safety understanding abilities in SafetyBench are correlated with safety generation abilities. Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench. Submission entrance and leaderboard are available at https://llmbench.ai/safety.",
    "num_pages": 17
}