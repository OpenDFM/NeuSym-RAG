{
    "uuid": "b67c0674-ffd4-548f-bc80-1837db6146f1",
    "title": "CodeNLP at SemEval-2023 Task 2: Data Augmentation for Named Entity Recognition by Combination of Sequence Generation Strategies",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{marcinczuk-walentynowicz-2023-codenlp,\n    title = \"{C}ode{NLP} at {S}em{E}val-2023 Task 2: Data Augmentation for Named Entity Recognition by Combination of Sequence Generation Strategies\",\n    author = \"Marci{\\'n}czuk, Micha  and\n      Walentynowicz, Wiktor\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.249\",\n    doi = \"10.18653/v1/2023.semeval-1.249\",\n    pages = \"1798--1804\",\n    abstract = \"In the article, we present the CodeNLP submission to the SemEval-2023 Task 2: MultiCoNER II Multilingual Complex Named Entity Recognition. Our approach is based on data augmentation by combining various strategies of sequence generation for training. We show that the extended procedure of fine-tuning a pre-trained language model can bring improvements compared to any single strategy. On the development subsets, the improvements were 1.7 pp and 3.1 pp of F-measure, for English and multilingual datasets, respectively. On the test subsets our models achieved 63.51{\\%} and 73.22{\\%} of Macro F1, respectively.\",\n}\n",
    "authors": [
        "Micha Marci≈Ñczuk",
        "Wiktor Walentynowicz"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.249.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b67c0674-ffd4-548f-bc80-1837db6146f1.pdf",
    "abstract": "In the article, we present the CodeNLP submission to the SemEval-2023 Task 2: MultiCoNER II Multilingual Complex Named Entity Recognition. Our approach is based on data augmentation by combining various strategies of sequence generation for training. We show that the extended procedure of fine-tuning a pre-trained language model can bring improvements compared to any single strategy. On the development subsets, the improvements were 1.7 pp and 3.1 pp of F-measure, for English and multilingual datasets, respectively. On the test subsets our models achieved 63.51% and 73.22% of Macro F1, respectively.",
    "num_pages": 7
}