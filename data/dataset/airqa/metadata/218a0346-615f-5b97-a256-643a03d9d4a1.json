{
    "uuid": "218a0346-615f-5b97-a256-643a03d9d4a1",
    "title": "Guiding Text-to-Text Privatization by Syntax",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)",
    "bibtex": "@inproceedings{arnold-etal-2023-guiding,\n    title = \"Guiding Text-to-Text Privatization by Syntax\",\n    author = \"Arnold, Stefan  and\n      Yesilbas, Dilara  and\n      Weinzierl, Sven\",\n    editor = \"Ovalle, Anaelia  and\n      Chang, Kai-Wei  and\n      Mehrabi, Ninareh  and\n      Pruksachatkun, Yada  and\n      Galystan, Aram  and\n      Dhamala, Jwala  and\n      Verma, Apurv  and\n      Cao, Trista  and\n      Kumar, Anoop  and\n      Gupta, Rahul\",\n    booktitle = \"Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.trustnlp-1.14\",\n    doi = \"10.18653/v1/2023.trustnlp-1.14\",\n    pages = \"151--162\",\n    abstract = \"Metric Differential Privacy is a generalization of differential privacy tailored to address the unique challenges of text-to-text privatization. By adding noise to the representation of words in the geometric space of embeddings, words are replaced with words located in the proximity of the noisy representation. Since embeddings are trained based on word co-occurrences, this mechanism ensures that substitutions stem from a common semantic context. Without considering the grammatical category of words, however, this mechanism cannot guarantee that substitutions play similar syntactic roles. We analyze the capability of text-to-text privatization to preserve the grammatical category of words after substitution and find that surrogate texts consist almost exclusively of nouns. Lacking the capability to produce surrogate texts that correlate with the structure of the sensitive texts, we encompass our analysis by transforming the privatization step into a candidate selection problem in which substitutions are directed to words with matching grammatical properties. We demonstrate a substantial improvement in the performance of downstream tasks by up to 4.66{\\%} while retaining comparative privacy guarantees.\",\n}\n",
    "authors": [
        "Stefan Arnold",
        "Dilara Yesilbas",
        "Sven Weinzierl"
    ],
    "pdf_url": "https://aclanthology.org/2023.trustnlp-1.14.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/218a0346-615f-5b97-a256-643a03d9d4a1.pdf",
    "abstract": "Metric Differential Privacy is a generalization of differential privacy tailored to address the unique challenges of text-to-text privatization. By adding noise to the representation of words in the geometric space of embeddings, words are replaced with words located in the proximity of the noisy representation. Since embeddings are trained based on word co-occurrences, this mechanism ensures that substitutions stem from a common semantic context. Without considering the grammatical category of words, however, this mechanism cannot guarantee that substitutions play similar syntactic roles. We analyze the capability of text-to-text privatization to preserve the grammatical category of words after substitution and find that surrogate texts consist almost exclusively of nouns. Lacking the capability to produce surrogate texts that correlate with the structure of the sensitive texts, we encompass our analysis by transforming the privatization step into a candidate selection problem in which substitutions are directed to words with matching grammatical properties. We demonstrate a substantial improvement in the performance of downstream tasks by up to 4.66% while retaining comparative privacy guarantees.",
    "num_pages": 12
}