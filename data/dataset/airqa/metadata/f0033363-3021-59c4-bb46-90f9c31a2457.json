{
    "uuid": "f0033363-3021-59c4-bb46-90f9c31a2457",
    "title": "Can we trust the evaluation on ChatGPT?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)",
    "bibtex": "@inproceedings{aiyappa-etal-2023-trust,\n    title = \"Can we trust the evaluation on {C}hat{GPT}?\",\n    author = \"Aiyappa, Rachith  and\n      An, Jisun  and\n      Kwak, Haewoon  and\n      Ahn, Yong-yeol\",\n    editor = \"Ovalle, Anaelia  and\n      Chang, Kai-Wei  and\n      Mehrabi, Ninareh  and\n      Pruksachatkun, Yada  and\n      Galystan, Aram  and\n      Dhamala, Jwala  and\n      Verma, Apurv  and\n      Cao, Trista  and\n      Kumar, Anoop  and\n      Gupta, Rahul\",\n    booktitle = \"Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.trustnlp-1.5\",\n    doi = \"10.18653/v1/2023.trustnlp-1.5\",\n    pages = \"47--54\",\n    abstract = \"ChatGPT, the first large language model with mass adoption, has demonstrated remarkableperformance in numerous natural language tasks. Despite its evident usefulness, evaluatingChatGPT{'}s performance in diverse problem domains remains challenging due to the closednature of the model and its continuous updates via Reinforcement Learning from HumanFeedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study in stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.\",\n}\n",
    "authors": [
        "Rachith Aiyappa",
        "Jisun An",
        "Haewoon Kwak",
        "Yong-yeol Ahn"
    ],
    "pdf_url": "https://aclanthology.org/2023.trustnlp-1.5.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f0033363-3021-59c4-bb46-90f9c31a2457.pdf",
    "abstract": "ChatGPT, the first large language model with mass adoption, has demonstrated remarkableperformance in numerous natural language tasks. Despite its evident usefulness, evaluatingChatGPTâ€™s performance in diverse problem domains remains challenging due to the closednature of the model and its continuous updates via Reinforcement Learning from HumanFeedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study in stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.",
    "num_pages": 8
}