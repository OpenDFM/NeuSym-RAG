{
    "uuid": "a3825b75-966e-53ec-aa24-6c48a51eca74",
    "title": "A Call for Standardization and Validation of Text Style Transfer Evaluation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{ostheimer-etal-2023-call,\n    title = \"A Call for Standardization and Validation of Text Style Transfer Evaluation\",\n    author = \"Ostheimer, Phil  and\n      Nagda, Mayank Kumar  and\n      Kloft, Marius  and\n      Fellenz, Sophie\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.687\",\n    doi = \"10.18653/v1/2023.findings-acl.687\",\n    pages = \"10791--10815\",\n    abstract = \"Text Style Transfer (TST) evaluation is, in practice, inconsistent. Therefore, we conduct a meta-analysis on human and automated TST evaluation and experimentation that thoroughly examines existing literature in the field. The meta-analysis reveals a substantial standardization gap in human and automated evaluation. In addition, we also find a validation gap: only few automated metrics have been validated using human experiments. To this end, we thoroughly scrutinize both the standardization and validation gap and reveal the resulting pitfalls. This work also paves the way to close the standardization and validation gap in TST evaluation by calling out requirements to be met by future research.\",\n}\n",
    "authors": [
        "Phil Ostheimer",
        "Mayank Kumar Nagda",
        "Marius Kloft",
        "Sophie Fellenz"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.687.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a3825b75-966e-53ec-aa24-6c48a51eca74.pdf",
    "abstract": "Text Style Transfer (TST) evaluation is, in practice, inconsistent. Therefore, we conduct a meta-analysis on human and automated TST evaluation and experimentation that thoroughly examines existing literature in the field. The meta-analysis reveals a substantial standardization gap in human and automated evaluation. In addition, we also find a validation gap: only few automated metrics have been validated using human experiments. To this end, we thoroughly scrutinize both the standardization and validation gap and reveal the resulting pitfalls. This work also paves the way to close the standardization and validation gap in TST evaluation by calling out requirements to be met by future research.",
    "num_pages": 25
}