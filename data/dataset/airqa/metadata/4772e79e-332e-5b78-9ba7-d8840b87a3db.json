{
    "uuid": "4772e79e-332e-5b78-9ba7-d8840b87a3db",
    "title": "Unsupervised Paraphrasing of Multiword Expressions",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{wada-etal-2023-unsupervised,\n    title = \"Unsupervised Paraphrasing of Multiword Expressions\",\n    author = \"Wada, Takashi  and\n      Matsumoto, Yuji  and\n      Baldwin, Timothy  and\n      Lau, Jey Han\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.290\",\n    doi = \"10.18653/v1/2023.findings-acl.290\",\n    pages = \"4732--4746\",\n    abstract = \"We propose an unsupervised approach to paraphrasing multiword expressions (MWEs) in context. Our model employs only monolingual corpus data and pre-trained language models (without fine-tuning), and does not make use of any external resources such as dictionaries. We evaluate our method on the SemEval 2022 idiomatic semantic text similarity task, and show that it outperforms all unsupervised systems and rivals supervised systems.\",\n}\n",
    "authors": [
        "Takashi Wada",
        "Yuji Matsumoto",
        "Timothy Baldwin",
        "Jey Han Lau"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.290.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4772e79e-332e-5b78-9ba7-d8840b87a3db.pdf",
    "abstract": "We propose an unsupervised approach to paraphrasing multiword expressions (MWEs) in context. Our model employs only monolingual corpus data and pre-trained language models (without fine-tuning), and does not make use of any external resources such as dictionaries. We evaluate our method on the SemEval 2022 idiomatic semantic text similarity task, and show that it outperforms all unsupervised systems and rivals supervised systems.",
    "num_pages": 15
}