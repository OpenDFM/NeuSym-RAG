{
    "uuid": "c86b73d7-a3ff-56e0-92fe-198d0cdfb567",
    "title": "On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{liu-etal-2023-copying,\n    title = \"On the Copying Problem of Unsupervised {NMT}: A Training Schedule with a Language Discriminator Loss\",\n    author = {Liu, Yihong  and\n      Chronopoulou, Alexandra  and\n      Sch{\\\"u}tze, Hinrich  and\n      Fraser, Alexander},\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.48\",\n    doi = \"10.18653/v1/2023.iwslt-1.48\",\n    pages = \"491--502\",\n    abstract = \"Although unsupervised neural machine translation (UNMT) has achieved success in many language pairs, the copying problem, i.e., directly copying some parts of the input sentence as the translation, is common among distant language pairs, especially when low-resource languages are involved. We find this issue is closely related to an unexpected copying behavior during online back-translation (BT). In this work, we propose a simple but effective training schedule that incorporates a language discriminator loss. The loss imposes constraints on the intermediate translation so that the translation is in the desired language. By conducting extensive experiments on different language pairs, including similar and distant, high and low-resource languages, we find that our method alleviates the copying problem, thus improving the translation performance on low-resource languages.\",\n}\n",
    "authors": [
        "Yihong Liu",
        "Alexandra Chronopoulou",
        "Hinrich Sch√ºtze",
        "Alexander Fraser"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.48.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/c86b73d7-a3ff-56e0-92fe-198d0cdfb567.pdf",
    "abstract": "Although unsupervised neural machine translation (UNMT) has achieved success in many language pairs, the copying problem, i.e., directly copying some parts of the input sentence as the translation, is common among distant language pairs, especially when low-resource languages are involved. We find this issue is closely related to an unexpected copying behavior during online back-translation (BT). In this work, we propose a simple but effective training schedule that incorporates a language discriminator loss. The loss imposes constraints on the intermediate translation so that the translation is in the desired language. By conducting extensive experiments on different language pairs, including similar and distant, high and low-resource languages, we find that our method alleviates the copying problem, thus improving the translation performance on low-resource languages.",
    "num_pages": 12
}