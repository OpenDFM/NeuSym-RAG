{
    "uuid": "0e97889b-1b68-5825-b558-085fcab7c5ce",
    "title": "Hybrid Hierarchical Retrieval for Open-Domain Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{arivazhagan-etal-2023-hybrid,\n    title = \"Hybrid Hierarchical Retrieval for Open-Domain Question Answering\",\n    author = \"Arivazhagan, Manoj Ghuhan  and\n      Liu, Lan  and\n      Qi, Peng  and\n      Chen, Xinchi  and\n      Wang, William Yang  and\n      Huang, Zhiheng\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.679\",\n    doi = \"10.18653/v1/2023.findings-acl.679\",\n    pages = \"10680--10689\",\n    abstract = \"Retrieval accuracy is crucial to the performance of open-domain question answering (ODQA) systems. Recent work has demonstrated that dense hierarchical retrieval (DHR), which retrieves document candidates first and then relevant passages from the refined document set, can significantly outperform the single stage dense passage retriever (DPR). While effective, this approach requires document structure information to learn document representation and is hard to adopt to other domains without this information. Additionally, the dense retrievers tend to generalize poorly on out-of-domain data comparing with sparse retrievers such as BM25. In this paper, we propose Hybrid Hierarchical Retrieval (HHR) to address the existing limitations. Instead of relying solely on dense retrievers, we can apply sparse retriever, dense retriever, and a combination of them in both stages of document and passage retrieval. We perform extensive experiments on ODQA benchmarks and observe that our framework not only brings in-domain gains, but also generalizes better to zero-shot TriviaQA and Web Questions datasets with an average of 4.69{\\%} improvement on recall@100 over DHR. We also offer practical insights to trade off between retrieval accuracy, latency, and storage cost. The code is available on github.\",\n}\n",
    "authors": [
        "Manoj Ghuhan Arivazhagan",
        "Lan Liu",
        "Peng Qi",
        "Xinchi Chen",
        "William Yang Wang",
        "Zhiheng Huang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.679.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0e97889b-1b68-5825-b558-085fcab7c5ce.pdf",
    "abstract": "Retrieval accuracy is crucial to the performance of open-domain question answering (ODQA) systems. Recent work has demonstrated that dense hierarchical retrieval (DHR), which retrieves document candidates first and then relevant passages from the refined document set, can significantly outperform the single stage dense passage retriever (DPR). While effective, this approach requires document structure information to learn document representation and is hard to adopt to other domains without this information. Additionally, the dense retrievers tend to generalize poorly on out-of-domain data comparing with sparse retrievers such as BM25. In this paper, we propose Hybrid Hierarchical Retrieval (HHR) to address the existing limitations. Instead of relying solely on dense retrievers, we can apply sparse retriever, dense retriever, and a combination of them in both stages of document and passage retrieval. We perform extensive experiments on ODQA benchmarks and observe that our framework not only brings in-domain gains, but also generalizes better to zero-shot TriviaQA and Web Questions datasets with an average of 4.69% improvement on recall@100 over DHR. We also offer practical insights to trade off between retrieval accuracy, latency, and storage cost. The code is available on github.",
    "num_pages": 10
}