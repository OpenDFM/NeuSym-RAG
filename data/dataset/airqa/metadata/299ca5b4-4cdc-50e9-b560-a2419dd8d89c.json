{
    "uuid": "299ca5b4-4cdc-50e9-b560-a2419dd8d89c",
    "title": "Nonlinear Structural Equation Model Guided Gaussian Mixture Hierarchical Topic Modeling",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{chen-etal-2023-nonlinear,\n    title = \"Nonlinear Structural Equation Model Guided {G}aussian Mixture Hierarchical Topic Modeling\",\n    author = \"Chen, HeGang  and\n      Mao, Pengbo  and\n      Lu, Yuyin  and\n      Rao, Yanghui\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.578\",\n    doi = \"10.18653/v1/2023.acl-long.578\",\n    pages = \"10377--10390\",\n    abstract = \"Hierarchical topic models, which can extract semantically meaningful topics from a textcorpus in an unsupervised manner and automatically organise them into a topic hierarchy, have been widely used to discover the underlying semantic structure of documents. However, the existing models often assume in the prior that the topic hierarchy is a tree structure, ignoring symmetrical dependenciesbetween topics at the same level. Moreover, the sparsity of text data often complicate the analysis. To address these issues, we propose NSEM-GMHTM as a deep topic model, witha Gaussian mixture prior distribution to improve the model{'}s ability to adapt to sparse data, which explicitly models hierarchical and symmetric relations between topics through the dependency matrices and nonlinear structural equations. Experiments on widely used datasets show that our NSEM-GMHTM generates more coherent topics and a more rational topic structure when compared to state-of-theart baselines. Our code is available at https: //github.com/nbnbhwyy/NSEM-GMHTM.\",\n}\n",
    "authors": [
        "HeGang Chen",
        "Pengbo Mao",
        "Yuyin Lu",
        "Yanghui Rao"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.578.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/299ca5b4-4cdc-50e9-b560-a2419dd8d89c.pdf",
    "abstract": "Hierarchical topic models, which can extract semantically meaningful topics from a textcorpus in an unsupervised manner and automatically organise them into a topic hierarchy, have been widely used to discover the underlying semantic structure of documents. However, the existing models often assume in the prior that the topic hierarchy is a tree structure, ignoring symmetrical dependenciesbetween topics at the same level. Moreover, the sparsity of text data often complicate the analysis. To address these issues, we propose NSEM-GMHTM as a deep topic model, witha Gaussian mixture prior distribution to improve the modelâ€™s ability to adapt to sparse data, which explicitly models hierarchical and symmetric relations between topics through the dependency matrices and nonlinear structural equations. Experiments on widely used datasets show that our NSEM-GMHTM generates more coherent topics and a more rational topic structure when compared to state-of-theart baselines. Our code is available at https: //github.com/nbnbhwyy/NSEM-GMHTM.",
    "num_pages": 14
}