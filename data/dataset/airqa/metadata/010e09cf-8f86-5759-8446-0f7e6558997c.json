{
    "uuid": "010e09cf-8f86-5759-8446-0f7e6558997c",
    "title": "Answering Unanswered Questions through Semantic Reformulations in Spoken QA",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
    "bibtex": "@inproceedings{faustini-etal-2023-answering,\n    title = \"Answering Unanswered Questions through Semantic Reformulations in Spoken {QA}\",\n    author = \"Faustini, Pedro  and\n      Chen, Zhiyu  and\n      Fetahu, Besnik  and\n      Rokhlenko, Oleg  and\n      Malmasi, Shervin\",\n    editor = \"Sitaram, Sunayana  and\n      Beigman Klebanov, Beata  and\n      Williams, Jason D\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-industry.70\",\n    doi = \"10.18653/v1/2023.acl-industry.70\",\n    pages = \"729--743\",\n    abstract = \"Spoken Question Answering (QA) is a key feature of voice assistants, usually backed by multiple QA systems. Users ask questions via spontaneous speech that can contain disfluencies, errors, and informal syntax or phrasing. This is a major challenge in QA, causing unanswered questions or irrelevant answers, leading to bad user experiences. We analyze failed QA requests to identify core challenges: lexical gaps, proposition types, complex syntactic structure, and high specificity. We propose a Semantic Question Reformulation (SURF) model offering three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite questions to facilitate answering. Offline evaluation on 1M unanswered questions from a leading voice assistant shows that SURF significantly improves answer rates: up to 24{\\%} of previously unanswered questions obtain relevant answers (75{\\%}). Live deployment shows positive impact for millions of customers with unanswered questions; explicit relevance feedback shows high user satisfaction.\",\n}\n",
    "authors": [
        "Pedro Faustini",
        "Zhiyu Chen",
        "Besnik Fetahu",
        "Oleg Rokhlenko",
        "Shervin Malmasi"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-industry.70.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/010e09cf-8f86-5759-8446-0f7e6558997c.pdf",
    "abstract": "Spoken Question Answering (QA) is a key feature of voice assistants, usually backed by multiple QA systems. Users ask questions via spontaneous speech that can contain disfluencies, errors, and informal syntax or phrasing. This is a major challenge in QA, causing unanswered questions or irrelevant answers, leading to bad user experiences. We analyze failed QA requests to identify core challenges: lexical gaps, proposition types, complex syntactic structure, and high specificity. We propose a Semantic Question Reformulation (SURF) model offering three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite questions to facilitate answering. Offline evaluation on 1M unanswered questions from a leading voice assistant shows that SURF significantly improves answer rates: up to 24% of previously unanswered questions obtain relevant answers (75%). Live deployment shows positive impact for millions of customers with unanswered questions; explicit relevance feedback shows high user satisfaction.",
    "num_pages": 15
}