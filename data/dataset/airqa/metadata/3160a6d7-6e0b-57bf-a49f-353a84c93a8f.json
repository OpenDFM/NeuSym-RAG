{
    "uuid": "3160a6d7-6e0b-57bf-a49f-353a84c93a8f",
    "title": "Word Boundary Information Isn’t Useful for Encoder Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)",
    "bibtex": "@inproceedings{gow-smith-etal-2024-word,\n    title = \"Word Boundary Information Isn{'}t Useful for Encoder Language Models\",\n    author = \"Gow-Smith, Edward  and\n      Phelps, Dylan  and\n      Tayyar Madabushi, Harish  and\n      Scarton, Carolina  and\n      Villavicencio, Aline\",\n    editor = \"Zhao, Chen  and\n      Mosbach, Marius  and\n      Atanasova, Pepa  and\n      Goldfarb-Tarrent, Seraphina  and\n      Hase, Peter  and\n      Hosseini, Arian  and\n      Elbayad, Maha  and\n      Pezzelle, Sandro  and\n      Mozes, Maximilian\",\n    booktitle = \"Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.repl4nlp-1.10\",\n    pages = \"118--135\",\n    abstract = \"All existing transformer-based approaches to NLP using subword tokenisation algorithms encode whitespace (word boundary information) through the use of special space symbols (such as {\\#}{\\#} or {\\_}) forming part of tokens. These symbols have been shown to a) lead to reduced morphological validity of tokenisations, and b) give substantial vocabulary redundancy. As such, removing these symbols has been shown to have a beneficial effect on the processing of morphologically complex words for transformer encoders in the pretrain-finetune paradigm. In this work, we explore whether word boundary information is at all useful to such models. In particular, we train transformer encoders across four different training scales, and investigate several alternative approaches to including word boundary information, evaluating on two languages (English and Finnish) with a range of tasks across different domains and problem set-ups: sentence classification datasets, NER (for token-level classification), and two classification datasets involving complex words (Superbizarre and FLOTA). Overall, through an extensive experimental setup that includes the pre-training of 35 models, we find no substantial improvements from our alternative approaches, suggesting that modifying tokenisers to remove word boundary information isn{'}t leading to a loss of useful information.\",\n}\n",
    "authors": [
        "Edward Gow-Smith",
        "Dylan Phelps",
        "Harish Tayyar Madabushi",
        "Carolina Scarton",
        "Aline Villavicencio"
    ],
    "pdf_url": "https://aclanthology.org/2024.repl4nlp-1.10.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3160a6d7-6e0b-57bf-a49f-353a84c93a8f.pdf",
    "abstract": "All existing transformer-based approaches to NLP using subword tokenisation algorithms encode whitespace (word boundary information) through the use of special space symbols (such as ## or _) forming part of tokens. These symbols have been shown to a) lead to reduced morphological validity of tokenisations, and b) give substantial vocabulary redundancy. As such, removing these symbols has been shown to have a beneficial effect on the processing of morphologically complex words for transformer encoders in the pretrain-finetune paradigm. In this work, we explore whether word boundary information is at all useful to such models. In particular, we train transformer encoders across four different training scales, and investigate several alternative approaches to including word boundary information, evaluating on two languages (English and Finnish) with a range of tasks across different domains and problem set-ups: sentence classification datasets, NER (for token-level classification), and two classification datasets involving complex words (Superbizarre and FLOTA). Overall, through an extensive experimental setup that includes the pre-training of 35 models, we find no substantial improvements from our alternative approaches, suggesting that modifying tokenisers to remove word boundary information isn’t leading to a loss of useful information.",
    "num_pages": 18
}