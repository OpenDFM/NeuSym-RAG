{
    "uuid": "fff6e53e-da7b-5fa4-a3e0-cc5a280079dc",
    "title": "disco: a toolkit for Distributional Control of Generative Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
    "bibtex": "@inproceedings{kruszewski-etal-2023-disco,\n    title = \"disco: a toolkit for Distributional Control of Generative Models\",\n    author = \"Kruszewski, Germ{\\'a}n  and\n      Rozen, Jos  and\n      Dymetman, Marc\",\n    editor = \"Bollegala, Danushka  and\n      Huang, Ruihong  and\n      Ritter, Alan\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-demo.14\",\n    doi = \"10.18653/v1/2023.acl-demo.14\",\n    pages = \"144--160\",\n    abstract = \"Pre-trained language models and other generative models have revolutionized NLP and beyond. However, these models tend to reproduce undesirable biases present in their training data. Also, they may overlook patterns that are important but challenging to capture. To address these limitations, researchers have introduced distributional control techniques. These techniques, not limited to language, allow controlling the prevalence (i.e. expectations) of any features of interest in the model{'}s outputs. Despite their potential, the widespread adoption of these techniques has been hindered by the difficulty in adapting the complex, disconnected code. Here, we present disco, an open-source Python library that brings these techniques to the broader public\",\n}\n",
    "authors": [
        "Germán Kruszewski",
        "Jos Rozen",
        "Marc Dymetman"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-demo.14.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/fff6e53e-da7b-5fa4-a3e0-cc5a280079dc.pdf",
    "abstract": "Pre-trained language models and other generative models have revolutionized NLP and beyond. However, these models tend to reproduce undesirable biases present in their training data. Also, they may overlook patterns that are important but challenging to capture. To address these limitations, researchers have introduced distributional control techniques. These techniques, not limited to language, allow controlling the prevalence (i.e. expectations) of any features of interest in the model’s outputs. Despite their potential, the widespread adoption of these techniques has been hindered by the difficulty in adapting the complex, disconnected code. Here, we present disco, an open-source Python library that brings these techniques to the broader public",
    "num_pages": 17
}