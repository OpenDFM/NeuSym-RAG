{
    "uuid": "eb36fc83-75f1-555f-bdc4-bc792ba119db",
    "title": "Evaluating Semantic Relations in Predicting Textual Labels for Images of Abstract and Concrete Concepts",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
    "bibtex": "@inproceedings{tater-etal-2024-evaluating,\n    title = \"Evaluating Semantic Relations in Predicting Textual Labels for Images of Abstract and Concrete Concepts\",\n    author = \"Tater, Tarun  and\n      Schulte Im Walde, Sabine  and\n      Frassinelli, Diego\",\n    editor = \"Kuribayashi, Tatsuki  and\n      Rambelli, Giulia  and\n      Takmaz, Ece  and\n      Wicke, Philipp  and\n      Oseki, Yohei\",\n    booktitle = \"Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.cmcl-1.18\",\n    doi = \"10.18653/v1/2024.cmcl-1.18\",\n    pages = \"214--220\",\n    abstract = \"This study investigates the performance of SigLIP, a state-of-the-art Vision-Language Model (VLM), in predicting labels for images depicting 1,278 concepts. Our analysis across 300 images per concept shows that the model frequently predicts the exact user-tagged labels, but similarly, it often predicts labels that are semantically related to the exact labels in various ways: synonyms, hypernyms, co-hyponyms, and associated words, particularly for abstract concepts. We then zoom into the diversity of the user tags of images and word associations for abstract versus concrete concepts. Surprisingly, not only abstract but also concrete concepts exhibit significant variability, thus challenging the traditional view that representations of concrete concepts are less diverse.\",\n}\n",
    "authors": [
        "Tarun Tater",
        "Sabine Schulte Im Walde",
        "Diego Frassinelli"
    ],
    "pdf_url": "https://aclanthology.org/2024.cmcl-1.18.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/eb36fc83-75f1-555f-bdc4-bc792ba119db.pdf",
    "abstract": "This study investigates the performance of SigLIP, a state-of-the-art Vision-Language Model (VLM), in predicting labels for images depicting 1,278 concepts. Our analysis across 300 images per concept shows that the model frequently predicts the exact user-tagged labels, but similarly, it often predicts labels that are semantically related to the exact labels in various ways: synonyms, hypernyms, co-hyponyms, and associated words, particularly for abstract concepts. We then zoom into the diversity of the user tags of images and word associations for abstract versus concrete concepts. Surprisingly, not only abstract but also concrete concepts exhibit significant variability, thus challenging the traditional view that representations of concrete concepts are less diverse.",
    "num_pages": 7
}