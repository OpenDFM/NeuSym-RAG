{
    "uuid": "44737fdb-34d0-53bf-b198-1ad7afd0a275",
    "title": "Cantonese Natural Language Processing in the Transformers Era",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)",
    "bibtex": "@inproceedings{xiang-etal-2024-cantonese,\n    title = \"{C}antonese Natural Language Processing in the Transformers Era\",\n    author = \"Xiang, Rong  and\n      Liao, Ming  and\n      Li, Jing\",\n    editor = \"Wong, Kam-Fai  and\n      Zhang, Min  and\n      Xu, Ruifeng  and\n      Li, Jing  and\n      Wei, Zhongyu  and\n      Gui, Lin  and\n      Liang, Bin  and\n      Zhao, Runcong\",\n    booktitle = \"Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sighan-1.8\",\n    pages = \"69--79\",\n    abstract = \"Despite being spoken by a large population of speakers worldwide, Cantonese is under-resourced in terms of the data scale and diversity compared to other major languages. This limitation has excluded it from the current {``}pre-training and fine-tuning{''} paradigm that is dominated by Transformer architectures.In this paper, we provide a comprehensive review on the existing resources and methodologies for Cantonese Natural Language Processing, covering the recent progress in language understanding, text generation and development of language models.We finally discuss two aspects of the Cantonese language that could make it potentially challenging even for state-of-the-art architectures: \\textit{colloquialism} and \\textit{multilinguality}.\",\n}\n",
    "authors": [
        "Rong Xiang",
        "Ming Liao",
        "Jing Li"
    ],
    "pdf_url": "https://aclanthology.org/2024.sighan-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/44737fdb-34d0-53bf-b198-1ad7afd0a275.pdf",
    "abstract": "Despite being spoken by a large population of speakers worldwide, Cantonese is under-resourced in terms of the data scale and diversity compared to other major languages. This limitation has excluded it from the current “pre-training and fine-tuning” paradigm that is dominated by Transformer architectures.In this paper, we provide a comprehensive review on the existing resources and methodologies for Cantonese Natural Language Processing, covering the recent progress in language understanding, text generation and development of language models.We finally discuss two aspects of the Cantonese language that could make it potentially challenging even for state-of-the-art architectures: colloquialism and multilinguality.",
    "num_pages": 11
}