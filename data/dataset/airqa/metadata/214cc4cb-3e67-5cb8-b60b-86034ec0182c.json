{
    "uuid": "214cc4cb-3e67-5cb8-b60b-86034ec0182c",
    "title": "Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{kwon-etal-2023-vision,\n    title = \"Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information\",\n    author = \"Kwon, Sunjae  and\n      Garodia, Rishabh  and\n      Lee, Minhwa  and\n      Yang, Zhichao  and\n      Yu, Hong\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.88\",\n    doi = \"10.18653/v1/2023.acl-long.88\",\n    pages = \"1583--1598\",\n    abstract = \"Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method.\",\n}\n",
    "authors": [
        "Sunjae Kwon",
        "Rishabh Garodia",
        "Minhwa Lee",
        "Zhichao Yang",
        "Hong Yu"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.88.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/214cc4cb-3e67-5cb8-b60b-86034ec0182c.pdf",
    "abstract": "Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method.",
    "num_pages": 16
}