{
    "uuid": "4ffbe06b-40b1-5198-b907-78f46df27a04",
    "title": "MaskLID: Code-Switching Language Identification through Iterative Masking",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{kargaran-etal-2024-masklid,\n    title = \"{M}ask{LID}: Code-Switching Language Identification through Iterative Masking\",\n    author = \"Kargaran, Amir Hossein  and\n      Yvon, Fran{\\c{c}}ois  and\n      Schuetze, Hinrich\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-short.43\",\n    doi = \"10.18653/v1/2024.acl-short.43\",\n    pages = \"459--469\",\n    abstract = \"We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single labels, typically using a softmax layer to turn scores into probabilities. However, in cases where a sentence is composed in both L1 and L2 languages, the LID classifier often only returns the dominant label L1. To address this limitation, MaskLID employs a strategy to mask text features associated with L1, allowing the LID to classify the text as L2 in the next round. This method uses the LID itself to identify the features that require masking and does not rely on any external resource. In this work, we explore the use of MaskLID for two open-source LIDs (GlotLID and OpenLID), that are both based on the FastText architecture. Code and demo are available at https://github.com/cisnlp/MaskLID.\",\n}\n",
    "authors": [
        "Amir Hossein Kargaran",
        "Fran√ßois Yvon",
        "Hinrich Schuetze"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-short.43.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4ffbe06b-40b1-5198-b907-78f46df27a04.pdf",
    "abstract": "We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single labels, typically using a softmax layer to turn scores into probabilities. However, in cases where a sentence is composed in both L1 and L2 languages, the LID classifier often only returns the dominant label L1. To address this limitation, MaskLID employs a strategy to mask text features associated with L1, allowing the LID to classify the text as L2 in the next round. This method uses the LID itself to identify the features that require masking and does not rely on any external resource. In this work, we explore the use of MaskLID for two open-source LIDs (GlotLID and OpenLID), that are both based on the FastText architecture. Code and demo are available at https://github.com/cisnlp/MaskLID.",
    "num_pages": 11
}