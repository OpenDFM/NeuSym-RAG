{
    "uuid": "4f5f68e8-16e9-5436-a570-f6ddd47be21a",
    "title": "Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhang-etal-2024-exploring,\n    title = \"Exploring Collaboration Mechanisms for {LLM} Agents: A Social Psychology View\",\n    author = \"Zhang, Jintian  and\n      Xu, Xin  and\n      Zhang, Ningyu  and\n      Liu, Ruibo  and\n      Hooi, Bryan  and\n      Deng, Shumin\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.782\",\n    doi = \"10.18653/v1/2024.acl-long.782\",\n    pages = \"14544--14607\",\n    abstract = \"As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: *Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?* This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique {`}societies{'} comprised of LLM agents, where each agent is characterized by a specific {`}trait{'} (easy-going or overconfident) and engages in collaboration with a distinct {`}thinking pattern{'} (debate or reflection). Through evaluating these multi-agent societies on three benchmark datasets, we discern that certain collaborative strategies not only outshine previous top-tier approaches but also optimize efficiency (using fewer API tokens). Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity and consensus reaching, mirroring foundational social psychology theories. In conclusion, we integrate insights from social psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets, hoping to catalyze further research in this promising avenue.\",\n}\n",
    "authors": [
        "Jintian Zhang",
        "Xin Xu",
        "Ningyu Zhang",
        "Ruibo Liu",
        "Bryan Hooi",
        "Shumin Deng"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.782.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4f5f68e8-16e9-5436-a570-f6ddd47be21a.pdf",
    "abstract": "As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: *Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)?* This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique ‘societies’ comprised of LLM agents, where each agent is characterized by a specific ‘trait’ (easy-going or overconfident) and engages in collaboration with a distinct ‘thinking pattern’ (debate or reflection). Through evaluating these multi-agent societies on three benchmark datasets, we discern that certain collaborative strategies not only outshine previous top-tier approaches but also optimize efficiency (using fewer API tokens). Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity and consensus reaching, mirroring foundational social psychology theories. In conclusion, we integrate insights from social psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets, hoping to catalyze further research in this promising avenue.",
    "num_pages": 64
}