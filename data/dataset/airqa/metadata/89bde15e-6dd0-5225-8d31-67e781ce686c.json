{
    "uuid": "89bde15e-6dd0-5225-8d31-67e781ce686c",
    "title": "Enhancing Video Translation Context with Object Labels",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{gwinnup-etal-2023-enhancing,\n    title = \"Enhancing Video Translation Context with Object Labels\",\n    author = \"Gwinnup, Jeremy  and\n      Anderson, Tim  and\n      Ore, Brian  and\n      Hansen, Eric  and\n      Duh, Kevin\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.8\",\n    doi = \"10.18653/v1/2023.iwslt-1.8\",\n    pages = \"130--137\",\n    abstract = \"We present a simple yet efficient method to enhance the quality of machine translation models trained on multimodal corpora by augmenting the training text with labels of detected objects in the corresponding video segments. We then test the effects of label augmentation in both baseline and two automatic speech recognition (ASR) conditions. In contrast with multimodal techniques that merge visual and textual features, our modular method is easy to implement and the results are more interpretable. Comparisons are made with Transformer translation architectures trained with baseline and augmented labels, showing improvements of up to +1.0 BLEU on the How2 dataset.\",\n}\n",
    "authors": [
        "Jeremy Gwinnup",
        "Tim Anderson",
        "Brian Ore",
        "Eric Hansen",
        "Kevin Duh"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/89bde15e-6dd0-5225-8d31-67e781ce686c.pdf",
    "abstract": "We present a simple yet efficient method to enhance the quality of machine translation models trained on multimodal corpora by augmenting the training text with labels of detected objects in the corresponding video segments. We then test the effects of label augmentation in both baseline and two automatic speech recognition (ASR) conditions. In contrast with multimodal techniques that merge visual and textual features, our modular method is easy to implement and the results are more interpretable. Comparisons are made with Transformer translation architectures trained with baseline and augmented labels, showing improvements of up to +1.0 BLEU on the How2 dataset.",
    "num_pages": 8
}