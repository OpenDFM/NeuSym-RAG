{
    "uuid": "e0e6c03e-8d19-5a57-98bd-c71e12e7d10f",
    "title": "Characterizing and Measuring Linguistic Dataset Drift",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{chang-etal-2023-characterizing,\n    title = \"Characterizing and Measuring Linguistic Dataset Drift\",\n    author = \"Chang, Tyler  and\n      Halder, Kishaloy  and\n      Anna John, Neha  and\n      Vyas, Yogarshi  and\n      Benajiba, Yassine  and\n      Ballesteros, Miguel  and\n      Roth, Dan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.498\",\n    doi = \"10.18653/v1/2023.acl-long.498\",\n    pages = \"8953--8967\",\n    abstract = \"NLP models often degrade in performance when real world data distributions differ markedly from training data. However, existing dataset drift metrics in NLP have generally not considered specific dimensions of linguistic drift that affect model performance, and they have not been validated in their ability to predict model performance at the individual example level, where such metrics are often used in practice. In this paper, we propose three dimensions of linguistic dataset drift: vocabulary, structural, and semantic drift. These dimensions correspond to content word frequency divergences, syntactic divergences, and meaning changes not captured by word frequencies (e.g. lexical semantic change). We propose interpretable metrics for all three drift dimensions, and we modify past performance prediction methods to predict model performance at both the example and dataset level for English sentiment classification and natural language inference. We find that our drift metrics are more effective than previous metrics at predicting out-of-domain model accuracies (mean 16.8{\\%} root mean square error decrease), particularly when compared to popular fine-tuned embedding distances (mean 47.7{\\%} error decrease). Fine-tuned embedding distances are much more effective at ranking individual examples by expected performance, but decomposing into vocabulary, structural, and semantic drift produces the best example rankings of all considered model-agnostic drift metrics (mean 6.7{\\%} ROC AUC increase).\",\n}\n",
    "authors": [
        "Tyler Chang",
        "Kishaloy Halder",
        "Neha Anna John",
        "Yogarshi Vyas",
        "Yassine Benajiba",
        "Miguel Ballesteros",
        "Dan Roth"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.498.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e0e6c03e-8d19-5a57-98bd-c71e12e7d10f.pdf",
    "abstract": "NLP models often degrade in performance when real world data distributions differ markedly from training data. However, existing dataset drift metrics in NLP have generally not considered specific dimensions of linguistic drift that affect model performance, and they have not been validated in their ability to predict model performance at the individual example level, where such metrics are often used in practice. In this paper, we propose three dimensions of linguistic dataset drift: vocabulary, structural, and semantic drift. These dimensions correspond to content word frequency divergences, syntactic divergences, and meaning changes not captured by word frequencies (e.g. lexical semantic change). We propose interpretable metrics for all three drift dimensions, and we modify past performance prediction methods to predict model performance at both the example and dataset level for English sentiment classification and natural language inference. We find that our drift metrics are more effective than previous metrics at predicting out-of-domain model accuracies (mean 16.8% root mean square error decrease), particularly when compared to popular fine-tuned embedding distances (mean 47.7% error decrease). Fine-tuned embedding distances are much more effective at ranking individual examples by expected performance, but decomposing into vocabulary, structural, and semantic drift produces the best example rankings of all considered model-agnostic drift metrics (mean 6.7% ROC AUC increase).",
    "num_pages": 15
}