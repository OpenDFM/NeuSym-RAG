{
    "uuid": "4301c7d5-5ba0-5a4d-8e8e-a2b6d8a21506",
    "title": "Cross-Domain Argument Quality Estimation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{fromm-etal-2023-cross,\n    title = \"Cross-Domain Argument Quality Estimation\",\n    author = \"Fromm, Michael  and\n      Berrendorf, Max  and\n      Faerman, Evgeniy  and\n      Seidl, Thomas\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.848\",\n    doi = \"10.18653/v1/2023.findings-acl.848\",\n    pages = \"13435--13448\",\n    abstract = \"Argumentation is one of society{'}s foundational pillars, and, sparked by advances in NLP, and the vast availability of text data, automated mining of arguments receives increasing attention. A decisive property of arguments is their strength or quality. While there are works on the automated estimation of argument strength, their scope is narrow:They focus on isolated datasets and neglect the interactions with related argument-mining tasks, such as argument identification and evidence detection. In this work, we close this gap by approaching argument quality estimation from multiple different angles:Grounded on rich results from thorough empirical evaluations, we assess the generalization capabilities of argument quality estimation across diverse domains and the interplay with related argument mining tasks. We find that generalization depends on a sufficient representation of different domains in the training part. In zero-shot transfer and multi-task experiments, we reveal that argument quality is among the more challenging tasks but can improve others. We publish our code at \\url{https://github.com/fromm-m/acl-cross-domain-aq}.\",\n}\n",
    "authors": [
        "Michael Fromm",
        "Max Berrendorf",
        "Evgeniy Faerman",
        "Thomas Seidl"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.848.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4301c7d5-5ba0-5a4d-8e8e-a2b6d8a21506.pdf",
    "abstract": "Argumentation is one of societyâ€™s foundational pillars, and, sparked by advances in NLP, and the vast availability of text data, automated mining of arguments receives increasing attention. A decisive property of arguments is their strength or quality. While there are works on the automated estimation of argument strength, their scope is narrow:They focus on isolated datasets and neglect the interactions with related argument-mining tasks, such as argument identification and evidence detection. In this work, we close this gap by approaching argument quality estimation from multiple different angles:Grounded on rich results from thorough empirical evaluations, we assess the generalization capabilities of argument quality estimation across diverse domains and the interplay with related argument mining tasks. We find that generalization depends on a sufficient representation of different domains in the training part. In zero-shot transfer and multi-task experiments, we reveal that argument quality is among the more challenging tasks but can improve others. We publish our code at https://github.com/fromm-m/acl-cross-domain-aq.",
    "num_pages": 14
}