{
    "uuid": "2da8008a-9722-5f9e-a981-82ec43159822",
    "title": "Open Set Relation Extraction via Unknown-Aware Training",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhao-etal-2023-open,\n    title = \"Open Set Relation Extraction via Unknown-Aware Training\",\n    author = \"Zhao, Jun  and\n      Zhao, Xin  and\n      Zhan, WenYu  and\n      Zhang, Qi  and\n      Gui, Tao  and\n      Wei, Zhongyu  and\n      Chen, Yun Wen  and\n      Gao, Xiang  and\n      Huang, Xuanjing\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.525\",\n    doi = \"10.18653/v1/2023.acl-long.525\",\n    pages = \"9453--9467\",\n    abstract = \"The existing supervised relation extraction methods have achieved impressive performance in a closed-set setting, in which the relations remain the same during both training and testing. In a more realistic open-set setting, unknown relations may appear in the test set. Due to the lack of supervision signals from unknown relations, a well-performing closed-set relation extractor can still confidently misclassify them into known relations. In this paper, we propose an unknown-aware training method, regularizing the model by dynamically synthesizing negative instances that can provide the missing supervision signals. Inspired by text adversarial attack, We adaptively apply small but critical perturbations to original training data,synthesizing \\textbf{difficult enough} negative instances that are mistaken by the model as known relations, thus facilitating a compact decision boundary. Experimental results show that our method achieves SOTA unknown relation detection without compromising the classification of known relations.\",\n}\n",
    "authors": [
        "Jun Zhao",
        "Xin Zhao",
        "WenYu Zhan",
        "Qi Zhang",
        "Tao Gui",
        "Zhongyu Wei",
        "Yun Wen Chen",
        "Xiang Gao",
        "Xuanjing Huang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.525.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/2da8008a-9722-5f9e-a981-82ec43159822.pdf",
    "abstract": "The existing supervised relation extraction methods have achieved impressive performance in a closed-set setting, in which the relations remain the same during both training and testing. In a more realistic open-set setting, unknown relations may appear in the test set. Due to the lack of supervision signals from unknown relations, a well-performing closed-set relation extractor can still confidently misclassify them into known relations. In this paper, we propose an unknown-aware training method, regularizing the model by dynamically synthesizing negative instances that can provide the missing supervision signals. Inspired by text adversarial attack, We adaptively apply small but critical perturbations to original training data,synthesizing difficult enough negative instances that are mistaken by the model as known relations, thus facilitating a compact decision boundary. Experimental results show that our method achieves SOTA unknown relation detection without compromising the classification of known relations.",
    "num_pages": 15
}