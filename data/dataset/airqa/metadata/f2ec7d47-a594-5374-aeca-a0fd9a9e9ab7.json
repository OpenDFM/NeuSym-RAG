{
    "uuid": "f2ec7d47-a594-5374-aeca-a0fd9a9e9ab7",
    "title": "Instruction Fusion: Advancing Prompt Evolution through Hybridization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{guo-etal-2024-instruction,\n    title = \"Instruction Fusion: Advancing Prompt Evolution through Hybridization\",\n    author = \"Guo, Weidong  and\n      Yang, Jiuding  and\n      Yang, Kaitong  and\n      Li, Xiangyang  and\n      Rao, Zhuwei  and\n      Xu, Yu  and\n      Niu, Di\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.214\",\n    doi = \"10.18653/v1/2024.acl-long.214\",\n    pages = \"3883--3893\",\n    abstract = \"The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code generation tasks. This paper examines the constraints of existing prompt evolution techniques and introduces a novel approach, Instruction Fusion (IF). IF innovatively combines two distinct prompts through a hybridization process, thereby enhancing the evolution of training prompts for code LLMs. Our experimental results reveal that the proposed novel method effectively addresses the shortcomings of prior methods, significantly improving the performance of Code LLMs across five code generation benchmarks, namely HumanEval, HumanEval+, MBPP, MBPP+ and MultiPL-E, which underscore the effectiveness of Instruction Fusion in advancing the capabilities of LLMs in code generation.\",\n}\n",
    "authors": [
        "Weidong Guo",
        "Jiuding Yang",
        "Kaitong Yang",
        "Xiangyang Li",
        "Zhuwei Rao",
        "Yu Xu",
        "Di Niu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.214.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/f2ec7d47-a594-5374-aeca-a0fd9a9e9ab7.pdf",
    "abstract": "The fine-tuning of Large Language Models (LLMs) specialized in code generation has seen notable advancements through the use of open-domain coding queries. Despite the successes, existing methodologies like Evol-Instruct encounter performance limitations, impeding further enhancements in code generation tasks. This paper examines the constraints of existing prompt evolution techniques and introduces a novel approach, Instruction Fusion (IF). IF innovatively combines two distinct prompts through a hybridization process, thereby enhancing the evolution of training prompts for code LLMs. Our experimental results reveal that the proposed novel method effectively addresses the shortcomings of prior methods, significantly improving the performance of Code LLMs across five code generation benchmarks, namely HumanEval, HumanEval+, MBPP, MBPP+ and MultiPL-E, which underscore the effectiveness of Instruction Fusion in advancing the capabilities of LLMs in code generation.",
    "num_pages": 11
}