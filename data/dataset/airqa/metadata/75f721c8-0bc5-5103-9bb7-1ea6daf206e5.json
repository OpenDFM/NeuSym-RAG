{
    "uuid": "75f721c8-0bc5-5103-9bb7-1ea6daf206e5",
    "title": "Revisiting Sentence Union Generation as a Testbed for Text Consolidation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{hirsch-etal-2023-revisiting,\n    title = \"Revisiting Sentence Union Generation as a Testbed for Text Consolidation\",\n    author = \"Hirsch, Eran  and\n      Pyatkin, Valentina  and\n      Wolhandler, Ruben  and\n      Caciularu, Avi  and\n      Shefer, Asi  and\n      Dagan, Ido\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.440\",\n    doi = \"10.18653/v1/2023.findings-acl.440\",\n    pages = \"7038--7058\",\n    abstract = \"Tasks involving text generation based on multiple input texts, such as multi-document summarization, long-form question answering and contemporary dialogue applications, challenge models for their ability to properly consolidate partly-overlapping multi-text information. However, these tasks entangle the consolidation phase with the often subjective and ill-defined content selection requirement, impeding proper assessment of models{'} consolidation capabilities. In this paper, we suggest revisiting the sentence union generation task as an effective well-defined testbed for assessing text consolidation capabilities, decoupling the consolidation challenge from subjective content selection. To support research on this task, we present refined annotation methodology and tools for crowdsourcing sentence union, create the largest union dataset to date and provide an analysis of its rich coverage of various consolidation aspects. We then propose a comprehensive evaluation protocol for union generation, including both human and automatic evaluation. Finally, as baselines, we evaluate state-of-the-art language models on the task, along with a detailed analysis of their capacity to address multi-text consolidation challenges and their limitations.\",\n}\n",
    "authors": [
        "Eran Hirsch",
        "Valentina Pyatkin",
        "Ruben Wolhandler",
        "Avi Caciularu",
        "Asi Shefer",
        "Ido Dagan"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.440.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/75f721c8-0bc5-5103-9bb7-1ea6daf206e5.pdf",
    "abstract": "Tasks involving text generation based on multiple input texts, such as multi-document summarization, long-form question answering and contemporary dialogue applications, challenge models for their ability to properly consolidate partly-overlapping multi-text information. However, these tasks entangle the consolidation phase with the often subjective and ill-defined content selection requirement, impeding proper assessment of modelsâ€™ consolidation capabilities. In this paper, we suggest revisiting the sentence union generation task as an effective well-defined testbed for assessing text consolidation capabilities, decoupling the consolidation challenge from subjective content selection. To support research on this task, we present refined annotation methodology and tools for crowdsourcing sentence union, create the largest union dataset to date and provide an analysis of its rich coverage of various consolidation aspects. We then propose a comprehensive evaluation protocol for union generation, including both human and automatic evaluation. Finally, as baselines, we evaluate state-of-the-art language models on the task, along with a detailed analysis of their capacity to address multi-text consolidation challenges and their limitations.",
    "num_pages": 21
}