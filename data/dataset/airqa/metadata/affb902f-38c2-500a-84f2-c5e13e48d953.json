{
    "uuid": "affb902f-38c2-500a-84f2-c5e13e48d953",
    "title": "CHECKWHY: Causal Fact Verification via Argument Structure",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{si-etal-2024-checkwhy,\n    title = \"{CHECKWHY}: Causal Fact Verification via Argument Structure\",\n    author = \"Si, Jiasheng  and\n      Zhao, Yibo  and\n      Zhu, Yingjie  and\n      Zhu, Haiyang  and\n      Lu, Wenpeng  and\n      Zhou, Deyu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.835\",\n    doi = \"10.18653/v1/2024.acl-long.835\",\n    pages = \"15636--15659\",\n    abstract = \"With the growing complexity of fact verification tasks, the concern with {``}thoughtful{''} reasoning capabilities is increasing. However, recent fact verification benchmarks mainly focus on checking a narrow scope of semantic factoids within claims and lack an explicit logical reasoning process. In this paper, we introduce CHECKWHY, a challenging dataset tailored to a novel causal fact verification task: checking the truthfulness of the causal relation within claims through rigorous reasoning steps. CHECKWHY consists of over 19K {``}why{''} claim-evidence- argument structure triplets with supports, refutes, and not enough info labels. Each argument structure is composed of connected evidence, representing the reasoning process that begins with foundational evidence and progresses toward claim establishment. Through extensive experiments on state-of-the-art models, we validate the importance of incorporating the argument structure for causal fact verification. Moreover, the automated and human evaluation of argument structure generation reveals the difficulty in producing satisfying argument structure by fine-tuned models or Chain-of-Thought prompted LLMs, leaving considerable room for future improvements.\",\n}\n",
    "authors": [
        "Jiasheng Si",
        "Yibo Zhao",
        "Yingjie Zhu",
        "Haiyang Zhu",
        "Wenpeng Lu",
        "Deyu Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.835.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/affb902f-38c2-500a-84f2-c5e13e48d953.pdf",
    "abstract": "With the growing complexity of fact verification tasks, the concern with “thoughtful” reasoning capabilities is increasing. However, recent fact verification benchmarks mainly focus on checking a narrow scope of semantic factoids within claims and lack an explicit logical reasoning process. In this paper, we introduce CHECKWHY, a challenging dataset tailored to a novel causal fact verification task: checking the truthfulness of the causal relation within claims through rigorous reasoning steps. CHECKWHY consists of over 19K “why” claim-evidence- argument structure triplets with supports, refutes, and not enough info labels. Each argument structure is composed of connected evidence, representing the reasoning process that begins with foundational evidence and progresses toward claim establishment. Through extensive experiments on state-of-the-art models, we validate the importance of incorporating the argument structure for causal fact verification. Moreover, the automated and human evaluation of argument structure generation reveals the difficulty in producing satisfying argument structure by fine-tuned models or Chain-of-Thought prompted LLMs, leaving considerable room for future improvements.",
    "num_pages": 24
}