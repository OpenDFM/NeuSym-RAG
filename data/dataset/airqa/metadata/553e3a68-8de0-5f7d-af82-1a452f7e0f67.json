{
    "uuid": "553e3a68-8de0-5f7d-af82-1a452f7e0f67",
    "title": "Four Approaches to Low-Resource Multilingual NMT: The Helsinki Submission to the AmericasNLP 2023 Shared Task",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)",
    "bibtex": "@inproceedings{de-gibert-etal-2023-four,\n    title = \"Four Approaches to Low-Resource Multilingual {NMT}: The {H}elsinki Submission to the {A}mericas{NLP} 2023 Shared Task\",\n    author = {De Gibert, Ona  and\n      V{\\'a}zquez, Ra{\\'u}l  and\n      Aulamo, Mikko  and\n      Scherrer, Yves  and\n      Virpioja, Sami  and\n      Tiedemann, J{\\\"o}rg},\n    editor = \"Mager, Manuel  and\n      Ebrahimi, Abteen  and\n      Oncevay, Arturo  and\n      Rice, Enora  and\n      Rijhwani, Shruti  and\n      Palmer, Alexis  and\n      Kann, Katharina\",\n    booktitle = \"Proceedings of the Workshop on Natural Language Processing for Indigenous Languages of the Americas (AmericasNLP)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.americasnlp-1.20\",\n    doi = \"10.18653/v1/2023.americasnlp-1.20\",\n    pages = \"177--191\",\n    abstract = \"The Helsinki-NLP team participated in the AmericasNLP 2023 Shared Task with 6 submissions for all 11 language pairs arising from 4 different multilingual systems. We provide a detailed look at the work that went into collecting and preprocessing the data that led to our submissions. We explore various setups for multilingual Neural Machine Translation (NMT), namely knowledge distillation and transfer learning, multilingual NMT including a high-resource language (English), language-specific fine-tuning, and multilingual NMT exclusively using low-resource data. Our multilingual Model B ranks first in 4 out of the 11 language pairs.\",\n}\n",
    "authors": [
        "Ona De Gibert",
        "Raúl Vázquez",
        "Mikko Aulamo",
        "Yves Scherrer",
        "Sami Virpioja",
        "Jörg Tiedemann"
    ],
    "pdf_url": "https://aclanthology.org/2023.americasnlp-1.20.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/553e3a68-8de0-5f7d-af82-1a452f7e0f67.pdf",
    "abstract": "The Helsinki-NLP team participated in the AmericasNLP 2023 Shared Task with 6 submissions for all 11 language pairs arising from 4 different multilingual systems. We provide a detailed look at the work that went into collecting and preprocessing the data that led to our submissions. We explore various setups for multilingual Neural Machine Translation (NMT), namely knowledge distillation and transfer learning, multilingual NMT including a high-resource language (English), language-specific fine-tuning, and multilingual NMT exclusively using low-resource data. Our multilingual Model B ranks first in 4 out of the 11 language pairs.",
    "num_pages": 15
}