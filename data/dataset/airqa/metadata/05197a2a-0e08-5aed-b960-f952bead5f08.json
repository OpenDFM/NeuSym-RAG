{
    "uuid": "05197a2a-0e08-5aed-b960-f952bead5f08",
    "title": "DITTO: Data-efficient and Fair Targeted Subset Selection for ASR Accent Adaptation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{kothawade-etal-2023-ditto,\n    title = \"{DITTO}: Data-efficient and Fair Targeted Subset Selection for {ASR} Accent Adaptation\",\n    author = \"Kothawade, Suraj  and\n      Mekala, Anmol  and\n      Hetha Havya, D.Chandra Sekhara  and\n      Kothyari, Mayank  and\n      Iyer, Rishabh  and\n      Ramakrishnan, Ganesh  and\n      Jyothi, Preethi\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.319\",\n    doi = \"10.18653/v1/2023.acl-long.319\",\n    pages = \"5810--5822\",\n    abstract = \"State-of-the-art Automatic Speech Recognition (ASR) systems are known to exhibit disparate performance on varying speech accents. To improve performance on a specific target accent, a commonly adopted solution is to finetune the ASR model using accent-specific labeled speech. However, acquiring large amounts of labeled speech for specific target accents is challenging. Choosing an informative subset of speech samples that are most representative of the target accents becomes important for effective ASR finetuning. To address this problem, we propose DITTO (Data-efficient and faIr Targeted subseT selectiOn that uses Submodular Mutual Information (SMI) functions as acquisition functions to find the most informative set of utterances matching a target accent within a fixed budget. An important feature of DITTO is that it supports fair targeting for multiple accents, i.e. it can automatically select representative data points from multiple accents when the ASR model needs to perform well on more than one accent. We show that compared to other speech selection methods, DITTO is 3-5 times as label-efficient for its improvements on the Indic-TTS and L2 datasets.\",\n}\n",
    "authors": [
        "Suraj Kothawade",
        "Anmol Mekala",
        "D.Chandra Sekhara Hetha Havya",
        "Mayank Kothyari",
        "Rishabh Iyer",
        "Ganesh Ramakrishnan",
        "Preethi Jyothi"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.319.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/05197a2a-0e08-5aed-b960-f952bead5f08.pdf",
    "abstract": "State-of-the-art Automatic Speech Recognition (ASR) systems are known to exhibit disparate performance on varying speech accents. To improve performance on a specific target accent, a commonly adopted solution is to finetune the ASR model using accent-specific labeled speech. However, acquiring large amounts of labeled speech for specific target accents is challenging. Choosing an informative subset of speech samples that are most representative of the target accents becomes important for effective ASR finetuning. To address this problem, we propose DITTO (Data-efficient and faIr Targeted subseT selectiOn that uses Submodular Mutual Information (SMI) functions as acquisition functions to find the most informative set of utterances matching a target accent within a fixed budget. An important feature of DITTO is that it supports fair targeting for multiple accents, i.e. it can automatically select representative data points from multiple accents when the ASR model needs to perform well on more than one accent. We show that compared to other speech selection methods, DITTO is 3-5 times as label-efficient for its improvements on the Indic-TTS and L2 datasets.",
    "num_pages": 13
}