{
    "uuid": "a08e7e81-2cd4-5fbb-84be-0fd09b0dc455",
    "title": "Towards Identifying Fine-Grained Depression Symptoms from Memes",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{yadav-etal-2023-towards,\n    title = \"Towards Identifying Fine-Grained Depression Symptoms from Memes\",\n    author = \"Yadav, Shweta  and\n      Caragea, Cornelia  and\n      Zhao, Chenye  and\n      Kumari, Naincy  and\n      Solberg, Marvin  and\n      Sharma, Tanmay\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.495\",\n    doi = \"10.18653/v1/2023.acl-long.495\",\n    pages = \"8890--8905\",\n    abstract = \"The past decade has observed significant attention toward developing computational methods for classifying social media data based on the presence or absence of mental health conditions. In the context of mental health, for clinicians to make an accurate diagnosis or provide personalized intervention, it is crucial to identify fine-grained mental health symptoms. To this end, we conduct a focused study on depression disorder and introduce a new task of identifying fine-grained depressive symptoms from memes. Toward this, we create a high-quality dataset (RESTORE) annotated with 8 fine-grained depression symptoms based on the clinically adopted PHQ-9 questionnaire. We benchmark RESTORE on 20 strong monomodal and multimodal methods. Additionally, we show how imposing orthogonal constraints on textual and visual feature representations in a multimodal setting can enforce the model to learn non-redundant and de-correlated features leading to a better prediction of fine-grained depression symptoms. Further, we conduct an extensive human analysis and elaborate on the limitations of existing multimodal models that often overlook the implicit connection between visual and textual elements of a meme.\",\n}\n",
    "authors": [
        "Shweta Yadav",
        "Cornelia Caragea",
        "Chenye Zhao",
        "Naincy Kumari",
        "Marvin Solberg",
        "Tanmay Sharma"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.495.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a08e7e81-2cd4-5fbb-84be-0fd09b0dc455.pdf",
    "abstract": "The past decade has observed significant attention toward developing computational methods for classifying social media data based on the presence or absence of mental health conditions. In the context of mental health, for clinicians to make an accurate diagnosis or provide personalized intervention, it is crucial to identify fine-grained mental health symptoms. To this end, we conduct a focused study on depression disorder and introduce a new task of identifying fine-grained depressive symptoms from memes. Toward this, we create a high-quality dataset (RESTORE) annotated with 8 fine-grained depression symptoms based on the clinically adopted PHQ-9 questionnaire. We benchmark RESTORE on 20 strong monomodal and multimodal methods. Additionally, we show how imposing orthogonal constraints on textual and visual feature representations in a multimodal setting can enforce the model to learn non-redundant and de-correlated features leading to a better prediction of fine-grained depression symptoms. Further, we conduct an extensive human analysis and elaborate on the limitations of existing multimodal models that often overlook the implicit connection between visual and textual elements of a meme.",
    "num_pages": 16
}