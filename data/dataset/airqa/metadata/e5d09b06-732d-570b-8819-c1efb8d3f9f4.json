{
    "uuid": "e5d09b06-732d-570b-8819-c1efb8d3f9f4",
    "title": "Towards Multiple References Era â€“ Addressing Data Leakage and Limited Reference Diversity in Machine Translation Evaluation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zeng-etal-2024-towards,\n    title = \"Towards Multiple References Era {--} Addressing Data Leakage and Limited Reference Diversity in Machine Translation Evaluation\",\n    author = \"Zeng, Xianfeng  and\n      Liu, Yijin  and\n      Meng, Fandong  and\n      Zhou, Jie\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.710\",\n    doi = \"10.18653/v1/2024.findings-acl.710\",\n    pages = \"11939--11951\",\n    abstract = \"Recent research has shown a weak correlation between n-gram-based metrics and human evaluations in machine translation task, particularly when evaluating large language models (LLMs). Additionally, the data leakage risk in LLMs may cause an overestimation problem when evaluating LLMs on downstream tasks. In this work, we identify the limited diversity of references as the primary cause for the inferior performance of n-gram-based metrics and the overestimation problem. To address this issue, we propose to utilize multiple references generated by LLMs, coupled with an effective selection strategy focused on accuracy and diversity, to improve the alignment between automatic metrics and human evaluations. We validate our approach on the WMT22 Metrics benchmark with 4 languages and observe a maximum accuracy gain of 9.5{\\%} in F200spBLEU, which makes it on par with computationally expensive neural-based metrics. We also show that using multi-reference with n-gram-based metrics significantly alleviates the overestimation problem when evaluating LLMs with data leakage. Further analysis explores the factors that affect the quality of generated references, offering insights into data synthesis by LLMs.\",\n}\n",
    "authors": [
        "Xianfeng Zeng",
        "Yijin Liu",
        "Fandong Meng",
        "Jie Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.710.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/e5d09b06-732d-570b-8819-c1efb8d3f9f4.pdf",
    "abstract": "Recent research has shown a weak correlation between n-gram-based metrics and human evaluations in machine translation task, particularly when evaluating large language models (LLMs). Additionally, the data leakage risk in LLMs may cause an overestimation problem when evaluating LLMs on downstream tasks. In this work, we identify the limited diversity of references as the primary cause for the inferior performance of n-gram-based metrics and the overestimation problem. To address this issue, we propose to utilize multiple references generated by LLMs, coupled with an effective selection strategy focused on accuracy and diversity, to improve the alignment between automatic metrics and human evaluations. We validate our approach on the WMT22 Metrics benchmark with 4 languages and observe a maximum accuracy gain of 9.5% in F200spBLEU, which makes it on par with computationally expensive neural-based metrics. We also show that using multi-reference with n-gram-based metrics significantly alleviates the overestimation problem when evaluating LLMs with data leakage. Further analysis explores the factors that affect the quality of generated references, offering insights into data synthesis by LLMs.",
    "num_pages": 13
}