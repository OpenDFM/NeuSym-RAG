{
    "uuid": "7b4fb947-e5a3-5d20-b058-e29934659dae",
    "title": "Reinforced Active Learning for Low-Resource, Domain-Specific, Multi-Label Text Classification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{wertz-etal-2023-reinforced,\n    title = \"Reinforced Active Learning for Low-Resource, Domain-Specific, Multi-Label Text Classification\",\n    author = \"Wertz, Lukas  and\n      Bogojeska, Jasmina  and\n      Mirylenka, Katsiaryna  and\n      Kuhn, Jonas\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.697\",\n    doi = \"10.18653/v1/2023.findings-acl.697\",\n    pages = \"10959--10977\",\n    abstract = \"Text classification datasets from specialised or technical domains are in high demand, especially in industrial applications. However, due to the high cost of annotation such datasets are usually expensive to create. While Active Learning (AL) can reduce the labeling cost, required AL strategies are often only tested on general knowledge domains and tend to use information sources that are not consistent across tasks. We propose Reinforced Active Learning (RAL) to train a Reinforcement Learning policy that utilizes many different aspects of the data and the task in order to select the most informative unlabeled subset dynamically over the course of the AL procedure. We demonstrate the superior performance of the proposed RAL framework compared to strong AL baselines across four intricate multi-class, multi-label text classification datasets taken from specialised domains. In addition, we experiment with a unique data augmentation approach to further reduce the number of samples RAL needs to annotate.\",\n}\n",
    "authors": [
        "Lukas Wertz",
        "Jasmina Bogojeska",
        "Katsiaryna Mirylenka",
        "Jonas Kuhn"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.697.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/7b4fb947-e5a3-5d20-b058-e29934659dae.pdf",
    "abstract": "Text classification datasets from specialised or technical domains are in high demand, especially in industrial applications. However, due to the high cost of annotation such datasets are usually expensive to create. While Active Learning (AL) can reduce the labeling cost, required AL strategies are often only tested on general knowledge domains and tend to use information sources that are not consistent across tasks. We propose Reinforced Active Learning (RAL) to train a Reinforcement Learning policy that utilizes many different aspects of the data and the task in order to select the most informative unlabeled subset dynamically over the course of the AL procedure. We demonstrate the superior performance of the proposed RAL framework compared to strong AL baselines across four intricate multi-class, multi-label text classification datasets taken from specialised domains. In addition, we experiment with a unique data augmentation approach to further reduce the number of samples RAL needs to annotate.",
    "num_pages": 19
}