{
    "uuid": "d1aa706a-7f4d-5db2-8feb-5ece78b31218",
    "title": "Evaluating Grammatical Well-Formedness in Large Language Models: A Comparative Study with Human Judgments",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
    "bibtex": "@inproceedings{qiu-etal-2024-evaluating,\n    title = \"Evaluating Grammatical Well-Formedness in Large Language Models: A Comparative Study with Human Judgments\",\n    author = \"Qiu, Zhuang  and\n      Duan, Xufeng  and\n      Cai, Zhenguang\",\n    editor = \"Kuribayashi, Tatsuki  and\n      Rambelli, Giulia  and\n      Takmaz, Ece  and\n      Wicke, Philipp  and\n      Oseki, Yohei\",\n    booktitle = \"Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.cmcl-1.16\",\n    doi = \"10.18653/v1/2024.cmcl-1.16\",\n    pages = \"189--198\",\n    abstract = \"Research in artificial intelligence has witnessed the surge of large language models (LLMs) demonstrating improved performance in various natural language processing tasks. This has sparked significant discussions about the extent to which large language models emulate human linguistic cognition and usage. This study delves into the representation of grammatical well-formedness in LLMs, which is a critical aspect of linguistic knowledge. In three preregistered experiments, we collected grammaticality judgment data for over 2400 English sentences with varying structures from ChatGPT and Vicuna, comparing them with human judgment data. The results reveal substantial alignment in the assessment of grammatical correctness between LLMs and human judgments, albeit with LLMs often showing more conservative judgments for grammatical correctness or incorrectness.\",\n}\n",
    "authors": [
        "Zhuang Qiu",
        "Xufeng Duan",
        "Zhenguang Cai"
    ],
    "pdf_url": "https://aclanthology.org/2024.cmcl-1.16.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d1aa706a-7f4d-5db2-8feb-5ece78b31218.pdf",
    "abstract": "Research in artificial intelligence has witnessed the surge of large language models (LLMs) demonstrating improved performance in various natural language processing tasks. This has sparked significant discussions about the extent to which large language models emulate human linguistic cognition and usage. This study delves into the representation of grammatical well-formedness in LLMs, which is a critical aspect of linguistic knowledge. In three preregistered experiments, we collected grammaticality judgment data for over 2400 English sentences with varying structures from ChatGPT and Vicuna, comparing them with human judgment data. The results reveal substantial alignment in the assessment of grammatical correctness between LLMs and human judgments, albeit with LLMs often showing more conservative judgments for grammatical correctness or incorrectness.",
    "num_pages": 10
}