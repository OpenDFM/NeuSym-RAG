{
    "uuid": "d688aaac-c6ab-58ff-ae61-d7a61b52f737",
    "title": "Walter Burns at SemEval-2023 Task 5: NLP-CIMAT - Leveraging Model Ensembles for Clickbait Spoiling",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{villa-cueva-etal-2023-walter,\n    title = \"Walter Burns at {S}em{E}val-2023 Task 5: {NLP}-{CIMAT} - Leveraging Model Ensembles for Clickbait Spoiling\",\n    author = \"Villa Cueva, Emilio  and\n      Vallejo Aldana, Daniel  and\n      S{\\'a}nchez Vega, Fernando  and\n      L{\\'o}pez Monroy, Adri{\\'a}n Pastor\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.95\",\n    doi = \"10.18653/v1/2023.semeval-1.95\",\n    pages = \"693--699\",\n    abstract = \"This paper describes our participation in the Clickbait challenge at SemEval 2023. In this work, we address the Clickbait classification task using transformers models in an ensemble configuration. We tackle the Spoiler Generation task using a two-level ensemble strategy of models trained for extractive QA, and selecting the best K candidates for multi-part spoilers. In the test partitions, our approaches obtained a classification accuracy of 0.716 for classification and a BLEU-4 score of 0.439 for spoiler generation.\",\n}\n",
    "authors": [
        "Emilio Villa Cueva",
        "Daniel Vallejo Aldana",
        "Fernando Sánchez Vega",
        "Adrián Pastor López Monroy"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.95.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/d688aaac-c6ab-58ff-ae61-d7a61b52f737.pdf",
    "abstract": "This paper describes our participation in the Clickbait challenge at SemEval 2023. In this work, we address the Clickbait classification task using transformers models in an ensemble configuration. We tackle the Spoiler Generation task using a two-level ensemble strategy of models trained for extractive QA, and selecting the best K candidates for multi-part spoilers. In the test partitions, our approaches obtained a classification accuracy of 0.716 for classification and a BLEU-4 score of 0.439 for spoiler generation.",
    "num_pages": 7
}