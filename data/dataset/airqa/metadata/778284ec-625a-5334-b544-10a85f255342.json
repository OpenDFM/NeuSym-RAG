{
    "uuid": "778284ec-625a-5334-b544-10a85f255342",
    "title": "Introducing Semantics into Speech Encoders",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{xu-etal-2023-introducing,\n    title = \"Introducing Semantics into Speech Encoders\",\n    author = \"Xu, Derek  and\n      Dong, Shuyan  and\n      Wang, Changhan  and\n      Kim, Suyoun  and\n      Lin, Zhaojiang  and\n      Liu, Bing  and\n      Shrivastava, Akshat  and\n      Li, Shang-Wen  and\n      Tseng, Liang-Hsuan  and\n      Lin, Guan-Ting  and\n      Baevski, Alexei  and\n      Lee, Hung-yi  and\n      Sun, Yizhou  and\n      Wang, Wei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.639\",\n    doi = \"10.18653/v1/2023.acl-long.639\",\n    pages = \"11413--11429\",\n    abstract = \"Recent studies find existing self-supervised speech encoders contain primarily acoustic rather than semantic information. As a result, pipelined supervised automatic speech recognition (ASR) to large language model (LLM) systems achieve state-of-the-art results on semantic spoken language tasks by utilizing rich semantic representations from the LLM. These systems come at the cost of labeled audio transcriptions, which is expensive and time-consuming to obtain. We propose a task-agnostic unsupervised way of incorporating semantic information from LLMs into self-supervised speech encoders without labeled audio transcriptions. By introducing semantics, we improve existing speech encoder spoken language understanding (SLU) performance by over 5{\\%} on intent classification (IC), with modest gains in named entity resolution (NER) and slot filling (SF), and spoken question answering (SQA) FF1 score by over 2{\\%}. Our approach, which uses no ASR data, achieves similar performance as methods trained on over 100 hours of labeled audio transcripts, demonstrating the feasibility of unsupervised semantic augmentations to existing speech encoders.\",\n}\n",
    "authors": [
        "Derek Xu",
        "Shuyan Dong",
        "Changhan Wang",
        "Suyoun Kim",
        "Zhaojiang Lin",
        "Bing Liu",
        "Akshat Shrivastava",
        "Shang-Wen Li",
        "Liang-Hsuan Tseng",
        "Guan-Ting Lin",
        "Alexei Baevski",
        "Hung-yi Lee",
        "Yizhou Sun",
        "Wei Wang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.639.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/778284ec-625a-5334-b544-10a85f255342.pdf",
    "abstract": "Recent studies find existing self-supervised speech encoders contain primarily acoustic rather than semantic information. As a result, pipelined supervised automatic speech recognition (ASR) to large language model (LLM) systems achieve state-of-the-art results on semantic spoken language tasks by utilizing rich semantic representations from the LLM. These systems come at the cost of labeled audio transcriptions, which is expensive and time-consuming to obtain. We propose a task-agnostic unsupervised way of incorporating semantic information from LLMs into self-supervised speech encoders without labeled audio transcriptions. By introducing semantics, we improve existing speech encoder spoken language understanding (SLU) performance by over 5% on intent classification (IC), with modest gains in named entity resolution (NER) and slot filling (SF), and spoken question answering (SQA) FF1 score by over 2%. Our approach, which uses no ASR data, achieves similar performance as methods trained on over 100 hours of labeled audio transcripts, demonstrating the feasibility of unsupervised semantic augmentations to existing speech encoders.",
    "num_pages": 17
}