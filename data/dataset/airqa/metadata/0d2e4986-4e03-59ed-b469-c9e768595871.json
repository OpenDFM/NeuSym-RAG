{
    "uuid": "0d2e4986-4e03-59ed-b469-c9e768595871",
    "title": "KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{yang-etal-2024-kg,\n    title = \"{KG}-Rank: Enhancing Large Language Models for Medical {QA} with Knowledge Graphs and Ranking Techniques\",\n    author = \"Yang, Rui  and\n      Liu, Haoran  and\n      Marrese-Taylor, Edison  and\n      Zeng, Qingcheng  and\n      Ke, Yuhe  and\n      Li, Wanxin  and\n      Cheng, Lechao  and\n      Chen, Qingyu  and\n      Caverlee, James  and\n      Matsuo, Yutaka  and\n      Li, Irene\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.13\",\n    doi = \"10.18653/v1/2024.bionlp-1.13\",\n    pages = \"155--166\",\n    abstract = \"Large Language Models (LLMs) have significantly advanced healthcare innovation on generation capabilities. However, their application in real clinical settings is challenging due to potential deviations from medical facts and inherent biases. In this work, we develop an augmented LLM framework, KG-Rank, which leverages a medical knowledge graph (KG) with ranking and re-ranking techniques, aiming to improve free-text question-answering (QA) in the medical domain. Specifically, upon receiving a question, we initially retrieve triplets from a medical KG to gather factual information. Subsequently, we innovatively apply ranking methods to refine the ordering of these triplets, aiming to yield more precise answers. To the best of our knowledge, KG-Rank is the first application of ranking models combined with KG in medical QA specifically for generating long answers. Evaluation of four selected medical QA datasets shows that KG-Rank achieves an improvement of over 18{\\%} in the ROUGE-L score. Moreover, we extend KG-Rank to open domains, where it realizes a 14{\\%} improvement in ROUGE-L, showing the effectiveness and potential of KG-Rank.\",\n}\n",
    "authors": [
        "Rui Yang",
        "Haoran Liu",
        "Edison Marrese-Taylor",
        "Qingcheng Zeng",
        "Yuhe Ke",
        "Wanxin Li",
        "Lechao Cheng",
        "Qingyu Chen",
        "James Caverlee",
        "Yutaka Matsuo",
        "Irene Li"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.13.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/0d2e4986-4e03-59ed-b469-c9e768595871.pdf",
    "abstract": "Large Language Models (LLMs) have significantly advanced healthcare innovation on generation capabilities. However, their application in real clinical settings is challenging due to potential deviations from medical facts and inherent biases. In this work, we develop an augmented LLM framework, KG-Rank, which leverages a medical knowledge graph (KG) with ranking and re-ranking techniques, aiming to improve free-text question-answering (QA) in the medical domain. Specifically, upon receiving a question, we initially retrieve triplets from a medical KG to gather factual information. Subsequently, we innovatively apply ranking methods to refine the ordering of these triplets, aiming to yield more precise answers. To the best of our knowledge, KG-Rank is the first application of ranking models combined with KG in medical QA specifically for generating long answers. Evaluation of four selected medical QA datasets shows that KG-Rank achieves an improvement of over 18% in the ROUGE-L score. Moreover, we extend KG-Rank to open domains, where it realizes a 14% improvement in ROUGE-L, showing the effectiveness and potential of KG-Rank.",
    "num_pages": 12
}