{
    "uuid": "51d7d19b-7108-57da-8fd0-b96b463aebb2",
    "title": "VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{nguyen-son-etal-2023-votetrans,\n    title = \"{V}ote{TRANS}: Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations\",\n    author = \"Nguyen-Son, Hoang-Quoc  and\n      Hidano, Seira  and\n      Fukushima, Kazuhide  and\n      Kiyomoto, Shinsaku  and\n      Echizen, Isao\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.315\",\n    doi = \"10.18653/v1/2023.findings-acl.315\",\n    pages = \"5090--5104\",\n    abstract = \"Adversarial attacks reveal serious flaws in deep learning models. More dangerously, these attacks preserve the original meaning and escape human recognition. Existing methods for detecting these attacks need to be trained using original/adversarial data. In this paper, we propose detection without training by voting on hard labels from predictions of transformations, namely, VoteTRANS. Specifically, VoteTRANS detects adversarial text by comparing the hard labels of input text and its transformation. The evaluation demonstrates that VoteTRANS effectively detects adversarial text across various state-of-the-art attacks, models, and datasets.\",\n}\n",
    "authors": [
        "Hoang-Quoc Nguyen-Son",
        "Seira Hidano",
        "Kazuhide Fukushima",
        "Shinsaku Kiyomoto",
        "Isao Echizen"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.315.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/51d7d19b-7108-57da-8fd0-b96b463aebb2.pdf",
    "abstract": "Adversarial attacks reveal serious flaws in deep learning models. More dangerously, these attacks preserve the original meaning and escape human recognition. Existing methods for detecting these attacks need to be trained using original/adversarial data. In this paper, we propose detection without training by voting on hard labels from predictions of transformations, namely, VoteTRANS. Specifically, VoteTRANS detects adversarial text by comparing the hard labels of input text and its transformation. The evaluation demonstrates that VoteTRANS effectively detects adversarial text across various state-of-the-art attacks, models, and datasets.",
    "num_pages": 15
}