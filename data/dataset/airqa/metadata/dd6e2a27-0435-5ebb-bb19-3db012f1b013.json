{
    "uuid": "dd6e2a27-0435-5ebb-bb19-3db012f1b013",
    "title": "Lightweight morpheme labeling in context: Using structured linguistic representations to support linguistic analysis for the language documentation context",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th SIGMORPHON workshop on Computational Research in Phonetics, Phonology, and Morphology",
    "bibtex": "@inproceedings{shandilya-palmer-2023-lightweight,\n    title = \"Lightweight morpheme labeling in context: Using structured linguistic representations to support linguistic analysis for the language documentation context\",\n    author = \"Shandilya, Bhargav  and\n      Palmer, Alexis\",\n    editor = {Nicolai, Garrett  and\n      Chodroff, Eleanor  and\n      Mailhot, Frederic  and\n      {\\c{C}}{\\\"o}ltekin, {\\c{C}}a{\\u{g}}r{\\i}},\n    booktitle = \"Proceedings of the 20th SIGMORPHON workshop on Computational Research in Phonetics, Phonology, and Morphology\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.sigmorphon-1.9\",\n    doi = \"10.18653/v1/2023.sigmorphon-1.9\",\n    pages = \"78--92\",\n    abstract = \"Linguistic analysis is a core task in the process of documenting, analyzing, and describing endangered and less-studied languages. In addition to providing insight into the properties of the language being studied, having tools to automatically label words in a language for grammatical category and morphological features can support a range of applications useful for language pedagogy and revitalization. At the same time, most modern NLP methods for these tasks require both large amounts of data in the language and compute costs well beyond the capacity of most research groups and language communities. In this paper, we present a gloss-to-gloss (g2g) model for linguistic analysis (specifically, morphological analysis and part-of-speech tagging) that is lightweight in terms of both data requirements and computational expense. The model is designed for the interlinear glossed text (IGT) format, in which we expect the source text of a sentence in a low-resource language, a translation of that sentence into a language of wider communication, and a detailed glossing of the morphological properties of each word in the sentence. We first produce silver standard parallel glossed data by automatically labeling the high-resource translation. The model then learns to transform source language morphological labels into output labels for the target language, mediated by a structured linguistic representation layer. We test the model on both low-resource and high-resource languages, and find that our simple CNN-based model achieves comparable performance to a state-of-the-art transformer-based model, at a fraction of the computational cost.\",\n}\n",
    "authors": [
        "Bhargav Shandilya",
        "Alexis Palmer"
    ],
    "pdf_url": "https://aclanthology.org/2023.sigmorphon-1.9.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/dd6e2a27-0435-5ebb-bb19-3db012f1b013.pdf",
    "abstract": "Linguistic analysis is a core task in the process of documenting, analyzing, and describing endangered and less-studied languages. In addition to providing insight into the properties of the language being studied, having tools to automatically label words in a language for grammatical category and morphological features can support a range of applications useful for language pedagogy and revitalization. At the same time, most modern NLP methods for these tasks require both large amounts of data in the language and compute costs well beyond the capacity of most research groups and language communities. In this paper, we present a gloss-to-gloss (g2g) model for linguistic analysis (specifically, morphological analysis and part-of-speech tagging) that is lightweight in terms of both data requirements and computational expense. The model is designed for the interlinear glossed text (IGT) format, in which we expect the source text of a sentence in a low-resource language, a translation of that sentence into a language of wider communication, and a detailed glossing of the morphological properties of each word in the sentence. We first produce silver standard parallel glossed data by automatically labeling the high-resource translation. The model then learns to transform source language morphological labels into output labels for the target language, mediated by a structured linguistic representation layer. We test the model on both low-resource and high-resource languages, and find that our simple CNN-based model achieves comparable performance to a state-of-the-art transformer-based model, at a fraction of the computational cost.",
    "num_pages": 15
}