{
    "uuid": "3b50a23a-b813-5ff3-bb54-6aa1bd01f6dc",
    "title": "Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)",
    "bibtex": "@inproceedings{yuan-vlachos-2024-zero,\n    title = \"Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs\",\n    author = \"Yuan, Moy  and\n      Vlachos, Andreas\",\n    editor = \"Biswas, Russa  and\n      Kaffee, Lucie-Aim{\\'e}e  and\n      Agarwal, Oshin  and\n      Minervini, Pasquale  and\n      Singh, Sameer  and\n      de Melo, Gerard\",\n    booktitle = \"Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.kallm-1.11\",\n    doi = \"10.18653/v1/2024.kallm-1.11\",\n    pages = \"105--115\",\n    abstract = \"Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive. In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference. This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for. Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets.\",\n}\n",
    "authors": [
        "Moy Yuan",
        "Andreas Vlachos"
    ],
    "pdf_url": "https://aclanthology.org/2024.kallm-1.11.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3b50a23a-b813-5ff3-bb54-6aa1bd01f6dc.pdf",
    "abstract": "Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive. In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference. This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for. Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets.",
    "num_pages": 11
}