{
    "uuid": "c7efcc2e-e3e4-5a25-9b8c-a4aa5a06a192",
    "title": "Towards Robust Personalized Dialogue Generation via Order-Insensitive Representation Regularization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{chen-etal-2023-towards-robust,\n    title = \"Towards Robust Personalized Dialogue Generation via Order-Insensitive Representation Regularization\",\n    author = \"Chen, Liang  and\n      Wang, Hongru  and\n      Deng, Yang  and\n      Kwan, Wai Chung  and\n      Wang, Zezhong  and\n      Wong, Kam-Fai\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.462\",\n    doi = \"10.18653/v1/2023.findings-acl.462\",\n    pages = \"7337--7345\",\n    abstract = \"Generating persona consistent dialogue response is important for developing an intelligent conversational agent. Recent works typically fine-tune large-scale pre-trained models on this task by concatenating persona texts and dialogue history as a single input sequence to generate the target response. While simple and effective, our analysis shows that this popular practice is seriously affected by order sensitivity where different input orders of persona sentences significantly impact the quality and consistency of generated response, resulting in severe performance fluctuations (i.e., 29.4{\\%} on GPT2 and 83.2{\\%} on BART). To mitigate the order sensitivity problem, we propose a model-agnostic framework, ORder Insensitive Generation (ORIG), which enables dialogue models to learn robust representation under different persona orders and improve the consistency of response generation. Experiments on the Persona-Chat dataset justify the effectiveness and superiority of our method with two dominant pre-trained models (GPT2 and BART).\",\n}\n",
    "authors": [
        "Liang Chen",
        "Hongru Wang",
        "Yang Deng",
        "Wai Chung Kwan",
        "Zezhong Wang",
        "Kam-Fai Wong"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.462.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/c7efcc2e-e3e4-5a25-9b8c-a4aa5a06a192.pdf",
    "abstract": "Generating persona consistent dialogue response is important for developing an intelligent conversational agent. Recent works typically fine-tune large-scale pre-trained models on this task by concatenating persona texts and dialogue history as a single input sequence to generate the target response. While simple and effective, our analysis shows that this popular practice is seriously affected by order sensitivity where different input orders of persona sentences significantly impact the quality and consistency of generated response, resulting in severe performance fluctuations (i.e., 29.4% on GPT2 and 83.2% on BART). To mitigate the order sensitivity problem, we propose a model-agnostic framework, ORder Insensitive Generation (ORIG), which enables dialogue models to learn robust representation under different persona orders and improve the consistency of response generation. Experiments on the Persona-Chat dataset justify the effectiveness and superiority of our method with two dominant pre-trained models (GPT2 and BART).",
    "num_pages": 9
}