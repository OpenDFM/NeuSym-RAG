{
    "uuid": "b57a0a0a-1445-540c-a9d3-41ba72235a8d",
    "title": "Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{yu-etal-2024-explanation,\n    title = \"Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning\",\n    author = \"Yu, Yue  and\n      Shen, Jiaming  and\n      Liu, Tianqi  and\n      Qin, Zhen  and\n      Yan, Jing Nathan  and\n      Liu, Jialu  and\n      Zhang, Chao  and\n      Bendersky, Michael\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.755\",\n    doi = \"10.18653/v1/2024.acl-long.755\",\n    pages = \"14002--14024\",\n    abstract = \"Large language models (LLMs) have shown remarkable capabilities in various natural language understanding tasks with a few demonstration examples via in-context learning. Common strategies to boost such {``}in-context{''} learning ability are to ensemble multiple model decoded results and require the model to generate an explanation along with the prediction. However, these models often treat different class predictions equally and neglect the potential discrepancy between the explanations and predictions. To fully unleash the power of explanations, we propose EASE, an \\textit{Explanation-Aware Soft Ensemble} framework to empower in-context learning with LLMs. We design two techniques, explanation-guided ensemble, and soft probability aggregation, to mitigate the effect of unreliable explanations and improve the consistency between explanations and final predictions. Experiments on seven natural language understanding tasks and four varying-size LLMs demonstrate the effectiveness of our proposed framework.\",\n}\n",
    "authors": [
        "Yue Yu",
        "Jiaming Shen",
        "Tianqi Liu",
        "Zhen Qin",
        "Jing Nathan Yan",
        "Jialu Liu",
        "Chao Zhang",
        "Michael Bendersky"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.755.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b57a0a0a-1445-540c-a9d3-41ba72235a8d.pdf",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in various natural language understanding tasks with a few demonstration examples via in-context learning. Common strategies to boost such “in-context” learning ability are to ensemble multiple model decoded results and require the model to generate an explanation along with the prediction. However, these models often treat different class predictions equally and neglect the potential discrepancy between the explanations and predictions. To fully unleash the power of explanations, we propose EASE, an Explanation-Aware Soft Ensemble framework to empower in-context learning with LLMs. We design two techniques, explanation-guided ensemble, and soft probability aggregation, to mitigate the effect of unreliable explanations and improve the consistency between explanations and final predictions. Experiments on seven natural language understanding tasks and four varying-size LLMs demonstrate the effectiveness of our proposed framework.",
    "num_pages": 23
}