{
    "uuid": "09ffc174-f707-5561-b24a-7f6b55323711",
    "title": "Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{yadav-etal-2024-tox,\n    title = \"Tox-{BART}: Leveraging Toxicity Attributes for Explanation Generation of Implicit Hate Speech\",\n    author = \"Yadav, Neemesh  and\n      Masud, Sarah  and\n      Goyal, Vikram  and\n      Akhtar, Md Shad  and\n      Chakraborty, Tanmoy\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.831\",\n    doi = \"10.18653/v1/2024.findings-acl.831\",\n    pages = \"13967--13983\",\n    abstract = \"Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide world knowledge and improve performance on standard metrics. Interestingly, our study presents conflicting evidence for the role of the quality of KG tuples in generating implicit explanations. Consequently, simpler models incorporating external toxicity signals outperform KG-infused models. Compared to the KG-based setup, we observe a comparable performance for SBIC (LatentHatred) datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and -4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and error analysis reveal that our proposed setup produces more precise explanations than zero-shot GPT-3.5, highlighting the intricate nature of the task.\",\n}\n",
    "authors": [
        "Neemesh Yadav",
        "Sarah Masud",
        "Vikram Goyal",
        "Md Shad Akhtar",
        "Tanmoy Chakraborty"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.831.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/09ffc174-f707-5561-b24a-7f6b55323711.pdf",
    "abstract": "Employing language models to generate explanations for an incoming implicit hate post is an active area of research. The explanation is intended to make explicit the underlying stereotype and aid content moderators. The training often combines top-k relevant knowledge graph (KG) tuples to provide world knowledge and improve performance on standard metrics. Interestingly, our study presents conflicting evidence for the role of the quality of KG tuples in generating implicit explanations. Consequently, simpler models incorporating external toxicity signals outperform KG-infused models. Compared to the KG-based setup, we observe a comparable performance for SBIC (LatentHatred) datasets with a performance variation of +0.44 (+0.49), +1.83 (-1.56), and -4.59 (+0.77) in BLEU, ROUGE-L, and BERTScore. Further human evaluation and error analysis reveal that our proposed setup produces more precise explanations than zero-shot GPT-3.5, highlighting the intricate nature of the task.",
    "num_pages": 17
}