{
    "uuid": "6a7927c0-5a66-548a-b5c8-90a3b447093e",
    "title": "Disentangling Text Representation With Counter-Template For Unsupervised Opinion Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zhang-zhou-2023-disentangling,\n    title = \"Disentangling Text Representation With Counter-Template For Unsupervised Opinion Summarization\",\n    author = \"Zhang, Yanyue  and\n      Zhou, Deyu\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.395\",\n    doi = \"10.18653/v1/2023.findings-acl.395\",\n    pages = \"6344--6357\",\n    abstract = \"Approaches for unsupervised opinion summarization are generally based on the reconstruction model and generate a summary by decoding the aggregated representation of inputs. Recent work has shown that aggregating via simple average leads to vector degeneration, generating the generic summary. To tackle the challenge, some approaches select the inputs before aggregating. However, we argue that the selection is too coarse as not all information in each input is equally essential for the summary. For example, the content information such as {``}great coffee maker, easy to set up{''} is more valuable than the pattern such as {``}this is a great product{''}. Therefore, we propose a novel framework for unsupervised opinion summarization based on text representation disentanglement with counter-template. In specific, a disentangling module is added to the encoder-decoder architecture which decouples the input text representation into two parts: content and pattern. To capture the pattern information, a counter-template is utilized as supervision, which is automatically generated based on contrastive learning. Experimental results on two benchmark datasets show that the proposed approach outperforms the state-of-the-art baselines on both quality and stability.\",\n}\n",
    "authors": [
        "Yanyue Zhang",
        "Deyu Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.395.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/6a7927c0-5a66-548a-b5c8-90a3b447093e.pdf",
    "abstract": "Approaches for unsupervised opinion summarization are generally based on the reconstruction model and generate a summary by decoding the aggregated representation of inputs. Recent work has shown that aggregating via simple average leads to vector degeneration, generating the generic summary. To tackle the challenge, some approaches select the inputs before aggregating. However, we argue that the selection is too coarse as not all information in each input is equally essential for the summary. For example, the content information such as “great coffee maker, easy to set up” is more valuable than the pattern such as “this is a great product”. Therefore, we propose a novel framework for unsupervised opinion summarization based on text representation disentanglement with counter-template. In specific, a disentangling module is added to the encoder-decoder architecture which decouples the input text representation into two parts: content and pattern. To capture the pattern information, a counter-template is utilized as supervision, which is automatically generated based on contrastive learning. Experimental results on two benchmark datasets show that the proposed approach outperforms the state-of-the-art baselines on both quality and stability.",
    "num_pages": 14
}