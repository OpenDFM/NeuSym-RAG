{
    "uuid": "0a9a5401-c9f8-5566-93be-1302d8b2ad00",
    "title": "Transferring General Multimodal Pretrained Models to Text Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{lin-etal-2023-transferring,\n    title = \"Transferring General Multimodal Pretrained Models to Text Recognition\",\n    author = \"Lin, Junyang  and\n      Ren, Xuancheng  and\n      Zhang, Yichang  and\n      Liu, Gao  and\n      Wang, Peng  and\n      Yang, An  and\n      Zhou, Chang\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.37\",\n    doi = \"10.18653/v1/2023.findings-acl.37\",\n    pages = \"588--597\",\n    abstract = \"This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained models to text recognition. Specifically, we recast text recognition as image captioning and directly transfer a unified vision-language pretrained model to the end task. Without pretraining on large-scale annotated or synthetic text recognition data, OFA-OCR outperforms the baselines and achieves state-of-the-art performance in the Chinese text recognition benchmark. Additionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate that it can achieve competitive performance with the product-level API.\",\n}\n",
    "authors": [
        "Junyang Lin",
        "Xuancheng Ren",
        "Yichang Zhang",
        "Gao Liu",
        "Peng Wang",
        "An Yang",
        "Chang Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.37.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0a9a5401-c9f8-5566-93be-1302d8b2ad00.pdf",
    "abstract": "This paper proposes a new method, OFA-OCR, to transfer multimodal pretrained models to text recognition. Specifically, we recast text recognition as image captioning and directly transfer a unified vision-language pretrained model to the end task. Without pretraining on large-scale annotated or synthetic text recognition data, OFA-OCR outperforms the baselines and achieves state-of-the-art performance in the Chinese text recognition benchmark. Additionally, we construct an OCR pipeline with OFA-OCR, and we demonstrate that it can achieve competitive performance with the product-level API.",
    "num_pages": 10
}