{
    "uuid": "be457dc2-b5e3-5d07-8c51-a67a8a5ee54a",
    "title": "Towards Alleviating the Object Bias in Prompt Tuning-based Factual Knowledge Extraction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{wang-etal-2023-towards-alleviating,\n    title = \"Towards Alleviating the Object Bias in Prompt Tuning-based Factual Knowledge Extraction\",\n    author = \"Wang, Yuhang  and\n      Lu, Dongyuan  and\n      Kong, Chao  and\n      Sang, Jitao\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.270\",\n    doi = \"10.18653/v1/2023.findings-acl.270\",\n    pages = \"4420--4432\",\n    abstract = \"Many works employed prompt tuning methods to automatically optimize prompt queries and extract the factual knowledge stored in Pre-trained Language Models. In this paper, we observe that the optimized prompts, including discrete prompts and continuous prompts, exhibit undesirable object bias. To handle this problem, we propose a novel prompt tuning method called MeCoD consisting of three modules: Prompt Encoder, Object Equalization and Biased Object Obstruction. Experimental results show that MeCoD can significantly reduce the object bias and at the same time improve accuracy of factual knowledge extraction.\",\n}\n",
    "authors": [
        "Yuhang Wang",
        "Dongyuan Lu",
        "Chao Kong",
        "Jitao Sang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.270.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/be457dc2-b5e3-5d07-8c51-a67a8a5ee54a.pdf",
    "abstract": "Many works employed prompt tuning methods to automatically optimize prompt queries and extract the factual knowledge stored in Pre-trained Language Models. In this paper, we observe that the optimized prompts, including discrete prompts and continuous prompts, exhibit undesirable object bias. To handle this problem, we propose a novel prompt tuning method called MeCoD consisting of three modules: Prompt Encoder, Object Equalization and Biased Object Obstruction. Experimental results show that MeCoD can significantly reduce the object bias and at the same time improve accuracy of factual knowledge extraction.",
    "num_pages": 13
}