{
    "uuid": "4f9dd029-8226-5e2a-8a42-1d763942b1ab",
    "title": "Distantly-Supervised Joint Extraction with Noise-Robust Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{li-etal-2024-distantly,\n    title = \"Distantly-Supervised Joint Extraction with Noise-Robust Learning\",\n    author = \"Li, Yufei  and\n      Yu, Xiao  and\n      Guo, Yanghong  and\n      Liu, Yanchi  and\n      Chen, Haifeng  and\n      Liu, Cong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.607\",\n    doi = \"10.18653/v1/2024.findings-acl.607\",\n    pages = \"10202--10217\",\n    abstract = \"Joint entity and relation extraction is a process that identifies entity pairs and their relations using a single model. We focus on the problem of joint extraction in distantly-labeled data, whose labels are generated by aligning entity mentions with the corresponding entity and relation tags using a knowledge base (KB). One key challenge is the presence of noisy labels arising from both incorrect entity and relation annotations, which significantly impairs the quality of supervised learning. Existing approaches, either considering only one source of noise or making decisions using external knowledge, cannot well-utilize significant information in the training data. We propose DENRL, a generalizable framework that 1) incorporates a lightweight transformer backbone into a sequence labeling scheme for joint tagging, and 2) employs a noise-robust framework that regularizes the tagging model with significant relation patterns and entity-relation dependencies, then iteratively self-adapts to instances with less noise from both sources. Surprisingly, experiments on two benchmark datasets show that DENRL, using merely its own parametric distribution and simple data-driven heuristics, outperforms strong baselines by a large margin with better interpretability.\",\n}\n",
    "authors": [
        "Yufei Li",
        "Xiao Yu",
        "Yanghong Guo",
        "Yanchi Liu",
        "Haifeng Chen",
        "Cong Liu"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.607.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4f9dd029-8226-5e2a-8a42-1d763942b1ab.pdf",
    "abstract": "Joint entity and relation extraction is a process that identifies entity pairs and their relations using a single model. We focus on the problem of joint extraction in distantly-labeled data, whose labels are generated by aligning entity mentions with the corresponding entity and relation tags using a knowledge base (KB). One key challenge is the presence of noisy labels arising from both incorrect entity and relation annotations, which significantly impairs the quality of supervised learning. Existing approaches, either considering only one source of noise or making decisions using external knowledge, cannot well-utilize significant information in the training data. We propose DENRL, a generalizable framework that 1) incorporates a lightweight transformer backbone into a sequence labeling scheme for joint tagging, and 2) employs a noise-robust framework that regularizes the tagging model with significant relation patterns and entity-relation dependencies, then iteratively self-adapts to instances with less noise from both sources. Surprisingly, experiments on two benchmark datasets show that DENRL, using merely its own parametric distribution and simple data-driven heuristics, outperforms strong baselines by a large margin with better interpretability.",
    "num_pages": 16
}