{
    "uuid": "d2eeaeb4-004c-5080-bcfa-360a07ff798d",
    "title": "Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{wang-etal-2024-llms,\n    title = \"Can {LLM}s Reason with Rules? Logic Scaffolding for Stress-Testing and Improving {LLM}s\",\n    author = \"Wang, Siyuan  and\n      Wei, Zhongyu  and\n      Choi, Yejin  and\n      Ren, Xiang\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.406\",\n    doi = \"10.18653/v1/2024.acl-long.406\",\n    pages = \"7523--7543\",\n    abstract = \"Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains. Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs{'} logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns. We further distill these rules into a smaller-scale inference engine for flexible rule generation and enhancing downstream reasoning. Through a multi-judger evaluation, our inference engine proves effective in generating accurate, complex and abstract conclusions and premises, and improve various commonsense reasoning tasks. Overall, our work sheds light on LLMs{'} limitations in grasping inferential rule and suggests ways to enhance their logical reasoning abilities .\",\n}\n",
    "authors": [
        "Siyuan Wang",
        "Zhongyu Wei",
        "Yejin Choi",
        "Xiang Ren"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.406.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d2eeaeb4-004c-5080-bcfa-360a07ff798d.pdf",
    "abstract": "Large language models (LLMs) have achieved impressive human-like performance across various reasoning tasks. However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains. Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns. We further distill these rules into a smaller-scale inference engine for flexible rule generation and enhancing downstream reasoning. Through a multi-judger evaluation, our inference engine proves effective in generating accurate, complex and abstract conclusions and premises, and improve various commonsense reasoning tasks. Overall, our work sheds light on LLMs’ limitations in grasping inferential rule and suggests ways to enhance their logical reasoning abilities .",
    "num_pages": 21
}