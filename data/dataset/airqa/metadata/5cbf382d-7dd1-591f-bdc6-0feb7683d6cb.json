{
    "uuid": "5cbf382d-7dd1-591f-bdc6-0feb7683d6cb",
    "title": "A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{tang-etal-2024-b,\n    title = \"A + {B}: A General Generator-Reader Framework for Optimizing {LLM}s to Unleash Synergy Potential\",\n    author = \"Tang, Wei  and\n      Cao, Yixin  and\n      Ying, Jiahao  and\n      Wang, Bo  and\n      Zhao, Yuyue  and\n      Liao, Yong  and\n      Zhou, Peng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.219\",\n    doi = \"10.18653/v1/2024.findings-acl.219\",\n    pages = \"3670--3685\",\n    abstract = \"Retrieval-Augmented Generation (RAG) is an effective solution to supplement necessary knowledge to large language models (LLMs). Targeting its bottleneck of retriever performance, {``}generate-then-read{''} pipeline is proposed to replace the retrieval stage with generation from the LLM itself. Although promising, this research direction is underexplored and still cannot work in the scenario when source knowledge is given. In this paper, we formalize a general {``}A + B{''} framework with varying combinations of foundation models and types for systematic investigation. We explore the efficacy of the base and chat versions of LLMs and found their different functionalities suitable for generator A and reader B, respectively. Their combinations consistently outperform single models, especially in complex scenarios. Furthermore, we extend the application of the {``}A + B{''} framework to scenarios involving source documents through continuous learning, enabling the direct integration of external knowledge into LLMs. This approach not only facilitates effective acquisition of new knowledge but also addresses the challenges of safety and helpfulness post-adaptation. The paper underscores the versatility of the {``}A + B{''} framework, demonstrating its potential to enhance the practical application of LLMs across various domains.\",\n}\n",
    "authors": [
        "Wei Tang",
        "Yixin Cao",
        "Jiahao Ying",
        "Bo Wang",
        "Yuyue Zhao",
        "Yong Liao",
        "Peng Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.219.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/5cbf382d-7dd1-591f-bdc6-0feb7683d6cb.pdf",
    "abstract": "Retrieval-Augmented Generation (RAG) is an effective solution to supplement necessary knowledge to large language models (LLMs). Targeting its bottleneck of retriever performance, “generate-then-read” pipeline is proposed to replace the retrieval stage with generation from the LLM itself. Although promising, this research direction is underexplored and still cannot work in the scenario when source knowledge is given. In this paper, we formalize a general “A + B” framework with varying combinations of foundation models and types for systematic investigation. We explore the efficacy of the base and chat versions of LLMs and found their different functionalities suitable for generator A and reader B, respectively. Their combinations consistently outperform single models, especially in complex scenarios. Furthermore, we extend the application of the “A + B” framework to scenarios involving source documents through continuous learning, enabling the direct integration of external knowledge into LLMs. This approach not only facilitates effective acquisition of new knowledge but also addresses the challenges of safety and helpfulness post-adaptation. The paper underscores the versatility of the “A + B” framework, demonstrating its potential to enhance the practical application of LLMs across various domains.",
    "num_pages": 16
}