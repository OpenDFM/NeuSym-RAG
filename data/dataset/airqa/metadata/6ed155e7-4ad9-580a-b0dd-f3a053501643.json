{
    "uuid": "6ed155e7-4ad9-580a-b0dd-f3a053501643",
    "title": "Unveiling the Art of Heading Design: A Harmonious Blend of Summarization, Neology, and Algorithm",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{cui-etal-2024-unveiling,\n    title = \"Unveiling the Art of Heading Design: A Harmonious Blend of Summarization, Neology, and Algorithm\",\n    author = \"Cui, Shaobo  and\n      Feng, Yiyang  and\n      Mao, Yisong  and\n      Hou, Yifan  and\n      Faltings, Boi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.368\",\n    doi = \"10.18653/v1/2024.findings-acl.368\",\n    pages = \"6149--6174\",\n    abstract = \"Crafting an appealing heading is crucial for attracting readers and marketing work or products. A popular way is to summarize the main idea with a refined description and a memorable acronym. However, there lacks a systematic study and a formal benchmark including datasets and metrics. Motivated by this absence, we introduce LOgogram, a novel benchmark comprising 6,653 paper abstracts with corresponding descriptions and acronyms. To measure the quality of heading generation, we propose a set of evaluation metrics from three aspects: summarization, neology, and algorithm. Additionally, we explore three strategies for heading generation(generation ordering, tokenization of acronyms, and framework design) under various prevalent learning paradigms(supervised fine-tuning, in-context learning with Large Language Models(LLMs), and reinforcement learning) on our benchmark. Our experimental results indicate the difficulty in identifying a practice that excels across all summarization, neologistic, and algorithmic aspects.\",\n}\n",
    "authors": [
        "Shaobo Cui",
        "Yiyang Feng",
        "Yisong Mao",
        "Yifan Hou",
        "Boi Faltings"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.368.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6ed155e7-4ad9-580a-b0dd-f3a053501643.pdf",
    "abstract": "Crafting an appealing heading is crucial for attracting readers and marketing work or products. A popular way is to summarize the main idea with a refined description and a memorable acronym. However, there lacks a systematic study and a formal benchmark including datasets and metrics. Motivated by this absence, we introduce LOgogram, a novel benchmark comprising 6,653 paper abstracts with corresponding descriptions and acronyms. To measure the quality of heading generation, we propose a set of evaluation metrics from three aspects: summarization, neology, and algorithm. Additionally, we explore three strategies for heading generation(generation ordering, tokenization of acronyms, and framework design) under various prevalent learning paradigms(supervised fine-tuning, in-context learning with Large Language Models(LLMs), and reinforcement learning) on our benchmark. Our experimental results indicate the difficulty in identifying a practice that excels across all summarization, neologistic, and algorithmic aspects.",
    "num_pages": 26
}