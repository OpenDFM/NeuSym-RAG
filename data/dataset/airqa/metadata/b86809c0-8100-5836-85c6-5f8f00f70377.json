{
    "uuid": "b86809c0-8100-5836-85c6-5f8f00f70377",
    "title": "Domain-specific Attention with Distributional Signatures for Multi-Domain End-to-end Task-Oriented Dialogue",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{ma-etal-2023-domain,\n    title = \"Domain-specific Attention with Distributional Signatures for Multi-Domain End-to-end Task-Oriented Dialogue\",\n    author = \"Ma, Xing  and\n      Zhang, Peng  and\n      Zhao, Feifei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.194\",\n    doi = \"10.18653/v1/2023.findings-acl.194\",\n    pages = \"3109--3122\",\n    abstract = \"The end-to-end task-oriented dialogue system has achieved great success in recent years. Most of these dialogue systems need to accommodate multi-domain dialogue in real-world scenarios. However, due to the high cost of dialogue data annotation and the scarcity of labeled dialogue data, existing methods are difficult to extend to new domains. Therefore, it is important to use limited data to construct multi-domain dialogue systems. To solve this problem, we propose a novel domain attention module. It use the distributional signatures to construct a multi-domain dialogue system effectively with limited data, which has strong extensibility. We also define a adjacent n-gram pattern to explore potential patterns for dialogue entities. Experimental results show that our approach outperforms the baseline models on most metrics. In the few-shot scenario, we show our method get a great improvement compared with previous methods while keeping smaller model scale.\",\n}\n",
    "authors": [
        "Xing Ma",
        "Peng Zhang",
        "Feifei Zhao"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.194.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b86809c0-8100-5836-85c6-5f8f00f70377.pdf",
    "abstract": "The end-to-end task-oriented dialogue system has achieved great success in recent years. Most of these dialogue systems need to accommodate multi-domain dialogue in real-world scenarios. However, due to the high cost of dialogue data annotation and the scarcity of labeled dialogue data, existing methods are difficult to extend to new domains. Therefore, it is important to use limited data to construct multi-domain dialogue systems. To solve this problem, we propose a novel domain attention module. It use the distributional signatures to construct a multi-domain dialogue system effectively with limited data, which has strong extensibility. We also define a adjacent n-gram pattern to explore potential patterns for dialogue entities. Experimental results show that our approach outperforms the baseline models on most metrics. In the few-shot scenario, we show our method get a great improvement compared with previous methods while keeping smaller model scale.",
    "num_pages": 14
}