{
    "uuid": "cf2437da-9ba6-54c5-a129-e85798f1fac9",
    "title": "From Sights to Insights: Towards Summarization of Multimodal Clinical Documents",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{ghosh-etal-2024-sights,\n    title = \"From Sights to Insights: Towards Summarization of Multimodal Clinical Documents\",\n    author = \"Ghosh, Akash  and\n      Tomar, Mohit  and\n      Tiwari, Abhisek  and\n      Saha, Sriparna  and\n      Salve, Jatin  and\n      Sinha, Setu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.708\",\n    doi = \"10.18653/v1/2024.acl-long.708\",\n    pages = \"13117--13129\",\n    abstract = \"The advancement of Artificial Intelligence is pivotal in reshaping healthcare, enhancing diagnostic precision, and facilitating personalized treatment strategies. One major challenge for healthcare professionals is quickly navigating through long clinical documents to provide timely and effective solutions. Doctors often struggle to draw quick conclusions from these extensive documents. To address this issue and save time for healthcare professionals, an effective summarization model is essential. Most current models assume the data is only text-based. However, patients often include images of their medical conditions in clinical documents. To effectively summarize these multimodal documents, we introduce \\textbf{ \\textit{EDI-Summ}}, an innovative Image-Guided Encoder-Decoder Model. This model uses modality-aware contextual attention on the encoder and an image cross-attention mechanism on the decoder, enhancing the BART base model to create detailed visual-guided summaries. We have tested our model extensively on three multimodal clinical benchmarks involving multimodal question and dialogue summarization tasks. Our analysis demonstrates that \\textbf{ \\textit{EDI-Summ}} outperforms state-of-the-art large language and vision-aware models in these summarization tasks. \\textbf{Disclaimer}: The work includes vivid medical illustrations, depicting the essential aspects of the subject matter.\",\n}\n",
    "authors": [
        "Akash Ghosh",
        "Mohit Tomar",
        "Abhisek Tiwari",
        "Sriparna Saha",
        "Jatin Salve",
        "Setu Sinha"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.708.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/cf2437da-9ba6-54c5-a129-e85798f1fac9.pdf",
    "abstract": "The advancement of Artificial Intelligence is pivotal in reshaping healthcare, enhancing diagnostic precision, and facilitating personalized treatment strategies. One major challenge for healthcare professionals is quickly navigating through long clinical documents to provide timely and effective solutions. Doctors often struggle to draw quick conclusions from these extensive documents. To address this issue and save time for healthcare professionals, an effective summarization model is essential. Most current models assume the data is only text-based. However, patients often include images of their medical conditions in clinical documents. To effectively summarize these multimodal documents, we introduce EDI-Summ, an innovative Image-Guided Encoder-Decoder Model. This model uses modality-aware contextual attention on the encoder and an image cross-attention mechanism on the decoder, enhancing the BART base model to create detailed visual-guided summaries. We have tested our model extensively on three multimodal clinical benchmarks involving multimodal question and dialogue summarization tasks. Our analysis demonstrates that EDI-Summ outperforms state-of-the-art large language and vision-aware models in these summarization tasks. Disclaimer: The work includes vivid medical illustrations, depicting the essential aspects of the subject matter.",
    "num_pages": 13
}