{
    "uuid": "124688a0-9c5d-569f-be65-ac69a4ef3af9",
    "title": "Towards Safer Communities: Detecting Aggression and Offensive Language in Code-Mixed Tweets to Combat Cyberbullying",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 7th Workshop on Online Abuse and Harms (WOAH)",
    "bibtex": "@inproceedings{nafis-etal-2023-towards,\n    title = \"Towards Safer Communities: Detecting Aggression and Offensive Language in Code-Mixed Tweets to Combat Cyberbullying\",\n    author = \"Nafis, Nazia  and\n      Kanojia, Diptesh  and\n      Saini, Naveen  and\n      Murthy, Rudra\",\n    editor = {Chung, Yi-ling  and\n      R{{\\textbackslash}\"ottger}, Paul  and\n      Nozza, Debora  and\n      Talat, Zeerak  and\n      Mostafazadeh Davani, Aida},\n    booktitle = \"The 7th Workshop on Online Abuse and Harms (WOAH)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.woah-1.3\",\n    doi = \"10.18653/v1/2023.woah-1.3\",\n    pages = \"29--41\",\n    abstract = \"Cyberbullying is a serious societal issue widespread on various channels and platforms, particularly social networking sites. Such platforms have proven to be exceptionally fertile grounds for such behavior. The dearth of high-quality training data for multilingual and low-resource scenarios, data that can accurately capture the nuances of social media conversations, often poses a roadblock to this task. This paper attempts to tackle cyberbullying, specifically its two most common manifestations - aggression and offensiveness. We present a novel, manually annotated dataset of a total of 10,000 English and Hindi-English code-mixed tweets, manually annotated for aggression detection and offensive language detection tasks. Our annotations are supported by inter-annotator agreement scores of 0.67 and 0.74 for the two tasks, indicating substantial agreement. We perform comprehensive fine-tuning of pre-trained language models (PTLMs) using this dataset to check its efficacy. Our challenging test sets show that the best models achieve macro F1-scores of 67.87 and 65.45 on the two tasks, respectively. Further, we perform cross-dataset transfer learning to benchmark our dataset against existing aggression and offensive language datasets. We also present a detailed quantitative and qualitative analysis of errors in prediction, and with this paper, we publicly release the novel dataset, code, and models.\",\n}\n",
    "authors": [
        "Nazia Nafis",
        "Diptesh Kanojia",
        "Naveen Saini",
        "Rudra Murthy"
    ],
    "pdf_url": "https://aclanthology.org/2023.woah-1.3.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/124688a0-9c5d-569f-be65-ac69a4ef3af9.pdf",
    "abstract": "Cyberbullying is a serious societal issue widespread on various channels and platforms, particularly social networking sites. Such platforms have proven to be exceptionally fertile grounds for such behavior. The dearth of high-quality training data for multilingual and low-resource scenarios, data that can accurately capture the nuances of social media conversations, often poses a roadblock to this task. This paper attempts to tackle cyberbullying, specifically its two most common manifestations - aggression and offensiveness. We present a novel, manually annotated dataset of a total of 10,000 English and Hindi-English code-mixed tweets, manually annotated for aggression detection and offensive language detection tasks. Our annotations are supported by inter-annotator agreement scores of 0.67 and 0.74 for the two tasks, indicating substantial agreement. We perform comprehensive fine-tuning of pre-trained language models (PTLMs) using this dataset to check its efficacy. Our challenging test sets show that the best models achieve macro F1-scores of 67.87 and 65.45 on the two tasks, respectively. Further, we perform cross-dataset transfer learning to benchmark our dataset against existing aggression and offensive language datasets. We also present a detailed quantitative and qualitative analysis of errors in prediction, and with this paper, we publicly release the novel dataset, code, and models.",
    "num_pages": 13
}