{
    "uuid": "bee19a51-eabd-5162-8d01-3414486a86f1",
    "title": "SEA-VQA: Southeast Asian Cultural Context Dataset For Visual Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR)",
    "bibtex": "@inproceedings{urailertprasert-etal-2024-sea,\n    title = \"{SEA}-{VQA}: {S}outheast {A}sian Cultural Context Dataset For Visual Question Answering\",\n    author = \"Urailertprasert, Norawit  and\n      Limkonchotiwat, Peerat  and\n      Suwajanakorn, Supasorn  and\n      Nutanong, Sarana\",\n    editor = \"Gu, Jing  and\n      Fu, Tsu-Jui (Ray)  and\n      Hudson, Drew  and\n      Celikyilmaz, Asli  and\n      Wang, William\",\n    booktitle = \"Proceedings of the 3rd Workshop on Advances in Language and Vision Research (ALVR)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.alvr-1.15\",\n    doi = \"10.18653/v1/2024.alvr-1.15\",\n    pages = \"173--185\",\n    abstract = \"Visual Question Answering (VQA) is a critical task that requires the simultaneous understanding of visual and textual information. While significant advancements have been made with multilingual datasets, these often lack cultural specificity, especially in the context of Southeast Asia (SEA). In this paper, we introduce SEA-VQA aiming to highlight the challenges and gaps in existing VQA models when confronted with culturally specific content. Our dataset includes images from eight SEA countries, curated from the UNESCO Cultural Heritage collection. Our evaluation, comparing GPT-4 and GEMINI models, demonstrates substantial performance drops on culture-centric questions compared to the A-OKVQA dataset, a commonsense and world-knowledge VQA benchmark comprising approximately 25,000 questions. Our findings underscore the importance of cultural diversity in VQA datasets and reveal substantial gaps in the ability of current VQA models to handle culturally rich contexts. SEA-VQA serves as a crucial benchmark for identifying these gaps and guiding future improvements in VQA systems.\",\n}\n",
    "authors": [
        "Norawit Urailertprasert",
        "Peerat Limkonchotiwat",
        "Supasorn Suwajanakorn",
        "Sarana Nutanong"
    ],
    "pdf_url": "https://aclanthology.org/2024.alvr-1.15.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/bee19a51-eabd-5162-8d01-3414486a86f1.pdf",
    "abstract": "Visual Question Answering (VQA) is a critical task that requires the simultaneous understanding of visual and textual information. While significant advancements have been made with multilingual datasets, these often lack cultural specificity, especially in the context of Southeast Asia (SEA). In this paper, we introduce SEA-VQA aiming to highlight the challenges and gaps in existing VQA models when confronted with culturally specific content. Our dataset includes images from eight SEA countries, curated from the UNESCO Cultural Heritage collection. Our evaluation, comparing GPT-4 and GEMINI models, demonstrates substantial performance drops on culture-centric questions compared to the A-OKVQA dataset, a commonsense and world-knowledge VQA benchmark comprising approximately 25,000 questions. Our findings underscore the importance of cultural diversity in VQA datasets and reveal substantial gaps in the ability of current VQA models to handle culturally rich contexts. SEA-VQA serves as a crucial benchmark for identifying these gaps and guiding future improvements in VQA systems.",
    "num_pages": 13
}