{
    "uuid": "4b59d0f7-bc1b-57c6-b819-fc4073a37906",
    "title": "SimulSeamless: FBK at IWSLT 2024 Simultaneous Speech Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
    "bibtex": "@inproceedings{papi-etal-2024-simulseamless,\n    title = \"{S}imul{S}eamless: {FBK} at {IWSLT} 2024 Simultaneous Speech Translation\",\n    author = \"Papi, Sara  and\n      Gaido, Marco  and\n      Negri, Matteo  and\n      Bentivogli, Luisa\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.iwslt-1.11\",\n    doi = \"10.18653/v1/2024.iwslt-1.11\",\n    pages = \"72--79\",\n    abstract = \"This paper describes the FBK{'}s participation in the Simultaneous Translation Evaluation Campaign at IWSLT 2024. For this year{'}s submission in the speech-to-text translation (ST) sub-track, we propose SimulSeamless, which is realized by combining AlignAtt and SeamlessM4T in its medium configuration. The SeamlessM4T model is used {`}off-the-shelf{'} and its simultaneous inference is enabled through the adoption of AlignAtt, a SimulST policy based on cross-attention that can be applied without any retraining or adaptation of the underlying model for the simultaneous task. We participated in all the Shared Task languages (English-{\\textgreater}German, Japanese, Chinese, and Czech-{\\textgreater}English), achieving acceptable or even better results compared to last year{'}s submissions. SimulSeamless, covering more than 143 source languages and 200 target languages, is released at: https://github.com/hlt-mt/FBK-fairseq/.\",\n}\n",
    "authors": [
        "Sara Papi",
        "Marco Gaido",
        "Matteo Negri",
        "Luisa Bentivogli"
    ],
    "pdf_url": "https://aclanthology.org/2024.iwslt-1.11.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4b59d0f7-bc1b-57c6-b819-fc4073a37906.pdf",
    "abstract": "This paper describes the FBK’s participation in the Simultaneous Translation Evaluation Campaign at IWSLT 2024. For this year’s submission in the speech-to-text translation (ST) sub-track, we propose SimulSeamless, which is realized by combining AlignAtt and SeamlessM4T in its medium configuration. The SeamlessM4T model is used ‘off-the-shelf’ and its simultaneous inference is enabled through the adoption of AlignAtt, a SimulST policy based on cross-attention that can be applied without any retraining or adaptation of the underlying model for the simultaneous task. We participated in all the Shared Task languages (English->German, Japanese, Chinese, and Czech->English), achieving acceptable or even better results compared to last year’s submissions. SimulSeamless, covering more than 143 source languages and 200 target languages, is released at: https://github.com/hlt-mt/FBK-fairseq/.",
    "num_pages": 8
}