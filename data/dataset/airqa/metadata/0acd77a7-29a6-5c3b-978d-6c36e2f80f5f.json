{
    "uuid": "0acd77a7-29a6-5c3b-978d-6c36e2f80f5f",
    "title": "Deepfake Defense: Constructing and Evaluating a Specialized Urdu Deepfake Audio Dataset",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{munir-etal-2024-deepfake,\n    title = \"Deepfake Defense: Constructing and Evaluating a Specialized {U}rdu Deepfake Audio Dataset\",\n    author = \"Munir, Sheza  and\n      Sajjad, Wassay  and\n      Raza, Mukeet  and\n      Abbas, Emaan  and\n      Azeemi, Abdul Hameed  and\n      Qazi, Ihsan Ayyub  and\n      Raza, Agha Ali\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.861\",\n    doi = \"10.18653/v1/2024.findings-acl.861\",\n    pages = \"14470--14480\",\n    abstract = \"Deepfakes, particularly in the auditory domain, have become a significant threat, necessitating the development of robust countermeasures. This paper addresses the escalating challenges posed by deepfake attacks on Automatic Speaker Verification (ASV) systems. We present a novel Urdu deepfake audio dataset for deepfake detection, focusing on two spoofing attacks {--} Tacotron and VITS TTS. The dataset construction involves careful consideration of phonemic cover and balance and comparison with existing corpora like PRUS and PronouncUR. Evaluation with AASIST-L model shows EERs of 0.495 and 0.524 for VITS TTS and Tacotron-generated audios, respectively, with variability across speakers. Further, this research implements a detailed human evaluation, incorporating a user study to gauge whether people are able to discern deepfake audios from real (bonafide) audios. The ROC curve analysis shows an area under the curve (AUC) of 0.63, indicating that individuals demonstrate a limited ability to detect deepfakes (approximately 1 in 3 fake audio samples are regarded as real). Our work contributes a valuable resource for training deepfake detection models in low-resource languages like Urdu, addressing the critical gap in existing datasets. The dataset is publicly available at: https://github.com/CSALT-LUMS/urdu-deepfake-dataset.\",\n}\n",
    "authors": [
        "Sheza Munir",
        "Wassay Sajjad",
        "Mukeet Raza",
        "Emaan Abbas",
        "Abdul Hameed Azeemi",
        "Ihsan Ayyub Qazi",
        "Agha Ali Raza"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.861.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/0acd77a7-29a6-5c3b-978d-6c36e2f80f5f.pdf",
    "abstract": "Deepfakes, particularly in the auditory domain, have become a significant threat, necessitating the development of robust countermeasures. This paper addresses the escalating challenges posed by deepfake attacks on Automatic Speaker Verification (ASV) systems. We present a novel Urdu deepfake audio dataset for deepfake detection, focusing on two spoofing attacks â€“ Tacotron and VITS TTS. The dataset construction involves careful consideration of phonemic cover and balance and comparison with existing corpora like PRUS and PronouncUR. Evaluation with AASIST-L model shows EERs of 0.495 and 0.524 for VITS TTS and Tacotron-generated audios, respectively, with variability across speakers. Further, this research implements a detailed human evaluation, incorporating a user study to gauge whether people are able to discern deepfake audios from real (bonafide) audios. The ROC curve analysis shows an area under the curve (AUC) of 0.63, indicating that individuals demonstrate a limited ability to detect deepfakes (approximately 1 in 3 fake audio samples are regarded as real). Our work contributes a valuable resource for training deepfake detection models in low-resource languages like Urdu, addressing the critical gap in existing datasets. The dataset is publicly available at: https://github.com/CSALT-LUMS/urdu-deepfake-dataset.",
    "num_pages": 11
}