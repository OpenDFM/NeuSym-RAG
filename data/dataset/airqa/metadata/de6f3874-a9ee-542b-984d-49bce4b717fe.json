{
    "uuid": "de6f3874-a9ee-542b-984d-49bce4b717fe",
    "title": "Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{miao-etal-2024-efficient,\n    title = \"Efficient Detection of {LLM}-generated Texts with a {B}ayesian Surrogate Model\",\n    author = \"Miao, Yibo  and\n      Gao, Hongcheng  and\n      Zhang, Hao  and\n      Deng, Zhijie\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.366\",\n    doi = \"10.18653/v1/2024.findings-acl.366\",\n    pages = \"6118--6130\",\n    abstract = \"The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot ones often yield suboptimal performance. Although the recent DetectGPT has shown promising detection performance, it suffers from significant inefficiency issues, as detecting a single candidate requires querying the source LLM with hundreds of its perturbations. This paper aims to bridge this gap. Concretely, we propose to incorporate a Bayesian surrogate model, which allows us to select typical samples based on Bayesian uncertainty and interpolate scores from typical samples to other samples, to improve query efficiency. Empirical results demonstrate that our method significantly outperforms existing approaches under a low query budget. Notably, when detecting the text generated by LLaMA family models, our method with just 2 or 3 queries can outperform DetectGPT with 200 queries.\",\n}\n",
    "authors": [
        "Yibo Miao",
        "Hongcheng Gao",
        "Hao Zhang",
        "Zhijie Deng"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.366.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/de6f3874-a9ee-542b-984d-49bce4b717fe.pdf",
    "abstract": "The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot ones often yield suboptimal performance. Although the recent DetectGPT has shown promising detection performance, it suffers from significant inefficiency issues, as detecting a single candidate requires querying the source LLM with hundreds of its perturbations. This paper aims to bridge this gap. Concretely, we propose to incorporate a Bayesian surrogate model, which allows us to select typical samples based on Bayesian uncertainty and interpolate scores from typical samples to other samples, to improve query efficiency. Empirical results demonstrate that our method significantly outperforms existing approaches under a low query budget. Notably, when detecting the text generated by LLaMA family models, our method with just 2 or 3 queries can outperform DetectGPT with 200 queries.",
    "num_pages": 13
}