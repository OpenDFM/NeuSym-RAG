{
    "uuid": "b9405d58-254f-5ab7-b283-decec8a0e25a",
    "title": "Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{nandi-etal-2023-simple,\n    title = \"Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion\",\n    author = \"Nandi, Ananjan  and\n      Kaur, Navdeep  and\n      Singla, Parag  and\n      {Mausam}\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.23\",\n    doi = \"10.18653/v1/2023.acl-short.23\",\n    pages = \"256--269\",\n    abstract = \"High-quality and high-coverage rule sets are imperative to the success of Neuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form the basis of all symbolic inferences. Recent literature builds neural models for generating rule sets, however, preliminary experiments show that they struggle with maintaining high coverage. In this work, we suggest three simple augmentations to existing rule sets: (1) transforming rules to their abductive forms, (2) generating equivalent rules that use inverse forms of constituent relations and (3) random walks that propose new rules. Finally, we prune potentially low quality rules. Experiments over four datasets and five ruleset-baseline settings suggest that these simple augmentations consistently improve results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using rules without augmentations.\",\n}\n",
    "authors": [
        "Ananjan Nandi",
        "Navdeep Kaur",
        "Parag Singla",
        "Mausam"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.23.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b9405d58-254f-5ab7-b283-decec8a0e25a.pdf",
    "abstract": "High-quality and high-coverage rule sets are imperative to the success of Neuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form the basis of all symbolic inferences. Recent literature builds neural models for generating rule sets, however, preliminary experiments show that they struggle with maintaining high coverage. In this work, we suggest three simple augmentations to existing rule sets: (1) transforming rules to their abductive forms, (2) generating equivalent rules that use inverse forms of constituent relations and (3) random walks that propose new rules. Finally, we prune potentially low quality rules. Experiments over four datasets and five ruleset-baseline settings suggest that these simple augmentations consistently improve results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using rules without augmentations.",
    "num_pages": 14
}