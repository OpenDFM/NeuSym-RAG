{
    "uuid": "57c21c09-20c4-5542-9669-f6b0846e1fcb",
    "title": "Enhancing Hyperbolic Knowledge Graph Embeddings via Lorentz Transformations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{fan-etal-2024-enhancing,\n    title = \"Enhancing Hyperbolic Knowledge Graph Embeddings via Lorentz Transformations\",\n    author = \"Fan, Xiran  and\n      Xu, Minghua  and\n      Chen, Huiyuan  and\n      Chen, Yuzhong  and\n      Das, Mahashweta  and\n      Yang, Hao\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.272\",\n    doi = \"10.18653/v1/2024.findings-acl.272\",\n    pages = \"4575--4589\",\n    abstract = \"Knowledge Graph Embedding (KGE) is a powerful technique for predicting missing links in Knowledge Graphs (KGs) by learning the entities and relations. Hyperbolic space has emerged as a promising embedding space for KGs due to its ability to represent hierarchical data. Nevertheless, most existing hyperbolic KGE methods rely on tangent approximation and are not fully hyperbolic, resulting in distortions and inaccuracies. To overcome this limitation, we propose LorentzKG, a fully hyperbolic KGE method that represents entities as points in the Lorentz model and represents relations as the intrinsic transformation{---}the Lorentz transformations between entities. We demonstrate that the Lorentz transformation, which can be decomposed into Lorentz rotation/reflection and Lorentz boost, captures various types of relations including hierarchical structures. Experimental results show that our LorentzKG achieves state-of-the-art performance.\",\n}\n",
    "authors": [
        "Xiran Fan",
        "Minghua Xu",
        "Huiyuan Chen",
        "Yuzhong Chen",
        "Mahashweta Das",
        "Hao Yang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.272.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/57c21c09-20c4-5542-9669-f6b0846e1fcb.pdf",
    "abstract": "Knowledge Graph Embedding (KGE) is a powerful technique for predicting missing links in Knowledge Graphs (KGs) by learning the entities and relations. Hyperbolic space has emerged as a promising embedding space for KGs due to its ability to represent hierarchical data. Nevertheless, most existing hyperbolic KGE methods rely on tangent approximation and are not fully hyperbolic, resulting in distortions and inaccuracies. To overcome this limitation, we propose LorentzKG, a fully hyperbolic KGE method that represents entities as points in the Lorentz model and represents relations as the intrinsic transformationâ€”the Lorentz transformations between entities. We demonstrate that the Lorentz transformation, which can be decomposed into Lorentz rotation/reflection and Lorentz boost, captures various types of relations including hierarchical structures. Experimental results show that our LorentzKG achieves state-of-the-art performance.",
    "num_pages": 15
}