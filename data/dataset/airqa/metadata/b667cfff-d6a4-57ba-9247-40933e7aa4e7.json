{
    "uuid": "b667cfff-d6a4-57ba-9247-40933e7aa4e7",
    "title": "PrimeQA: The Prime Repository for State-of-the-Art Multilingual Question Answering Research and Development",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
    "bibtex": "@inproceedings{sil-etal-2023-primeqa,\n    title = \"{P}rime{QA}: The Prime Repository for State-of-the-Art Multilingual Question Answering Research and Development\",\n    author = \"Sil, Avi  and\n      Sen, Jaydeep  and\n      Iyer, Bhavani  and\n      Franz, Martin  and\n      Fadnis, Kshitij  and\n      Bornea, Mihaela  and\n      Rosenthal, Sara  and\n      McCarley, Scott  and\n      Zhang, Rong  and\n      Kumar, Vishwajeet  and\n      Li, Yulong  and\n      Sultan, Md Arafat  and\n      Bhat, Riyaz  and\n      Bross, Juergen  and\n      Florian, Radu  and\n      Roukos, Salim\",\n    editor = \"Bollegala, Danushka  and\n      Huang, Ruihong  and\n      Ritter, Alan\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-demo.5\",\n    doi = \"10.18653/v1/2023.acl-demo.5\",\n    pages = \"51--62\",\n    abstract = \"The field of Question Answering (QA) has made remarkable progress in recent years, thanks to the advent of large pre-trained language models, newer realistic benchmark datasets with leaderboards, and novel algorithms for key components such as retrievers and readers. In this paper, we introduce PrimeQA: a one-stop and open-source QA repository with an aim to democratize QA research and facilitate easy replication of state-of-the-art (SOTA) QA methods. PrimeQA supports core QA functionalities like retrieval and reading comprehension as well as auxiliary capabilities such as question generation. It has been designed as an end-to-end toolkit for various use cases: building front-end applications, replicating SOTA methods on public benchmarks, and expanding pre-existing methods. PrimeQA is available at: \\url{https://github.com/primeqa}.\",\n}\n",
    "authors": [
        "Avi Sil",
        "Jaydeep Sen",
        "Bhavani Iyer",
        "Martin Franz",
        "Kshitij Fadnis",
        "Mihaela Bornea",
        "Sara Rosenthal",
        "Scott McCarley",
        "Rong Zhang",
        "Vishwajeet Kumar",
        "Yulong Li",
        "Md Arafat Sultan",
        "Riyaz Bhat",
        "Juergen Bross",
        "Radu Florian",
        "Salim Roukos"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-demo.5.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b667cfff-d6a4-57ba-9247-40933e7aa4e7.pdf",
    "abstract": "The field of Question Answering (QA) has made remarkable progress in recent years, thanks to the advent of large pre-trained language models, newer realistic benchmark datasets with leaderboards, and novel algorithms for key components such as retrievers and readers. In this paper, we introduce PrimeQA: a one-stop and open-source QA repository with an aim to democratize QA research and facilitate easy replication of state-of-the-art (SOTA) QA methods. PrimeQA supports core QA functionalities like retrieval and reading comprehension as well as auxiliary capabilities such as question generation. It has been designed as an end-to-end toolkit for various use cases: building front-end applications, replicating SOTA methods on public benchmarks, and expanding pre-existing methods. PrimeQA is available at: https://github.com/primeqa.",
    "num_pages": 12
}