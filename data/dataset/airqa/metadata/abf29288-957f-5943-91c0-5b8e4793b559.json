{
    "uuid": "abf29288-957f-5943-91c0-5b8e4793b559",
    "title": "Collaboration or Corporate Capture? Quantifying NLPâ€™s Reliance on Industry Artifacts and Contributions",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{aitken-etal-2024-collaboration,\n    title = \"Collaboration or Corporate Capture? Quantifying {NLP}{'}s Reliance on Industry Artifacts and Contributions\",\n    author = \"Aitken, Will  and\n      Abdalla, Mohamed  and\n      Rudie, Karen  and\n      Stinson, Catherine\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.188\",\n    doi = \"10.18653/v1/2024.acl-long.188\",\n    pages = \"3433--3448\",\n    abstract = \"Impressive performance of pre-trained models has garnered public attention and made news headlines in recent years. Almost always, these models are produced by or in collaboration with industry. Using them is critical for competing on natural language processing (NLP) benchmarks and correspondingly to stay relevant in NLP research. We surveyed 100 papers published at EMNLP 2022 to determine the degree to which researchers rely on industry models, other artifacts, and contributions to publish in prestigious NLP venues and found that the ratio of their citation is at least three times greater than what would be expected. Our work serves as a scaffold to enable future researchers to more accurately address whether: 1) Collaboration with industry is still collaboration in the absence of an alternative or 2) if NLP inquiry has been captured by the motivations and research direction of private corporations.\",\n}\n",
    "authors": [
        "Will Aitken",
        "Mohamed Abdalla",
        "Karen Rudie",
        "Catherine Stinson"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.188.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/abf29288-957f-5943-91c0-5b8e4793b559.pdf",
    "abstract": "Impressive performance of pre-trained models has garnered public attention and made news headlines in recent years. Almost always, these models are produced by or in collaboration with industry. Using them is critical for competing on natural language processing (NLP) benchmarks and correspondingly to stay relevant in NLP research. We surveyed 100 papers published at EMNLP 2022 to determine the degree to which researchers rely on industry models, other artifacts, and contributions to publish in prestigious NLP venues and found that the ratio of their citation is at least three times greater than what would be expected. Our work serves as a scaffold to enable future researchers to more accurately address whether: 1) Collaboration with industry is still collaboration in the absence of an alternative or 2) if NLP inquiry has been captured by the motivations and research direction of private corporations.",
    "num_pages": 16
}