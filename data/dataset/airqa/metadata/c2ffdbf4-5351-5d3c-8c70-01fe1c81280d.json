{
    "uuid": "c2ffdbf4-5351-5d3c-8c70-01fe1c81280d",
    "title": "Medical Visual Textual Entailment for Numerical Understanding of Vision-and-Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{yanaka-etal-2023-medical,\n    title = \"Medical Visual Textual Entailment for Numerical Understanding of Vision-and-Language Models\",\n    author = \"Yanaka, Hitomi  and\n      Nakamura, Yuta  and\n      Chida, Yuki  and\n      Kurosawa, Tomoya\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.2\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.2\",\n    pages = \"8--18\",\n    abstract = \"Assessing the capacity of numerical understanding of vision-and-language models over images and texts is crucial for real vision-and-language applications, such as systems for automated medical image analysis. We provide a visual reasoning dataset focusing on numerical understanding in the medical domain. The experiments using our dataset show that current vision-and-language models fail to perform numerical inference in the medical domain. However, the data augmentation with only a small amount of our dataset improves the model performance, while maintaining the performance in the general domain.\",\n}\n",
    "authors": [
        "Hitomi Yanaka",
        "Yuta Nakamura",
        "Yuki Chida",
        "Tomoya Kurosawa"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.2.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/c2ffdbf4-5351-5d3c-8c70-01fe1c81280d.pdf",
    "abstract": "Assessing the capacity of numerical understanding of vision-and-language models over images and texts is crucial for real vision-and-language applications, such as systems for automated medical image analysis. We provide a visual reasoning dataset focusing on numerical understanding in the medical domain. The experiments using our dataset show that current vision-and-language models fail to perform numerical inference in the medical domain. However, the data augmentation with only a small amount of our dataset improves the model performance, while maintaining the performance in the general domain.",
    "num_pages": 11
}