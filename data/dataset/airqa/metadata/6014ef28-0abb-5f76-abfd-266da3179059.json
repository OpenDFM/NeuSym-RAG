{
    "uuid": "6014ef28-0abb-5f76-abfd-266da3179059",
    "title": "Lenient Evaluation of Japanese Speech Recognition: Modeling Naturally Occurring Spelling Inconsistency",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the Workshop on Computation and Written Language (CAWL 2023)",
    "bibtex": "@inproceedings{karita-etal-2023-lenient,\n    title = \"Lenient Evaluation of {J}apanese Speech Recognition: Modeling Naturally Occurring Spelling Inconsistency\",\n    author = \"Karita, Shigeki  and\n      Sproat, Richard  and\n      Ishikawa, Haruko\",\n    editor = \"Gorman, Kyle  and\n      Sproat, Richard  and\n      Roark, Brian\",\n    booktitle = \"Proceedings of the Workshop on Computation and Written Language (CAWL 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.cawl-1.8\",\n    doi = \"10.18653/v1/2023.cawl-1.8\",\n    pages = \"61--70\",\n    abstract = \"Word error rate (WER) and character error rate (CER) are standard metrics in Speech Recognition (ASR), but one problem has always been alternative spellings: If one{'}s system transcribes adviser whereas the ground truth has advisor, this will count as an error even though the two spellings really represent the same word. Japanese is notorious for {``}lacking orthography{''}: most words can be spelled in multiple ways, presenting a problem for accurate ASR evaluation. In this paper we propose a new lenient evaluation metric as a more defensible CER measure for Japanese ASR. We create a lattice of plausible respellings of the reference transcription, using a combination of lexical resources, a Japanese text-processing system, and a neural machine translation model for reconstructing kanji from hiragana or katakana. In a manual evaluation, raters rated 95.4{\\%} of the proposed spelling variants as plausible. ASR results show that our method, which does not penalize the system for choosing a valid alternate spelling of a word, affords a 2.4{\\%}{--}3.1{\\%} absolute reduction in CER depending on the task.\",\n}\n",
    "authors": [
        "Shigeki Karita",
        "Richard Sproat",
        "Haruko Ishikawa"
    ],
    "pdf_url": "https://aclanthology.org/2023.cawl-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/6014ef28-0abb-5f76-abfd-266da3179059.pdf",
    "abstract": "Word error rate (WER) and character error rate (CER) are standard metrics in Speech Recognition (ASR), but one problem has always been alternative spellings: If one’s system transcribes adviser whereas the ground truth has advisor, this will count as an error even though the two spellings really represent the same word. Japanese is notorious for “lacking orthography”: most words can be spelled in multiple ways, presenting a problem for accurate ASR evaluation. In this paper we propose a new lenient evaluation metric as a more defensible CER measure for Japanese ASR. We create a lattice of plausible respellings of the reference transcription, using a combination of lexical resources, a Japanese text-processing system, and a neural machine translation model for reconstructing kanji from hiragana or katakana. In a manual evaluation, raters rated 95.4% of the proposed spelling variants as plausible. ASR results show that our method, which does not penalize the system for choosing a valid alternate spelling of a word, affords a 2.4%–3.1% absolute reduction in CER depending on the task.",
    "num_pages": 10
}