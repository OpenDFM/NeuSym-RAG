{
    "uuid": "225e616e-cb83-5a08-9ab9-b0f51c8386dc",
    "title": "An Open Dataset and Model for Language Identification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{burchell-etal-2023-open,\n    title = \"An Open Dataset and Model for Language Identification\",\n    author = \"Burchell, Laurie  and\n      Birch, Alexandra  and\n      Bogoychev, Nikolay  and\n      Heafield, Kenneth\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.75\",\n    doi = \"10.18653/v1/2023.acl-short.75\",\n    pages = \"865--879\",\n    abstract = \"Language identification (LID) is a fundamental step in many natural language processing pipelines. However, current LID systems are far from perfect, particularly on lower-resource languages. We present a LID model which achieves a macro-average F1 score of 0.93 and a false positive rate of 0.033{\\%} across 201 languages, outperforming previous work. We achieve this by training on a curated dataset of monolingual data, which we audit manually to ensure reliability. We make both the model and the dataset available to the research community. Finally, we carry out detailed analysis into our model{'}s performance, both in comparison to existing open models and by language class.\",\n}\n",
    "authors": [
        "Laurie Burchell",
        "Alexandra Birch",
        "Nikolay Bogoychev",
        "Kenneth Heafield"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.75.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/225e616e-cb83-5a08-9ab9-b0f51c8386dc.pdf",
    "abstract": "Language identification (LID) is a fundamental step in many natural language processing pipelines. However, current LID systems are far from perfect, particularly on lower-resource languages. We present a LID model which achieves a macro-average F1 score of 0.93 and a false positive rate of 0.033% across 201 languages, outperforming previous work. We achieve this by training on a curated dataset of monolingual data, which we audit manually to ensure reliability. We make both the model and the dataset available to the research community. Finally, we carry out detailed analysis into our modelâ€™s performance, both in comparison to existing open models and by language class.",
    "num_pages": 15
}