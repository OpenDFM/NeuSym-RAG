{
    "uuid": "e54fe0e4-60c5-5142-a3bc-5ea4e1a81c11",
    "title": "LexiconLadies at FIGNEWS 2024 Shared Task: Identifying Keywords for Bias Annotation Guidelines of Facebook News Headlines on the Israel-Palestine 2023 War",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The Second Arabic Natural Language Processing Conference",
    "bibtex": "@inproceedings{el-ghawi-etal-2024-lexiconladies,\n    title = \"{L}exicon{L}adies at {FIGNEWS} 2024 Shared Task: Identifying Keywords for Bias Annotation Guidelines of {F}acebook News Headlines on the {I}srael-{P}alestine 2023 War\",\n    author = \"El-Ghawi, Yousra  and\n      Marzouk, Abeer  and\n      Khamis, Aya\",\n    editor = \"Habash, Nizar  and\n      Bouamor, Houda  and\n      Eskander, Ramy  and\n      Tomeh, Nadi  and\n      Abu Farha, Ibrahim  and\n      Abdelali, Ahmed  and\n      Touileb, Samia  and\n      Hamed, Injy  and\n      Onaizan, Yaser  and\n      Alhafni, Bashar  and\n      Antoun, Wissam  and\n      Khalifa, Salam  and\n      Haddad, Hatem  and\n      Zitouni, Imed  and\n      AlKhamissi, Badr  and\n      Almatham, Rawan  and\n      Mrini, Khalil\",\n    booktitle = \"Proceedings of The Second Arabic Natural Language Processing Conference\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.arabicnlp-1.59\",\n    doi = \"10.18653/v1/2024.arabicnlp-1.59\",\n    pages = \"561--566\",\n    abstract = \"News bias is difficult for humans to identify, but even more so for machines. This is largely due to the lack of linguistically appropriate annotated datasets suitable for use by classifier algorithms. The FIGNEWS Subtask 1: Bias Annotation involved classifying bias through manually annotated 1800 headlines from social media. Our proposed guidelines investigated which combinations of keywords available for classification, across sentence and token levels, may be used to detect possible bias in a conflict where neutrality is highly undesirable. Much of the headlines{'} percentage required contextual knowledge of events to identify criteria that matched biased or targeted language. The final annotation guidelines paved the way for a theoretical system which uses keyword and hashtag significance to classify major instances of bias. Minor instances with bias undertones or clickbait may require advanced machine learning methods which learn context through scraping user engagements on social media.\",\n}\n",
    "authors": [
        "Yousra El-Ghawi",
        "Abeer Marzouk",
        "Aya Khamis"
    ],
    "pdf_url": "https://aclanthology.org/2024.arabicnlp-1.59.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/e54fe0e4-60c5-5142-a3bc-5ea4e1a81c11.pdf",
    "abstract": "News bias is difficult for humans to identify, but even more so for machines. This is largely due to the lack of linguistically appropriate annotated datasets suitable for use by classifier algorithms. The FIGNEWS Subtask 1: Bias Annotation involved classifying bias through manually annotated 1800 headlines from social media. Our proposed guidelines investigated which combinations of keywords available for classification, across sentence and token levels, may be used to detect possible bias in a conflict where neutrality is highly undesirable. Much of the headlinesâ€™ percentage required contextual knowledge of events to identify criteria that matched biased or targeted language. The final annotation guidelines paved the way for a theoretical system which uses keyword and hashtag significance to classify major instances of bias. Minor instances with bias undertones or clickbait may require advanced machine learning methods which learn context through scraping user engagements on social media.",
    "num_pages": 6
}