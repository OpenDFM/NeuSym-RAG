{
    "uuid": "f251fddc-f80b-53d9-87e1-dc61dde3a981",
    "title": "DiffusionNER: Boundary Diffusion for Named Entity Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{shen-etal-2023-diffusionner,\n    title = \"{D}iffusion{NER}: Boundary Diffusion for Named Entity Recognition\",\n    author = \"Shen, Yongliang  and\n      Song, Kaitao  and\n      Tan, Xu  and\n      Li, Dongsheng  and\n      Lu, Weiming  and\n      Zhuang, Yueting\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.215\",\n    doi = \"10.18653/v1/2023.acl-long.215\",\n    pages = \"3875--3890\",\n    abstract = \"In this paper, we propose DiffusionNER, which formulates the named entity recognition task as a boundary-denoising diffusion process and thus generates named entities from noisy spans. During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries. In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process. The proposed boundary-denoising diffusion process allows progressive refinement and dynamic sampling of entities, empowering DiffusionNER with efficient and flexible entity generation capability. Experiments on multiple flat and nested NER datasets demonstrate that DiffusionNER achieves comparable or even better performance than previous state-of-the-art models.\",\n}\n",
    "authors": [
        "Yongliang Shen",
        "Kaitao Song",
        "Xu Tan",
        "Dongsheng Li",
        "Weiming Lu",
        "Yueting Zhuang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.215.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f251fddc-f80b-53d9-87e1-dc61dde3a981.pdf",
    "abstract": "In this paper, we propose DiffusionNER, which formulates the named entity recognition task as a boundary-denoising diffusion process and thus generates named entities from noisy spans. During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries. In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process. The proposed boundary-denoising diffusion process allows progressive refinement and dynamic sampling of entities, empowering DiffusionNER with efficient and flexible entity generation capability. Experiments on multiple flat and nested NER datasets demonstrate that DiffusionNER achieves comparable or even better performance than previous state-of-the-art models.",
    "num_pages": 16
}