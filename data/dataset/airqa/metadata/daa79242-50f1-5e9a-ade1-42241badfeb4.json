{
    "uuid": "daa79242-50f1-5e9a-ade1-42241badfeb4",
    "title": "Sociodemographic Bias in Language Models: A Survey and Forward Path",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
    "bibtex": "@inproceedings{gupta-etal-2024-sociodemographic,\n    title = \"Sociodemographic Bias in Language Models: A Survey and Forward Path\",\n    author = \"Gupta, Vipul  and\n      Narayanan Venkit, Pranav  and\n      Wilson, Shomir  and\n      Passonneau, Rebecca\",\n    editor = \"Fale{\\'n}ska, Agnieszka  and\n      Basta, Christine  and\n      Costa-juss{\\`a}, Marta  and\n      Goldfarb-Tarrant, Seraphina  and\n      Nozza, Debora\",\n    booktitle = \"Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.gebnlp-1.19\",\n    doi = \"10.18653/v1/2024.gebnlp-1.19\",\n    pages = \"295--322\",\n    abstract = \"Sociodemographic bias in language models (LMs) has the potential for harm when deployed in real-world settings. This paper presents a comprehensive survey of the past decade of research on sociodemographic bias in LMs, organized into a typology that facilitates examining the different aims: types of bias, quantifying bias, and debiasing techniques. We track the evolution of the latter two questions, then identify current trends and their limitations, as well as emerging techniques. To guide future research towards more effective and reliable solutions, and to help authors situate their work within this broad landscape, we conclude with a checklist of open questions.\",\n}\n",
    "authors": [
        "Vipul Gupta",
        "Pranav Narayanan Venkit",
        "Shomir Wilson",
        "Rebecca Passonneau"
    ],
    "pdf_url": "https://aclanthology.org/2024.gebnlp-1.19.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/daa79242-50f1-5e9a-ade1-42241badfeb4.pdf",
    "abstract": "Sociodemographic bias in language models (LMs) has the potential for harm when deployed in real-world settings. This paper presents a comprehensive survey of the past decade of research on sociodemographic bias in LMs, organized into a typology that facilitates examining the different aims: types of bias, quantifying bias, and debiasing techniques. We track the evolution of the latter two questions, then identify current trends and their limitations, as well as emerging techniques. To guide future research towards more effective and reliable solutions, and to help authors situate their work within this broad landscape, we conclude with a checklist of open questions.",
    "num_pages": 28
}