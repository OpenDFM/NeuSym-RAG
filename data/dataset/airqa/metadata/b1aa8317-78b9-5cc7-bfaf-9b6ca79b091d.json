{
    "uuid": "b1aa8317-78b9-5cc7-bfaf-9b6ca79b091d",
    "title": "MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{guo-vosoughi-2024-modabs,\n    title = \"{MODABS}: Multi-Objective Learning for Dynamic Aspect-Based Summarization\",\n    author = \"Guo, Xiaobo  and\n      Vosoughi, Soroush\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.165\",\n    doi = \"10.18653/v1/2024.findings-acl.165\",\n    pages = \"2814--2827\",\n    abstract = \"The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out. Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text. We introduce a novel multi-objective learning framework employing a Longformer-Encoder-Decoder for this task. The framework optimizes aspect number prediction, minimizes disparity between generated and reference summaries for each aspect, and maximizes dissimilarity across aspect-specific summaries. Extensive experiments show our method significantly outperforms baselines on three diverse datasets, largely due to the effective alignment of generated and reference aspect counts without sacrificing single-aspect summarization quality.\",\n}\n",
    "authors": [
        "Xiaobo Guo",
        "Soroush Vosoughi"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.165.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b1aa8317-78b9-5cc7-bfaf-9b6ca79b091d.pdf",
    "abstract": "The rapid proliferation of online content necessitates effective summarization methods, among which dynamic aspect-based summarization stands out. Unlike its traditional counterpart, which assumes a fixed set of known aspects, this approach adapts to the varied aspects of the input text. We introduce a novel multi-objective learning framework employing a Longformer-Encoder-Decoder for this task. The framework optimizes aspect number prediction, minimizes disparity between generated and reference summaries for each aspect, and maximizes dissimilarity across aspect-specific summaries. Extensive experiments show our method significantly outperforms baselines on three diverse datasets, largely due to the effective alignment of generated and reference aspect counts without sacrificing single-aspect summarization quality.",
    "num_pages": 14
}