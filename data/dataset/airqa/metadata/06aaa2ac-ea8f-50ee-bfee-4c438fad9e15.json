{
    "uuid": "06aaa2ac-ea8f-50ee-bfee-4c438fad9e15",
    "title": "ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{ghazarian-etal-2023-accent,\n    title = \"{ACCENT}: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems\",\n    author = \"Ghazarian, Sarik  and\n      Shao, Yijia  and\n      Han, Rujun  and\n      Galstyan, Aram  and\n      Peng, Nanyun\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.241\",\n    doi = \"10.18653/v1/2023.acl-long.241\",\n    pages = \"4398--4419\",\n    abstract = \"Commonsense reasoning is omnipresent in human communications and thus is an important feature for open-domain dialogue systems. However, evaluating commonsense in dialogue systems is still an open challenge. We take the first step by focusing on \\textit{event commonsense} that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning. We propose \\textbf{ACCENT}, an event commonsense evaluation metric empowered by commonsense knowledge bases (CSKBs). ACCENT first extracts event-relation tuples from a dialogue, and then evaluates the response by scoring the tuples in terms of their compatibility with the CSKB. To evaluate ACCENT, we construct the first public event commonsense evaluation dataset for open-domain dialogues.Our experiments show that ACCENT is an efficient metric for event commonsense evaluation, which achieves higher correlations with human judgments than existing baselines.\",\n}\n",
    "authors": [
        "Sarik Ghazarian",
        "Yijia Shao",
        "Rujun Han",
        "Aram Galstyan",
        "Nanyun Peng"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.241.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/06aaa2ac-ea8f-50ee-bfee-4c438fad9e15.pdf",
    "abstract": "Commonsense reasoning is omnipresent in human communications and thus is an important feature for open-domain dialogue systems. However, evaluating commonsense in dialogue systems is still an open challenge. We take the first step by focusing on event commonsense that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning. We propose ACCENT, an event commonsense evaluation metric empowered by commonsense knowledge bases (CSKBs). ACCENT first extracts event-relation tuples from a dialogue, and then evaluates the response by scoring the tuples in terms of their compatibility with the CSKB. To evaluate ACCENT, we construct the first public event commonsense evaluation dataset for open-domain dialogues.Our experiments show that ACCENT is an efficient metric for event commonsense evaluation, which achieves higher correlations with human judgments than existing baselines.",
    "num_pages": 22
}