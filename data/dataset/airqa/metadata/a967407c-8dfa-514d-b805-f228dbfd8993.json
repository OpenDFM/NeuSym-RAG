{
    "uuid": "a967407c-8dfa-514d-b805-f228dbfd8993",
    "title": "Race, Gender, and Age Biases in Biomedical Masked Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{kim-etal-2023-race,\n    title = \"Race, Gender, and Age Biases in Biomedical Masked Language Models\",\n    author = \"Kim, Michelle  and\n      Kim, Junghwan  and\n      Johnson, Kristen\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.749\",\n    doi = \"10.18653/v1/2023.findings-acl.749\",\n    pages = \"11806--11815\",\n    abstract = \"Biases cause discrepancies in healthcare services. Race, gender, and age of a patient affect interactions with physicians and the medical treatments one receives. These biases in clinical practices can be amplified following the release of pre-trained language models trained on biomedical corpora. To bring awareness to such repercussions, we examine social biases present in the biomedical masked language models. We curate prompts based on evidence-based practice and compare generated diagnoses based on biases. For a case study, we measure bias in diagnosing coronary artery disease and using cardiovascular procedures based on bias. Our study demonstrates that biomedical models are less biased than BERT in gender, while the opposite is true for race and age.\",\n}\n",
    "authors": [
        "Michelle Kim",
        "Junghwan Kim",
        "Kristen Johnson"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.749.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a967407c-8dfa-514d-b805-f228dbfd8993.pdf",
    "abstract": "Biases cause discrepancies in healthcare services. Race, gender, and age of a patient affect interactions with physicians and the medical treatments one receives. These biases in clinical practices can be amplified following the release of pre-trained language models trained on biomedical corpora. To bring awareness to such repercussions, we examine social biases present in the biomedical masked language models. We curate prompts based on evidence-based practice and compare generated diagnoses based on biases. For a case study, we measure bias in diagnosing coronary artery disease and using cardiovascular procedures based on bias. Our study demonstrates that biomedical models are less biased than BERT in gender, while the opposite is true for race and age.",
    "num_pages": 10
}