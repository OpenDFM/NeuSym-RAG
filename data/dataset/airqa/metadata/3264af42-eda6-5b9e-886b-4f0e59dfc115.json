{
    "uuid": "3264af42-eda6-5b9e-886b-4f0e59dfc115",
    "title": "CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{yu-etal-2024-cmoraleval,\n    title = \"{CM}oral{E}val: A Moral Evaluation Benchmark for {C}hinese Large Language Models\",\n    author = \"Yu, Linhao  and\n      Leng, Yongqi  and\n      Huang, Yufei  and\n      Wu, Shang  and\n      Liu, Haixin  and\n      Ji, Xinmeng  and\n      Zhao, Jiahui  and\n      Song, Jinwang  and\n      Cui, Tingting  and\n      Cheng, Xiaoqing  and\n      Liutao, Liutao  and\n      Xiong, Deyi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.703\",\n    doi = \"10.18653/v1/2024.findings-acl.703\",\n    pages = \"11817--11837\",\n    abstract = \"What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality. With these sources, we aim to create a moral evaluation dataset characterized by diversity and authenticity. We develop a morality taxonomy and a set of fundamental moral principles that are not only rooted in traditional Chinese culture but also consistent with contemporary societal norms. To facilitate efficient construction and annotation of instances in CMoralEval, we establish a platform with AI-assisted instance generation to streamline the annotation process. These help us curate CMoralEval that encompasses both explicit moral scenarios (14,964 instances) and moral dilemma scenarios (15,424 instances), each with instances from different data sources. We conduct extensive experiments with CMoralEval to examine a variety of Chinese LLMs. Experiment results demonstrate that CMoralEval is a challenging benchmark for Chinese LLMs.\",\n}\n",
    "authors": [
        "Linhao Yu",
        "Yongqi Leng",
        "Yufei Huang",
        "Shang Wu",
        "Haixin Liu",
        "Xinmeng Ji",
        "Jiahui Zhao",
        "Jinwang Song",
        "Tingting Cui",
        "Xiaoqing Cheng",
        "Liutao Liutao",
        "Deyi Xiong"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.703.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3264af42-eda6-5b9e-886b-4f0e59dfc115.pdf",
    "abstract": "What a large language model (LLM) would respond in ethically relevant context? In this paper, we curate a large benchmark CMoralEval for morality evaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a Chinese TV program discussing Chinese moral norms with stories from the society and 2) a collection of Chinese moral anomies from various newspapers and academic papers on morality. With these sources, we aim to create a moral evaluation dataset characterized by diversity and authenticity. We develop a morality taxonomy and a set of fundamental moral principles that are not only rooted in traditional Chinese culture but also consistent with contemporary societal norms. To facilitate efficient construction and annotation of instances in CMoralEval, we establish a platform with AI-assisted instance generation to streamline the annotation process. These help us curate CMoralEval that encompasses both explicit moral scenarios (14,964 instances) and moral dilemma scenarios (15,424 instances), each with instances from different data sources. We conduct extensive experiments with CMoralEval to examine a variety of Chinese LLMs. Experiment results demonstrate that CMoralEval is a challenging benchmark for Chinese LLMs.",
    "num_pages": 21
}