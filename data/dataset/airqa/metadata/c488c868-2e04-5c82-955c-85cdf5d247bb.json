{
    "uuid": "c488c868-2e04-5c82-955c-85cdf5d247bb",
    "title": "Intermediate Domain Finetuning for Weakly Supervised Domain-adaptive Clinical NER",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
    "bibtex": "@inproceedings{suresh-etal-2023-intermediate,\n    title = \"Intermediate Domain Finetuning for Weakly Supervised Domain-adaptive Clinical {NER}\",\n    author = \"Suresh, Shilpa  and\n      Tavabi, Nazgol  and\n      Golchin, Shahriar  and\n      Gilreath, Leah  and\n      Garcia-Andujar, Rafael  and\n      Kim, Alexander  and\n      Murray, Joseph  and\n      Bacevich, Blake  and\n      Kiapour, Ata\",\n    editor = \"Demner-fushman, Dina  and\n      Ananiadou, Sophia  and\n      Cohen, Kevin\",\n    booktitle = \"The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bionlp-1.29\",\n    doi = \"10.18653/v1/2023.bionlp-1.29\",\n    pages = \"320--325\",\n    abstract = \"Accurate human-annotated data for real-worlduse cases can be scarce and expensive to obtain. In the clinical domain, obtaining such data is evenmore difficult due to privacy concerns which notonly restrict open access to quality data but also require that the annotation be done by domain experts. In this paper, we propose a novel framework - InterDAPT - that leverages Intermediate Domain Finetuning to allow language models to adapt to narrow domains with small, noisy datasets. By making use of peripherally-related, unlabeled datasets,this framework circumvents domain-specific datascarcity issues. Our results show that this weaklysupervised framework provides performance improvements in downstream clinical named entityrecognition tasks.\",\n}\n",
    "authors": [
        "Shilpa Suresh",
        "Nazgol Tavabi",
        "Shahriar Golchin",
        "Leah Gilreath",
        "Rafael Garcia-Andujar",
        "Alexander Kim",
        "Joseph Murray",
        "Blake Bacevich",
        "Ata Kiapour"
    ],
    "pdf_url": "https://aclanthology.org/2023.bionlp-1.29.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/c488c868-2e04-5c82-955c-85cdf5d247bb.pdf",
    "abstract": "Accurate human-annotated data for real-worlduse cases can be scarce and expensive to obtain. In the clinical domain, obtaining such data is evenmore difficult due to privacy concerns which notonly restrict open access to quality data but also require that the annotation be done by domain experts. In this paper, we propose a novel framework - InterDAPT - that leverages Intermediate Domain Finetuning to allow language models to adapt to narrow domains with small, noisy datasets. By making use of peripherally-related, unlabeled datasets,this framework circumvents domain-specific datascarcity issues. Our results show that this weaklysupervised framework provides performance improvements in downstream clinical named entityrecognition tasks.",
    "num_pages": 6
}