{
    "uuid": "6a48b9d1-2679-5512-aec8-af4bfb535f0b",
    "title": "MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{razdaibiedina-brechalov-2023-miread,\n    title = \"{MIR}e{AD}: Simple Method for Learning High-quality Representations from Scientific Documents\",\n    author = \"Razdaibiedina, Anastasiia  and\n      Brechalov, Aleksandr\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.46\",\n    doi = \"10.18653/v1/2023.acl-short.46\",\n    pages = \"530--539\",\n    abstract = \"Learning semantically meaningful representations from scientific documents can facilitate academic literature search and improve performance of recommendation systems. Pretrained language models have been shown to learn rich textual representations, yet they cannot provide powerful document-level representations for scientific articles. We propose MIReAD, a simple method that learns highquality representations of scientific papers by fine-tuning transformer model to predict the target journal class based on the abstract. We train MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000 journal classes. We show that MIReAD produces representations that can be used for similar papers retrieval, topic categorization and literature search. Our proposed approach outperforms six existing models for representation learning on scientific documents across four evaluation standards.\",\n}\n",
    "authors": [
        "Anastasiia Razdaibiedina",
        "Aleksandr Brechalov"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.46.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/6a48b9d1-2679-5512-aec8-af4bfb535f0b.pdf",
    "abstract": "Learning semantically meaningful representations from scientific documents can facilitate academic literature search and improve performance of recommendation systems. Pretrained language models have been shown to learn rich textual representations, yet they cannot provide powerful document-level representations for scientific articles. We propose MIReAD, a simple method that learns highquality representations of scientific papers by fine-tuning transformer model to predict the target journal class based on the abstract. We train MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000 journal classes. We show that MIReAD produces representations that can be used for similar papers retrieval, topic categorization and literature search. Our proposed approach outperforms six existing models for representation learning on scientific documents across four evaluation standards.",
    "num_pages": 10
}