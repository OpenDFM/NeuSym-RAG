{
    "uuid": "047880ae-ccf5-513a-b9b1-3e505cb14e09",
    "title": "Learning Answer Generation using Supervision from Automatic Question Answering Evaluators",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{gabburo-etal-2023-learning,\n    title = \"Learning Answer Generation using Supervision from Automatic Question Answering Evaluators\",\n    author = \"Gabburo, Matteo  and\n      Garg, Siddhant  and\n      Koncel-Kedziorski, Rik  and\n      Moschitti, Alessandro\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.467\",\n    doi = \"10.18653/v1/2023.acl-long.467\",\n    pages = \"8389--8403\",\n    abstract = \"Recent studies show that sentence-level extractive QA, i.e., based on Answer Sentence Selection (AS2), is outperformed by Generation-based QA (GenQA) models, which generate answers using the top-k answer sentences ranked by AS2 models (a la retrieval-augmented generation style). In this paper, we propose a novel training paradigm for GenQA using supervision from automatic QA evaluation models (GAVA). Specifically, we propose three strategies to transfer knowledge from these QA evaluation models to a GenQA model: (i) augmenting training data with answers generated by the GenQA model and labelled by GAVA (either statically, before training, or (ii) dynamically, at every training epoch); and (iii) using the GAVA score for weighting the generator loss during the learning of the GenQA model. We evaluate our proposed methods on two academic and one industrial dataset, obtaining a significant improvement in answering accuracy over the previous state of the art.\",\n}\n",
    "authors": [
        "Matteo Gabburo",
        "Siddhant Garg",
        "Rik Koncel-Kedziorski",
        "Alessandro Moschitti"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.467.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/047880ae-ccf5-513a-b9b1-3e505cb14e09.pdf",
    "abstract": "Recent studies show that sentence-level extractive QA, i.e., based on Answer Sentence Selection (AS2), is outperformed by Generation-based QA (GenQA) models, which generate answers using the top-k answer sentences ranked by AS2 models (a la retrieval-augmented generation style). In this paper, we propose a novel training paradigm for GenQA using supervision from automatic QA evaluation models (GAVA). Specifically, we propose three strategies to transfer knowledge from these QA evaluation models to a GenQA model: (i) augmenting training data with answers generated by the GenQA model and labelled by GAVA (either statically, before training, or (ii) dynamically, at every training epoch); and (iii) using the GAVA score for weighting the generator loss during the learning of the GenQA model. We evaluate our proposed methods on two academic and one industrial dataset, obtaining a significant improvement in answering accuracy over the previous state of the art.",
    "num_pages": 15
}