{
    "uuid": "cf82fbc9-d9ab-57ba-9d6d-b6ad67ef4354",
    "title": "CARE: A Clue-guided Assistant for CSRs to Read User Manuals",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{du-etal-2024-care,\n    title = \"{CARE}: A Clue-guided Assistant for {CSR}s to Read User Manuals\",\n    author = \"Du, Weihong  and\n      Liu, Jia  and\n      Wen, Zujie  and\n      Jin, Dingnan  and\n      Liang, Hongru  and\n      Lei, Wenqiang\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.581\",\n    doi = \"10.18653/v1/2024.acl-long.581\",\n    pages = \"10795--10811\",\n    abstract = \"It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don{'}t fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence, we propose to develop a time-saving and careful reading assistant for CSRs, named CARE. It can help the CSRs quickly find proper responses from the user manuals via explicit clue chains. Specifically, each of the clue chains is formed by inferring over the user manuals, starting from the question clue aligned with the user question and ending at a possible response. To overcome the shortage of supervised data, we adopt the self-supervised strategy for model learning. The offline experiment shows that CARE is efficient in automatically inferring accurate responses from the user manual. The online experiment further demonstrates the superiority of CARE to reduce CSRs{'} reading burden and keep high service quality, in particular with {\\textgreater}35{\\%} decrease in time spent and keeping a {\\textgreater}0.75 ICC score.\",\n}\n",
    "authors": [
        "Weihong Du",
        "Jia Liu",
        "Zujie Wen",
        "Dingnan Jin",
        "Hongru Liang",
        "Wenqiang Lei"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.581.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/cf82fbc9-d9ab-57ba-9d6d-b6ad67ef4354.pdf",
    "abstract": "It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don’t fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence, we propose to develop a time-saving and careful reading assistant for CSRs, named CARE. It can help the CSRs quickly find proper responses from the user manuals via explicit clue chains. Specifically, each of the clue chains is formed by inferring over the user manuals, starting from the question clue aligned with the user question and ending at a possible response. To overcome the shortage of supervised data, we adopt the self-supervised strategy for model learning. The offline experiment shows that CARE is efficient in automatically inferring accurate responses from the user manual. The online experiment further demonstrates the superiority of CARE to reduce CSRs’ reading burden and keep high service quality, in particular with >35% decrease in time spent and keeping a >0.75 ICC score.",
    "num_pages": 17
}