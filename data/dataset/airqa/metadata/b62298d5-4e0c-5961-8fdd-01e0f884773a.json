{
    "uuid": "b62298d5-4e0c-5961-8fdd-01e0f884773a",
    "title": "Exploring the Impact of Vision Features in News Image Captioning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zhang-wan-2023-exploring,\n    title = \"Exploring the Impact of Vision Features in News Image Captioning\",\n    author = \"Zhang, Junzhe  and\n      Wan, Xiaojun\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.818\",\n    doi = \"10.18653/v1/2023.findings-acl.818\",\n    pages = \"12923--12936\",\n    abstract = \"The task of news image captioning aims to generate a detailed caption which describes the specific information of an image in a news article. However, we find that recent state-of-art models can achieve competitive performance even without vision features. To resolve the impact of vision features in the news image captioning task, we conduct extensive experiments with mainstream models based on encoder-decoder framework. From our exploration, we find 1) vision features do contribute to the generation of news image captions; 2) vision features can assist models to better generate entities of captions when the entity information is sufficient in the input textual context of the given article; 3) Regions of specific objects in images contribute to the generation of related entities in captions.\",\n}\n",
    "authors": [
        "Junzhe Zhang",
        "Xiaojun Wan"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.818.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b62298d5-4e0c-5961-8fdd-01e0f884773a.pdf",
    "abstract": "The task of news image captioning aims to generate a detailed caption which describes the specific information of an image in a news article. However, we find that recent state-of-art models can achieve competitive performance even without vision features. To resolve the impact of vision features in the news image captioning task, we conduct extensive experiments with mainstream models based on encoder-decoder framework. From our exploration, we find 1) vision features do contribute to the generation of news image captions; 2) vision features can assist models to better generate entities of captions when the entity information is sufficient in the input textual context of the given article; 3) Regions of specific objects in images contribute to the generation of related entities in captions.",
    "num_pages": 14
}