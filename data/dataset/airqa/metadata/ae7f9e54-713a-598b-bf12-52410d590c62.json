{
    "uuid": "ae7f9e54-713a-598b-bf12-52410d590c62",
    "title": "A Survey on Asking Clarification Questions Datasets in Conversational Systems",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{rahmani-etal-2023-survey,\n    title = \"A Survey on Asking Clarification Questions Datasets in Conversational Systems\",\n    author = \"Rahmani, Hossein A.  and\n      Wang, Xi  and\n      Feng, Yue  and\n      Zhang, Qiang  and\n      Yilmaz, Emine  and\n      Lipani, Aldo\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.152\",\n    doi = \"10.18653/v1/2023.acl-long.152\",\n    pages = \"2698--2716\",\n    abstract = \"The ability to understand a user{'}s underlying needs is critical for conversational systems, especially with limited input from users in a conversation. Thus, in such a domain, Asking Clarification Questions (ACQs) to reveal users{'} true intent from their queries or utterances arise as an essential task. However, it is noticeable that a key limitation of the existing ACQs studies is their incomparability, from inconsistent use of data, distinct experimental setups and evaluation strategies. Therefore, in this paper, to assist the development of ACQs techniques, we comprehensively analyse the current ACQs research status, which offers a detailed comparison of publicly available datasets, and discusses the applied evaluation metrics, joined with benchmarks for multiple ACQs-related tasks. In particular, given a thorough analysis of the ACQs task, we discuss a number of corresponding research directions for the investigation of ACQs as well as the development of conversational systems.\",\n}\n",
    "authors": [
        "Hossein A. Rahmani",
        "Xi Wang",
        "Yue Feng",
        "Qiang Zhang",
        "Emine Yilmaz",
        "Aldo Lipani"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.152.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ae7f9e54-713a-598b-bf12-52410d590c62.pdf",
    "abstract": "The ability to understand a user’s underlying needs is critical for conversational systems, especially with limited input from users in a conversation. Thus, in such a domain, Asking Clarification Questions (ACQs) to reveal users’ true intent from their queries or utterances arise as an essential task. However, it is noticeable that a key limitation of the existing ACQs studies is their incomparability, from inconsistent use of data, distinct experimental setups and evaluation strategies. Therefore, in this paper, to assist the development of ACQs techniques, we comprehensively analyse the current ACQs research status, which offers a detailed comparison of publicly available datasets, and discusses the applied evaluation metrics, joined with benchmarks for multiple ACQs-related tasks. In particular, given a thorough analysis of the ACQs task, we discuss a number of corresponding research directions for the investigation of ACQs as well as the development of conversational systems.",
    "num_pages": 19
}