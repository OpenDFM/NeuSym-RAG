{
    "uuid": "0bbb3735-213e-5179-bde8-0058b3dd41bb",
    "title": "WebCPM: Interactive Web Search for Chinese Long-form Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{qin-etal-2023-webcpm,\n    title = \"{W}eb{CPM}: Interactive Web Search for {C}hinese Long-form Question Answering\",\n    author = \"Qin, Yujia  and\n      Cai, Zihan  and\n      Jin, Dian  and\n      Yan, Lan  and\n      Liang, Shihao  and\n      Zhu, Kunlun  and\n      Lin, Yankai  and\n      Han, Xu  and\n      Ding, Ning  and\n      Wang, Huadong  and\n      Xie, Ruobing  and\n      Qi, Fanchao  and\n      Liu, Zhiyuan  and\n      Sun, Maosong  and\n      Zhou, Jie\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.499\",\n    doi = \"10.18653/v1/2023.acl-long.499\",\n    pages = \"8968--8988\",\n    abstract = \"Long-form question answering (LFQA) aims at answering complex, open-ended questions with detailed, paragraph-length responses. The de facto paradigm of LFQA necessitates two procedures: information retrieval, which searches for relevant supporting facts, and information synthesis, which integrates these facts into a coherent answer. In this paper, we introduce WebCPM, the first Chinese LFQA dataset. One unique feature of WebCPM is that its information retrieval is based on interactive web search, which engages with a search engine in real time. Following WebGPT, we develop a web search interface. We recruit annotators to search for relevant information using our interface and then answer questions. Meanwhile, the web search behaviors of our annotators would be recorded. In total, we collect 5,500 high-quality question-answer pairs, together with 15,372 supporting facts and 125,954 web search actions. We fine-tune pre-trained language models to imitate human behaviors for web search and to generate answers based on the collected facts. Our LFQA pipeline, built on these fine-tuned models, generates answers that are no worse than human-written ones in 32.5{\\%} and 47.5{\\%} of the cases on our dataset and DuReader, respectively. The interface, dataset, and codes are publicly available at \\url{https://github.com/thunlp/WebCPM}.\",\n}\n",
    "authors": [
        "Yujia Qin",
        "Zihan Cai",
        "Dian Jin",
        "Lan Yan",
        "Shihao Liang",
        "Kunlun Zhu",
        "Yankai Lin",
        "Xu Han",
        "Ning Ding",
        "Huadong Wang",
        "Ruobing Xie",
        "Fanchao Qi",
        "Zhiyuan Liu",
        "Maosong Sun",
        "Jie Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.499.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0bbb3735-213e-5179-bde8-0058b3dd41bb.pdf",
    "abstract": "Long-form question answering (LFQA) aims at answering complex, open-ended questions with detailed, paragraph-length responses. The de facto paradigm of LFQA necessitates two procedures: information retrieval, which searches for relevant supporting facts, and information synthesis, which integrates these facts into a coherent answer. In this paper, we introduce WebCPM, the first Chinese LFQA dataset. One unique feature of WebCPM is that its information retrieval is based on interactive web search, which engages with a search engine in real time. Following WebGPT, we develop a web search interface. We recruit annotators to search for relevant information using our interface and then answer questions. Meanwhile, the web search behaviors of our annotators would be recorded. In total, we collect 5,500 high-quality question-answer pairs, together with 15,372 supporting facts and 125,954 web search actions. We fine-tune pre-trained language models to imitate human behaviors for web search and to generate answers based on the collected facts. Our LFQA pipeline, built on these fine-tuned models, generates answers that are no worse than human-written ones in 32.5% and 47.5% of the cases on our dataset and DuReader, respectively. The interface, dataset, and codes are publicly available at https://github.com/thunlp/WebCPM.",
    "num_pages": 21
}