{
    "uuid": "ed3dd315-bf4c-5445-ab78-13f9fdf8b71b",
    "title": "Using Neural Machine Translation for Generating Diverse Challenging Exercises for Language Learner",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{palma-gomez-etal-2023-using,\n    title = \"Using Neural Machine Translation for Generating Diverse Challenging Exercises for Language Learner\",\n    author = \"Palma Gomez, Frank  and\n      Panda, Subhadarshi  and\n      Flor, Michael  and\n      Rozovskaya, Alla\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.337\",\n    doi = \"10.18653/v1/2023.acl-long.337\",\n    pages = \"6115--6129\",\n    abstract = \"We propose a novel approach to automatically generate distractors for cloze exercises for English language learners, using round-trip neural machine translation. A carrier sentence is translated from English into another (pivot) language and back, and distractors are produced by aligning the original sentence with its round-trip translation. We make use of 16 linguistically-diverse pivots and generate hundreds of translation hypotheses in each direction. We show that using hundreds of translations allows us to generate a rich set of challenging distractors. Moreover, we find that typologically unrelated language pivots contribute more diverse candidate distractors, compared to language pivots that are closely related. We further evaluate the use of machine translation systems of varying quality and find that better quality MT systems produce more challenging distractors. Finally, we conduct a study with language learners, demonstrating that the automatically generated distractors are of the same difficulty as the gold distractors produced by human experts.\",\n}\n",
    "authors": [
        "Frank Palma Gomez",
        "Subhadarshi Panda",
        "Michael Flor",
        "Alla Rozovskaya"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.337.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ed3dd315-bf4c-5445-ab78-13f9fdf8b71b.pdf",
    "abstract": "We propose a novel approach to automatically generate distractors for cloze exercises for English language learners, using round-trip neural machine translation. A carrier sentence is translated from English into another (pivot) language and back, and distractors are produced by aligning the original sentence with its round-trip translation. We make use of 16 linguistically-diverse pivots and generate hundreds of translation hypotheses in each direction. We show that using hundreds of translations allows us to generate a rich set of challenging distractors. Moreover, we find that typologically unrelated language pivots contribute more diverse candidate distractors, compared to language pivots that are closely related. We further evaluate the use of machine translation systems of varying quality and find that better quality MT systems produce more challenging distractors. Finally, we conduct a study with language learners, demonstrating that the automatically generated distractors are of the same difficulty as the gold distractors produced by human experts.",
    "num_pages": 15
}