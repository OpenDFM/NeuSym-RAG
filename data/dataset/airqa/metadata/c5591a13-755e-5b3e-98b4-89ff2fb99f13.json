{
    "uuid": "c5591a13-755e-5b3e-98b4-89ff2fb99f13",
    "title": "Applying RLAIF for Code Generation with API-usage in Lightweight LLMs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 2nd Workshop on Natural Language Reasoning and Structured Explanations (@ACL 2024)",
    "bibtex": "@inproceedings{dutta-etal-2024-applying,\n    title = \"Applying {RLAIF} for Code Generation with {API}-usage in Lightweight {LLM}s\",\n    author = \"Dutta, Sujan  and\n      Mahinder, Sayantan  and\n      Anantha, Raviteja  and\n      Bandyopadhyay, Bortik\",\n    editor = \"Dalvi Mishra, Bhavana  and\n      Durrett, Greg  and\n      Jansen, Peter  and\n      Lipkin, Ben  and\n      Neves Ribeiro, Danilo  and\n      Wong, Lionel  and\n      Ye, Xi  and\n      Zhao, Wenting\",\n    booktitle = \"Proceedings of the 2nd Workshop on Natural Language Reasoning and Structured Explanations (@ACL 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.nlrse-1.4\",\n    pages = \"39--45\",\n    abstract = \"Reinforcement Learning from AI Feedback (RLAIF) has demonstrated significant potential across various domains, including mitigating harm in LLM outputs, enhancing text summarization, and mathematical reasoning. This paper introduces an RLAIF framework for improving the code generation abilities of lightweight ({\\textless}1B parameters) LLMs. We specifically focus on code generation tasks that require writing appropriate API calls, which is challenging due to the well-known issue of hallucination in LLMs. Our framework extracts AI feedback from a larger LLM (e.g., GPT-3.5) through a specialized prompting strategy and uses this data to train a reward model towards better alignment from smaller LLMs. We run our experiments on the Gorilla dataset and meticulously assess the quality of the model-generated code across various metrics, including AST, ROUGE, and Code-BLEU, and develop a pipeline to compute its executability rate accurately. Our approach significantly enhances the fine-tuned LLM baseline{'}s performance, achieving a 4.5{\\%} improvement in executability rate. Notably, a smaller LLM model (780M parameters) trained with RLAIF surpasses a much larger fine-tuned baseline with 7B parameters, achieving a 1.0{\\%} higher code executability rate.\",\n}\n",
    "authors": [
        "Sujan Dutta",
        "Sayantan Mahinder",
        "Raviteja Anantha",
        "Bortik Bandyopadhyay"
    ],
    "pdf_url": "https://aclanthology.org/2024.nlrse-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/c5591a13-755e-5b3e-98b4-89ff2fb99f13.pdf",
    "abstract": "Reinforcement Learning from AI Feedback (RLAIF) has demonstrated significant potential across various domains, including mitigating harm in LLM outputs, enhancing text summarization, and mathematical reasoning. This paper introduces an RLAIF framework for improving the code generation abilities of lightweight (<1B parameters) LLMs. We specifically focus on code generation tasks that require writing appropriate API calls, which is challenging due to the well-known issue of hallucination in LLMs. Our framework extracts AI feedback from a larger LLM (e.g., GPT-3.5) through a specialized prompting strategy and uses this data to train a reward model towards better alignment from smaller LLMs. We run our experiments on the Gorilla dataset and meticulously assess the quality of the model-generated code across various metrics, including AST, ROUGE, and Code-BLEU, and develop a pipeline to compute its executability rate accurately. Our approach significantly enhances the fine-tuned LLM baselineâ€™s performance, achieving a 4.5% improvement in executability rate. Notably, a smaller LLM model (780M parameters) trained with RLAIF surpasses a much larger fine-tuned baseline with 7B parameters, achieving a 1.0% higher code executability rate.",
    "num_pages": 7
}