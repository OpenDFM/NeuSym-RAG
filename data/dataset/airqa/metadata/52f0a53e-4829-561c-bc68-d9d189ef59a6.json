{
    "uuid": "52f0a53e-4829-561c-bc68-d9d189ef59a6",
    "title": "Varta: A Large-Scale Headline-Generation Dataset for Indic Languages",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{aralikatte-etal-2023-varta,\n    title = \"Varta: A Large-Scale Headline-Generation Dataset for {I}ndic Languages\",\n    author = \"Aralikatte, Rahul  and\n      Cheng, Ziling  and\n      Doddapaneni, Sumanth  and\n      Cheung, Jackie Chi Kit\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.215\",\n    doi = \"10.18653/v1/2023.findings-acl.215\",\n    pages = \"3468--3492\",\n    abstract = \"We present Varta, a large-scale multilingual dataset for headline generation in Indic languages. This dataset includes more than 41 million pairs of headlines and articles in 14 different Indic languages (and English), which come from a variety of high-quality news sources. To the best of our knowledge, this is the largest collection of curated news articles for Indic languages currently available. We use the collected data in a series of experiments to answer important questions related to Indic NLP and multilinguality research in general. We show that the dataset is challenging even for state-of-the-art abstractive models and that they perform only slightly better than extractive baselines. Owing to its size, we also show that the dataset can be used to pre-train strong language models that outperform competitive baselines in both NLU and NLG benchmarks.\",\n}\n",
    "authors": [
        "Rahul Aralikatte",
        "Ziling Cheng",
        "Sumanth Doddapaneni",
        "Jackie Chi Kit Cheung"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.215.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/52f0a53e-4829-561c-bc68-d9d189ef59a6.pdf",
    "abstract": "We present Varta, a large-scale multilingual dataset for headline generation in Indic languages. This dataset includes more than 41 million pairs of headlines and articles in 14 different Indic languages (and English), which come from a variety of high-quality news sources. To the best of our knowledge, this is the largest collection of curated news articles for Indic languages currently available. We use the collected data in a series of experiments to answer important questions related to Indic NLP and multilinguality research in general. We show that the dataset is challenging even for state-of-the-art abstractive models and that they perform only slightly better than extractive baselines. Owing to its size, we also show that the dataset can be used to pre-train strong language models that outperform competitive baselines in both NLU and NLG benchmarks.",
    "num_pages": 25
}