{
    "uuid": "5ee23f14-8f29-5937-99e0-bea3ecc5cdd1",
    "title": "Self-Para-Consistency: Improving Reasoning Tasks at Low Cost for Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{chen-etal-2024-self-para,\n    title = \"Self-Para-Consistency: Improving Reasoning Tasks at Low Cost for Large Language Models\",\n    author = \"Chen, Wenqing  and\n      Wang, Weicheng  and\n      Chu, Zhixuan  and\n      Ren, Kui  and\n      Zheng, Zibin  and\n      Lu, Zhichao\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.842\",\n    doi = \"10.18653/v1/2024.findings-acl.842\",\n    pages = \"14162--14167\",\n    abstract = \"Recently, the self-consistency decoding strategy has shown the ability to improve performance for complex reasoning tasks with large language models (LLMs). However, the costs may be high because the sampling process of the strategy generates some low-probability text, resulting in low-quality reasoning paths. As a consequence, it requires a relatively large sampling number to obtain good aggregation performance. In this paper, we propose an alternative strategy, \\textit{self-para-consistency}. It first generates multiple paraphrases for each test question, then generates reasoning paths for the original and all the paraphrased questions based on greedy decoding, and finally selects the most consistent answer. Since all the candidate paths have relatively high probabilities, the sampling number could be much smaller than the self-consistency strategy. Extensive experiments on complex reasoning datasets demonstrate the effectiveness of our method in reducing the sampling number.\",\n}\n",
    "authors": [
        "Wenqing Chen",
        "Weicheng Wang",
        "Zhixuan Chu",
        "Kui Ren",
        "Zibin Zheng",
        "Zhichao Lu"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.842.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/5ee23f14-8f29-5937-99e0-bea3ecc5cdd1.pdf",
    "abstract": "Recently, the self-consistency decoding strategy has shown the ability to improve performance for complex reasoning tasks with large language models (LLMs). However, the costs may be high because the sampling process of the strategy generates some low-probability text, resulting in low-quality reasoning paths. As a consequence, it requires a relatively large sampling number to obtain good aggregation performance. In this paper, we propose an alternative strategy, self-para-consistency. It first generates multiple paraphrases for each test question, then generates reasoning paths for the original and all the paraphrased questions based on greedy decoding, and finally selects the most consistent answer. Since all the candidate paths have relatively high probabilities, the sampling number could be much smaller than the self-consistency strategy. Extensive experiments on complex reasoning datasets demonstrate the effectiveness of our method in reducing the sampling number.",
    "num_pages": 6
}