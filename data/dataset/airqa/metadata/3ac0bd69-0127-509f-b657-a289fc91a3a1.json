{
    "uuid": "3ac0bd69-0127-509f-b657-a289fc91a3a1",
    "title": "Leveraging Prefix Transfer for Multi-Intent Text Revision",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{chong-etal-2023-leveraging,\n    title = \"Leveraging Prefix Transfer for Multi-Intent Text Revision\",\n    author = \"Chong, Ruining  and\n      Kong, Cunliang  and\n      Wu, Liu  and\n      Liu, Zhenghao  and\n      Jin, Ziye  and\n      Yang, Liner  and\n      Fan, Yange  and\n      Fan, Hanghang  and\n      Yang, Erhong\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.105\",\n    doi = \"10.18653/v1/2023.acl-short.105\",\n    pages = \"1219--1228\",\n    abstract = \"Text revision is a necessary process to improve text quality. During this process, writers constantly edit texts out of different edit intentions. Identifying edit intention for a raw text is always an ambiguous work, and most previous work on revision systems mainly focuses on editing texts according to one specific edit intention. In this work, we aim to build a multi-intent text revision system that could revise texts without explicit intent annotation. Our system is based on prefix-tuning, which first gets prefixes for every edit intent, and then trains a prefix transfer module, enabling the system to selectively leverage the knowledge from various prefixes according to the input text. We conduct experiments on the IteraTeR dataset, and the results show that our system outperforms baselines. The system can significantly improve the SARI score with more than 3{\\%} improvements, which thrives on the learned editing intention prefixes.\",\n}\n",
    "authors": [
        "Ruining Chong",
        "Cunliang Kong",
        "Liu Wu",
        "Zhenghao Liu",
        "Ziye Jin",
        "Liner Yang",
        "Yange Fan",
        "Hanghang Fan",
        "Erhong Yang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.105.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/3ac0bd69-0127-509f-b657-a289fc91a3a1.pdf",
    "abstract": "Text revision is a necessary process to improve text quality. During this process, writers constantly edit texts out of different edit intentions. Identifying edit intention for a raw text is always an ambiguous work, and most previous work on revision systems mainly focuses on editing texts according to one specific edit intention. In this work, we aim to build a multi-intent text revision system that could revise texts without explicit intent annotation. Our system is based on prefix-tuning, which first gets prefixes for every edit intent, and then trains a prefix transfer module, enabling the system to selectively leverage the knowledge from various prefixes according to the input text. We conduct experiments on the IteraTeR dataset, and the results show that our system outperforms baselines. The system can significantly improve the SARI score with more than 3% improvements, which thrives on the learned editing intention prefixes.",
    "num_pages": 10
}