{
    "uuid": "d3f17c1f-53b9-5459-aa44-2082fb183335",
    "title": "Transfer Learning for Low-Resource Clinical Named Entity Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{sasikumar-mantri-2023-transfer,\n    title = \"Transfer Learning for Low-Resource Clinical Named Entity Recognition\",\n    author = \"Sasikumar, Nevasini  and\n      Mantri, Krishna Sri Ipsit\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.53\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.53\",\n    pages = \"514--518\",\n    abstract = \"We propose a transfer learning method that adapts a high-resource English clinical NER model to low-resource languages and domains using only small amounts of in-domain annotated data. Our approach involves translating in-domain datasets to English, fine-tuning the English model on the translated data, and then transferring it to the target language/domain. Experiments on Spanish, French, and conversational clinical text datasets show accuracy gains over models trained on target data alone. Our method achieves state-of-the-art performance and can enable clinical NLP in more languages and modalities with limited resources.\",\n}\n",
    "authors": [
        "Nevasini Sasikumar",
        "Krishna Sri Ipsit Mantri"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.53.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/d3f17c1f-53b9-5459-aa44-2082fb183335.pdf",
    "abstract": "We propose a transfer learning method that adapts a high-resource English clinical NER model to low-resource languages and domains using only small amounts of in-domain annotated data. Our approach involves translating in-domain datasets to English, fine-tuning the English model on the translated data, and then transferring it to the target language/domain. Experiments on Spanish, French, and conversational clinical text datasets show accuracy gains over models trained on target data alone. Our method achieves state-of-the-art performance and can enable clinical NLP in more languages and modalities with limited resources.",
    "num_pages": 5
}