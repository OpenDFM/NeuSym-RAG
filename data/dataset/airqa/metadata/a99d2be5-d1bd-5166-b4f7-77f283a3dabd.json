{
    "uuid": "a99d2be5-d1bd-5166-b4f7-77f283a3dabd",
    "title": "Privacy Aware Question-Answering System for Online Mental Health Risk Assessment",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
    "bibtex": "@inproceedings{chhikara-etal-2023-privacy,\n    title = \"Privacy Aware Question-Answering System for Online Mental Health Risk Assessment\",\n    author = \"Chhikara, Prateek  and\n      Pasupulety, Ujjwal  and\n      Marshall, John  and\n      Chaurasia, Dhiraj  and\n      Kumari, Shweta\",\n    editor = \"Demner-fushman, Dina  and\n      Ananiadou, Sophia  and\n      Cohen, Kevin\",\n    booktitle = \"The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bionlp-1.18\",\n    doi = \"10.18653/v1/2023.bionlp-1.18\",\n    pages = \"215--222\",\n    abstract = \"Social media platforms have enabled individuals suffering from mental illnesses to share their lived experiences and find the online support necessary to cope. However, many users fail to receive genuine clinical support, thus exacerbating their symptoms. Screening users based on what they post online can aid providers in administering targeted healthcare and minimize false positives. Pre-trained Language Models (LMs) can assess users{'} social media data and classify them in terms of their mental health risk. We propose a Question-Answering (QA) approach to assess mental health risk using the Unified-QA model on two large mental health datasets. To protect user data, we extend Unified-QA by anonymizing the model training process using differential privacy. Our results demonstrate the effectiveness of modeling risk assessment as a QA task, specifically for mental health use cases. Furthermore, the model{'}s performance decreases by less than 1{\\%} with the inclusion of differential privacy. The proposed system{'}s performance is indicative of a promising research direction that will lead to the development of privacy-aware diagnostic systems.\",\n}\n",
    "authors": [
        "Prateek Chhikara",
        "Ujjwal Pasupulety",
        "John Marshall",
        "Dhiraj Chaurasia",
        "Shweta Kumari"
    ],
    "pdf_url": "https://aclanthology.org/2023.bionlp-1.18.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a99d2be5-d1bd-5166-b4f7-77f283a3dabd.pdf",
    "abstract": "Social media platforms have enabled individuals suffering from mental illnesses to share their lived experiences and find the online support necessary to cope. However, many users fail to receive genuine clinical support, thus exacerbating their symptoms. Screening users based on what they post online can aid providers in administering targeted healthcare and minimize false positives. Pre-trained Language Models (LMs) can assess users’ social media data and classify them in terms of their mental health risk. We propose a Question-Answering (QA) approach to assess mental health risk using the Unified-QA model on two large mental health datasets. To protect user data, we extend Unified-QA by anonymizing the model training process using differential privacy. Our results demonstrate the effectiveness of modeling risk assessment as a QA task, specifically for mental health use cases. Furthermore, the model’s performance decreases by less than 1% with the inclusion of differential privacy. The proposed system’s performance is indicative of a promising research direction that will lead to the development of privacy-aware diagnostic systems.",
    "num_pages": 8
}