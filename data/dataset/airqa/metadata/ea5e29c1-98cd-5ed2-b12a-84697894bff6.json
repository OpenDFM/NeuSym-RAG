{
    "uuid": "ea5e29c1-98cd-5ed2-b12a-84697894bff6",
    "title": "Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{iskander-etal-2023-shielded,\n    title = \"Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection\",\n    author = \"Iskander, Shadi  and\n      Radinsky, Kira  and\n      Belinkov, Yonatan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.369\",\n    doi = \"10.18653/v1/2023.findings-acl.369\",\n    pages = \"5961--5977\",\n    abstract = \"Natural language processing models tend to learn and encode social biases present in the data. One popular approach for addressing such biases is to eliminate encoded information from the model{'}s representations. However, current methods are restricted to removing only linearly encoded information. In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations. Our method consists of iteratively training neural classifiers to predict a particular attribute we seek to eliminate, followed by a projection of the representation on a hypersurface, such that the classifiers become oblivious to the target attribute. We evaluate the effectiveness of our method on the task of removing gender and race information as sensitive attributes. Our results demonstrate that IGBP is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.\",\n}\n",
    "authors": [
        "Shadi Iskander",
        "Kira Radinsky",
        "Yonatan Belinkov"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.369.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ea5e29c1-98cd-5ed2-b12a-84697894bff6.pdf",
    "abstract": "Natural language processing models tend to learn and encode social biases present in the data. One popular approach for addressing such biases is to eliminate encoded information from the modelâ€™s representations. However, current methods are restricted to removing only linearly encoded information. In this work, we propose Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations. Our method consists of iteratively training neural classifiers to predict a particular attribute we seek to eliminate, followed by a projection of the representation on a hypersurface, such that the classifiers become oblivious to the target attribute. We evaluate the effectiveness of our method on the task of removing gender and race information as sensitive attributes. Our results demonstrate that IGBP is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.",
    "num_pages": 17
}