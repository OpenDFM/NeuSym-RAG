{
    "uuid": "70784df4-dcf1-5c90-84bf-b753d6f5ca4b",
    "title": "FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{li-etal-2023-factual,\n    title = \"{FACTUAL}: A Benchmark for Faithful and Consistent Textual Scene Graph Parsing\",\n    author = \"Li, Zhuang  and\n      Chai, Yuyang  and\n      Zhuo, Terry Yue  and\n      Qu, Lizhen  and\n      Haffari, Gholamreza  and\n      Li, Fei  and\n      Ji, Donghong  and\n      Tran, Quan Hung\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.398\",\n    doi = \"10.18653/v1/2023.findings-acl.398\",\n    pages = \"6377--6390\",\n    abstract = \"Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations. To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvement leads to a significant performance boost in both image caption evaluation and zero-shot image retrieval tasks. Furthermore, we introduce a novel metric for measuring scene graph similarity, which, when combined with the improved scene graph parser, achieves state-of-the-art (SOTA) results on multiple benchmark datasets for the aforementioned tasks.\",\n}\n",
    "authors": [
        "Zhuang Li",
        "Yuyang Chai",
        "Terry Yue Zhuo",
        "Lizhen Qu",
        "Gholamreza Haffari",
        "Fei Li",
        "Donghong Ji",
        "Quan Hung Tran"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.398.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/70784df4-dcf1-5c90-84bf-b753d6f5ca4b.pdf",
    "abstract": "Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations. To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvement leads to a significant performance boost in both image caption evaluation and zero-shot image retrieval tasks. Furthermore, we introduce a novel metric for measuring scene graph similarity, which, when combined with the improved scene graph parser, achieves state-of-the-art (SOTA) results on multiple benchmark datasets for the aforementioned tasks.",
    "num_pages": 14
}