{
    "uuid": "8981aae4-89f0-54b4-93c0-5532186ebf47",
    "title": "Understanding Cross-Lingual Alignment—A Survey",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{hammerl-etal-2024-understanding,\n    title = \"Understanding Cross-Lingual {A}lignment{---}{A} Survey\",\n    author = {H{\\\"a}mmerl, Katharina  and\n      Libovick{\\'y}, Jind{\\v{r}}ich  and\n      Fraser, Alexander},\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.649\",\n    doi = \"10.18653/v1/2024.findings-acl.649\",\n    pages = \"10922--10943\",\n    abstract = \"Cross-lingual alignment, the meaningful similarity of representations across languages in multilingual language models, has been an active field of research in recent years. We survey the literature of techniques to improve cross-lingual alignment, providing a taxonomy of methods and summarising insights from throughout the field. We present different understandings of cross-lingual alignment and their limitations. We provide a qualitative summary of results from a number of surveyed papers. Finally, we discuss how these insights may be applied not only to encoder models, where this topic has been heavily studied, but also to encoder-decoder or even decoder-only models, and argue that an effective trade-off between language-neutral and language-specific information is key.\",\n}\n",
    "authors": [
        "Katharina Hämmerl",
        "Jindřich Libovický",
        "Alexander Fraser"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.649.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8981aae4-89f0-54b4-93c0-5532186ebf47.pdf",
    "abstract": "Cross-lingual alignment, the meaningful similarity of representations across languages in multilingual language models, has been an active field of research in recent years. We survey the literature of techniques to improve cross-lingual alignment, providing a taxonomy of methods and summarising insights from throughout the field. We present different understandings of cross-lingual alignment and their limitations. We provide a qualitative summary of results from a number of surveyed papers. Finally, we discuss how these insights may be applied not only to encoder models, where this topic has been heavily studied, but also to encoder-decoder or even decoder-only models, and argue that an effective trade-off between language-neutral and language-specific information is key.",
    "num_pages": 22
}