{
    "uuid": "893e57c5-17d5-53ea-ad0f-aa72a37548d9",
    "title": "The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{gera-etal-2023-benefits,\n    title = \"The Benefits of Bad Advice: Autocontrastive Decoding across Model Layers\",\n    author = \"Gera, Ariel  and\n      Friedman, Roni  and\n      Arviv, Ofir  and\n      Gunasekara, Chulaka  and\n      Sznajder, Benjamin  and\n      Slonim, Noam  and\n      Shnarch, Eyal\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.580\",\n    doi = \"10.18653/v1/2023.acl-long.580\",\n    pages = \"10406--10420\",\n    abstract = \"Applying language models to natural language processing tasks typically relies on the representations in the final model layer, as intermediate hidden layer representations are presumed to be less informative. In this work, we argue that due to the gradual improvement across model layers, additional information can be gleaned from the contrast between higher and lower layers during inference. Specifically, in choosing between the probable next token predictions of a generative model, the predictions of lower layers can be used to highlight which candidates are best avoided. We propose a novel approach that utilizes the contrast between layers to improve text generation outputs, and show that it mitigates degenerative behaviors of the model in open-ended generation, significantly improving the quality of generated texts. Furthermore, our results indicate that contrasting between model layers at inference time can yield substantial benefits to certain aspects of general language model capabilities, more effectively extracting knowledge during inference from a given set of model parameters.\",\n}\n",
    "authors": [
        "Ariel Gera",
        "Roni Friedman",
        "Ofir Arviv",
        "Chulaka Gunasekara",
        "Benjamin Sznajder",
        "Noam Slonim",
        "Eyal Shnarch"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.580.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/893e57c5-17d5-53ea-ad0f-aa72a37548d9.pdf",
    "abstract": "Applying language models to natural language processing tasks typically relies on the representations in the final model layer, as intermediate hidden layer representations are presumed to be less informative. In this work, we argue that due to the gradual improvement across model layers, additional information can be gleaned from the contrast between higher and lower layers during inference. Specifically, in choosing between the probable next token predictions of a generative model, the predictions of lower layers can be used to highlight which candidates are best avoided. We propose a novel approach that utilizes the contrast between layers to improve text generation outputs, and show that it mitigates degenerative behaviors of the model in open-ended generation, significantly improving the quality of generated texts. Furthermore, our results indicate that contrasting between model layers at inference time can yield substantial benefits to certain aspects of general language model capabilities, more effectively extracting knowledge during inference from a given set of model parameters.",
    "num_pages": 15
}