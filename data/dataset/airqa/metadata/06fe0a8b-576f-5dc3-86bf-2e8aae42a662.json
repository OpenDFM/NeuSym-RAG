{
    "uuid": "06fe0a8b-576f-5dc3-86bf-2e8aae42a662",
    "title": "Intervention extraction in preclinical animal studies of Alzheimerâ€™s Disease: Enhancing regex performance with language model-based filtering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{pu-etal-2024-intervention,\n    title = \"Intervention extraction in preclinical animal studies of {A}lzheimer{'}s Disease: Enhancing regex performance with language model-based filtering\",\n    author = \"Pu, Yiyuan  and\n      Hair, Kaitlyn  and\n      Beck, Daniel  and\n      Conway, Mike  and\n      MacLeod, Malcolm  and\n      Verspoor, Karin\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.39\",\n    doi = \"10.18653/v1/2024.bionlp-1.39\",\n    pages = \"486--492\",\n    abstract = \"We explore different information extraction tools for annotation of interventions to support automated systematic reviews of preclinical AD animal studies. We compare two PICO (Population, Intervention, Comparison, and Outcome) extraction tools and two prompting-based learning strategies based on Large Language Models (LLMs). Motivated by the high recall of a dictionary-based approach, we define a two-stage method, removing false positives obtained from regexes with a pre-trained LM. With ChatGPT-based filtering using three-shot prompting, our approach reduces almost two-thirds of False Positives compared to the dictionary approach alone, while outperforming knowledge-free instructional prompting.\",\n}\n",
    "authors": [
        "Yiyuan Pu",
        "Kaitlyn Hair",
        "Daniel Beck",
        "Mike Conway",
        "Malcolm MacLeod",
        "Karin Verspoor"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.39.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/06fe0a8b-576f-5dc3-86bf-2e8aae42a662.pdf",
    "abstract": "We explore different information extraction tools for annotation of interventions to support automated systematic reviews of preclinical AD animal studies. We compare two PICO (Population, Intervention, Comparison, and Outcome) extraction tools and two prompting-based learning strategies based on Large Language Models (LLMs). Motivated by the high recall of a dictionary-based approach, we define a two-stage method, removing false positives obtained from regexes with a pre-trained LM. With ChatGPT-based filtering using three-shot prompting, our approach reduces almost two-thirds of False Positives compared to the dictionary approach alone, while outperforming knowledge-free instructional prompting.",
    "num_pages": 7
}