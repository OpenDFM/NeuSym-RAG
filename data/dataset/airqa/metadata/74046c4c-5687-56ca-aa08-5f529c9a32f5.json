{
    "uuid": "74046c4c-5687-56ca-aa08-5f529c9a32f5",
    "title": "LLM-REDIAL: A Large-Scale Dataset for Conversational Recommender Systems Created from User Behaviors with LLMs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{liang-etal-2024-llm,\n    title = \"{LLM}-{REDIAL}: A Large-Scale Dataset for Conversational Recommender Systems Created from User Behaviors with {LLM}s\",\n    author = \"Liang, Tingting  and\n      Jin, Chenxin  and\n      Wang, Lingzhi  and\n      Fan, Wenqi  and\n      Xia, Congying  and\n      Chen, Kai  and\n      Yin, Yuyu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.529\",\n    doi = \"10.18653/v1/2024.findings-acl.529\",\n    pages = \"8926--8939\",\n    abstract = \"The large-scale conversational recommendation dataset is pivotal for the development of conversational recommender systems (CRS). Most existing CRS datasets suffers from the problems of data inextensibility and semantic inconsistency. To tackle these limitations and establish a benchmark in the conversational recommendation scenario, in this paper, we introduce the LLM-REDIAL dataset to facilitate the research in CRS. LLM-REDIAL is constructed by leveraging large language models (LLMs) to generate the high-quality dialogues. To provide the LLMs with detailed guidance, we integrate historical user behavior data with dialogue templates that are carefully designed through the combination of multiple pre-defined goals. LLM-REDIAL has two main advantages. First, it is the largest multi-domain CRS dataset which consists of 47.6k multi-turn dialogues with 482.6k utterances across 4 domains. Second, dialogue semantics and the users{'} historical interaction information is highly consistent. Human evaluation are conducted to verify the quality of LLM-REDIAL. In addition, we evaluate the usability of advanced LLM-based models on LLM-REDIAL.\",\n}\n",
    "authors": [
        "Tingting Liang",
        "Chenxin Jin",
        "Lingzhi Wang",
        "Wenqi Fan",
        "Congying Xia",
        "Kai Chen",
        "Yuyu Yin"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.529.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/74046c4c-5687-56ca-aa08-5f529c9a32f5.pdf",
    "abstract": "The large-scale conversational recommendation dataset is pivotal for the development of conversational recommender systems (CRS). Most existing CRS datasets suffers from the problems of data inextensibility and semantic inconsistency. To tackle these limitations and establish a benchmark in the conversational recommendation scenario, in this paper, we introduce the LLM-REDIAL dataset to facilitate the research in CRS. LLM-REDIAL is constructed by leveraging large language models (LLMs) to generate the high-quality dialogues. To provide the LLMs with detailed guidance, we integrate historical user behavior data with dialogue templates that are carefully designed through the combination of multiple pre-defined goals. LLM-REDIAL has two main advantages. First, it is the largest multi-domain CRS dataset which consists of 47.6k multi-turn dialogues with 482.6k utterances across 4 domains. Second, dialogue semantics and the usersâ€™ historical interaction information is highly consistent. Human evaluation are conducted to verify the quality of LLM-REDIAL. In addition, we evaluate the usability of advanced LLM-based models on LLM-REDIAL.",
    "num_pages": 14
}