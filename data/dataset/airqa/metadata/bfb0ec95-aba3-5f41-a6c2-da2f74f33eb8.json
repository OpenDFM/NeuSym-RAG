{
    "uuid": "bfb0ec95-aba3-5f41-a6c2-da2f74f33eb8",
    "title": "LTRC at SemEval-2023 Task 6: Experiments with Ensemble Embeddings",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{baswani-etal-2023-ltrc,\n    title = \"{LTRC} at {S}em{E}val-2023 Task 6: Experiments with Ensemble Embeddings\",\n    author = \"Baswani, Pavan  and\n      Sri Adibhatla, Hiranmai  and\n      Shrivastava, Manish\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.116\",\n    doi = \"10.18653/v1/2023.semeval-1.116\",\n    pages = \"841--846\",\n    abstract = \"In this paper, we present our team{'}s involvement in Task 6: LegalEval: Understanding Legal Texts. The task comprised three subtasks, and we focus on subtask A: Rhetorical Roles prediction. Our approach included experimenting with pre-trained embeddings and refining them with statistical and neural classifiers. We provide a thorough examination ofour experiments, solutions, and analysis, culminating in our best-performing model and current progress. We achieved a micro F1 score of 0.6133 on the test data using fine-tuned LegalBERT embeddings.\",\n}\n",
    "authors": [
        "Pavan Baswani",
        "Hiranmai Sri Adibhatla",
        "Manish Shrivastava"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.116.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/bfb0ec95-aba3-5f41-a6c2-da2f74f33eb8.pdf",
    "abstract": "In this paper, we present our teamâ€™s involvement in Task 6: LegalEval: Understanding Legal Texts. The task comprised three subtasks, and we focus on subtask A: Rhetorical Roles prediction. Our approach included experimenting with pre-trained embeddings and refining them with statistical and neural classifiers. We provide a thorough examination ofour experiments, solutions, and analysis, culminating in our best-performing model and current progress. We achieved a micro F1 score of 0.6133 on the test data using fine-tuned LegalBERT embeddings.",
    "num_pages": 6
}