{
    "uuid": "b8077f5e-8860-55f6-a7b5-9d10bc0b5565",
    "title": "Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{cheng-etal-2024-call,\n    title = \"Call Me When Necessary: {LLM}s can Efficiently and Faithfully Reason over Structured Environments\",\n    author = \"Cheng, Sitao  and\n      Zhuang, Ziyuan  and\n      Xu, Yong  and\n      Yang, Fangkai  and\n      Zhang, Chaoyun  and\n      Qin, Xiaoting  and\n      Huang, Xiang  and\n      Chen, Ling  and\n      Lin, Qingwei  and\n      Zhang, Dongmei  and\n      Rajmohan, Saravan  and\n      Zhang, Qi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.254\",\n    doi = \"10.18653/v1/2024.findings-acl.254\",\n    pages = \"4275--4295\",\n    abstract = \"Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graphs and tables. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous works adopt LLMs to incrementally build a reasoning path, where LLMs either invoke tools or pick up items by step-by-step interacting with the environment. We propose Reasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently and faithfully reason over structured environments. In Readi, LLMs initially generate a reasoning path given a query, and edit the path only when necessary. We instantiate the path on structured environments and provide feedback to edit the path if anything goes wrong. Experimental results on three KGQA and two TableQA datasets show the effectiveness of Readi, significantly surpassing previous LLM-based methods (by 9.1{\\%} Hit@1 on WebQSP, 12.4{\\%} on MQA-3H and 9.5{\\%} on WTQ), comparable with state-of-the-art fine-tuned methods (67{\\%} on CWQ and 74.7{\\%} on WebQSP) and substantially boosting the vanilla LLMs (by 14.9{\\%} on CWQ). Our code will be available on \\url{https://aka.ms/readi}.\",\n}\n",
    "authors": [
        "Sitao Cheng",
        "Ziyuan Zhuang",
        "Yong Xu",
        "Fangkai Yang",
        "Chaoyun Zhang",
        "Xiaoting Qin",
        "Xiang Huang",
        "Ling Chen",
        "Qingwei Lin",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.254.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b8077f5e-8860-55f6-a7b5-9d10bc0b5565.pdf",
    "abstract": "Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graphs and tables. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous works adopt LLMs to incrementally build a reasoning path, where LLMs either invoke tools or pick up items by step-by-step interacting with the environment. We propose Reasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently and faithfully reason over structured environments. In Readi, LLMs initially generate a reasoning path given a query, and edit the path only when necessary. We instantiate the path on structured environments and provide feedback to edit the path if anything goes wrong. Experimental results on three KGQA and two TableQA datasets show the effectiveness of Readi, significantly surpassing previous LLM-based methods (by 9.1% Hit@1 on WebQSP, 12.4% on MQA-3H and 9.5% on WTQ), comparable with state-of-the-art fine-tuned methods (67% on CWQ and 74.7% on WebQSP) and substantially boosting the vanilla LLMs (by 14.9% on CWQ). Our code will be available on https://aka.ms/readi.",
    "num_pages": 21
}