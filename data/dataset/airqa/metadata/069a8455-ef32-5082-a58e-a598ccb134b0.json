{
    "uuid": "069a8455-ef32-5082-a58e-a598ccb134b0",
    "title": "ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)",
    "bibtex": "@inproceedings{yan-etal-2023-espnet,\n    title = \"{ESP}net-{ST}-v2: Multipurpose Spoken Language Translation Toolkit\",\n    author = \"Yan, Brian  and\n      Shi, Jiatong  and\n      Tang, Yun  and\n      Inaguma, Hirofumi  and\n      Peng, Yifan  and\n      Dalmia, Siddharth  and\n      Pol{\\'a}k, Peter  and\n      Fernandes, Patrick  and\n      Berrebbi, Dan  and\n      Hayashi, Tomoki  and\n      Zhang, Xiaohui  and\n      Ni, Zhaoheng  and\n      Hira, Moto  and\n      Maiti, Soumi  and\n      Pino, Juan  and\n      Watanabe, Shinji\",\n    editor = \"Bollegala, Danushka  and\n      Huang, Ruihong  and\n      Ritter, Alan\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-demo.38\",\n    doi = \"10.18653/v1/2023.acl-demo.38\",\n    pages = \"400--411\",\n    abstract = \"ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) {--} each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at \\url{https://github.com/espnet/espnet}.\",\n}\n",
    "authors": [
        "Brian Yan",
        "Jiatong Shi",
        "Yun Tang",
        "Hirofumi Inaguma",
        "Yifan Peng",
        "Siddharth Dalmia",
        "Peter Polák",
        "Patrick Fernandes",
        "Dan Berrebbi",
        "Tomoki Hayashi",
        "Xiaohui Zhang",
        "Zhaoheng Ni",
        "Moto Hira",
        "Soumi Maiti",
        "Juan Pino",
        "Shinji Watanabe"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-demo.38.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/069a8455-ef32-5082-a58e-a598ccb134b0.pdf",
    "abstract": "ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) – each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.",
    "num_pages": 12
}