{
    "uuid": "6c26675a-540e-5566-92f5-e881be8c107a",
    "title": "Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{baek-etal-2023-towards,\n    title = \"Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints\",\n    author = \"Baek, Yujin  and\n      Lee, Koanho  and\n      Ki, Dayeon  and\n      Park, Cheonbok  and\n      Lee, Hyoung-Gyu  and\n      Choo, Jaegul\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.298\",\n    doi = \"10.18653/v1/2023.findings-acl.298\",\n    pages = \"4839--4855\",\n    abstract = \"Lexically-constrained NMT (LNMT) aims to incorporate user-provided terminology into translations. Despite its practical advantages, existing work has not evaluated LNMT models under challenging real-world conditions. In this paper, we focus on two important but understudied issues that lie in the current evaluation process of LNMT studies. The model needs to cope with challenging lexical constraints that are {``}homographs{''} or {``}unseen{''} during training. To this end, we first design a homograph disambiguation module to differentiate the meanings of homographs. Moreover, we propose PLUMCOT which integrates contextually rich information about unseen lexical constraints from pre-trained language models and strengthens a copy mechanism of the pointer network via direct supervision of a copying score. We also release HOLLY, an evaluation benchmark for assessing the ability of model to cope with {``}homographic{''} and {``}unseen{''} lexical constraints. Experiments on HOLLY and the previous test setup show the effectiveness of our method. The effects of PLUMCOT are shown to be remarkable in {``}unseen{''} constraints. Our dataset is available at \\url{https://github.com/papago-lab/HOLLY-benchmark}.\",\n}\n",
    "authors": [
        "Yujin Baek",
        "Koanho Lee",
        "Dayeon Ki",
        "Cheonbok Park",
        "Hyoung-Gyu Lee",
        "Jaegul Choo"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.298.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/6c26675a-540e-5566-92f5-e881be8c107a.pdf",
    "abstract": "Lexically-constrained NMT (LNMT) aims to incorporate user-provided terminology into translations. Despite its practical advantages, existing work has not evaluated LNMT models under challenging real-world conditions. In this paper, we focus on two important but understudied issues that lie in the current evaluation process of LNMT studies. The model needs to cope with challenging lexical constraints that are “homographs” or “unseen” during training. To this end, we first design a homograph disambiguation module to differentiate the meanings of homographs. Moreover, we propose PLUMCOT which integrates contextually rich information about unseen lexical constraints from pre-trained language models and strengthens a copy mechanism of the pointer network via direct supervision of a copying score. We also release HOLLY, an evaluation benchmark for assessing the ability of model to cope with “homographic” and “unseen” lexical constraints. Experiments on HOLLY and the previous test setup show the effectiveness of our method. The effects of PLUMCOT are shown to be remarkable in “unseen” constraints. Our dataset is available at https://github.com/papago-lab/HOLLY-benchmark.",
    "num_pages": 17
}