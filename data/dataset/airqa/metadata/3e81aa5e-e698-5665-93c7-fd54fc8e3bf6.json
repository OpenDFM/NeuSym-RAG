{
    "uuid": "3e81aa5e-e698-5665-93c7-fd54fc8e3bf6",
    "title": "Speaking the Language of Your Listener: Audience-Aware Adaptation via Plug-and-Play Theory of Mind",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{takmaz-etal-2023-speaking,\n    title = \"Speaking the Language of Your Listener: Audience-Aware Adaptation via Plug-and-Play Theory of Mind\",\n    author = \"Takmaz, Ece  and\n      Brandizzi, Nicolo{'}  and\n      Giulianelli, Mario  and\n      Pezzelle, Sandro  and\n      Fernandez, Raquel\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.258\",\n    doi = \"10.18653/v1/2023.findings-acl.258\",\n    pages = \"4198--4217\",\n    abstract = \"Dialogue participants may have varying levels of knowledge about the topic under discussion. In such cases, it is essential for speakers to adapt their utterances by taking their audience into account. Yet, it is an open question how such adaptation can be modelled in computational agents. In this paper, we model a visually grounded referential game between a knowledgeable speaker and a listener with more limited visual and linguistic experience. Inspired by psycholinguistic theories, we endow our speaker with the ability to adapt its referring expressions via a simulation module that monitors the effectiveness of planned utterances from the listener{'}s perspective. We propose an adaptation mechanism building on plug-and-play approaches to controlled language generation, where utterance generation is steered on the fly by the simulator without finetuning the speaker{'}s underlying language model. Our results and analyses show that our approach is effective: the speaker{'}s utterances become closer to the listener{'}s domain of expertise, which leads to higher communicative success.\",\n}\n",
    "authors": [
        "Ece Takmaz",
        "Nicolo’ Brandizzi",
        "Mario Giulianelli",
        "Sandro Pezzelle",
        "Raquel Fernandez"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.258.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/3e81aa5e-e698-5665-93c7-fd54fc8e3bf6.pdf",
    "abstract": "Dialogue participants may have varying levels of knowledge about the topic under discussion. In such cases, it is essential for speakers to adapt their utterances by taking their audience into account. Yet, it is an open question how such adaptation can be modelled in computational agents. In this paper, we model a visually grounded referential game between a knowledgeable speaker and a listener with more limited visual and linguistic experience. Inspired by psycholinguistic theories, we endow our speaker with the ability to adapt its referring expressions via a simulation module that monitors the effectiveness of planned utterances from the listener’s perspective. We propose an adaptation mechanism building on plug-and-play approaches to controlled language generation, where utterance generation is steered on the fly by the simulator without finetuning the speaker’s underlying language model. Our results and analyses show that our approach is effective: the speaker’s utterances become closer to the listener’s domain of expertise, which leads to higher communicative success.",
    "num_pages": 20
}