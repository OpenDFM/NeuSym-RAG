{
    "uuid": "a6e57c05-46cc-55de-a93c-e3d4eb1b4db5",
    "title": "The BIGAI Offline Speech Translation Systems for IWSLT 2023 Evaluation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{xie-2023-bigai,\n    title = \"The {BIGAI} Offline Speech Translation Systems for {IWSLT} 2023 Evaluation\",\n    author = \"Xie, Zhihang\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.7\",\n    doi = \"10.18653/v1/2023.iwslt-1.7\",\n    pages = \"123--129\",\n    abstract = \"This paper describes the BIGAI{'}s submission to IWSLT 2023 Offline Speech Translation task on three language tracks from English to Chinese, German and Japanese. The end-to-end systems are built upon a Wav2Vec2 model for speech recognition and mBART50 models for machine translation. An adapter module is applied to bridge the speech module and the translation module. The CTC loss between speech features and source token sequence is incorporated during training. Experiments show that the systems can generate reasonable translations on three languages. The proposed models achieve BLEU scores of 22.3 for enâde, 10.7 for enâja and 33.0 for enâzh on tst2023 TED datasets. However, the performance is decreased by a significant margin on complex scenarios like persentations and interview.\",\n}\n",
    "authors": [
        "Zhihang Xie"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.7.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a6e57c05-46cc-55de-a93c-e3d4eb1b4db5.pdf",
    "abstract": "This paper describes the BIGAI’s submission to IWSLT 2023 Offline Speech Translation task on three language tracks from English to Chinese, German and Japanese. The end-to-end systems are built upon a Wav2Vec2 model for speech recognition and mBART50 models for machine translation. An adapter module is applied to bridge the speech module and the translation module. The CTC loss between speech features and source token sequence is incorporated during training. Experiments show that the systems can generate reasonable translations on three languages. The proposed models achieve BLEU scores of 22.3 for en→de, 10.7 for en→ja and 33.0 for en→zh on tst2023 TED datasets. However, the performance is decreased by a significant margin on complex scenarios like persentations and interview.",
    "num_pages": 7
}