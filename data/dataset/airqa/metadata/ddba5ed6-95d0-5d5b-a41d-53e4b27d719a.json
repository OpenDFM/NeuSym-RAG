{
    "uuid": "ddba5ed6-95d0-5d5b-a41d-53e4b27d719a",
    "title": "Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{li-etal-2024-evaluating-mathematical,\n    title = \"Evaluating Mathematical Reasoning of Large Language Models: A Focus on Error Identification and Correction\",\n    author = \"Li, Xiaoyuan  and\n      Wang, Wenjie  and\n      Li, Moxin  and\n      Guo, Junrong  and\n      Zhang, Yang  and\n      Feng, Fuli\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.673\",\n    doi = \"10.18653/v1/2024.findings-acl.673\",\n    pages = \"11316--11360\",\n    abstract = \"The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem-solving from the examinee perspective, overlooking a dual perspective of examiner regarding error identification and correction.From the examiner perspective, we define four evaluation tasks for error identification and correction along with a new dataset with annotated error types and steps. We also design diverse prompts to thoroughly evaluate eleven representative LLMs. Our principal findings indicate that GPT-4 outperforms all models, while open-source model LLaMA-2-7B demonstrates comparable abilities to closed-source models GPT-3.5 and Gemini Pro.Notably, calculation error proves the most challenging error type. Moreover, prompting LLMs with the error types can improve the average correction accuracy by 47.9{\\%}. These results reveal potential directions for developing the mathematical reasoning abilities of LLMs.Our code and dataset is available on https://github.com/LittleCirc1e/EIC.\",\n}\n",
    "authors": [
        "Xiaoyuan Li",
        "Wenjie Wang",
        "Moxin Li",
        "Junrong Guo",
        "Yang Zhang",
        "Fuli Feng"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.673.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ddba5ed6-95d0-5d5b-a41d-53e4b27d719a.pdf",
    "abstract": "The rapid advancement of Large Language Models (LLMs) in the realm of mathematical reasoning necessitates comprehensive evaluations to gauge progress and inspire future directions. Existing assessments predominantly focus on problem-solving from the examinee perspective, overlooking a dual perspective of examiner regarding error identification and correction.From the examiner perspective, we define four evaluation tasks for error identification and correction along with a new dataset with annotated error types and steps. We also design diverse prompts to thoroughly evaluate eleven representative LLMs. Our principal findings indicate that GPT-4 outperforms all models, while open-source model LLaMA-2-7B demonstrates comparable abilities to closed-source models GPT-3.5 and Gemini Pro.Notably, calculation error proves the most challenging error type. Moreover, prompting LLMs with the error types can improve the average correction accuracy by 47.9%. These results reveal potential directions for developing the mathematical reasoning abilities of LLMs.Our code and dataset is available on https://github.com/LittleCirc1e/EIC.",
    "num_pages": 45
}