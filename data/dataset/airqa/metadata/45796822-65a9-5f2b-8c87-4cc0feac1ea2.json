{
    "uuid": "45796822-65a9-5f2b-8c87-4cc0feac1ea2",
    "title": "Multilingual Language Models are not Multicultural: A Case Study in Emotion",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{havaldar-etal-2023-multilingual,\n    title = \"Multilingual Language Models are not Multicultural: A Case Study in Emotion\",\n    author = \"Havaldar, Shreya  and\n      Singhal, Bhumika  and\n      Rai, Sunny  and\n      Liu, Langchen  and\n      Guntuku, Sharath Chandra  and\n      Ungar, Lyle\",\n    editor = \"Barnes, Jeremy  and\n      De Clercq, Orph{\\'e}e  and\n      Klinger, Roman\",\n    booktitle = \"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wassa-1.19\",\n    doi = \"10.18653/v1/2023.wassa-1.19\",\n    pages = \"202--214\",\n    abstract = \"Emotions are experienced and expressed differently across the world. In order to use Large Language Models (LMs) for multilingual tasks that require emotional sensitivity, LMs must reflect this cultural variation in emotion. In this study, we investigate whether the widely-used multilingual LMs in 2023 reflect differences in emotional expressions across cultures and languages. We find that embeddings obtained from LMs (e.g., XLM-RoBERTa) are Anglocentric, and generative LMs (e.g., ChatGPT) reflect Western norms, even when responding to prompts in other languages. Our results show that multilingual LMs do not successfully learn the culturally appropriate nuances of emotion and we highlight possible research directions towards correcting this.\",\n}\n",
    "authors": [
        "Shreya Havaldar",
        "Bhumika Singhal",
        "Sunny Rai",
        "Langchen Liu",
        "Sharath Chandra Guntuku",
        "Lyle Ungar"
    ],
    "pdf_url": "https://aclanthology.org/2023.wassa-1.19.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/45796822-65a9-5f2b-8c87-4cc0feac1ea2.pdf",
    "abstract": "Emotions are experienced and expressed differently across the world. In order to use Large Language Models (LMs) for multilingual tasks that require emotional sensitivity, LMs must reflect this cultural variation in emotion. In this study, we investigate whether the widely-used multilingual LMs in 2023 reflect differences in emotional expressions across cultures and languages. We find that embeddings obtained from LMs (e.g., XLM-RoBERTa) are Anglocentric, and generative LMs (e.g., ChatGPT) reflect Western norms, even when responding to prompts in other languages. Our results show that multilingual LMs do not successfully learn the culturally appropriate nuances of emotion and we highlight possible research directions towards correcting this.",
    "num_pages": 13
}