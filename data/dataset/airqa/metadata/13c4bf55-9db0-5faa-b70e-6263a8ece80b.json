{
    "uuid": "13c4bf55-9db0-5faa-b70e-6263a8ece80b",
    "title": "FII_Better at SemEval-2023 Task 2: MultiCoNER II Multilingual Complex Named Entity Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{lupancu-etal-2023-fii,\n    title = \"{FII}{\\_}{B}etter at {S}em{E}val-2023 Task 2: {M}ulti{C}o{NER} {II} Multilingual Complex Named Entity Recognition\",\n    author = \"Lupancu, Viorica-Camelia  and\n      Platica, Alexandru-Gabriel  and\n      Rosu, Cristian-Mihai  and\n      Gifu, Daniela  and\n      Trandabat, Diana\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.153\",\n    doi = \"10.18653/v1/2023.semeval-1.153\",\n    pages = \"1107--1113\",\n    abstract = \"This task focuses on identifying complex named entities (NEs) in several languages. In the context of SemEval-2023 competition, our team presents an exploration of a base transformer model{'}s capabilities regarding the task, focused more specifically on five languages (English, Spanish, Swedish, German, Italian). We take DistilBERT and BERT as two examples of basic transformer models, using DistilBERT as a baseline and BERT as the platform to create an improved model. The dataset that we are using, MultiCoNER II, is a large multilingual dataset used for NER, that covers domains like: Wiki sentences, questions and search queries across 12 languages. This dataset contains 26M tokens and it is assembled from public resources. MultiCoNER II defines a NER tag-set with 6 classes and 67 tags. We have managed to get moderate results in the English track (we ranked 17th out of 34), while our results in the other tracks could be further improved in the future (overall third to last).\",\n}\n",
    "authors": [
        "Viorica-Camelia Lupancu",
        "Alexandru-Gabriel Platica",
        "Cristian-Mihai Rosu",
        "Daniela Gifu",
        "Diana Trandabat"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.153.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/13c4bf55-9db0-5faa-b70e-6263a8ece80b.pdf",
    "abstract": "This task focuses on identifying complex named entities (NEs) in several languages. In the context of SemEval-2023 competition, our team presents an exploration of a base transformer modelâ€™s capabilities regarding the task, focused more specifically on five languages (English, Spanish, Swedish, German, Italian). We take DistilBERT and BERT as two examples of basic transformer models, using DistilBERT as a baseline and BERT as the platform to create an improved model. The dataset that we are using, MultiCoNER II, is a large multilingual dataset used for NER, that covers domains like: Wiki sentences, questions and search queries across 12 languages. This dataset contains 26M tokens and it is assembled from public resources. MultiCoNER II defines a NER tag-set with 6 classes and 67 tags. We have managed to get moderate results in the English track (we ranked 17th out of 34), while our results in the other tracks could be further improved in the future (overall third to last).",
    "num_pages": 7
}