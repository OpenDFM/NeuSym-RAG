{
    "uuid": "f9fae973-a46e-597b-b5ec-108069288c02",
    "title": "A Prompting Assignment for Exploring Pretrained LLMs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Sixth Workshop on Teaching NLP",
    "bibtex": "@inproceedings{anderson-2024-prompting-assignment,\n    title = \"A Prompting Assignment for Exploring Pretrained {LLM}s\",\n    author = \"Anderson, Carolyn\",\n    editor = {Al-azzawi, Sana  and\n      Biester, Laura  and\n      Kov{\\'a}cs, Gy{\\\"o}rgy  and\n      Marasovi{\\'c}, Ana  and\n      Mathur, Leena  and\n      Mieskes, Margot  and\n      Weissweiler, Leonie},\n    booktitle = \"Proceedings of the Sixth Workshop on Teaching NLP\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.teachingnlp-1.12\",\n    pages = \"81--84\",\n    abstract = \"As the scale of publicly-available large language models (LLMs) has increased, so has interest in few-shot prompting methods. This paper presents an assignment that asks students to explore three aspects of large language model capabilities (commonsense reasoning, factuality, and wordplay) with a prompt engineering focus. The assignment consists of three tasks designed to share a common programming framework, so that students can reuse and adapt code from earlier tasks. Two of the tasks also involve dataset construction: students are asked to construct a simple dataset for the wordplay task, and a more challenging dataset for the factuality task. In addition, the assignment includes reflection questions that ask students to think critically about what they observe.\",\n}\n",
    "authors": [
        "Carolyn Anderson"
    ],
    "pdf_url": "https://aclanthology.org/2024.teachingnlp-1.12.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/f9fae973-a46e-597b-b5ec-108069288c02.pdf",
    "abstract": "As the scale of publicly-available large language models (LLMs) has increased, so has interest in few-shot prompting methods. This paper presents an assignment that asks students to explore three aspects of large language model capabilities (commonsense reasoning, factuality, and wordplay) with a prompt engineering focus. The assignment consists of three tasks designed to share a common programming framework, so that students can reuse and adapt code from earlier tasks. Two of the tasks also involve dataset construction: students are asked to construct a simple dataset for the wordplay task, and a more challenging dataset for the factuality task. In addition, the assignment includes reflection questions that ask students to think critically about what they observe.",
    "num_pages": 4
}