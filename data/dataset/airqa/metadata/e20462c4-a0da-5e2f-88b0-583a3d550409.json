{
    "uuid": "e20462c4-a0da-5e2f-88b0-583a3d550409",
    "title": "FAA: Fine-grained Attention Alignment for Cascade Document Ranking",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{li-etal-2023-faa,\n    title = \"{FAA}: Fine-grained Attention Alignment for Cascade Document Ranking\",\n    author = \"Li, Zhen  and\n      Tao, Chongyang  and\n      Feng, Jiazhan  and\n      Shen, Tao  and\n      Zhao, Dongyan  and\n      Geng, Xiubo  and\n      Jiang, Daxin\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.94\",\n    doi = \"10.18653/v1/2023.acl-long.94\",\n    pages = \"1688--1700\",\n    abstract = \"Document ranking aims at sorting a collection of documents with their relevance to a query. Contemporary methods explore more efficient transformers or divide long documents into passages to handle the long input. However, intensive query-irrelevant content may lead to harmful distraction and high query latency. Some recent works further propose cascade document ranking models that extract relevant passages with an efficient selector before ranking, however, their selection and ranking modules are almost independently optimized and deployed, leading to selecting error reinforcement and sub-optimal performance. In fact, the document ranker can provide fine-grained supervision to make the selector more generalizable and compatible, and the selector built upon a different structure can offer a distinct perspective to assist in document ranking. Inspired by this, we propose a fine-grained attention alignment approach to jointly optimize a cascade document ranking model. Specifically, we utilize the attention activations over the passages from the ranker as fine-grained attention feedback to optimize the selector. Meanwhile, we fuse the relevance scores from the passage selector into the ranker to assist in calculating the cooperative matching representation. Experiments on MS MARCO and TREC DL demonstrate the effectiveness of our method.\",\n}\n",
    "authors": [
        "Zhen Li",
        "Chongyang Tao",
        "Jiazhan Feng",
        "Tao Shen",
        "Dongyan Zhao",
        "Xiubo Geng",
        "Daxin Jiang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.94.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e20462c4-a0da-5e2f-88b0-583a3d550409.pdf",
    "abstract": "Document ranking aims at sorting a collection of documents with their relevance to a query. Contemporary methods explore more efficient transformers or divide long documents into passages to handle the long input. However, intensive query-irrelevant content may lead to harmful distraction and high query latency. Some recent works further propose cascade document ranking models that extract relevant passages with an efficient selector before ranking, however, their selection and ranking modules are almost independently optimized and deployed, leading to selecting error reinforcement and sub-optimal performance. In fact, the document ranker can provide fine-grained supervision to make the selector more generalizable and compatible, and the selector built upon a different structure can offer a distinct perspective to assist in document ranking. Inspired by this, we propose a fine-grained attention alignment approach to jointly optimize a cascade document ranking model. Specifically, we utilize the attention activations over the passages from the ranker as fine-grained attention feedback to optimize the selector. Meanwhile, we fuse the relevance scores from the passage selector into the ranker to assist in calculating the cooperative matching representation. Experiments on MS MARCO and TREC DL demonstrate the effectiveness of our method.",
    "num_pages": 13
}