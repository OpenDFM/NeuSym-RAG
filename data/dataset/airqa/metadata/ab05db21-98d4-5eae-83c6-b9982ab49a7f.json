{
    "uuid": "ab05db21-98d4-5eae-83c6-b9982ab49a7f",
    "title": "AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zheng-etal-2023-augesc,\n    title = \"{A}ug{ESC}: Dialogue Augmentation with Large Language Models for Emotional Support Conversation\",\n    author = \"Zheng, Chujie  and\n      Sabour, Sahand  and\n      Wen, Jiaxin  and\n      Zhang, Zheng  and\n      Huang, Minlie\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.99\",\n    doi = \"10.18653/v1/2023.findings-acl.99\",\n    pages = \"1552--1568\",\n    abstract = \"Crowdsourced dialogue corpora are usually limited in scale and topic coverage due to the expensive cost of data curation. This would hinder the generalization of downstream dialogue models to open-domain topics. In this work, we leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). By treating dialogue augmentation as a dialogue completion task, we prompt a fine-tuned language model to complete full dialogues from available dialogue posts of various topics, which are then postprocessed based on heuristics. Applying this approach, we construct AugESC, an augmented dataset for the ESC task, which largely extends the scale and topic coverage of the crowdsourced ESConv corpus. Through comprehensive human evaluation, we demonstrate that our approach is superior to strong baselines of dialogue augmentation and that AugESC has comparable dialogue quality to the crowdsourced corpus. We also conduct human interactive evaluation and prove that post-training on AugESC improves downstream dialogue models{'} generalization ability to open-domain topics. These results suggest the utility of AugESC and highlight the potential of large language models in improving data-scarce dialogue generation tasks.\",\n}\n",
    "authors": [
        "Chujie Zheng",
        "Sahand Sabour",
        "Jiaxin Wen",
        "Zheng Zhang",
        "Minlie Huang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.99.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ab05db21-98d4-5eae-83c6-b9982ab49a7f.pdf",
    "abstract": "Crowdsourced dialogue corpora are usually limited in scale and topic coverage due to the expensive cost of data curation. This would hinder the generalization of downstream dialogue models to open-domain topics. In this work, we leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). By treating dialogue augmentation as a dialogue completion task, we prompt a fine-tuned language model to complete full dialogues from available dialogue posts of various topics, which are then postprocessed based on heuristics. Applying this approach, we construct AugESC, an augmented dataset for the ESC task, which largely extends the scale and topic coverage of the crowdsourced ESConv corpus. Through comprehensive human evaluation, we demonstrate that our approach is superior to strong baselines of dialogue augmentation and that AugESC has comparable dialogue quality to the crowdsourced corpus. We also conduct human interactive evaluation and prove that post-training on AugESC improves downstream dialogue modelsâ€™ generalization ability to open-domain topics. These results suggest the utility of AugESC and highlight the potential of large language models in improving data-scarce dialogue generation tasks.",
    "num_pages": 17
}