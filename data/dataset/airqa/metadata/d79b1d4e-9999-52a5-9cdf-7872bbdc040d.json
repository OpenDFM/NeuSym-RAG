{
    "uuid": "d79b1d4e-9999-52a5-9cdf-7872bbdc040d",
    "title": "WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{deng-etal-2024-webcites,\n    title = \"{W}eb{C}ite{S}: Attributed Query-Focused Summarization on {C}hinese Web Search Results with Citations\",\n    author = \"Deng, Haolin  and\n      Wang, Chang  and\n      Xin, Li  and\n      Yuan, Dezhang  and\n      Zhan, Junlang  and\n      Zhou, Tian  and\n      Ma, Jin  and\n      Gao, Jun  and\n      Xu, Ruifeng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.806\",\n    doi = \"10.18653/v1/2024.acl-long.806\",\n    pages = \"15095--15114\",\n    abstract = \"Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grained verification. Our comprehensive evaluation of both open-source and proprietary models on WebCiteS highlights the challenge LLMs face in correctly citing sources, underscoring the necessity for further improvement. The dataset and code will be open-sourced to facilitate further research in this crucial field.\",\n}\n",
    "authors": [
        "Haolin Deng",
        "Chang Wang",
        "Li Xin",
        "Dezhang Yuan",
        "Junlang Zhan",
        "Tian Zhou",
        "Jin Ma",
        "Jun Gao",
        "Ruifeng Xu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.806.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d79b1d4e-9999-52a5-9cdf-7872bbdc040d.pdf",
    "abstract": "Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grained verification. Our comprehensive evaluation of both open-source and proprietary models on WebCiteS highlights the challenge LLMs face in correctly citing sources, underscoring the necessity for further improvement. The dataset and code will be open-sourced to facilitate further research in this crucial field.",
    "num_pages": 20
}