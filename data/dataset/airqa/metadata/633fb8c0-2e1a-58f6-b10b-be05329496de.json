{
    "uuid": "633fb8c0-2e1a-58f6-b10b-be05329496de",
    "title": "Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{ulmer-etal-2024-bootstrapping,\n    title = \"Bootstrapping {LLM}-based Task-Oriented Dialogue Agents via Self-Talk\",\n    author = \"Ulmer, Dennis  and\n      Mansimov, Elman  and\n      Lin, Kaixiang  and\n      Sun, Lijia  and\n      Gao, Xibin  and\n      Zhang, Yi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.566\",\n    doi = \"10.18653/v1/2024.findings-acl.566\",\n    pages = \"9500--9522\",\n    abstract = \"Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via {``}self-talk{''} of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the generated conversational data that is fed back in LLM for training. Based on our automated and human evaluations of conversation quality, we demonstrate that such self-talk data improves results. In addition, we examine the various characteristics that showcase the quality of generated dialogues and how they can be connected to their potential utility as training data.\",\n}\n",
    "authors": [
        "Dennis Ulmer",
        "Elman Mansimov",
        "Kaixiang Lin",
        "Lijia Sun",
        "Xibin Gao",
        "Yi Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.566.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/633fb8c0-2e1a-58f6-b10b-be05329496de.pdf",
    "abstract": "Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via “self-talk” of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the generated conversational data that is fed back in LLM for training. Based on our automated and human evaluations of conversation quality, we demonstrate that such self-talk data improves results. In addition, we examine the various characteristics that showcase the quality of generated dialogues and how they can be connected to their potential utility as training data.",
    "num_pages": 23
}