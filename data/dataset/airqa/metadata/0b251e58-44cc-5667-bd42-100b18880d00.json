{
    "uuid": "0b251e58-44cc-5667-bd42-100b18880d00",
    "title": "Chick Adams at SemEval-2023 Task 5: Using RoBERTa and DeBERTa to Extract Post and Document-based Features for Clickbait Spoiling",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{pan-etal-2023-chick,\n    title = \"Chick Adams at {S}em{E}val-2023 Task 5: Using {R}o{BERT}a and {D}e{BERT}a to Extract Post and Document-based Features for Clickbait Spoiling\",\n    author = \"Pan, Ronghao  and\n      Garc{\\'\\i}a-D{\\'\\i}az, Jos{\\'e} Antonio  and\n      Garc{\\'\\i}a-S{\\'a}nchez, Franciso  and\n      Valencia-Garc{\\'\\i}a, Rafael\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.85\",\n    doi = \"10.18653/v1/2023.semeval-1.85\",\n    pages = \"624--628\",\n    abstract = \"In this manuscript, we describe the participation of the UMUTeam in SemEval-2023 Task 5, namely, Clickbait Spoiling, a shared task on identifying spoiler type (i.e., a phrase or a passage) and generating short texts that satisfy curiosity induced by a clickbait post, i.e. generating spoilers for the clickbait post. Our participation in Task 1 is based on fine-tuning pre-trained models, which consists in taking a pre-trained model and tuning it to fit the spoiler classification task. Our system has obtained excellent results in Task 1: we outperformed all proposed baselines, being within the Top 10 for most measures. Foremost, we reached Top 3 in F1 score in the passage spoiler ranking.\",\n}\n",
    "authors": [
        "Ronghao Pan",
        "José Antonio García-Díaz",
        "Franciso García-Sánchez",
        "Rafael Valencia-García"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.85.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/0b251e58-44cc-5667-bd42-100b18880d00.pdf",
    "abstract": "In this manuscript, we describe the participation of the UMUTeam in SemEval-2023 Task 5, namely, Clickbait Spoiling, a shared task on identifying spoiler type (i.e., a phrase or a passage) and generating short texts that satisfy curiosity induced by a clickbait post, i.e. generating spoilers for the clickbait post. Our participation in Task 1 is based on fine-tuning pre-trained models, which consists in taking a pre-trained model and tuning it to fit the spoiler classification task. Our system has obtained excellent results in Task 1: we outperformed all proposed baselines, being within the Top 10 for most measures. Foremost, we reached Top 3 in F1 score in the passage spoiler ranking.",
    "num_pages": 5
}