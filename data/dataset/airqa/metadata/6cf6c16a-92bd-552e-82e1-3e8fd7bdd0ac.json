{
    "uuid": "6cf6c16a-92bd-552e-82e1-3e8fd7bdd0ac",
    "title": "Automatic Subtitling and Subtitle Compression: FBK at the IWSLT 2024 Subtitling track",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
    "bibtex": "@inproceedings{gaido-etal-2024-automatic,\n    title = \"Automatic Subtitling and Subtitle Compression: {FBK} at the {IWSLT} 2024 Subtitling track\",\n    author = \"Gaido, Marco  and\n      Papi, Sara  and\n      Cettolo, Mauro  and\n      Cattoni, Roldano  and\n      Piergentili, Andrea  and\n      Negri, Matteo  and\n      Bentivogli, Luisa\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.iwslt-1.13\",\n    doi = \"10.18653/v1/2024.iwslt-1.13\",\n    pages = \"86--96\",\n    abstract = \"The paper describes the FBK submissions to the Subtitling track of the 2024 IWSLT Evaluation Campaign, which covers both the Automatic Subtitling and the Subtitle Compression task for two language pairs: English to German (en-de) and English to Spanish (en-es). For the Automatic Subtitling task, we submitted two systems: i) a direct model, trained in constrained conditions, that produces the SRT files from the audio without intermediate outputs (e.g., transcripts), and ii) a cascade solution that integrates only free-to-use components, either taken off-the-shelf or developed in-house. Results show that, on both language pairs, our direct model outperforms both cascade and direct systems trained in constrained conditions in last year{'}s edition of the campaign, while our cascade solution is competitive with the best 2023 runs. For the Subtitle Compression task, our primary submission involved prompting a Large Language Model (LLM) in zero-shot mode to shorten subtitles that exceed the reading speed limit of 21 characters per second. Our results highlight the challenges inherent in shrinking out-of-context sentence fragments that are automatically generated and potentially error-prone, underscoring the need for future studies to develop targeted solutions.\",\n}\n",
    "authors": [
        "Marco Gaido",
        "Sara Papi",
        "Mauro Cettolo",
        "Roldano Cattoni",
        "Andrea Piergentili",
        "Matteo Negri",
        "Luisa Bentivogli"
    ],
    "pdf_url": "https://aclanthology.org/2024.iwslt-1.13.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6cf6c16a-92bd-552e-82e1-3e8fd7bdd0ac.pdf",
    "abstract": "The paper describes the FBK submissions to the Subtitling track of the 2024 IWSLT Evaluation Campaign, which covers both the Automatic Subtitling and the Subtitle Compression task for two language pairs: English to German (en-de) and English to Spanish (en-es). For the Automatic Subtitling task, we submitted two systems: i) a direct model, trained in constrained conditions, that produces the SRT files from the audio without intermediate outputs (e.g., transcripts), and ii) a cascade solution that integrates only free-to-use components, either taken off-the-shelf or developed in-house. Results show that, on both language pairs, our direct model outperforms both cascade and direct systems trained in constrained conditions in last yearâ€™s edition of the campaign, while our cascade solution is competitive with the best 2023 runs. For the Subtitle Compression task, our primary submission involved prompting a Large Language Model (LLM) in zero-shot mode to shorten subtitles that exceed the reading speed limit of 21 characters per second. Our results highlight the challenges inherent in shrinking out-of-context sentence fragments that are automatically generated and potentially error-prone, underscoring the need for future studies to develop targeted solutions.",
    "num_pages": 11
}