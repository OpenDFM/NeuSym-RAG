{
    "uuid": "49449907-c47d-56b3-a700-60c135e738f2",
    "title": "Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{geng-etal-2024-sketch,\n    title = \"Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access\",\n    author = {Geng, Saibo  and\n      D{\\\"o}ner, Berkay  and\n      Wendler, Chris  and\n      Josifoski, Martin  and\n      West, Robert},\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-short.23\",\n    doi = \"10.18653/v1/2024.acl-short.23\",\n    pages = \"234--245\",\n    abstract = \"Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs). This paper introduces sketch-guided constrained decoding (SketchGCD), a novel approach to constrained decoding for blackbox LLMs, which operates without access to the logits of the blackbox LLM. SketchGCD utilizes a locally hosted auxiliary model to refine the output of an unconstrained blackbox LLM, effectively treating this initial output as a {``}sketch{''} for further elaboration. This approach is complementary to traditional logit-based techniques and enables the application of constrained decoding in settings where full model transparency is unavailable. We demonstrate the efficacy of SketchGCD through experiments in closed information extraction and constituency parsing, showing how it enhances the utility and flexibility of blackbox LLMs for complex NLP tasks.\",\n}\n",
    "authors": [
        "Saibo Geng",
        "Berkay Döner",
        "Chris Wendler",
        "Martin Josifoski",
        "Robert West"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-short.23.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/49449907-c47d-56b3-a700-60c135e738f2.pdf",
    "abstract": "Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs). This paper introduces sketch-guided constrained decoding (SketchGCD), a novel approach to constrained decoding for blackbox LLMs, which operates without access to the logits of the blackbox LLM. SketchGCD utilizes a locally hosted auxiliary model to refine the output of an unconstrained blackbox LLM, effectively treating this initial output as a “sketch” for further elaboration. This approach is complementary to traditional logit-based techniques and enables the application of constrained decoding in settings where full model transparency is unavailable. We demonstrate the efficacy of SketchGCD through experiments in closed information extraction and constituency parsing, showing how it enhances the utility and flexibility of blackbox LLMs for complex NLP tasks.",
    "num_pages": 12
}