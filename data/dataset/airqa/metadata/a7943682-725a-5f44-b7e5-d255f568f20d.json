{
    "uuid": "a7943682-725a-5f44-b7e5-d255f568f20d",
    "title": "When Do Annotator Demographics Matter? Measuring the Influence of Annotator Demographics with the POPQUORN Dataset",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)",
    "bibtex": "@inproceedings{pei-jurgens-2023-annotator,\n    title = \"When Do Annotator Demographics Matter? Measuring the Influence of Annotator Demographics with the {POPQUORN} Dataset\",\n    author = \"Pei, Jiaxin  and\n      Jurgens, David\",\n    editor = \"Prange, Jakob  and\n      Friedrich, Annemarie\",\n    booktitle = \"Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.law-1.25\",\n    doi = \"10.18653/v1/2023.law-1.25\",\n    pages = \"252--265\",\n    abstract = \"Annotators are not fungible. Their demographics, life experiences, and backgrounds all contribute to how they label data. However, NLP has only recently considered how annotator identity might influence their decisions. Here, we present POPQUORN (the Potato-Prolific dataset for Question-Answering, Offensiveness, text Rewriting and politeness rating with demographic Nuance). POPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a representative sample regarding sex, age, and race as the US population. Through a series of analyses, we show that annotators{'} background plays a significant role in their judgments. Further, our work shows that backgrounds not previously considered in NLP (e.g., education), are meaningful and should be considered. Our study suggests that understanding the background of annotators and collecting labels from a demographically balanced pool of crowd workers is important to reduce the bias of datasets. The dataset, annotator background, and annotation interface are available at \\url{https://github.com/Jiaxin-Pei/potato-prolific-dataset}.\",\n}\n",
    "authors": [
        "Jiaxin Pei",
        "David Jurgens"
    ],
    "pdf_url": "https://aclanthology.org/2023.law-1.25.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a7943682-725a-5f44-b7e5-d255f568f20d.pdf",
    "abstract": "Annotators are not fungible. Their demographics, life experiences, and backgrounds all contribute to how they label data. However, NLP has only recently considered how annotator identity might influence their decisions. Here, we present POPQUORN (the Potato-Prolific dataset for Question-Answering, Offensiveness, text Rewriting and politeness rating with demographic Nuance). POPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a representative sample regarding sex, age, and race as the US population. Through a series of analyses, we show that annotatorsâ€™ background plays a significant role in their judgments. Further, our work shows that backgrounds not previously considered in NLP (e.g., education), are meaningful and should be considered. Our study suggests that understanding the background of annotators and collecting labels from a demographically balanced pool of crowd workers is important to reduce the bias of datasets. The dataset, annotator background, and annotation interface are available at https://github.com/Jiaxin-Pei/potato-prolific-dataset.",
    "num_pages": 14
}