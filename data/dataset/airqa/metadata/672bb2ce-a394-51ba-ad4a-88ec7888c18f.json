{
    "uuid": "672bb2ce-a394-51ba-ad4a-88ec7888c18f",
    "title": "Privacy- and Utility-Preserving NLP with Anonymized data: A case study of Pseudonymization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)",
    "bibtex": "@inproceedings{yermilov-etal-2023-privacy,\n    title = \"Privacy- and Utility-Preserving {NLP} with Anonymized data: A case study of Pseudonymization\",\n    author = \"Yermilov, Oleksandr  and\n      Raheja, Vipul  and\n      Chernodub, Artem\",\n    editor = \"Ovalle, Anaelia  and\n      Chang, Kai-Wei  and\n      Mehrabi, Ninareh  and\n      Pruksachatkun, Yada  and\n      Galystan, Aram  and\n      Dhamala, Jwala  and\n      Verma, Apurv  and\n      Cao, Trista  and\n      Kumar, Anoop  and\n      Gupta, Rahul\",\n    booktitle = \"Proceedings of the 3rd Workshop on Trustworthy Natural Language Processing (TrustNLP 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.trustnlp-1.20\",\n    doi = \"10.18653/v1/2023.trustnlp-1.20\",\n    pages = \"232--241\",\n    abstract = \"This work investigates the effectiveness of different pseudonymization techniques, ranging from rule-based substitutions to using pre-trained Large Language Models (LLMs), on a variety of datasets and models used for two widely used NLP tasks: text classification and summarization. Our work provides crucial insights into the gaps between original and anonymized data (focusing on the pseudonymization technique) and model quality and fosters future research into higher-quality anonymization techniques better to balance the trade-offs between data protection and utility preservation. We make our code, pseudonymized datasets, and downstream models publicly available.\",\n}\n",
    "authors": [
        "Oleksandr Yermilov",
        "Vipul Raheja",
        "Artem Chernodub"
    ],
    "pdf_url": "https://aclanthology.org/2023.trustnlp-1.20.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/672bb2ce-a394-51ba-ad4a-88ec7888c18f.pdf",
    "abstract": "This work investigates the effectiveness of different pseudonymization techniques, ranging from rule-based substitutions to using pre-trained Large Language Models (LLMs), on a variety of datasets and models used for two widely used NLP tasks: text classification and summarization. Our work provides crucial insights into the gaps between original and anonymized data (focusing on the pseudonymization technique) and model quality and fosters future research into higher-quality anonymization techniques better to balance the trade-offs between data protection and utility preservation. We make our code, pseudonymized datasets, and downstream models publicly available.",
    "num_pages": 10
}