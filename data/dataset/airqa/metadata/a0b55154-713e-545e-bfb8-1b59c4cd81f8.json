{
    "uuid": "a0b55154-713e-545e-bfb8-1b59c4cd81f8",
    "title": "Analysis of Annotator Demographics in Sexism Detection",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
    "bibtex": "@inproceedings{tahaei-bergler-2024-analysis,\n    title = \"Analysis of Annotator Demographics in Sexism Detection\",\n    author = \"Tahaei, Narjes  and\n      Bergler, Sabine\",\n    editor = \"Fale{\\'n}ska, Agnieszka  and\n      Basta, Christine  and\n      Costa-juss{\\`a}, Marta  and\n      Goldfarb-Tarrant, Seraphina  and\n      Nozza, Debora\",\n    booktitle = \"Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.gebnlp-1.24\",\n    doi = \"10.18653/v1/2024.gebnlp-1.24\",\n    pages = \"376--383\",\n    abstract = \"This study explores the effect of annotators{'} demographic features on labeling sexist content in social media datasets, specifically focusing on the EXIST dataset, which includes direct sexist messages, reports and descriptions of sexist experiences and stereotypes. We investigate how various demographic backgrounds influence annotation outcomes and examine methods to incorporate these features into BERT-based model training. Our experiments demonstrate that adding demographic information improves performance in detecting sexism and assessing intention of the author.\",\n}\n",
    "authors": [
        "Narjes Tahaei",
        "Sabine Bergler"
    ],
    "pdf_url": "https://aclanthology.org/2024.gebnlp-1.24.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a0b55154-713e-545e-bfb8-1b59c4cd81f8.pdf",
    "abstract": "This study explores the effect of annotatorsâ€™ demographic features on labeling sexist content in social media datasets, specifically focusing on the EXIST dataset, which includes direct sexist messages, reports and descriptions of sexist experiences and stereotypes. We investigate how various demographic backgrounds influence annotation outcomes and examine methods to incorporate these features into BERT-based model training. Our experiments demonstrate that adding demographic information improves performance in detecting sexism and assessing intention of the author.",
    "num_pages": 8
}