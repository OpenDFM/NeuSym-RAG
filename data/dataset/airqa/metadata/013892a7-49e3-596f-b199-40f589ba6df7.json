{
    "uuid": "013892a7-49e3-596f-b199-40f589ba6df7",
    "title": "Multilingual Summarization with Factual Consistency Evaluation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{aharoni-etal-2023-multilingual,\n    title = \"Multilingual Summarization with Factual Consistency Evaluation\",\n    author = \"Aharoni, Roee  and\n      Narayan, Shashi  and\n      Maynez, Joshua  and\n      Herzig, Jonathan  and\n      Clark, Elizabeth  and\n      Lapata, Mirella\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.220\",\n    doi = \"10.18653/v1/2023.findings-acl.220\",\n    pages = \"3562--3591\",\n    abstract = \"Abstractive summarization has enjoyed renewed interest in recent years, thanks to pre-trained language models and the availability of large-scale datasets. Despite promising results, current models still suffer from generating factually inconsistent summaries, reducing their utility for real-world application. Several recent efforts attempt to address this by devising models that automatically detect factual inconsistencies in machine generated summaries. However, they focus exclusively on English, a language with abundant resources. In this work, we leverage factual consistency evaluation models to improve \\textit{multilingual} summarization. We explore two intuitive approaches to mitigate hallucinations based on the signal provided by a multilingual NLI model, namely data filtering and controlled generation. Experimental results in the 45 languages from the XLSum dataset show gains over strong baselines in both automatic and human evaluation. We release models and human judgements of summaries to foster progress towards more factually consistent multilingual summarization.\",\n}\n",
    "authors": [
        "Roee Aharoni",
        "Shashi Narayan",
        "Joshua Maynez",
        "Jonathan Herzig",
        "Elizabeth Clark",
        "Mirella Lapata"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.220.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/013892a7-49e3-596f-b199-40f589ba6df7.pdf",
    "abstract": "Abstractive summarization has enjoyed renewed interest in recent years, thanks to pre-trained language models and the availability of large-scale datasets. Despite promising results, current models still suffer from generating factually inconsistent summaries, reducing their utility for real-world application. Several recent efforts attempt to address this by devising models that automatically detect factual inconsistencies in machine generated summaries. However, they focus exclusively on English, a language with abundant resources. In this work, we leverage factual consistency evaluation models to improve multilingual summarization. We explore two intuitive approaches to mitigate hallucinations based on the signal provided by a multilingual NLI model, namely data filtering and controlled generation. Experimental results in the 45 languages from the XLSum dataset show gains over strong baselines in both automatic and human evaluation. We release models and human judgements of summaries to foster progress towards more factually consistent multilingual summarization.",
    "num_pages": 30
}