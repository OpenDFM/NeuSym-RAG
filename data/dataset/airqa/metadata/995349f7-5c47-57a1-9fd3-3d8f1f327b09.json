{
    "uuid": "995349f7-5c47-57a1-9fd3-3d8f1f327b09",
    "title": "Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{chen-etal-2024-large,\n    title = \"Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?\",\n    author = \"Chen, Yuyan  and\n      Li, Yueze  and\n      Yan, Songzhou  and\n      Liu, Sijia  and\n      Liang, Jiaqing  and\n      Xiao, Yanghua\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.131\",\n    doi = \"10.18653/v1/2024.findings-acl.131\",\n    pages = \"2225--2238\",\n    abstract = \"The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs{'} problem-solving capability such as {``}Twenty Questions{''}.However, these kinds of games do not require recognizing misleading cues which are necessary in the incomplete information scenario.Moreover, the existing game such as {``}Who is undercover{''} are highly subjective, making it challenging for evaluation.Therefore, in this paper, we introduce a novel game named BrainKing based on the {``}Who is undercover{''} and {``}Twenty Questions{''} for evaluating LLM capabilities under incomplete information scenarios. It requires LLMs to identify target entities with limited yes-or-no questions and potential misleading answers. By setting up easy, medium, and hard difficulty modes, we comprehensively assess the performance of LLMs across various aspects. Our results reveal the capabilities and limitations of LLMs in BrainKing, providing significant insights of LLM problem-solving levels.\",\n}\n",
    "authors": [
        "Yuyan Chen",
        "Yueze Li",
        "Songzhou Yan",
        "Sijia Liu",
        "Jiaqing Liang",
        "Yanghua Xiao"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.131.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/995349f7-5c47-57a1-9fd3-3d8f1f327b09.pdf",
    "abstract": "The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs’ problem-solving capability such as “Twenty Questions”.However, these kinds of games do not require recognizing misleading cues which are necessary in the incomplete information scenario.Moreover, the existing game such as “Who is undercover” are highly subjective, making it challenging for evaluation.Therefore, in this paper, we introduce a novel game named BrainKing based on the “Who is undercover” and “Twenty Questions” for evaluating LLM capabilities under incomplete information scenarios. It requires LLMs to identify target entities with limited yes-or-no questions and potential misleading answers. By setting up easy, medium, and hard difficulty modes, we comprehensively assess the performance of LLMs across various aspects. Our results reveal the capabilities and limitations of LLMs in BrainKing, providing significant insights of LLM problem-solving levels.",
    "num_pages": 14
}