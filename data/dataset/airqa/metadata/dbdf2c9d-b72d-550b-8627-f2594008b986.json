{
    "uuid": "dbdf2c9d-b72d-550b-8627-f2594008b986",
    "title": "Understanding Retrieval Robustness for Retrieval-augmented Image Captioning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{li-etal-2024-understanding-retrieval,\n    title = \"Understanding Retrieval Robustness for Retrieval-augmented Image Captioning\",\n    author = \"Li, Wenyan  and\n      Li, Jiaang  and\n      Ramos, Rita  and\n      Tang, Raphael  and\n      Elliott, Desmond\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.503\",\n    doi = \"10.18653/v1/2024.acl-long.503\",\n    pages = \"9285--9299\",\n    abstract = \"Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far from perfect in practice: the retrieved information can sometimes mislead the model, resulting in incorrect generation and worse performance. In this paper, we analyze the robustness of a retrieval-augmented captioning model SmallCap. Our analysis shows that the model is sensitive to tokens that appear in the majority of the retrieved captions, and the input attribution shows that those tokens are likely copied into the generated output. Given these findings, we propose to train the model by sampling retrieved captions from more diverse sets. This decreases the chance that the model learns to copy majority tokens, and improves both in-domain and cross-domain performance.\",\n}\n",
    "authors": [
        "Wenyan Li",
        "Jiaang Li",
        "Rita Ramos",
        "Raphael Tang",
        "Desmond Elliott"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.503.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/dbdf2c9d-b72d-550b-8627-f2594008b986.pdf",
    "abstract": "Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far from perfect in practice: the retrieved information can sometimes mislead the model, resulting in incorrect generation and worse performance. In this paper, we analyze the robustness of a retrieval-augmented captioning model SmallCap. Our analysis shows that the model is sensitive to tokens that appear in the majority of the retrieved captions, and the input attribution shows that those tokens are likely copied into the generated output. Given these findings, we propose to train the model by sampling retrieved captions from more diverse sets. This decreases the chance that the model learns to copy majority tokens, and improves both in-domain and cross-domain performance.",
    "num_pages": 15
}