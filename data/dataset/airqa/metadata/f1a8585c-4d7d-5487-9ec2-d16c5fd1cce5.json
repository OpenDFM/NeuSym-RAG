{
    "uuid": "f1a8585c-4d7d-5487-9ec2-d16c5fd1cce5",
    "title": "ZBL2W at SemEval-2023 Task 9: A Multilingual Fine-tuning Model with Data Augmentation for Tweet Intimacy Analysis",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{zhang-etal-2023-zbl2w,\n    title = \"{ZBL}2{W} at {S}em{E}val-2023 Task 9: A Multilingual Fine-tuning Model with Data Augmentation for Tweet Intimacy Analysis\",\n    author = \"Zhang, Hao  and\n      Wu, Youlin  and\n      Lu, Junyu  and\n      Bai, Zewen  and\n      Wu, Jiangming  and\n      Lin, Hongfei  and\n      Zhang, Shaowu\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.106\",\n    doi = \"10.18653/v1/2023.semeval-1.106\",\n    pages = \"770--775\",\n    abstract = \"This paper describes our system used in the SemEval-2023 Task 9 Multilingual Tweet Intimacy Analysis. There are two key challenges in this task: the complexity of multilingual and zero-shot cross-lingual learning, and the difficulty of semantic mining of tweet intimacy. To solve the above problems, our system extracts contextual representations from the pretrained language models, XLM-T, and employs various optimization methods, including adversarial training, data augmentation, ordinal regression loss and special training strategy. Our system ranked 14th out of 54 participating teams on the leaderboard and ranked 10th on predicting languages not in the training data. Our code is available on Github.\",\n}\n",
    "authors": [
        "Hao Zhang",
        "Youlin Wu",
        "Junyu Lu",
        "Zewen Bai",
        "Jiangming Wu",
        "Hongfei Lin",
        "Shaowu Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.106.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f1a8585c-4d7d-5487-9ec2-d16c5fd1cce5.pdf",
    "abstract": "This paper describes our system used in the SemEval-2023 Task 9 Multilingual Tweet Intimacy Analysis. There are two key challenges in this task: the complexity of multilingual and zero-shot cross-lingual learning, and the difficulty of semantic mining of tweet intimacy. To solve the above problems, our system extracts contextual representations from the pretrained language models, XLM-T, and employs various optimization methods, including adversarial training, data augmentation, ordinal regression loss and special training strategy. Our system ranked 14th out of 54 participating teams on the leaderboard and ranked 10th on predicting languages not in the training data. Our code is available on Github.",
    "num_pages": 6
}