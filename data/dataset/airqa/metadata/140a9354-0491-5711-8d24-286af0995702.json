{
    "uuid": "140a9354-0491-5711-8d24-286af0995702",
    "title": "Characterization of Stigmatizing Language in Medical Records",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{harrigian-etal-2023-characterization,\n    title = \"Characterization of Stigmatizing Language in Medical Records\",\n    author = \"Harrigian, Keith  and\n      Zirikly, Ayah  and\n      Chee, Brant  and\n      Ahmad, Alya  and\n      Links, Anne  and\n      Saha, Somnath  and\n      Beach, Mary Catherine  and\n      Dredze, Mark\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.28\",\n    doi = \"10.18653/v1/2023.acl-short.28\",\n    pages = \"312--329\",\n    abstract = \"Widespread disparities in clinical outcomes exist between different demographic groups in the United States. A new line of work in medical sociology has demonstrated physicians often use stigmatizing language in electronic medical records within certain groups, such as black patients, which may exacerbate disparities. In this study, we characterize these instances at scale using a series of domain-informed NLP techniques. We highlight important differences between this task and analogous bias-related tasks studied within the NLP community (e.g., classifying microaggressions). Our study establishes a foundation for NLP researchers to contribute timely insights to a problem domain brought to the forefront by recent legislation regarding clinical documentation transparency. We release data, code, and models.\",\n}\n",
    "authors": [
        "Keith Harrigian",
        "Ayah Zirikly",
        "Brant Chee",
        "Alya Ahmad",
        "Anne Links",
        "Somnath Saha",
        "Mary Catherine Beach",
        "Mark Dredze"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.28.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/140a9354-0491-5711-8d24-286af0995702.pdf",
    "abstract": "Widespread disparities in clinical outcomes exist between different demographic groups in the United States. A new line of work in medical sociology has demonstrated physicians often use stigmatizing language in electronic medical records within certain groups, such as black patients, which may exacerbate disparities. In this study, we characterize these instances at scale using a series of domain-informed NLP techniques. We highlight important differences between this task and analogous bias-related tasks studied within the NLP community (e.g., classifying microaggressions). Our study establishes a foundation for NLP researchers to contribute timely insights to a problem domain brought to the forefront by recent legislation regarding clinical documentation transparency. We release data, code, and models.",
    "num_pages": 18
}