{
    "uuid": "8038e5ad-430e-5d62-ac98-db510cf71447",
    "title": "Whitening Not Recommended for Classification Tasks in LLMs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)",
    "bibtex": "@inproceedings{forooghi-etal-2024-whitening,\n    title = \"Whitening Not Recommended for Classification Tasks in {LLM}s\",\n    author = \"Forooghi, Ali  and\n      Sadeghi, Shaghayegh  and\n      Lu, Jianguo\",\n    editor = \"Zhao, Chen  and\n      Mosbach, Marius  and\n      Atanasova, Pepa  and\n      Goldfarb-Tarrent, Seraphina  and\n      Hase, Peter  and\n      Hosseini, Arian  and\n      Elbayad, Maha  and\n      Pezzelle, Sandro  and\n      Mozes, Maximilian\",\n    booktitle = \"Proceedings of the 9th Workshop on Representation Learning for NLP (RepL4NLP-2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.repl4nlp-1.21\",\n    pages = \"285--289\",\n    abstract = \"Sentence embedding is a cornerstone in NLP. Whitening has been claimed to be an effective method to improve embeddings obtained from Large Language Models (LLMs) for sentence embedding. However, we find that the effectiveness of whitening is model-dependent and task-dependent. In particular, whitening degenerates embeddings for classification tasks. The conclusion is supported by extensive experiments. A by-product of our research is embedding evaluation platform for LLMs called SentEval+\",\n}\n",
    "authors": [
        "Ali Forooghi",
        "Shaghayegh Sadeghi",
        "Jianguo Lu"
    ],
    "pdf_url": "https://aclanthology.org/2024.repl4nlp-1.21.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8038e5ad-430e-5d62-ac98-db510cf71447.pdf",
    "abstract": "Sentence embedding is a cornerstone in NLP. Whitening has been claimed to be an effective method to improve embeddings obtained from Large Language Models (LLMs) for sentence embedding. However, we find that the effectiveness of whitening is model-dependent and task-dependent. In particular, whitening degenerates embeddings for classification tasks. The conclusion is supported by extensive experiments. A by-product of our research is embedding evaluation platform for LLMs called SentEval+",
    "num_pages": 5
}