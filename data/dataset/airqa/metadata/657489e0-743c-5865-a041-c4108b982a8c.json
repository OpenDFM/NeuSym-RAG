{
    "uuid": "657489e0-743c-5865-a041-c4108b982a8c",
    "title": "An Integrated Approach for Political Bias Prediction and Explanation Based on Discursive Structure",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{devatine-etal-2023-integrated,\n    title = \"An Integrated Approach for Political Bias Prediction and Explanation Based on Discursive Structure\",\n    author = \"Devatine, Nicolas  and\n      Muller, Philippe  and\n      Braud, Chlo{\\'e}\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.711\",\n    doi = \"10.18653/v1/2023.findings-acl.711\",\n    pages = \"11196--11211\",\n    abstract = \"One crucial aspect of democracy is fair information sharing. While it is hard to prevent biases in news, they should be identified for better transparency. We propose an approach to automatically characterize biases that takes into account structural differences and that is efficient for long texts. This yields new ways to provide explanations for a textual classifier, going beyond mere lexical cues. We show that: (i) the use of discourse-based structure-aware document representations compare well to local, computationally heavy, or domain-specific models on classification tasks that deal with textual bias (ii) our approach based on different levels of granularity allows for the generation of better explanations of model decisions, both at the lexical and structural level, while addressing the challenge posed by long texts.\",\n}\n",
    "authors": [
        "Nicolas Devatine",
        "Philippe Muller",
        "Chlo√© Braud"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.711.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/657489e0-743c-5865-a041-c4108b982a8c.pdf",
    "abstract": "One crucial aspect of democracy is fair information sharing. While it is hard to prevent biases in news, they should be identified for better transparency. We propose an approach to automatically characterize biases that takes into account structural differences and that is efficient for long texts. This yields new ways to provide explanations for a textual classifier, going beyond mere lexical cues. We show that: (i) the use of discourse-based structure-aware document representations compare well to local, computationally heavy, or domain-specific models on classification tasks that deal with textual bias (ii) our approach based on different levels of granularity allows for the generation of better explanations of model decisions, both at the lexical and structural level, while addressing the challenge posed by long texts.",
    "num_pages": 16
}