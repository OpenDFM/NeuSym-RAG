{
    "uuid": "816b9ba6-5c20-5890-8087-b1cef2c367fd",
    "title": "Competition-Level Problems are Effective LLM Evaluators",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{huang-etal-2024-competition,\n    title = \"Competition-Level Problems are Effective {LLM} Evaluators\",\n    author = \"Huang, Yiming  and\n      Lin, Zhenghao  and\n      Liu, Xiao  and\n      Gong, Yeyun  and\n      Lu, Shuai  and\n      Lei, Fangyu  and\n      Liang, Yaobo  and\n      Shen, Yelong  and\n      Lin, Chen  and\n      Duan, Nan  and\n      Chen, Weizhu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.803\",\n    doi = \"10.18653/v1/2024.findings-acl.803\",\n    pages = \"13526--13544\",\n    abstract = \"Large language models (LLMs) have demonstrated impressive reasoning capabilities, yet there is ongoing debate about these abilities and the potential data contamination problem recently. This paper aims to evaluate the reasoning capacities of LLMs, specifically in solving recent competition-level programming problems in Codeforces, which are expert-crafted and unique, requiring deep understanding and robust reasoning skills. We first provide a comprehensive evaluation of GPT-4{'}s perceived zero-shot performance on this task, considering various aspects such as problems{'} release time, difficulties, and types of errors encountered. Surprisingly, the perceived performance of GPT-4 has experienced a cliff like decline in problems after September 2021 consistently across all the difficulties and types of problems, which shows the potential data contamination, as well as the challenges for any existing LLM to solve unseen complex reasoning problems. We further explore various approaches such as fine-tuning, Chain-of-Thought prompting and problem description simplification. Unfortunately, none of them is able to consistently mitigate the challenges. Through our work, we emphasize the importance of this excellent data source for assessing the genuine reasoning capabilities of LLMs, and foster the development of LLMs with stronger reasoning abilities and better generalization in the future.\",\n}\n",
    "authors": [
        "Yiming Huang",
        "Zhenghao Lin",
        "Xiao Liu",
        "Yeyun Gong",
        "Shuai Lu",
        "Fangyu Lei",
        "Yaobo Liang",
        "Yelong Shen",
        "Chen Lin",
        "Nan Duan",
        "Weizhu Chen"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.803.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/816b9ba6-5c20-5890-8087-b1cef2c367fd.pdf",
    "abstract": "Large language models (LLMs) have demonstrated impressive reasoning capabilities, yet there is ongoing debate about these abilities and the potential data contamination problem recently. This paper aims to evaluate the reasoning capacities of LLMs, specifically in solving recent competition-level programming problems in Codeforces, which are expert-crafted and unique, requiring deep understanding and robust reasoning skills. We first provide a comprehensive evaluation of GPT-4’s perceived zero-shot performance on this task, considering various aspects such as problems’ release time, difficulties, and types of errors encountered. Surprisingly, the perceived performance of GPT-4 has experienced a cliff like decline in problems after September 2021 consistently across all the difficulties and types of problems, which shows the potential data contamination, as well as the challenges for any existing LLM to solve unseen complex reasoning problems. We further explore various approaches such as fine-tuning, Chain-of-Thought prompting and problem description simplification. Unfortunately, none of them is able to consistently mitigate the challenges. Through our work, we emphasize the importance of this excellent data source for assessing the genuine reasoning capabilities of LLMs, and foster the development of LLMs with stronger reasoning abilities and better generalization in the future.",
    "num_pages": 19
}