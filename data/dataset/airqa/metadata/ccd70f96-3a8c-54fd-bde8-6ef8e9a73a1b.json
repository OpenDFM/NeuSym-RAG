{
    "uuid": "ccd70f96-3a8c-54fd-bde8-6ef8e9a73a1b",
    "title": "Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{spliethover-etal-2024-disentangling,\n    title = \"Disentangling Dialect from Social Bias via Multitask Learning to Improve Fairness\",\n    author = {Splieth{\\\"o}ver, Maximilian  and\n      Menon, Sai Nikhil  and\n      Wachsmuth, Henning},\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.553\",\n    doi = \"10.18653/v1/2024.findings-acl.553\",\n    pages = \"9294--9313\",\n    abstract = \"Dialects introduce syntactic and lexical variations in language that occur in regional or social groups. Most NLP methods are not sensitive to such variations. This may lead to unfair behavior of the methods, conveying negative bias towards dialect speakers. While previous work has studied dialect-related fairness for aspects like hate speech, other aspects of biased language, such as lewdness, remain fully unexplored. To fill this gap, we investigate performance disparities between dialects in the detection of five aspects of biased language and how to mitigate them. To alleviate bias, we present a multitask learning approach that models dialect language as an auxiliary task to incorporate syntactic and lexical variations. In our experiments with African-American English dialect, we provide empirical evidence that complementing common learning approaches with dialect modeling improves their fairness. Furthermore, the results suggest that multitask learning achieves state-of-the-art performance and helps to detect properties of biased language more reliably.\",\n}\n",
    "authors": [
        "Maximilian Splieth√∂ver",
        "Sai Nikhil Menon",
        "Henning Wachsmuth"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.553.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ccd70f96-3a8c-54fd-bde8-6ef8e9a73a1b.pdf",
    "abstract": "Dialects introduce syntactic and lexical variations in language that occur in regional or social groups. Most NLP methods are not sensitive to such variations. This may lead to unfair behavior of the methods, conveying negative bias towards dialect speakers. While previous work has studied dialect-related fairness for aspects like hate speech, other aspects of biased language, such as lewdness, remain fully unexplored. To fill this gap, we investigate performance disparities between dialects in the detection of five aspects of biased language and how to mitigate them. To alleviate bias, we present a multitask learning approach that models dialect language as an auxiliary task to incorporate syntactic and lexical variations. In our experiments with African-American English dialect, we provide empirical evidence that complementing common learning approaches with dialect modeling improves their fairness. Furthermore, the results suggest that multitask learning achieves state-of-the-art performance and helps to detect properties of biased language more reliably.",
    "num_pages": 20
}