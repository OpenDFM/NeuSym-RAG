{
    "uuid": "e1ceeafa-c64c-5101-9636-981d2f7bd0ba",
    "title": "Coconut: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{park-etal-2024-coconut,\n    title = \"Coconut: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models\",\n    author = \"Park, Jun-Hyung  and\n      Lee, Mingyu  and\n      Kim, Junho  and\n      Lee, SangKeun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.346\",\n    doi = \"10.18653/v1/2024.findings-acl.346\",\n    pages = \"5815--5830\",\n    abstract = \"In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on largelanguage models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examplesfrom a large language model. These examples are subsequently distilled into small language models to enhance their contextualization capability. Extensive evaluations show that COCONUT considerably improves commonsense reasoning performance across diverse benchmarks, models, and settings, exhibiting its flexibility and universality in generating contextualized commonsense knowledge. Notably,COCONUT consistently outperforms the state-of-the-art technique by an average of 5.8{\\%}.\",\n}\n",
    "authors": [
        "Jun-Hyung Park",
        "Mingyu Lee",
        "Junho Kim",
        "SangKeun Lee"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.346.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/e1ceeafa-c64c-5101-9636-981d2f7bd0ba.pdf",
    "abstract": "In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on largelanguage models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examplesfrom a large language model. These examples are subsequently distilled into small language models to enhance their contextualization capability. Extensive evaluations show that COCONUT considerably improves commonsense reasoning performance across diverse benchmarks, models, and settings, exhibiting its flexibility and universality in generating contextualized commonsense knowledge. Notably,COCONUT consistently outperforms the state-of-the-art technique by an average of 5.8%.",
    "num_pages": 16
}