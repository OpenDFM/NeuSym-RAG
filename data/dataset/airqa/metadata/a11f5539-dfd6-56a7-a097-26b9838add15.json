{
    "uuid": "a11f5539-dfd6-56a7-a097-26b9838add15",
    "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{yan-etal-2024-talk,\n    title = \"Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction\",\n    author = \"Yan, Haoqiu  and\n      Zhu, Yongxin  and\n      Zheng, Kai  and\n      Liu, Bing  and\n      Cao, Haoyu  and\n      Jiang, Deqiang  and\n      Xu, Linli\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.801\",\n    doi = \"10.18653/v1/2024.acl-long.801\",\n    pages = \"15009--15022\",\n    abstract = \"Large Language Model (LLM)-enhanced agents become increasingly prevalent in Human-AI communication, offering vast potential from entertainment to professional domains. However, current multi-modal dialogue systems overlook the acoustic information present in speech, which is crucial for understanding human communication nuances. This oversight can lead to misinterpretations of speakers{'} intentions, resulting in inconsistent or even contradictory responses within dialogues. To bridge this gap, in this paper, we propose PerceptiveAgent, an empathetic multi-modal dialogue system designed to discern deeper or more subtle meanings beyond the literal interpretations of words through the integration of speech modality perception. Employing LLMs as a cognitive core, PerceptiveAgent perceives acoustic information from input speech and generates empathetic responses based on speaking styles described in natural language. Experimental results indicate that PerceptiveAgent excels in contextual understanding by accurately discerning the speakers{'} true intentions in scenarios where the linguistic meaning is either contrary to or inconsistent with the speaker{'}s true feelings, producing more nuanced and expressive spoken dialogues. Code is publicly available at: https://github.com/Haoqiu-Yan/PerceptiveAgent.\",\n}\n",
    "authors": [
        "Haoqiu Yan",
        "Yongxin Zhu",
        "Kai Zheng",
        "Bing Liu",
        "Haoyu Cao",
        "Deqiang Jiang",
        "Linli Xu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.801.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a11f5539-dfd6-56a7-a097-26b9838add15.pdf",
    "abstract": "Large Language Model (LLM)-enhanced agents become increasingly prevalent in Human-AI communication, offering vast potential from entertainment to professional domains. However, current multi-modal dialogue systems overlook the acoustic information present in speech, which is crucial for understanding human communication nuances. This oversight can lead to misinterpretations of speakers’ intentions, resulting in inconsistent or even contradictory responses within dialogues. To bridge this gap, in this paper, we propose PerceptiveAgent, an empathetic multi-modal dialogue system designed to discern deeper or more subtle meanings beyond the literal interpretations of words through the integration of speech modality perception. Employing LLMs as a cognitive core, PerceptiveAgent perceives acoustic information from input speech and generates empathetic responses based on speaking styles described in natural language. Experimental results indicate that PerceptiveAgent excels in contextual understanding by accurately discerning the speakers’ true intentions in scenarios where the linguistic meaning is either contrary to or inconsistent with the speaker’s true feelings, producing more nuanced and expressive spoken dialogues. Code is publicly available at: https://github.com/Haoqiu-Yan/PerceptiveAgent.",
    "num_pages": 14
}