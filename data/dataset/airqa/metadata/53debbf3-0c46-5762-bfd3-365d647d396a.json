{
    "uuid": "53debbf3-0c46-5762-bfd3-365d647d396a",
    "title": "Hitachi at SemEval-2023 Task 4: Exploring Various Task Formulations Reveals the Importance of Description Texts on Human Values",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{tsunokake-etal-2023-hitachi,\n    title = \"Hitachi at {S}em{E}val-2023 Task 4: Exploring Various Task Formulations Reveals the Importance of Description Texts on Human Values\",\n    author = \"Tsunokake, Masaya  and\n      Yamaguchi, Atsuki  and\n      Koreeda, Yuta  and\n      Ozaki, Hiroaki  and\n      Sogawa, Yasuhiro\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.240\",\n    doi = \"10.18653/v1/2023.semeval-1.240\",\n    pages = \"1723--1735\",\n    abstract = \"This paper describes our participation in SemEval-2023 Task 4, ValueEval: Identification of Human Values behind Arguments. The aim of this task is to identify whether or not an input text supports each of the 20 pre-defined human values. Previous work on human value detection has shown the effectiveness of a sequence classification approach using BERT. However, little is known about what type of task formulation is suitable for the task. To this end, this paper explores various task formulations, including sequence classification, question answering, and question answering with chain-of-thought prompting and evaluates their performances on the shared task dataset. Experiments show that a zero-shot approach is not as effective as other methods, and there is no one approach that is optimal in every scenario. Our analysis also reveals that utilizing the descriptions of human values can help to improve performance.\",\n}\n",
    "authors": [
        "Masaya Tsunokake",
        "Atsuki Yamaguchi",
        "Yuta Koreeda",
        "Hiroaki Ozaki",
        "Yasuhiro Sogawa"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.240.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/53debbf3-0c46-5762-bfd3-365d647d396a.pdf",
    "abstract": "This paper describes our participation in SemEval-2023 Task 4, ValueEval: Identification of Human Values behind Arguments. The aim of this task is to identify whether or not an input text supports each of the 20 pre-defined human values. Previous work on human value detection has shown the effectiveness of a sequence classification approach using BERT. However, little is known about what type of task formulation is suitable for the task. To this end, this paper explores various task formulations, including sequence classification, question answering, and question answering with chain-of-thought prompting and evaluates their performances on the shared task dataset. Experiments show that a zero-shot approach is not as effective as other methods, and there is no one approach that is optimal in every scenario. Our analysis also reveals that utilizing the descriptions of human values can help to improve performance.",
    "num_pages": 13
}