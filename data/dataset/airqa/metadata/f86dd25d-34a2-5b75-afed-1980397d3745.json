{
    "uuid": "f86dd25d-34a2-5b75-afed-1980397d3745",
    "title": "LC4EE: LLMs as Good Corrector for Event Extraction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhu-etal-2024-lc4ee,\n    title = \"{LC}4{EE}: {LLM}s as Good Corrector for Event Extraction\",\n    author = \"Zhu, Mengna  and\n      Zeng, Kaisheng  and\n      JibingWu, JibingWu  and\n      Liu, Lihua  and\n      Huang, Hongbin  and\n      Hou, Lei  and\n      Li, Juanzi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.715\",\n    doi = \"10.18653/v1/2024.findings-acl.715\",\n    pages = \"12028--12038\",\n    abstract = \"Event extraction (EE) is a critical task in natural language processing, yet deploying a practical EE system remains challenging. On one hand, powerful large language models (LLMs) currently show poor performance because EE task is more complex than other tasks. On the other hand, state-of-the-art (SOTA) small language models (SLMs) for EE tasks are typically developed through fine-tuning, lack flexibility, and have considerable room for improvement. We propose an approach, **L**LMs-as-**C**orrector for **E**vent **E**xtraction (**LC4EE**), aiming to leverage the superior extraction capability of SLMs and the instruction-following ability of LLMs to construct a robust and highly available EE system. By utilizing LLMs to identify and correct errors of SLMs predictions based on automatically generated feedback information, EE performances can be improved significantly. Experimental results on the representative datasets ACE2005 and MAVEN-Arg for Event Detection (ED) and EE tasks validated the effectiveness of our method.\",\n}\n",
    "authors": [
        "Mengna Zhu",
        "Kaisheng Zeng",
        "JibingWu JibingWu",
        "Lihua Liu",
        "Hongbin Huang",
        "Lei Hou",
        "Juanzi Li"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.715.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/f86dd25d-34a2-5b75-afed-1980397d3745.pdf",
    "abstract": "Event extraction (EE) is a critical task in natural language processing, yet deploying a practical EE system remains challenging. On one hand, powerful large language models (LLMs) currently show poor performance because EE task is more complex than other tasks. On the other hand, state-of-the-art (SOTA) small language models (SLMs) for EE tasks are typically developed through fine-tuning, lack flexibility, and have considerable room for improvement. We propose an approach, **L**LMs-as-**C**orrector for **E**vent **E**xtraction (**LC4EE**), aiming to leverage the superior extraction capability of SLMs and the instruction-following ability of LLMs to construct a robust and highly available EE system. By utilizing LLMs to identify and correct errors of SLMs predictions based on automatically generated feedback information, EE performances can be improved significantly. Experimental results on the representative datasets ACE2005 and MAVEN-Arg for Event Detection (ED) and EE tasks validated the effectiveness of our method.",
    "num_pages": 11
}