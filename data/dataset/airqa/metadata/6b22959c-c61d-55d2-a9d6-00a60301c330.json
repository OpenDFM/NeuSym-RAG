{
    "uuid": "6b22959c-c61d-55d2-a9d6-00a60301c330",
    "title": "STRUCTSUM Generation for Faster Text Comprehension",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{jain-etal-2024-structsum,\n    title = \"{STRUCTSUM} Generation for Faster Text Comprehension\",\n    author = \"Jain, Parag  and\n      Marzoca, Andreea  and\n      Piccinno, Francesco\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.426\",\n    doi = \"10.18653/v1/2024.acl-long.426\",\n    pages = \"7876--7896\",\n    abstract = \"We consider the task of generating structured representations of text using large language models (LLMs). We focus on tables and mind maps as representative modalities. Tables are more organized way of representing data, while mind maps provide a visually dynamic and flexible approach, particularly suitable for sparse content. Despite the effectiveness of LLMs on different tasks, we show that current models struggle with generating structured outputs. In response, we present effective prompting strategies for both of these tasks. We introduce a taxonomy of problems around factuality, global and local structure, common to both modalities and propose a set of critiques to tackle these issues resulting in an absolute improvement in accuracy of $+37$pp (79{\\%}) for mind maps and $+15$pp (78{\\%}) for tables. To evaluate semantic coverage of generated structured representations we propose Auto-QA, and we verify the adequacy of Auto-QA using SQuAD dataset. We further evaluate the usefulness of structured representations via a text comprehension user study. The results show a significant reduction in comprehension time compared to text when using table (42.9{\\%}) and mind map (31.9{\\%}), without loss in accuracy.\",\n}\n",
    "authors": [
        "Parag Jain",
        "Andreea Marzoca",
        "Francesco Piccinno"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.426.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6b22959c-c61d-55d2-a9d6-00a60301c330.pdf",
    "abstract": "We consider the task of generating structured representations of text using large language models (LLMs). We focus on tables and mind maps as representative modalities. Tables are more organized way of representing data, while mind maps provide a visually dynamic and flexible approach, particularly suitable for sparse content. Despite the effectiveness of LLMs on different tasks, we show that current models struggle with generating structured outputs. In response, we present effective prompting strategies for both of these tasks. We introduce a taxonomy of problems around factuality, global and local structure, common to both modalities and propose a set of critiques to tackle these issues resulting in an absolute improvement in accuracy of +37pp (79%) for mind maps and +15pp (78%) for tables. To evaluate semantic coverage of generated structured representations we propose Auto-QA, and we verify the adequacy of Auto-QA using SQuAD dataset. We further evaluate the usefulness of structured representations via a text comprehension user study. The results show a significant reduction in comprehension time compared to text when using table (42.9%) and mind map (31.9%), without loss in accuracy.",
    "num_pages": 21
}