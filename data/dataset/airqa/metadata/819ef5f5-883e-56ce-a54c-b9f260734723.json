{
    "uuid": "819ef5f5-883e-56ce-a54c-b9f260734723",
    "title": "GVdoc - Graph-based Visual DOcument Classification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{mohbat-etal-2023-gvdoc,\n    title = \"{GV}doc - Graph-based Visual {DO}cument Classification\",\n    author = \"Mohbat, Fnu  and\n      Zaki, Mohammed J  and\n      Finegan-Dollak, Catherine  and\n      Verma, Ashish\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.329\",\n    doi = \"10.18653/v1/2023.findings-acl.329\",\n    pages = \"5342--5357\",\n    abstract = \"The robustness of a model for real-world deployment is decided by how well it performs on unseen data and distinguishes between in-domain and out-of-domain samples. Visual document classifiers have shown impressive performance on in-distribution test sets. However, they tend to have a hard time correctly classifying and differentiating out-of-distribution examples. Image-based classifiers lack the text component, whereas multi-modality transformer-based models face the token serialization problem in visual documents due to their diverse layouts. They also require a lot of computing power during inference, making them impractical for many real-world applications. We propose, GVdoc, a graph-based document classification model that addresses both of these challenges. Our approach generates a document graph based on its layout, and then trains a graph neural network to learn node and graph embeddings. Through experiments, we show that our model, even with fewer parameters, outperforms state-of-the-art models on out-of-distribution data while retaining comparable performance on the in-distribution test set.\",\n}\n",
    "authors": [
        "Fnu Mohbat",
        "Mohammed J Zaki",
        "Catherine Finegan-Dollak",
        "Ashish Verma"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.329.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/819ef5f5-883e-56ce-a54c-b9f260734723.pdf",
    "abstract": "The robustness of a model for real-world deployment is decided by how well it performs on unseen data and distinguishes between in-domain and out-of-domain samples. Visual document classifiers have shown impressive performance on in-distribution test sets. However, they tend to have a hard time correctly classifying and differentiating out-of-distribution examples. Image-based classifiers lack the text component, whereas multi-modality transformer-based models face the token serialization problem in visual documents due to their diverse layouts. They also require a lot of computing power during inference, making them impractical for many real-world applications. We propose, GVdoc, a graph-based document classification model that addresses both of these challenges. Our approach generates a document graph based on its layout, and then trains a graph neural network to learn node and graph embeddings. Through experiments, we show that our model, even with fewer parameters, outperforms state-of-the-art models on out-of-distribution data while retaining comparable performance on the in-distribution test set.",
    "num_pages": 16
}