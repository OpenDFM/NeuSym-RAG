{
    "uuid": "f32fffaf-06f1-5137-aafc-48dc2d86d197",
    "title": "User Simulator Assisted Open-ended Conversational Recommendation System",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)",
    "bibtex": "@inproceedings{zhan-etal-2023-user,\n    title = \"User Simulator Assisted Open-ended Conversational Recommendation System\",\n    author = \"Zhan, Qiusi  and\n      Guo, Xiaojie  and\n      Ji, Heng  and\n      Wu, Lingfei\",\n    editor = \"Chen, Yun-Nung  and\n      Rastogi, Abhinav\",\n    booktitle = \"Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.nlp4convai-1.8\",\n    doi = \"10.18653/v1/2023.nlp4convai-1.8\",\n    pages = \"89--101\",\n    abstract = \"Conversational recommendation systems (CRS) have gained popularity in e-commerce as they can recommend items during user interactions. However, current open-ended CRS have limited recommendation performance due to their short-sighted training process, which only predicts one utterance at a time without considering its future impact. To address this, we propose a User Simulator (US) that communicates with the CRS using natural language based on given user preferences, enabling long-term reinforcement learning. We also introduce a framework that uses reinforcement learning (RL) with two novel rewards, i.e., recommendation and conversation rewards, to train the CRS. This approach considers the long-term goals and improves both the conversation and recommendation performance of the CRS. Our experiments show that our proposed framework improves the recall of recommendations by almost 100{\\%}. Moreover, human evaluation demonstrates the superiority of our framework in enhancing the informativeness of generated utterances.\",\n}\n",
    "authors": [
        "Qiusi Zhan",
        "Xiaojie Guo",
        "Heng Ji",
        "Lingfei Wu"
    ],
    "pdf_url": "https://aclanthology.org/2023.nlp4convai-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f32fffaf-06f1-5137-aafc-48dc2d86d197.pdf",
    "abstract": "Conversational recommendation systems (CRS) have gained popularity in e-commerce as they can recommend items during user interactions. However, current open-ended CRS have limited recommendation performance due to their short-sighted training process, which only predicts one utterance at a time without considering its future impact. To address this, we propose a User Simulator (US) that communicates with the CRS using natural language based on given user preferences, enabling long-term reinforcement learning. We also introduce a framework that uses reinforcement learning (RL) with two novel rewards, i.e., recommendation and conversation rewards, to train the CRS. This approach considers the long-term goals and improves both the conversation and recommendation performance of the CRS. Our experiments show that our proposed framework improves the recall of recommendations by almost 100%. Moreover, human evaluation demonstrates the superiority of our framework in enhancing the informativeness of generated utterances.",
    "num_pages": 13
}