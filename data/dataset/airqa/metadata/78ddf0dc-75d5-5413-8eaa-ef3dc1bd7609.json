{
    "uuid": "78ddf0dc-75d5-5413-8eaa-ef3dc1bd7609",
    "title": "Generate then Select: Open-ended Visual Question Answering Guided by World Knowledge",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{fu-etal-2023-generate,\n    title = \"Generate then Select: Open-ended Visual Question Answering Guided by World Knowledge\",\n    author = \"Fu, Xingyu  and\n      Zhang, Sheng  and\n      Kwon, Gukyeong  and\n      Perera, Pramuditha  and\n      Zhu, Henghui  and\n      Zhang, Yuhao  and\n      Li, Alexander Hanbo  and\n      Wang, William Yang  and\n      Wang, Zhiguo  and\n      Castelli, Vittorio  and\n      Ng, Patrick  and\n      Roth, Dan  and\n      Xiang, Bing\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.147\",\n    doi = \"10.18653/v1/2023.findings-acl.147\",\n    pages = \"2333--2346\",\n    abstract = \"The open-ended Visual Question Answering (VQA) task requires AI models to jointly reason over visual and natural language inputs using world knowledge. Recently, pre-trained Language Models (PLM) such as GPT-3 have been applied to the task and shown to be powerful world knowledge sources. However, these methods suffer from low knowledge coverage caused by PLM bias {--} the tendency to generate certain tokens over other tokens regardless of prompt changes, and high dependency on the PLM quality {--} only models using GPT-3 can achieve the best result. To address the aforementioned challenges, we propose RASO: a new VQA pipeline that deploys a generate-then-select strategy guided by world knowledge for the first time. Rather than following the de facto standard to train a multi-modal model that directly generates the VQA answer, {pasted macro {`}MODEL{'}}name first adopts PLM to generate all the possible answers, and then trains a lightweight answer selection model for the correct answer. As proved in our analysis, RASO expands the knowledge coverage from in-domain training data by a large margin. We provide extensive experimentation and show the effectiveness of our pipeline by advancing the state-of-the-art by 4.1{\\%} on OK-VQA, without additional computation cost.\",\n}\n",
    "authors": [
        "Xingyu Fu",
        "Sheng Zhang",
        "Gukyeong Kwon",
        "Pramuditha Perera",
        "Henghui Zhu",
        "Yuhao Zhang",
        "Alexander Hanbo Li",
        "William Yang Wang",
        "Zhiguo Wang",
        "Vittorio Castelli",
        "Patrick Ng",
        "Dan Roth",
        "Bing Xiang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.147.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/78ddf0dc-75d5-5413-8eaa-ef3dc1bd7609.pdf",
    "abstract": "The open-ended Visual Question Answering (VQA) task requires AI models to jointly reason over visual and natural language inputs using world knowledge. Recently, pre-trained Language Models (PLM) such as GPT-3 have been applied to the task and shown to be powerful world knowledge sources. However, these methods suffer from low knowledge coverage caused by PLM bias – the tendency to generate certain tokens over other tokens regardless of prompt changes, and high dependency on the PLM quality – only models using GPT-3 can achieve the best result. To address the aforementioned challenges, we propose RASO: a new VQA pipeline that deploys a generate-then-select strategy guided by world knowledge for the first time. Rather than following the de facto standard to train a multi-modal model that directly generates the VQA answer, {pasted macro ‘MODEL’}name first adopts PLM to generate all the possible answers, and then trains a lightweight answer selection model for the correct answer. As proved in our analysis, RASO expands the knowledge coverage from in-domain training data by a large margin. We provide extensive experimentation and show the effectiveness of our pipeline by advancing the state-of-the-art by 4.1% on OK-VQA, without additional computation cost.",
    "num_pages": 12
}