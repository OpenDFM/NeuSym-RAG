{
    "uuid": "ca1c8036-ddcd-509a-84a0-aa17270efcd8",
    "title": "Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 4th Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2024)",
    "bibtex": "@inproceedings{sadler-etal-2024-learning,\n    title = \"Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game\",\n    author = \"Sadler, Philipp  and\n      Hakimov, Sherzod  and\n      Schlangen, David\",\n    editor = \"Kordjamshidi, Parisa  and\n      Wang, Xin Eric  and\n      Zhang, Yue  and\n      Ma, Ziqiao  and\n      Inan, Mert\",\n    booktitle = \"Proceedings of the 4th Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.splurobonlp-1.2\",\n    pages = \"17--29\",\n    abstract = \"In this work, we evaluate the adaptability of neural agents towards assumed partner behaviors in a collaborative reference game. In this game, success is achieved when a knowledgeable guide can verbally lead a follower to the selection of a specific puzzle piece among several distractors. We frame this language grounding and coordination task as a reinforcement learning problem and measure to which extent a common reinforcement training algorithm (PPO) is able to produce neural agents (the guides) that perform well with various heuristic follower behaviors that vary along the dimensions of confidence and autonomy. We experiment with a learning signal that in addition to the goal condition also respects an assumed communicative effort. Our results indicate that this novel ingredient leads to communicative strategies that are less verbose (staying silent in some of the steps) and that with respect to that the guide{'}s strategies indeed adapt to the partner{'}s level of confidence and autonomy.\",\n}\n",
    "authors": [
        "Philipp Sadler",
        "Sherzod Hakimov",
        "David Schlangen"
    ],
    "pdf_url": "https://aclanthology.org/2024.splurobonlp-1.2.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ca1c8036-ddcd-509a-84a0-aa17270efcd8.pdf",
    "abstract": "In this work, we evaluate the adaptability of neural agents towards assumed partner behaviors in a collaborative reference game. In this game, success is achieved when a knowledgeable guide can verbally lead a follower to the selection of a specific puzzle piece among several distractors. We frame this language grounding and coordination task as a reinforcement learning problem and measure to which extent a common reinforcement training algorithm (PPO) is able to produce neural agents (the guides) that perform well with various heuristic follower behaviors that vary along the dimensions of confidence and autonomy. We experiment with a learning signal that in addition to the goal condition also respects an assumed communicative effort. Our results indicate that this novel ingredient leads to communicative strategies that are less verbose (staying silent in some of the steps) and that with respect to that the guide’s strategies indeed adapt to the partner’s level of confidence and autonomy.",
    "num_pages": 13
}