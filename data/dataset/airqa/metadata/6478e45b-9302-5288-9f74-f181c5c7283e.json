{
    "uuid": "6478e45b-9302-5288-9f74-f181c5c7283e",
    "title": "ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{ren-etal-2024-valuebench,\n    title = \"{V}alue{B}ench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models\",\n    author = \"Ren, Yuanyi  and\n      Ye, Haoran  and\n      Fang, Hanjun  and\n      Zhang, Xin  and\n      Song, Guojie\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.111\",\n    doi = \"10.18653/v1/2024.acl-long.111\",\n    pages = \"2015--2040\",\n    abstract = \"Large Language Models (LLMs) are transforming diverse fields and gaining increasing influence as human proxies. This development underscores the urgent need for evaluating value orientations and understanding of LLMs to ensure their responsible integration into public-facing applications. This work introduces ValueBench, the first comprehensive psychometric benchmark for evaluating value orientations and understanding in LLMs. ValueBench collects data from 44 established psychometric inventories, encompassing 453 multifaceted value dimensions. We propose an evaluation pipeline grounded in realistic human-AI interactions to probe value orientations, along with novel tasks for evaluating value understanding in an open-ended value space. With extensive experiments conducted on six representative LLMs, we unveil their shared and distinctive value orientations and exhibit their ability to approximate expert conclusions in value-related extraction and generation tasks.\",\n}\n",
    "authors": [
        "Yuanyi Ren",
        "Haoran Ye",
        "Hanjun Fang",
        "Xin Zhang",
        "Guojie Song"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.111.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6478e45b-9302-5288-9f74-f181c5c7283e.pdf",
    "abstract": "Large Language Models (LLMs) are transforming diverse fields and gaining increasing influence as human proxies. This development underscores the urgent need for evaluating value orientations and understanding of LLMs to ensure their responsible integration into public-facing applications. This work introduces ValueBench, the first comprehensive psychometric benchmark for evaluating value orientations and understanding in LLMs. ValueBench collects data from 44 established psychometric inventories, encompassing 453 multifaceted value dimensions. We propose an evaluation pipeline grounded in realistic human-AI interactions to probe value orientations, along with novel tasks for evaluating value understanding in an open-ended value space. With extensive experiments conducted on six representative LLMs, we unveil their shared and distinctive value orientations and exhibit their ability to approximate expert conclusions in value-related extraction and generation tasks.",
    "num_pages": 26
}