{
    "uuid": "ccd5f729-ce36-5fc9-ab4a-2dd7a5a1a355",
    "title": "SemanticCuetSync at ArAIEval Shared Task: Detecting Propagandistic Spans with Persuasion Techniques Identification using Pre-trained Transformers",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The Second Arabic Natural Language Processing Conference",
    "bibtex": "@inproceedings{shohan-etal-2024-semanticcuetsync,\n    title = \"{S}emantic{C}uet{S}ync at {A}r{AIE}val Shared Task: Detecting Propagandistic Spans with Persuasion Techniques Identification using Pre-trained Transformers\",\n    author = \"Shohan, Symom  and\n      Hossain, Md.  and\n      Paran, Ashraful  and\n      Ahsan, Shawly  and\n      Hossain, Jawad  and\n      Hoque, Mohammed Moshiul\",\n    editor = \"Habash, Nizar  and\n      Bouamor, Houda  and\n      Eskander, Ramy  and\n      Tomeh, Nadi  and\n      Abu Farha, Ibrahim  and\n      Abdelali, Ahmed  and\n      Touileb, Samia  and\n      Hamed, Injy  and\n      Onaizan, Yaser  and\n      Alhafni, Bashar  and\n      Antoun, Wissam  and\n      Khalifa, Salam  and\n      Haddad, Hatem  and\n      Zitouni, Imed  and\n      AlKhamissi, Badr  and\n      Almatham, Rawan  and\n      Mrini, Khalil\",\n    booktitle = \"Proceedings of The Second Arabic Natural Language Processing Conference\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.arabicnlp-1.54\",\n    doi = \"10.18653/v1/2024.arabicnlp-1.54\",\n    pages = \"518--523\",\n    abstract = \"Detecting propagandistic spans and identifying persuasion techniques are crucial for promoting informed decision-making, safeguarding democratic processes, and fostering a media environment characterized by integrity and transparency. Various machine learning (Logistic Regression, Random Forest, and Multinomial Naive Bayes), deep learning (CNN, CNN+LSTM, CNN+BiLSTM), and transformer-based (AraBERTv2, AraBERT-NER, CamelBERT, BERT-Base-Arabic) models were exploited to perform the task. The evaluation results indicate that CamelBERT achieved the highest micro-F1 score (24.09{\\%}), outperforming CNN+LSTM and AraBERTv2. The study found that most models struggle to detect propagandistic spans when multiple spans are present within the same article. Overall, the model{'}s performance secured a $6^{th}$ place ranking in the ArAIEval Shared Task-1.\",\n}\n",
    "authors": [
        "Symom Shohan",
        "Md. Hossain",
        "Ashraful Paran",
        "Shawly Ahsan",
        "Jawad Hossain",
        "Mohammed Moshiul Hoque"
    ],
    "pdf_url": "https://aclanthology.org/2024.arabicnlp-1.54.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ccd5f729-ce36-5fc9-ab4a-2dd7a5a1a355.pdf",
    "abstract": "Detecting propagandistic spans and identifying persuasion techniques are crucial for promoting informed decision-making, safeguarding democratic processes, and fostering a media environment characterized by integrity and transparency. Various machine learning (Logistic Regression, Random Forest, and Multinomial Naive Bayes), deep learning (CNN, CNN+LSTM, CNN+BiLSTM), and transformer-based (AraBERTv2, AraBERT-NER, CamelBERT, BERT-Base-Arabic) models were exploited to perform the task. The evaluation results indicate that CamelBERT achieved the highest micro-F1 score (24.09%), outperforming CNN+LSTM and AraBERTv2. The study found that most models struggle to detect propagandistic spans when multiple spans are present within the same article. Overall, the modelâ€™s performance secured a 6th place ranking in the ArAIEval Shared Task-1.",
    "num_pages": 6
}