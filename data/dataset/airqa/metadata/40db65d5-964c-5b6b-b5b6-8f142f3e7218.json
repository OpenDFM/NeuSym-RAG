{
    "uuid": "40db65d5-964c-5b6b-b5b6-8f142f3e7218",
    "title": "Multi-Domain Dialogue State Tracking with Disentangled Domain-Slot Attention",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{yang-etal-2023-multi,\n    title = \"Multi-Domain Dialogue State Tracking with Disentangled Domain-Slot Attention\",\n    author = \"Yang, Longfei  and\n      Li, Jiyi  and\n      Li, Sheng  and\n      Shinozaki, Takahiro\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.304\",\n    doi = \"10.18653/v1/2023.findings-acl.304\",\n    pages = \"4928--4938\",\n    abstract = \"As the core of task-oriented dialogue systems, dialogue state tracking (DST) is designed to track the dialogue state through the conversation between users and systems. Multi-domain DST has been an important challenge in which the dialogue states across multiple domains need to consider. In recent mainstream approaches, each domain and slot are aggregated and regarded as a single query feeding into attention with the dialogue history to obtain domain-slot specific representations. In this work, we propose disentangled domain-slot attention for multi-domain dialogue state tracking. The proposed approach disentangles the domain-slot specific information extraction in a flexible and context-dependent manner by separating the query about domains and slots in the attention component. Through a series of experiments on MultiWOZ 2.0 and MultiWOZ 2.4 datasets, we demonstrate that our proposed approach outperforms the standard multi-head attention with aggregated domain-slot query.\",\n}\n",
    "authors": [
        "Longfei Yang",
        "Jiyi Li",
        "Sheng Li",
        "Takahiro Shinozaki"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.304.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/40db65d5-964c-5b6b-b5b6-8f142f3e7218.pdf",
    "abstract": "As the core of task-oriented dialogue systems, dialogue state tracking (DST) is designed to track the dialogue state through the conversation between users and systems. Multi-domain DST has been an important challenge in which the dialogue states across multiple domains need to consider. In recent mainstream approaches, each domain and slot are aggregated and regarded as a single query feeding into attention with the dialogue history to obtain domain-slot specific representations. In this work, we propose disentangled domain-slot attention for multi-domain dialogue state tracking. The proposed approach disentangles the domain-slot specific information extraction in a flexible and context-dependent manner by separating the query about domains and slots in the attention component. Through a series of experiments on MultiWOZ 2.0 and MultiWOZ 2.4 datasets, we demonstrate that our proposed approach outperforms the standard multi-head attention with aggregated domain-slot query.",
    "num_pages": 11
}