{
    "uuid": "bce575ce-92da-59bb-b27e-faa66c45e5b9",
    "title": "ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{wu-etal-2024-conceptmath,\n    title = \"{C}oncept{M}ath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models\",\n    author = \"Wu, Yanan  and\n      Liu, Jie  and\n      Bu, Xingyuan  and\n      Liu, Jiaheng  and\n      Zhou, Zhanhui  and\n      Zhang, Yuanxing  and\n      Zhang, Chenchen  and\n      ZhiqiBai, ZhiqiBai  and\n      Chen, Haibin  and\n      Ge, Tiezheng  and\n      Ouyang, Wanli  and\n      Su, Wenbo  and\n      Zheng, Bo\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.407\",\n    doi = \"10.18653/v1/2024.findings-acl.407\",\n    pages = \"6815--6839\",\n    abstract = \"This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath systemically organizes math problems under a hierarchy of math concepts, so that mathematical reasoning can be evaluated at different granularity with concept-wise accuracies. Based on our ConcepthMath, we then evaluate a broad range of LLMs, and we observe existing LLMs, though achieving high average accuracies on traditional benchmarks, exhibit significant performance variations across different math concepts and may even fail catastrophically on the most basic ones. Besides, we also introduce an efficient fine-tuning strategy to enhance the weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the developers to understand the fine-grained mathematical abilities of their models and facilitate the growth of foundation models. Code is available at https://github.com/conceptmath/conceptmath.\",\n}\n",
    "authors": [
        "Yanan Wu",
        "Jie Liu",
        "Xingyuan Bu",
        "Jiaheng Liu",
        "Zhanhui Zhou",
        "Yuanxing Zhang",
        "Chenchen Zhang",
        "ZhiqiBai ZhiqiBai",
        "Haibin Chen",
        "Tiezheng Ge",
        "Wanli Ouyang",
        "Wenbo Su",
        "Bo Zheng"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.407.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/bce575ce-92da-59bb-b27e-faa66c45e5b9.pdf",
    "abstract": "This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath systemically organizes math problems under a hierarchy of math concepts, so that mathematical reasoning can be evaluated at different granularity with concept-wise accuracies. Based on our ConcepthMath, we then evaluate a broad range of LLMs, and we observe existing LLMs, though achieving high average accuracies on traditional benchmarks, exhibit significant performance variations across different math concepts and may even fail catastrophically on the most basic ones. Besides, we also introduce an efficient fine-tuning strategy to enhance the weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the developers to understand the fine-grained mathematical abilities of their models and facilitate the growth of foundation models. Code is available at https://github.com/conceptmath/conceptmath.",
    "num_pages": 25
}