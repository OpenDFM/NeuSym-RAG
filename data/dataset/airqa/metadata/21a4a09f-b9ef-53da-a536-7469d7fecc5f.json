{
    "uuid": "21a4a09f-b9ef-53da-a536-7469d7fecc5f",
    "title": "Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{song-etal-2023-multilingual,\n    title = \"Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints\",\n    author = \"Song, Ran  and\n      He, Shizhu  and\n      Gao, Shengxiang  and\n      Cai, Li  and\n      Liu, Kang  and\n      Yu, Zhengtao  and\n      Zhao, Jun\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.488\",\n    doi = \"10.18653/v1/2023.findings-acl.488\",\n    pages = \"7709--7721\",\n    abstract = \"Multilingual Knowledge Graph Completion (mKGC) aim at solving queries in different languages by reasoning a tail entity thus improving multilingual knowledge graphs. Previous studies leverage multilingual pretrained language models (PLMs) and the generative paradigm to achieve mKGC. Although multilingual pretrained language models contain extensive knowledge of different languages, its pretraining tasks cannot be directly aligned with the mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit a pronounced English-centric bias. This makes it difficult for mKGC to achieve good results, particularly in the context of low-resource languages. To overcome previous problems, this paper introduces global and local knowledge constraints for mKGC. The former is used to constrain the reasoning of answer entities , while the latter is used to enhance the representation of query contexts. The proposed method makes the pretrained model better adapt to the mKGC task. Experimental results on public datasets demonstrate that our method outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32{\\%} and 16.03{\\%}, which indicates that our proposed method has significant enhancement on mKGC.\",\n}\n",
    "authors": [
        "Ran Song",
        "Shizhu He",
        "Shengxiang Gao",
        "Li Cai",
        "Kang Liu",
        "Zhengtao Yu",
        "Jun Zhao"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.488.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/21a4a09f-b9ef-53da-a536-7469d7fecc5f.pdf",
    "abstract": "Multilingual Knowledge Graph Completion (mKGC) aim at solving queries in different languages by reasoning a tail entity thus improving multilingual knowledge graphs. Previous studies leverage multilingual pretrained language models (PLMs) and the generative paradigm to achieve mKGC. Although multilingual pretrained language models contain extensive knowledge of different languages, its pretraining tasks cannot be directly aligned with the mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit a pronounced English-centric bias. This makes it difficult for mKGC to achieve good results, particularly in the context of low-resource languages. To overcome previous problems, this paper introduces global and local knowledge constraints for mKGC. The former is used to constrain the reasoning of answer entities , while the latter is used to enhance the representation of query contexts. The proposed method makes the pretrained model better adapt to the mKGC task. Experimental results on public datasets demonstrate that our method outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and 16.03%, which indicates that our proposed method has significant enhancement on mKGC.",
    "num_pages": 13
}