{
    "uuid": "4a1cfce1-5f18-5909-aead-421fe6d62c9c",
    "title": "Causal-Guided Active Learning for Debiasing Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{sun-etal-2024-causal,\n    title = \"Causal-Guided Active Learning for Debiasing Large Language Models\",\n    author = \"Sun, Zhouhao  and\n      Du, Li  and\n      Ding, Xiao  and\n      Ma, Yixuan  and\n      Zhao, Yang  and\n      Qiu, Kaitao  and\n      Liu, Ting  and\n      Qin, Bing\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.778\",\n    doi = \"10.18653/v1/2024.acl-long.778\",\n    pages = \"14455--14469\",\n    abstract = \"Although achieving promising performance, recent analyses show that current generative large language models (LLMs) may still capture dataset biases and utilize them for generation, leading to poor generalizability and harmfulness of LLMs. However, due to the diversity of dataset biases and the over-optimization problem, previous prior-knowledge-based debiasing methods and fine-tuning-based debiasing methods may not be suitable for current LLMs.To address this issue, we explore combining active learning with the causal mechanisms and propose a casual-guided active learning (CAL) framework, which utilizes LLMs itself to automatically and autonomously identify informative biased samples and induce the bias patterns. Then a cost-effective and efficient in-context learning based method is employed to prevent LLMs from utilizing dataset biases during generation.Experimental results show that CAL can effectively recognize typical biased instances and induce various bias patterns for debiasing LLMs.\",\n}\n",
    "authors": [
        "Zhouhao Sun",
        "Li Du",
        "Xiao Ding",
        "Yixuan Ma",
        "Yang Zhao",
        "Kaitao Qiu",
        "Ting Liu",
        "Bing Qin"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.778.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/4a1cfce1-5f18-5909-aead-421fe6d62c9c.pdf",
    "abstract": "Although achieving promising performance, recent analyses show that current generative large language models (LLMs) may still capture dataset biases and utilize them for generation, leading to poor generalizability and harmfulness of LLMs. However, due to the diversity of dataset biases and the over-optimization problem, previous prior-knowledge-based debiasing methods and fine-tuning-based debiasing methods may not be suitable for current LLMs.To address this issue, we explore combining active learning with the causal mechanisms and propose a casual-guided active learning (CAL) framework, which utilizes LLMs itself to automatically and autonomously identify informative biased samples and induce the bias patterns. Then a cost-effective and efficient in-context learning based method is employed to prevent LLMs from utilizing dataset biases during generation.Experimental results show that CAL can effectively recognize typical biased instances and induce various bias patterns for debiasing LLMs.",
    "num_pages": 15
}