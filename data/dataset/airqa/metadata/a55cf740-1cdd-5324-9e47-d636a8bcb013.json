{
    "uuid": "a55cf740-1cdd-5324-9e47-d636a8bcb013",
    "title": "Reducing Sensitivity on Speaker Names for Text Generation from Dialogues",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{jia-etal-2023-reducing,\n    title = \"Reducing Sensitivity on Speaker Names for Text Generation from Dialogues\",\n    author = \"Jia, Qi  and\n      Tang, Haifeng  and\n      Zhu, Kenny\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.129\",\n    doi = \"10.18653/v1/2023.findings-acl.129\",\n    pages = \"2058--2073\",\n    abstract = \"Changing speaker names consistently throughout a dialogue should not affect its meaning and corresponding outputs for text generation from dialogues. However, pre-trained language models, serving as the backbone for dialogue-processing tasks, have shown to be sensitive to nuances. This may result in unfairness in real-world applications. No comprehensive analysis of this problem has been done in the past. In this work, we propose to quantitatively measure a model{'}s sensitivity on speaker names, and comprehensively evaluate a number of known methods for reducing speaker name sensitivity, including a novel approach of our own. Extensive experiments on multiple datasets provide a benchmark for this problem and show the favorable performance of our approach in sensitivity reduction and quality of generation.\",\n}\n",
    "authors": [
        "Qi Jia",
        "Haifeng Tang",
        "Kenny Zhu"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.129.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a55cf740-1cdd-5324-9e47-d636a8bcb013.pdf",
    "abstract": "Changing speaker names consistently throughout a dialogue should not affect its meaning and corresponding outputs for text generation from dialogues. However, pre-trained language models, serving as the backbone for dialogue-processing tasks, have shown to be sensitive to nuances. This may result in unfairness in real-world applications. No comprehensive analysis of this problem has been done in the past. In this work, we propose to quantitatively measure a modelâ€™s sensitivity on speaker names, and comprehensively evaluate a number of known methods for reducing speaker name sensitivity, including a novel approach of our own. Extensive experiments on multiple datasets provide a benchmark for this problem and show the favorable performance of our approach in sensitivity reduction and quality of generation.",
    "num_pages": 16
}