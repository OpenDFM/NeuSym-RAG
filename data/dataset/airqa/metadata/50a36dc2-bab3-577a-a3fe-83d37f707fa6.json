{
    "uuid": "50a36dc2-bab3-577a-a3fe-83d37f707fa6",
    "title": "A Class-Rebalancing Self-Training Framework for Distantly-Supervised Named Entity Recognition",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{li-etal-2023-class,\n    title = \"A Class-Rebalancing Self-Training Framework for Distantly-Supervised Named Entity Recognition\",\n    author = \"Li, Qi  and\n      Xie, Tingyu  and\n      Peng, Peng  and\n      Wang, Hongwei  and\n      Wang, Gaoang\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.703\",\n    doi = \"10.18653/v1/2023.findings-acl.703\",\n    pages = \"11054--11068\",\n    abstract = \"Distant supervision reduces the reliance on human annotation in the named entity recognition tasks. The class-level imbalanced distant annotation is a realistic and unexplored problem, and the popular method of self-training can not handle class-level imbalanced learning. More importantly, self-training is dominated by the high-performance class in selecting candidates, and deteriorates the low-performance class with the bias of generated pseudo label. To address the class-level imbalance performance, we propose a class-rebalancing self-training framework for improving the distantly-supervised named entity recognition. In candidate selection, a class-wise flexible threshold is designed to fully explore other classes besides the high-performance class. In label generation, injecting the distant label, a hybrid pseudo label is adopted to provide straight semantic information for the low-performance class. Experiments on five flat and two nested datasets show that our model achieves state-of-the-art results. We also conduct extensive research to analyze the effectiveness of the flexible threshold and the hybrid pseudo label.\",\n}\n",
    "authors": [
        "Qi Li",
        "Tingyu Xie",
        "Peng Peng",
        "Hongwei Wang",
        "Gaoang Wang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.703.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/50a36dc2-bab3-577a-a3fe-83d37f707fa6.pdf",
    "abstract": "Distant supervision reduces the reliance on human annotation in the named entity recognition tasks. The class-level imbalanced distant annotation is a realistic and unexplored problem, and the popular method of self-training can not handle class-level imbalanced learning. More importantly, self-training is dominated by the high-performance class in selecting candidates, and deteriorates the low-performance class with the bias of generated pseudo label. To address the class-level imbalance performance, we propose a class-rebalancing self-training framework for improving the distantly-supervised named entity recognition. In candidate selection, a class-wise flexible threshold is designed to fully explore other classes besides the high-performance class. In label generation, injecting the distant label, a hybrid pseudo label is adopted to provide straight semantic information for the low-performance class. Experiments on five flat and two nested datasets show that our model achieves state-of-the-art results. We also conduct extensive research to analyze the effectiveness of the flexible threshold and the hybrid pseudo label.",
    "num_pages": 15
}