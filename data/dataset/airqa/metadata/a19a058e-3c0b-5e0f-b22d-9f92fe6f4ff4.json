{
    "uuid": "a19a058e-3c0b-5e0f-b22d-9f92fe6f4ff4",
    "title": "Tell2Design: A Dataset for Language-Guided Floor Plan Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{leng-etal-2023-tell2design,\n    title = \"{T}ell2{D}esign: A Dataset for Language-Guided Floor Plan Generation\",\n    author = \"Leng, Sicong  and\n      Zhou, Yang  and\n      Dupty, Mohammed Haroon  and\n      Lee, Wee Sun  and\n      Joyce, Sam  and\n      Lu, Wei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.820\",\n    doi = \"10.18653/v1/2023.acl-long.820\",\n    pages = \"14680--14697\",\n    abstract = \"We consider the task of generating designs directly from natural language descriptions, and consider floor plan generation as the initial research area. Language conditional generative models have recently been very successful in generating high-quality artistic images. However, designs must satisfy different constraints that are not present in generating artistic images, particularly spatial and relational constraints. We make multiple contributions to initiate research on this task. First, we introduce a novel dataset, Tell2Design (T2D), which contains more than 80k floor plan designs associated with natural language instructions. Second, we propose a Sequence-to-Sequence model that can serve as a strong baseline for future research. Third, we benchmark this task with several text-conditional image generation models. We conclude by conducting human evaluations on the generated samples and providing an analysis of human performance. We hope our contributions will propel the research on language-guided design generation forward.\",\n}\n",
    "authors": [
        "Sicong Leng",
        "Yang Zhou",
        "Mohammed Haroon Dupty",
        "Wee Sun Lee",
        "Sam Joyce",
        "Wei Lu"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.820.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a19a058e-3c0b-5e0f-b22d-9f92fe6f4ff4.pdf",
    "abstract": "We consider the task of generating designs directly from natural language descriptions, and consider floor plan generation as the initial research area. Language conditional generative models have recently been very successful in generating high-quality artistic images. However, designs must satisfy different constraints that are not present in generating artistic images, particularly spatial and relational constraints. We make multiple contributions to initiate research on this task. First, we introduce a novel dataset, Tell2Design (T2D), which contains more than 80k floor plan designs associated with natural language instructions. Second, we propose a Sequence-to-Sequence model that can serve as a strong baseline for future research. Third, we benchmark this task with several text-conditional image generation models. We conclude by conducting human evaluations on the generated samples and providing an analysis of human performance. We hope our contributions will propel the research on language-guided design generation forward.",
    "num_pages": 18
}