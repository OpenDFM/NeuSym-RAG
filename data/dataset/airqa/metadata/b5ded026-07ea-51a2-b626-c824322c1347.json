{
    "uuid": "b5ded026-07ea-51a2-b626-c824322c1347",
    "title": "A Graph per Persona: Reasoning about Subjective Natural Language Descriptions",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{hwang-etal-2024-graph,\n    title = \"A Graph per Persona: Reasoning about Subjective Natural Language Descriptions\",\n    author = \"Hwang, EunJeong  and\n      Shwartz, Vered  and\n      Gutfreund, Dan  and\n      Thost, Veronika\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.115\",\n    doi = \"10.18653/v1/2024.findings-acl.115\",\n    pages = \"1928--1942\",\n    abstract = \"Reasoning about subjective natural language descriptions, such as opinions and preferences, is a challenging topic that largely remains unsolved to date. In particular, state-of-the-art large language models (LLMs) perform disappointingly in this task, show strong biases, and do not meet the interpretability requirements often needed in these kinds of applications. We propose a novel approach for reasoning about subjective knowledge that integrates potential and implicit meanings and explicitly models the relational nature of the information. We apply supervised graph learning, offer explanations for the model{'}s reasoning, and show that our model performs well across all 15 topics of OpinionQA, outperforming several prominent LLMs. Our detailed analysis further shows its unique advantages and the complementary nature it offers in comparison to LLMs.\",\n}\n",
    "authors": [
        "EunJeong Hwang",
        "Vered Shwartz",
        "Dan Gutfreund",
        "Veronika Thost"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.115.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b5ded026-07ea-51a2-b626-c824322c1347.pdf",
    "abstract": "Reasoning about subjective natural language descriptions, such as opinions and preferences, is a challenging topic that largely remains unsolved to date. In particular, state-of-the-art large language models (LLMs) perform disappointingly in this task, show strong biases, and do not meet the interpretability requirements often needed in these kinds of applications. We propose a novel approach for reasoning about subjective knowledge that integrates potential and implicit meanings and explicitly models the relational nature of the information. We apply supervised graph learning, offer explanations for the modelâ€™s reasoning, and show that our model performs well across all 15 topics of OpinionQA, outperforming several prominent LLMs. Our detailed analysis further shows its unique advantages and the complementary nature it offers in comparison to LLMs.",
    "num_pages": 15
}