{
    "uuid": "d68ee661-ea83-5d2e-85c3-6c45e7a17316",
    "title": "CTC-based Non-autoregressive Textless Speech-to-Speech Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{fang-etal-2024-ctc,\n    title = \"{CTC}-based Non-autoregressive Textless Speech-to-Speech Translation\",\n    author = \"Fang, Qingkai  and\n      Ma, Zhengrui  and\n      Zhou, Yan  and\n      Zhang, Min  and\n      Feng, Yang\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.543\",\n    doi = \"10.18653/v1/2024.findings-acl.543\",\n    pages = \"9155--9161\",\n    abstract = \"Direct speech-to-speech translation (S2ST) has achieved impressive translation quality, but it often faces the challenge of slow decoding due to the considerable length of speech sequences. Recently, some research has turned to non-autoregressive (NAR) models to expedite decoding, yet the translation quality typically lags behind autoregressive (AR) models significantly. In this paper, we investigate the performance of CTC-based NAR models in S2ST, as these models have shown impressive results in machine translation. Experimental results demonstrate that by combining pretraining, knowledge distillation, and advanced NAR training techniques such as glancing training and non-monotonic latent alignments, CTC-based NAR models achieve translation quality comparable to the AR model, while preserving up to 26.81$\\times$ decoding speedup.\",\n}\n",
    "authors": [
        "Qingkai Fang",
        "Zhengrui Ma",
        "Yan Zhou",
        "Min Zhang",
        "Yang Feng"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.543.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/d68ee661-ea83-5d2e-85c3-6c45e7a17316.pdf",
    "abstract": "Direct speech-to-speech translation (S2ST) has achieved impressive translation quality, but it often faces the challenge of slow decoding due to the considerable length of speech sequences. Recently, some research has turned to non-autoregressive (NAR) models to expedite decoding, yet the translation quality typically lags behind autoregressive (AR) models significantly. In this paper, we investigate the performance of CTC-based NAR models in S2ST, as these models have shown impressive results in machine translation. Experimental results demonstrate that by combining pretraining, knowledge distillation, and advanced NAR training techniques such as glancing training and non-monotonic latent alignments, CTC-based NAR models achieve translation quality comparable to the AR model, while preserving up to 26.81Ã— decoding speedup.",
    "num_pages": 7
}