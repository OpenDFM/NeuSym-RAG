{
    "uuid": "fc737b6a-e85f-534f-b540-ff3d8586de6b",
    "title": "GLIMPSE: Pragmatically Informative Multi-Document Summarization for Scholarly Reviews",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{darrin-etal-2024-glimpse,\n    title = \"{GLIMPSE}: Pragmatically Informative Multi-Document Summarization for Scholarly Reviews\",\n    author = \"Darrin, Maxime  and\n      Arous, Ines  and\n      Piantanida, Pablo  and\n      Cheung, Jackie\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.688\",\n    doi = \"10.18653/v1/2024.acl-long.688\",\n    pages = \"12737--12752\",\n    abstract = \"Scientific peer review is essential for the quality of academic publications. However, the increasing number of paper submissions to conferences has strained the reviewing process. This surge poses a burden on area chairs who have to carefully read an ever-growing volume of reviews and discern each reviewer{'}s main arguments as part of their decision process. In this paper, we introduce , a summarization method designed to offer a concise yet comprehensive overview of scholarly reviews. Unlike traditional consensus-based methods, extracts both common and unique opinions from the reviews. We introduce novel uniqueness scores based on the Rational Speech Act framework to identify relevant sentences in the reviews. Our method aims to provide a pragmatic glimpse into all reviews, offering a balanced perspective on their opinions. Our experimental results with both automatic metrics and human evaluation show that generates more discriminative summaries than baseline methods in terms of human evaluation while achieving comparable performance with these methods in terms of automatic metrics.\",\n}\n",
    "authors": [
        "Maxime Darrin",
        "Ines Arous",
        "Pablo Piantanida",
        "Jackie Cheung"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.688.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/fc737b6a-e85f-534f-b540-ff3d8586de6b.pdf",
    "abstract": "Scientific peer review is essential for the quality of academic publications. However, the increasing number of paper submissions to conferences has strained the reviewing process. This surge poses a burden on area chairs who have to carefully read an ever-growing volume of reviews and discern each reviewerâ€™s main arguments as part of their decision process. In this paper, we introduce , a summarization method designed to offer a concise yet comprehensive overview of scholarly reviews. Unlike traditional consensus-based methods, extracts both common and unique opinions from the reviews. We introduce novel uniqueness scores based on the Rational Speech Act framework to identify relevant sentences in the reviews. Our method aims to provide a pragmatic glimpse into all reviews, offering a balanced perspective on their opinions. Our experimental results with both automatic metrics and human evaluation show that generates more discriminative summaries than baseline methods in terms of human evaluation while achieving comparable performance with these methods in terms of automatic metrics.",
    "num_pages": 16
}