{
    "uuid": "dc30bd6d-383d-5a40-84ac-581fc8538b56",
    "title": "Eliciting Affective Events from Language Models by Multiple View Co-prompting",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zhuang-riloff-2023-eliciting,\n    title = \"Eliciting Affective Events from Language Models by Multiple View Co-prompting\",\n    author = \"Zhuang, Yuan  and\n      Riloff, Ellen\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.199\",\n    doi = \"10.18653/v1/2023.findings-acl.199\",\n    pages = \"3189--3201\",\n    abstract = \"Prior research on affective event classification showed that exploiting weakly labeled data for training can improve model performance. In this work, we propose a simpler and more effective approach for generating training data by automatically acquiring and labeling affective events with Multiple View Co-prompting, which leverages two language model prompts that provide independent views of an event. The approach starts with a modest amount of gold data and prompts pre-trained language models to generate new events. Next, information about the probable affective polarity of each event is collected from two complementary language model prompts and jointly used to assign polarity labels. Experimental results on two datasets show that the newly acquired events improve a state-of-the-art affective event classifier. We also present analyses which show that using multiple views produces polarity labels of higher quality than either view on its own.\",\n}\n",
    "authors": [
        "Yuan Zhuang",
        "Ellen Riloff"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.199.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/dc30bd6d-383d-5a40-84ac-581fc8538b56.pdf",
    "abstract": "Prior research on affective event classification showed that exploiting weakly labeled data for training can improve model performance. In this work, we propose a simpler and more effective approach for generating training data by automatically acquiring and labeling affective events with Multiple View Co-prompting, which leverages two language model prompts that provide independent views of an event. The approach starts with a modest amount of gold data and prompts pre-trained language models to generate new events. Next, information about the probable affective polarity of each event is collected from two complementary language model prompts and jointly used to assign polarity labels. Experimental results on two datasets show that the newly acquired events improve a state-of-the-art affective event classifier. We also present analyses which show that using multiple views produces polarity labels of higher quality than either view on its own.",
    "num_pages": 13
}