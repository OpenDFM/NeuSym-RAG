{
    "uuid": "05b5963b-1ee6-503c-9077-c8e178d0d0a3",
    "title": "Latent Learningscape Guided In-context Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhou-etal-2024-latent,\n    title = \"Latent Learningscape Guided In-context Learning\",\n    author = \"Zhou, Anlai  and\n      Jiang, Sunshine  and\n      Liu, Yifei  and\n      Wu, Yiquan  and\n      Kuang, Kun  and\n      Xiao, Jun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.482\",\n    doi = \"10.18653/v1/2024.findings-acl.482\",\n    pages = \"8090--8101\",\n    abstract = \"The growing interest in leveraging large language models is driven by their exceptional imitation and reasoning capabilities. In-context learning (ICL), a streamlined method, has shown potential in boosting these models{'} performance without modifying their underlying parameters, especially when supplied with suitable demonstrations. However, existing methods mainly choose demonstrations by comparing surface-level semantic similarities (e.g., based on embedding) and fall short of identifying the most fitting ones. This paper introduces the concept of a {``}latent learningscape{''}, a more nuanced representation that describes the characteristic of the demonstrations. Building on this concept, we develop a results-driven approach to characterize the latent learningscape features of demonstrations, which then inform the creation of more effective prompts. Through comprehensive testing across datasets in arithmetic, commonsense, and symbolic reasoning tasks, our approach outperforms leading models, showing an average increase in scores by 7.4 percentage points.\",\n}\n",
    "authors": [
        "Anlai Zhou",
        "Sunshine Jiang",
        "Yifei Liu",
        "Yiquan Wu",
        "Kun Kuang",
        "Jun Xiao"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.482.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/05b5963b-1ee6-503c-9077-c8e178d0d0a3.pdf",
    "abstract": "The growing interest in leveraging large language models is driven by their exceptional imitation and reasoning capabilities. In-context learning (ICL), a streamlined method, has shown potential in boosting these models’ performance without modifying their underlying parameters, especially when supplied with suitable demonstrations. However, existing methods mainly choose demonstrations by comparing surface-level semantic similarities (e.g., based on embedding) and fall short of identifying the most fitting ones. This paper introduces the concept of a “latent learningscape”, a more nuanced representation that describes the characteristic of the demonstrations. Building on this concept, we develop a results-driven approach to characterize the latent learningscape features of demonstrations, which then inform the creation of more effective prompts. Through comprehensive testing across datasets in arithmetic, commonsense, and symbolic reasoning tasks, our approach outperforms leading models, showing an average increase in scores by 7.4 percentage points.",
    "num_pages": 12
}