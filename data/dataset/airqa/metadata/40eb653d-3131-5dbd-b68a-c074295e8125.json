{
    "uuid": "40eb653d-3131-5dbd-b68a-c074295e8125",
    "title": "ChartCheck: Explainable Fact-Checking over Real-World Chart Images",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{akhtar-etal-2024-chartcheck,\n    title = \"{C}hart{C}heck: Explainable Fact-Checking over Real-World Chart Images\",\n    author = \"Akhtar, Mubashara  and\n      Subedi, Nikesh  and\n      Gupta, Vivek  and\n      Tahmasebi, Sahar  and\n      Cocarascu, Oana  and\n      Simperl, Elena\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.828\",\n    doi = \"10.18653/v1/2024.findings-acl.828\",\n    pages = \"13921--13937\",\n    abstract = \"Whilst fact verification has attracted substantial interest in the natural language processing community, verifying misinforming statements against data visualizations such as charts has so far been overlooked. Charts are commonly used in the real-world to summarize and com municate key information, but they can also be easily misused to spread misinformation and promote certain agendas. In this paper, we introduce ChartCheck, a novel, large-scale dataset for explainable fact-checking against real-world charts, consisting of 1.7k charts and 10.5k human-written claims and explanations. We systematically evaluate ChartCheck using vision-language and chart-to-table models, and propose a baseline to the community. Finally, we study chart reasoning types and visual attributes that pose a challenge to these models.\",\n}\n",
    "authors": [
        "Mubashara Akhtar",
        "Nikesh Subedi",
        "Vivek Gupta",
        "Sahar Tahmasebi",
        "Oana Cocarascu",
        "Elena Simperl"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.828.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/40eb653d-3131-5dbd-b68a-c074295e8125.pdf",
    "abstract": "Whilst fact verification has attracted substantial interest in the natural language processing community, verifying misinforming statements against data visualizations such as charts has so far been overlooked. Charts are commonly used in the real-world to summarize and com municate key information, but they can also be easily misused to spread misinformation and promote certain agendas. In this paper, we introduce ChartCheck, a novel, large-scale dataset for explainable fact-checking against real-world charts, consisting of 1.7k charts and 10.5k human-written claims and explanations. We systematically evaluate ChartCheck using vision-language and chart-to-table models, and propose a baseline to the community. Finally, we study chart reasoning types and visual attributes that pose a challenge to these models.",
    "num_pages": 17
}