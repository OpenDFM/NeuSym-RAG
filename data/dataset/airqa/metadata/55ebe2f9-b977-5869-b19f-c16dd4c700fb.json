{
    "uuid": "55ebe2f9-b977-5869-b19f-c16dd4c700fb",
    "title": "Open-Set Semi-Supervised Text Classification via Adversarial Disagreement Maximization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{chen-etal-2024-open,\n    title = \"Open-Set Semi-Supervised Text Classification via Adversarial Disagreement Maximization\",\n    author = \"Chen, Junfan  and\n      Zhang, Richong  and\n      Chen, Junchi  and\n      Hu, Chunming\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.118\",\n    doi = \"10.18653/v1/2024.acl-long.118\",\n    pages = \"2170--2180\",\n    abstract = \"Open-Set Semi-Supervised Text Classification (OSTC) aims to train a classification model on a limited set of labeled texts, alongside plenty of unlabeled texts that include both in-distribution and out-of-distribution examples. In this paper, we revisit the main challenge in OSTC, i.e., outlier detection, from a measurement disagreement perspective and innovatively propose to improve OSTC performance by directly maximizing the measurement disagreements. Based on the properties of in-measurement and cross-measurements, we design an Adversarial Disagreement Maximization (ADM) model that synergeticly optimizes the measurement disagreements. In addition, we develop an abnormal example detection and measurement calibration approach to guarantee the effectiveness of ADM training. Experiment results and comprehensive analysis of three benchmarks demonstrate the effectiveness of our model.\",\n}\n",
    "authors": [
        "Junfan Chen",
        "Richong Zhang",
        "Junchi Chen",
        "Chunming Hu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.118.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/55ebe2f9-b977-5869-b19f-c16dd4c700fb.pdf",
    "abstract": "Open-Set Semi-Supervised Text Classification (OSTC) aims to train a classification model on a limited set of labeled texts, alongside plenty of unlabeled texts that include both in-distribution and out-of-distribution examples. In this paper, we revisit the main challenge in OSTC, i.e., outlier detection, from a measurement disagreement perspective and innovatively propose to improve OSTC performance by directly maximizing the measurement disagreements. Based on the properties of in-measurement and cross-measurements, we design an Adversarial Disagreement Maximization (ADM) model that synergeticly optimizes the measurement disagreements. In addition, we develop an abnormal example detection and measurement calibration approach to guarantee the effectiveness of ADM training. Experiment results and comprehensive analysis of three benchmarks demonstrate the effectiveness of our model.",
    "num_pages": 11
}