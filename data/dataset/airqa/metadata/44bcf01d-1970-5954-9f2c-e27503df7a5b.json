{
    "uuid": "44bcf01d-1970-5954-9f2c-e27503df7a5b",
    "title": "teamPN at SemEval-2023 Task 1: Visual Word Sense Disambiguation Using Zero-Shot MultiModal Approach",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{katyal-etal-2023-teampn,\n    title = \"team{PN} at {S}em{E}val-2023 Task 1: Visual Word Sense Disambiguation Using Zero-Shot {M}ulti{M}odal Approach\",\n    author = \"Katyal, Nikita  and\n      Rajpoot, Pawan  and\n      Tamilarasu, Subhanandh  and\n      Mustafi, Joy\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.63\",\n    doi = \"10.18653/v1/2023.semeval-1.63\",\n    pages = \"457--461\",\n    abstract = \"Visual Word Sense Disambiguation shared task at SemEval-2023 aims to identify an image corresponding to the intended meaning of a given ambiguous word (with related context) from a set of candidate images. The lack of textual description for the candidate image and the corresponding word{'}s ambiguity makes it a challenging problem. This paper describes teamPN{'}s multi-modal and modular approach to solving this in English track of the task. We efficiently used recent multi-modal pre-trained models backed by real-time multi-modal knowledge graphs to augment textual knowledge for the images and select the best matching image accordingly. We outperformed the baseline model by {\\textasciitilde}5 points and proposed a unique approach that can further work as a framework for other modular and knowledge-backed solutions.\",\n}\n",
    "authors": [
        "Nikita Katyal",
        "Pawan Rajpoot",
        "Subhanandh Tamilarasu",
        "Joy Mustafi"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.63.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/44bcf01d-1970-5954-9f2c-e27503df7a5b.pdf",
    "abstract": "Visual Word Sense Disambiguation shared task at SemEval-2023 aims to identify an image corresponding to the intended meaning of a given ambiguous word (with related context) from a set of candidate images. The lack of textual description for the candidate image and the corresponding word’s ambiguity makes it a challenging problem. This paper describes teamPN’s multi-modal and modular approach to solving this in English track of the task. We efficiently used recent multi-modal pre-trained models backed by real-time multi-modal knowledge graphs to augment textual knowledge for the images and select the best matching image accordingly. We outperformed the baseline model by ~5 points and proposed a unique approach that can further work as a framework for other modular and knowledge-backed solutions.",
    "num_pages": 5
}