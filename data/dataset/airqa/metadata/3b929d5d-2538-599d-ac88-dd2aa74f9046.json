{
    "uuid": "3b929d5d-2538-599d-ac88-dd2aa74f9046",
    "title": "MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{sun-etal-2023-moraldial,\n    title = \"{M}oral{D}ial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions\",\n    author = \"Sun, Hao  and\n      Zhang, Zhexin  and\n      Mi, Fei  and\n      Wang, Yasheng  and\n      Liu, Wei  and\n      Cui, Jianwei  and\n      Wang, Bin  and\n      Liu, Qun  and\n      Huang, Minlie\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.123\",\n    doi = \"10.18653/v1/2023.acl-long.123\",\n    pages = \"2213--2230\",\n    abstract = \"Morality in dialogue systems has raised great attention in research recently. A moral dialogue system aligned with users{'} values could enhance conversation engagement and user connections. In this paper, we propose a framework, MoralDial to train and evaluate moral dialogue systems. In our framework, we first explore the communication mechanisms of morality and resolve expressed morality into three parts, which indicate the roadmap for building a moral dialogue system. Based on that, we design a simple yet effective method: constructing moral discussions between simulated specific users and the dialogue system. The constructed discussions consist of expressing, explaining, revising, and inferring moral views in dialogue exchanges, which makes conversational models learn morality well in a natural manner. Furthermore, we propose a novel evaluation method under the framework. We evaluate the multiple aspects of morality by judging the relation between dialogue responses and human values in discussions, where the multifaceted nature of morality is particularly considered. Automatic and manual experiments demonstrate that our framework is promising to train and evaluate moral dialogue systems.\",\n}\n",
    "authors": [
        "Hao Sun",
        "Zhexin Zhang",
        "Fei Mi",
        "Yasheng Wang",
        "Wei Liu",
        "Jianwei Cui",
        "Bin Wang",
        "Qun Liu",
        "Minlie Huang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.123.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/3b929d5d-2538-599d-ac88-dd2aa74f9046.pdf",
    "abstract": "Morality in dialogue systems has raised great attention in research recently. A moral dialogue system aligned with usersâ€™ values could enhance conversation engagement and user connections. In this paper, we propose a framework, MoralDial to train and evaluate moral dialogue systems. In our framework, we first explore the communication mechanisms of morality and resolve expressed morality into three parts, which indicate the roadmap for building a moral dialogue system. Based on that, we design a simple yet effective method: constructing moral discussions between simulated specific users and the dialogue system. The constructed discussions consist of expressing, explaining, revising, and inferring moral views in dialogue exchanges, which makes conversational models learn morality well in a natural manner. Furthermore, we propose a novel evaluation method under the framework. We evaluate the multiple aspects of morality by judging the relation between dialogue responses and human values in discussions, where the multifaceted nature of morality is particularly considered. Automatic and manual experiments demonstrate that our framework is promising to train and evaluate moral dialogue systems.",
    "num_pages": 18
}