{
    "uuid": "d7370cb5-c804-521a-9e62-8fe6ca240a25",
    "title": "Summarizing, Simplifying, and Synthesizing Medical Evidence using GPT-3 (with Varying Success)",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{shaib-etal-2023-summarizing,\n    title = \"Summarizing, Simplifying, and Synthesizing Medical Evidence using {GPT}-3 (with Varying Success)\",\n    author = \"Shaib, Chantal  and\n      Li, Millicent  and\n      Joseph, Sebastian  and\n      Marshall, Iain  and\n      Li, Junyi Jessy  and\n      Wallace, Byron\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.119\",\n    doi = \"10.18653/v1/2023.acl-short.119\",\n    pages = \"1387--1407\",\n    abstract = \"Large language models, particularly GPT-3, are able to produce high quality summaries ofgeneral domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized domains such as biomedicine. In this paper we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given no supervision. We consider bothsingle- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in thelatter, we assess the degree to which GPT-3 is able to synthesize evidence reported acrossa collection of articles. We design an annotation scheme for evaluating model outputs, withan emphasis on assessing the factual accuracy of generated summaries. We find that whileGPT-3 is able to summarize and simplify single biomedical articles faithfully, it strugglesto provide accurate aggregations of findings over multiple documents. We release all data,code, and annotations used in this work.\",\n}\n",
    "authors": [
        "Chantal Shaib",
        "Millicent Li",
        "Sebastian Joseph",
        "Iain Marshall",
        "Junyi Jessy Li",
        "Byron Wallace"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.119.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/d7370cb5-c804-521a-9e62-8fe6ca240a25.pdf",
    "abstract": "Large language models, particularly GPT-3, are able to produce high quality summaries ofgeneral domain news articles in few- and zero-shot settings. However, it is unclear if such models are similarly capable in more specialized domains such as biomedicine. In this paper we enlist domain experts (individuals with medical training) to evaluate summaries of biomedical articles generated by GPT-3, given no supervision. We consider bothsingle- and multi-document settings. In the former, GPT-3 is tasked with generating regular and plain-language summaries of articles describing randomized controlled trials; in thelatter, we assess the degree to which GPT-3 is able to synthesize evidence reported acrossa collection of articles. We design an annotation scheme for evaluating model outputs, withan emphasis on assessing the factual accuracy of generated summaries. We find that whileGPT-3 is able to summarize and simplify single biomedical articles faithfully, it strugglesto provide accurate aggregations of findings over multiple documents. We release all data,code, and annotations used in this work.",
    "num_pages": 21
}