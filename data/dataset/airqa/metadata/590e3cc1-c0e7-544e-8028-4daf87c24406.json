{
    "uuid": "590e3cc1-c0e7-544e-8028-4daf87c24406",
    "title": "JHU IWSLT 2023 Dialect Speech Translation System Description",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{hussein-etal-2023-jhu,\n    title = \"{JHU} {IWSLT} 2023 Dialect Speech Translation System Description\",\n    author = \"Hussein, Amir  and\n      Xiao, Cihan  and\n      Verma, Neha  and\n      Thebaud, Thomas  and\n      Wiesner, Matthew  and\n      Khudanpur, Sanjeev\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.26\",\n    doi = \"10.18653/v1/2023.iwslt-1.26\",\n    pages = \"283--290\",\n    abstract = \"This paper presents JHU{'}s submissions to the IWSLT 2023 dialectal and low-resource track of Tunisian Arabic to English speech translation. The Tunisian dialect lacks formal orthography and abundant training data, making it challenging to develop effective speech translation (ST) systems. To address these challenges, we explore the integration of large pre-trained machine translation (MT) models, such as mBART and NLLB-200 in both end-to-end (E2E) and cascaded speech translation (ST) systems. We also improve the performance of automatic speech recognition (ASR) through the use of pseudo-labeling data augmentation and channel matching on telephone data. Finally, we combine our E2E and cascaded ST systems with Minimum Bayes-Risk decoding. Our combined system achieves a BLEU score of 21.6 and 19.1 on test2 and test3, respectively.\",\n}\n",
    "authors": [
        "Amir Hussein",
        "Cihan Xiao",
        "Neha Verma",
        "Thomas Thebaud",
        "Matthew Wiesner",
        "Sanjeev Khudanpur"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.26.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/590e3cc1-c0e7-544e-8028-4daf87c24406.pdf",
    "abstract": "This paper presents JHUâ€™s submissions to the IWSLT 2023 dialectal and low-resource track of Tunisian Arabic to English speech translation. The Tunisian dialect lacks formal orthography and abundant training data, making it challenging to develop effective speech translation (ST) systems. To address these challenges, we explore the integration of large pre-trained machine translation (MT) models, such as mBART and NLLB-200 in both end-to-end (E2E) and cascaded speech translation (ST) systems. We also improve the performance of automatic speech recognition (ASR) through the use of pseudo-labeling data augmentation and channel matching on telephone data. Finally, we combine our E2E and cascaded ST systems with Minimum Bayes-Risk decoding. Our combined system achieves a BLEU score of 21.6 and 19.1 on test2 and test3, respectively.",
    "num_pages": 8
}