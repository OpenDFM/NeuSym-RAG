{
    "uuid": "a23058c1-3baa-50d5-9e8e-6a858d28df26",
    "title": "Incomplete Utterance Rewriting as Sequential Greedy Tagging",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{chen-2023-incomplete,\n    title = \"Incomplete Utterance Rewriting as Sequential Greedy Tagging\",\n    author = \"Chen, Yunshan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.456\",\n    doi = \"10.18653/v1/2023.findings-acl.456\",\n    pages = \"7265--7276\",\n    abstract = \"The task of incomplete utterance rewriting has recently gotten much attention. Previous models struggled to extract information from the dialogue context, as evidenced by the low restoration scores. To address this issue, we propose a novel sequence tagging-based model, which is more adept at extracting information from context. Meanwhile, we introduce speaker-aware embedding to model speaker variation. Experiments on multiple public datasets show that our model achieves optimal results on all nine restoration scores while having other metric scores comparable to previous state-of-the-art models. Furthermore, benefitting from the model{'}s simplicity, our approach outperforms most previous models on inference speed.\",\n}\n",
    "authors": [
        "Yunshan Chen"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.456.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a23058c1-3baa-50d5-9e8e-6a858d28df26.pdf",
    "abstract": "The task of incomplete utterance rewriting has recently gotten much attention. Previous models struggled to extract information from the dialogue context, as evidenced by the low restoration scores. To address this issue, we propose a novel sequence tagging-based model, which is more adept at extracting information from context. Meanwhile, we introduce speaker-aware embedding to model speaker variation. Experiments on multiple public datasets show that our model achieves optimal results on all nine restoration scores while having other metric scores comparable to previous state-of-the-art models. Furthermore, benefitting from the modelâ€™s simplicity, our approach outperforms most previous models on inference speed.",
    "num_pages": 12
}