{
    "uuid": "73662d92-74ff-5256-8638-5bf04b503a73",
    "title": "Chain-of-Quizzes: Pedagogy-inspired Example Selection in In-Context-Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{wu-etal-2024-chain,\n    title = \"Chain-of-Quizzes: Pedagogy-inspired Example Selection in In-Context-Learning\",\n    author = \"Wu, Yiquan  and\n      Zhou, Anlai  and\n      Liu, Yuhang  and\n      Liu, Yifei  and\n      Jatowt, Adam  and\n      Lu, Weiming  and\n      Xiao, Jun  and\n      Kuang, Kun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.603\",\n    doi = \"10.18653/v1/2024.findings-acl.603\",\n    pages = \"10136--10142\",\n    abstract = \"In-context learning (ICL) has emerged as a powerful tool for enhancing large language models (LLMs) in addressing downstream tasks. In this paper, we explore the vital task of example selection in ICL by mimicking the human learning process. We propose a Chain-of-Quizzes (CoQ) framework inspired by educational theories such as Bruner{'}s Spiral Learning and Mastery Learning theory. Specifically, our framework employs the LLMs to answer the quiz (question in the example) to sift {`}good{'} examples, combines these examples iteratively with the increasing complexity, and utilizes a final exam to gauge the combined example chains. Our extensive experiments on diverse reasoning datasets show the proposed approach outperforms baseline models. These findings underscore the framework{'}s potential for future research.\",\n}\n",
    "authors": [
        "Yiquan Wu",
        "Anlai Zhou",
        "Yuhang Liu",
        "Yifei Liu",
        "Adam Jatowt",
        "Weiming Lu",
        "Jun Xiao",
        "Kun Kuang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.603.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/73662d92-74ff-5256-8638-5bf04b503a73.pdf",
    "abstract": "In-context learning (ICL) has emerged as a powerful tool for enhancing large language models (LLMs) in addressing downstream tasks. In this paper, we explore the vital task of example selection in ICL by mimicking the human learning process. We propose a Chain-of-Quizzes (CoQ) framework inspired by educational theories such as Bruner’s Spiral Learning and Mastery Learning theory. Specifically, our framework employs the LLMs to answer the quiz (question in the example) to sift ‘good’ examples, combines these examples iteratively with the increasing complexity, and utilizes a final exam to gauge the combined example chains. Our extensive experiments on diverse reasoning datasets show the proposed approach outperforms baseline models. These findings underscore the framework’s potential for future research.",
    "num_pages": 7
}