{
    "uuid": "25f1cec1-f20b-5515-9c1a-dbf45db8afb5",
    "title": "Contrastive Learning with Generated Representations for Inductive Knowledge Graph Embedding",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{li-etal-2023-contrastive-learning,\n    title = \"Contrastive Learning with Generated Representations for Inductive Knowledge Graph Embedding\",\n    author = \"Li, Qian  and\n      Joty, Shafiq  and\n      Wang, Daling  and\n      Feng, Shi  and\n      Zhang, Yifei  and\n      Qin, Chengwei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.900\",\n    doi = \"10.18653/v1/2023.findings-acl.900\",\n    pages = \"14273--14287\",\n    abstract = \"With the evolution of Knowledge Graphs (KGs), new entities emerge which are not seen before. Representation learning of KGs in such an inductive setting aims to capture and transfer the structural patterns from existing entities to new entities. However, the performance of existing methods in inductive KGs are limited by sparsity and implicit transfer. In this paper, we propose VMCL, a Contrastive Learning (CL) framework with graph guided Variational autoencoder on Meta-KGs in the inductive setting. We first propose representation generation to capture the encoded and generated representations of entities, where the generated variations can densify representations with complementary features. Then, we design two CL objectives that work across entities and meta-KGs to simulate the transfer mode. With extensive experiments we demonstrate that our proposed VMCL can significantly outperform previous state-of-the-art baselines.\",\n}\n",
    "authors": [
        "Qian Li",
        "Shafiq Joty",
        "Daling Wang",
        "Shi Feng",
        "Yifei Zhang",
        "Chengwei Qin"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.900.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/25f1cec1-f20b-5515-9c1a-dbf45db8afb5.pdf",
    "abstract": "With the evolution of Knowledge Graphs (KGs), new entities emerge which are not seen before. Representation learning of KGs in such an inductive setting aims to capture and transfer the structural patterns from existing entities to new entities. However, the performance of existing methods in inductive KGs are limited by sparsity and implicit transfer. In this paper, we propose VMCL, a Contrastive Learning (CL) framework with graph guided Variational autoencoder on Meta-KGs in the inductive setting. We first propose representation generation to capture the encoded and generated representations of entities, where the generated variations can densify representations with complementary features. Then, we design two CL objectives that work across entities and meta-KGs to simulate the transfer mode. With extensive experiments we demonstrate that our proposed VMCL can significantly outperform previous state-of-the-art baselines.",
    "num_pages": 15
}