{
    "uuid": "5fc1d693-a4ee-5600-be0e-4de93b6b8b02",
    "title": "Improving Domain Generalization for Prompt-Aware Essay Scoring via Disentangled Representation Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{jiang-etal-2023-improving,\n    title = \"Improving Domain Generalization for Prompt-Aware Essay Scoring via Disentangled Representation Learning\",\n    author = \"Jiang, Zhiwei  and\n      Gao, Tianyi  and\n      Yin, Yafeng  and\n      Liu, Meng  and\n      Yu, Hua  and\n      Cheng, Zifeng  and\n      Gu, Qing\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.696\",\n    doi = \"10.18653/v1/2023.acl-long.696\",\n    pages = \"12456--12470\",\n    abstract = \"Automated Essay Scoring (AES) aims to score essays written in response to specific prompts. Many AES models have been proposed, but most of them are either prompt-specific or prompt-adaptive and cannot generalize well on {``}unseen{''} prompts. This work focuses on improving the generalization ability of AES models from the perspective of domain generalization, where the data of target prompts cannot be accessed during training. Specifically, we propose a prompt-aware neural AES model to extract comprehensive representation for essay scoring, including both prompt-invariant and prompt-specific features. To improve the generalization of representation, we further propose a novel disentangled representation learning framework. In this framework, a contrastive norm-angular alignment strategy and a counterfactual self-training strategy are designed to disentangle the prompt-invariant information and prompt-specific information in representation. Extensive experimental results on datasets of both ASAP and TOEFL11 demonstrate the effectiveness of our method under the domain generalization setting.\",\n}\n",
    "authors": [
        "Zhiwei Jiang",
        "Tianyi Gao",
        "Yafeng Yin",
        "Meng Liu",
        "Hua Yu",
        "Zifeng Cheng",
        "Qing Gu"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.696.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/5fc1d693-a4ee-5600-be0e-4de93b6b8b02.pdf",
    "abstract": "Automated Essay Scoring (AES) aims to score essays written in response to specific prompts. Many AES models have been proposed, but most of them are either prompt-specific or prompt-adaptive and cannot generalize well on “unseen” prompts. This work focuses on improving the generalization ability of AES models from the perspective of domain generalization, where the data of target prompts cannot be accessed during training. Specifically, we propose a prompt-aware neural AES model to extract comprehensive representation for essay scoring, including both prompt-invariant and prompt-specific features. To improve the generalization of representation, we further propose a novel disentangled representation learning framework. In this framework, a contrastive norm-angular alignment strategy and a counterfactual self-training strategy are designed to disentangle the prompt-invariant information and prompt-specific information in representation. Extensive experimental results on datasets of both ASAP and TOEFL11 demonstrate the effectiveness of our method under the domain generalization setting.",
    "num_pages": 15
}