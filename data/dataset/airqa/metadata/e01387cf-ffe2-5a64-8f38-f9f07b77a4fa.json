{
    "uuid": "e01387cf-ffe2-5a64-8f38-f9f07b77a4fa",
    "title": "Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhong-etal-2024-benchmarking,\n    title = \"Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation\",\n    author = \"Zhong, Tianqi  and\n      Li, Zhaoyi  and\n      Wang, Quan  and\n      Song, Linqi  and\n      Wei, Ying  and\n      Lian, Defu  and\n      Mao, Zhendong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.351\",\n    doi = \"10.18653/v1/2024.acl-long.351\",\n    pages = \"6486--6517\",\n    abstract = \"Compositional generalization, representing the model{'}s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking. We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of MCTG approaches. We observe that existing MCTG works generally confront a noticeable performance drop in compositional testing. To mitigate this issue, we introduce Meta-MCTG, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase. We demonstrate the effectiveness of Meta-MCTG through achieving obvious improvement (by at most 3.64{\\%}) for compositional testing performance in 94.4{\\%}.\",\n}\n",
    "authors": [
        "Tianqi Zhong",
        "Zhaoyi Li",
        "Quan Wang",
        "Linqi Song",
        "Ying Wei",
        "Defu Lian",
        "Zhendong Mao"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.351.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/e01387cf-ffe2-5a64-8f38-f9f07b77a4fa.pdf",
    "abstract": "Compositional generalization, representing the modelâ€™s ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking. We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of MCTG approaches. We observe that existing MCTG works generally confront a noticeable performance drop in compositional testing. To mitigate this issue, we introduce Meta-MCTG, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase. We demonstrate the effectiveness of Meta-MCTG through achieving obvious improvement (by at most 3.64%) for compositional testing performance in 94.4%.",
    "num_pages": 32
}