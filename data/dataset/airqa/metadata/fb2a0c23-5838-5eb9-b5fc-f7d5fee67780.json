{
    "uuid": "fb2a0c23-5838-5eb9-b5fc-f7d5fee67780",
    "title": "TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{ahn-etal-2024-timechara,\n    title = \"{T}ime{C}hara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models\",\n    author = \"Ahn, Jaewoo  and\n      Lee, Taehyun  and\n      Lim, Junyoung  and\n      Kim, Jin-Hwa  and\n      Yun, Sangdoo  and\n      Lee, Hwaran  and\n      Kim, Gunhee\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.197\",\n    doi = \"10.18653/v1/2024.findings-acl.197\",\n    pages = \"3291--3325\",\n    abstract = \"While Large Language Models (LLMs) can serve as agents to simulate human behaviors (i.e., role-playing agents), we emphasize the importance of point-in-time role-playing. This situates characters at specific moments in the narrative progression for three main reasons: (i) enhancing users{'} narrative immersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom role-playing. To accurately represent characters at specific time points, agents must avoid character hallucination, where they display knowledge that contradicts their characters{'} identities and historical timelines. We introduce TimeChara, a new benchmark designed to evaluate point-in-time character hallucination in role-playing LLMs. Comprising 10,895 instances generated through an automated pipeline, this benchmark reveals significant hallucination issues in current state-of-the-art LLMs (e.g., GPT-4o). To counter this challenge, we propose Narrative-Experts, a method that decomposes the reasoning steps and utilizes narrative experts to reduce point-in-time character hallucinations effectively. Still, our findings with TimeChara highlight the ongoing challenges of point-in-time character hallucination, calling for further study.\",\n}\n",
    "authors": [
        "Jaewoo Ahn",
        "Taehyun Lee",
        "Junyoung Lim",
        "Jin-Hwa Kim",
        "Sangdoo Yun",
        "Hwaran Lee",
        "Gunhee Kim"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.197.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/fb2a0c23-5838-5eb9-b5fc-f7d5fee67780.pdf",
    "abstract": "While Large Language Models (LLMs) can serve as agents to simulate human behaviors (i.e., role-playing agents), we emphasize the importance of point-in-time role-playing. This situates characters at specific moments in the narrative progression for three main reasons: (i) enhancing users’ narrative immersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom role-playing. To accurately represent characters at specific time points, agents must avoid character hallucination, where they display knowledge that contradicts their characters’ identities and historical timelines. We introduce TimeChara, a new benchmark designed to evaluate point-in-time character hallucination in role-playing LLMs. Comprising 10,895 instances generated through an automated pipeline, this benchmark reveals significant hallucination issues in current state-of-the-art LLMs (e.g., GPT-4o). To counter this challenge, we propose Narrative-Experts, a method that decomposes the reasoning steps and utilizes narrative experts to reduce point-in-time character hallucinations effectively. Still, our findings with TimeChara highlight the ongoing challenges of point-in-time character hallucination, calling for further study.",
    "num_pages": 35
}