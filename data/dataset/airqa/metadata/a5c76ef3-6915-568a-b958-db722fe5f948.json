{
    "uuid": "a5c76ef3-6915-568a-b958-db722fe5f948",
    "title": "Natural Language to Code Generation in Interactive Data Science Notebooks",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{yin-etal-2023-natural,\n    title = \"Natural Language to Code Generation in Interactive Data Science Notebooks\",\n    author = \"Yin, Pengcheng  and\n      Li, Wen-Ding  and\n      Xiao, Kefan  and\n      Rao, Abhishek  and\n      Wen, Yeming  and\n      Shi, Kensen  and\n      Howland, Joshua  and\n      Bailey, Paige  and\n      Catasta, Michele  and\n      Michalewski, Henryk  and\n      Polozov, Oleksandr  and\n      Sutton, Charles\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.9\",\n    doi = \"10.18653/v1/2023.acl-long.9\",\n    pages = \"126--173\",\n    abstract = \"Computational notebooks, such as Jupyter notebooks, are interactive computing environments that are ubiquitous among data scientists to perform data wrangling and analytic tasks. To measure the performance of AI pair programmers that automatically synthesize programs for those tasks given natural language (NL) intents from users, we build ARCADE, a benchmark of 1078 code generation problems using the pandas data analysis framework in data science notebooks. ARCADE features multiple rounds of NL-to-code problems from the same notebook. It requires a model to understand rich multi-modal contexts, such as existing notebook cells and their execution states as well as previous turns of interaction. To establish a strong baseline on this challenging task, we develop PaChiNCo, a 62B code language model (LM) for Python computational notebooks, which significantly outperforms public code LMs. Finally, we explore few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanation, showing the potential to improve the diversity and explainability of model predictions. Arcade is publicly available at \\url{https://github.com/google-research/arcade-nl2code/}.\",\n}\n",
    "authors": [
        "Pengcheng Yin",
        "Wen-Ding Li",
        "Kefan Xiao",
        "Abhishek Rao",
        "Yeming Wen",
        "Kensen Shi",
        "Joshua Howland",
        "Paige Bailey",
        "Michele Catasta",
        "Henryk Michalewski",
        "Oleksandr Polozov",
        "Charles Sutton"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.9.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a5c76ef3-6915-568a-b958-db722fe5f948.pdf",
    "abstract": "Computational notebooks, such as Jupyter notebooks, are interactive computing environments that are ubiquitous among data scientists to perform data wrangling and analytic tasks. To measure the performance of AI pair programmers that automatically synthesize programs for those tasks given natural language (NL) intents from users, we build ARCADE, a benchmark of 1078 code generation problems using the pandas data analysis framework in data science notebooks. ARCADE features multiple rounds of NL-to-code problems from the same notebook. It requires a model to understand rich multi-modal contexts, such as existing notebook cells and their execution states as well as previous turns of interaction. To establish a strong baseline on this challenging task, we develop PaChiNCo, a 62B code language model (LM) for Python computational notebooks, which significantly outperforms public code LMs. Finally, we explore few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanation, showing the potential to improve the diversity and explainability of model predictions. Arcade is publicly available at https://github.com/google-research/arcade-nl2code/.",
    "num_pages": 48
}