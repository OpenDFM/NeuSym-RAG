{
    "uuid": "5dbdd326-788d-5791-89c0-a21590dbb7ce",
    "title": "Emotion classification on code-mixed text messages via soft prompt tuning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{zhang-etal-2023-emotion,\n    title = \"Emotion classification on code-mixed text messages via soft prompt tuning\",\n    author = \"Zhang, Jinghui  and\n      Yang, Dongming  and\n      Bao, Siyu  and\n      Cao, Lina  and\n      Fan, Shunguo\",\n    editor = \"Barnes, Jeremy  and\n      De Clercq, Orph{\\'e}e  and\n      Klinger, Roman\",\n    booktitle = \"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wassa-1.57\",\n    doi = \"10.18653/v1/2023.wassa-1.57\",\n    pages = \"596--600\",\n    abstract = \"Emotion classification on code-mixed text messages is challenging due to the multilingual languages and non-literal cues (i.e., emoticons). To solve these problems, we propose an innovative soft prompt tuning method, which is lightweight and effective to release potential abilities of the pre-trained language models and improve the classification results. Firstly, we transform emoticons into textual information to utilize their rich emotional information. Then, variety of innovative templates and verbalizers are applied to promote emotion classification. Extensive experiments show that transforming emoticons and employing prompt tuning both benefit the performance. Finally, as a part of WASSA 2023, we obtain the accuracy of 0.972 in track MLEC and 0.892 in track MCEC, yielding the second place in both two tracks.\",\n}\n",
    "authors": [
        "Jinghui Zhang",
        "Dongming Yang",
        "Siyu Bao",
        "Lina Cao",
        "Shunguo Fan"
    ],
    "pdf_url": "https://aclanthology.org/2023.wassa-1.57.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/5dbdd326-788d-5791-89c0-a21590dbb7ce.pdf",
    "abstract": "Emotion classification on code-mixed text messages is challenging due to the multilingual languages and non-literal cues (i.e., emoticons). To solve these problems, we propose an innovative soft prompt tuning method, which is lightweight and effective to release potential abilities of the pre-trained language models and improve the classification results. Firstly, we transform emoticons into textual information to utilize their rich emotional information. Then, variety of innovative templates and verbalizers are applied to promote emotion classification. Extensive experiments show that transforming emoticons and employing prompt tuning both benefit the performance. Finally, as a part of WASSA 2023, we obtain the accuracy of 0.972 in track MLEC and 0.892 in track MCEC, yielding the second place in both two tracks.",
    "num_pages": 5
}