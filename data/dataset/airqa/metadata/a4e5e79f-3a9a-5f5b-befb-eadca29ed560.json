{
    "uuid": "a4e5e79f-3a9a-5f5b-befb-eadca29ed560",
    "title": "Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{sel-etal-2024-skin,\n    title = \"Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in {LLM}s\",\n    author = \"Sel, Bilgehan  and\n      Shanmugasundaram, Priya  and\n      Kachuee, Mohammad  and\n      Zhou, Kun  and\n      Jia, Ruoxi  and\n      Jin, Ming\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.751\",\n    doi = \"10.18653/v1/2024.acl-long.751\",\n    pages = \"13921--13959\",\n    abstract = \"Large Language Models (LLMs) have shown remarkable capabilities in tasks such as summarization, arithmetic reasoning, and question answering. However, they encounter significant challenges in the domain of moral reasoning and ethical decision-making, especially in complex scenarios with multiple stakeholders. This paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing moral reasoning in LLMs by exploring decisions{'} consequences from multiple stakeholder perspectives. The core components of the framework consist of simulating accountability for decisions, conducting empathy exercises on different stakeholders, and evaluating the risks associated with the impacts of potential actions. We study SKIG{'}s performance across various moral reasoning benchmarks with proprietary and open-source LLMs, and investigate its crucial components through extensive ablation analyses. Our framework exhibits marked improvements in performance compared to baselines across different language models and benchmarks.\",\n}\n",
    "authors": [
        "Bilgehan Sel",
        "Priya Shanmugasundaram",
        "Mohammad Kachuee",
        "Kun Zhou",
        "Ruoxi Jia",
        "Ming Jin"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.751.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a4e5e79f-3a9a-5f5b-befb-eadca29ed560.pdf",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tasks such as summarization, arithmetic reasoning, and question answering. However, they encounter significant challenges in the domain of moral reasoning and ethical decision-making, especially in complex scenarios with multiple stakeholders. This paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing moral reasoning in LLMs by exploring decisions’ consequences from multiple stakeholder perspectives. The core components of the framework consist of simulating accountability for decisions, conducting empathy exercises on different stakeholders, and evaluating the risks associated with the impacts of potential actions. We study SKIG’s performance across various moral reasoning benchmarks with proprietary and open-source LLMs, and investigate its crucial components through extensive ablation analyses. Our framework exhibits marked improvements in performance compared to baselines across different language models and benchmarks.",
    "num_pages": 39
}