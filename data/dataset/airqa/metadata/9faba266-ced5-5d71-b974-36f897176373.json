{
    "uuid": "9faba266-ced5-5d71-b974-36f897176373",
    "title": "Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{wang-etal-2024-mementos,\n    title = \"Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences\",\n    author = \"Wang, Xiyao  and\n      Zhou, Yuhang  and\n      Liu, Xiaoyu  and\n      Lu, Hongjin  and\n      Xu, Yuancheng  and\n      He, Feihong  and\n      Yoon, Jaehong  and\n      Lu, Taixi  and\n      Liu, Fuxiao  and\n      Bertasius, Gedas  and\n      Bansal, Mohit  and\n      Yao, Huaxiu  and\n      Huang, Furong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.25\",\n    doi = \"10.18653/v1/2024.acl-long.25\",\n    pages = \"416--442\",\n    abstract = \"Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate from image sequences, which is essential for understanding our ever-changing world, has been less investigated. To address this challenge, this paper introduces Mementos, a new benchmark designed to assess MLLMs{'} sequential image reasoning abilities. Mementos features 4,761 diverse image sequences with varying lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning performance. Through a careful evaluation of nine recent MLLMs on Mementos, including GPT-4V and Gemini, we find that they struggle to accurately describe dynamic information about given image sequences, often leading to hallucinations/misrepresentations of objects and their corresponding behaviors. Our quantitative analysis and case studies identify three key factors impacting MLLMs{'} sequential image reasoning: the correlation between object and behavioral hallucinations, the influence of co-occurring behaviors, and the compounding impact of behavioral hallucinations.\",\n}\n",
    "authors": [
        "Xiyao Wang",
        "Yuhang Zhou",
        "Xiaoyu Liu",
        "Hongjin Lu",
        "Yuancheng Xu",
        "Feihong He",
        "Jaehong Yoon",
        "Taixi Lu",
        "Fuxiao Liu",
        "Gedas Bertasius",
        "Mohit Bansal",
        "Huaxiu Yao",
        "Furong Huang"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.25.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9faba266-ced5-5d71-b974-36f897176373.pdf",
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated proficiency in handling a variety of visual-language tasks. However, current MLLM benchmarks are predominantly designed to evaluate reasoning based on static information about a single image, and the ability of modern MLLMs to extrapolate from image sequences, which is essential for understanding our ever-changing world, has been less investigated. To address this challenge, this paper introduces Mementos, a new benchmark designed to assess MLLMs’ sequential image reasoning abilities. Mementos features 4,761 diverse image sequences with varying lengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning performance. Through a careful evaluation of nine recent MLLMs on Mementos, including GPT-4V and Gemini, we find that they struggle to accurately describe dynamic information about given image sequences, often leading to hallucinations/misrepresentations of objects and their corresponding behaviors. Our quantitative analysis and case studies identify three key factors impacting MLLMs’ sequential image reasoning: the correlation between object and behavioral hallucinations, the influence of co-occurring behaviors, and the compounding impact of behavioral hallucinations.",
    "num_pages": 27
}