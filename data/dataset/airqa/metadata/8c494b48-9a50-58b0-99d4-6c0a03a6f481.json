{
    "uuid": "8c494b48-9a50-58b0-99d4-6c0a03a6f481",
    "title": "Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhang-etal-2024-knowledgeable,\n    title = \"Knowledgeable Preference Alignment for {LLM}s in Domain-specific Question Answering\",\n    author = \"Zhang, Yichi  and\n      Chen, Zhuo  and\n      Fang, Yin  and\n      Lu, Yanxi  and\n      Fangming, Li  and\n      Zhang, Wen  and\n      Chen, Huajun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.52\",\n    doi = \"10.18653/v1/2024.findings-acl.52\",\n    pages = \"891--904\",\n    abstract = \"Deploying large language models (LLMs) to real scenarios for domain-specific question answering (QA) is a key thrust for LLM applications, which poses numerous challenges, especially in ensuring that responses are both accommodating to user requirements and appropriately leveraging domain-specific knowledge bases. They are the two major difficulties for LLM application as vanilla fine-tuning falls short of addressing. Combining these requirements, we conceive of them as the requirement for the model{'}s preference to be harmoniously aligned with humans{'}. Thus, we introduce Knowledgeable Preference AlignmenT (KnowPAT), which constructs two kinds of preference sets to tackle the two issues. Besides, we design a new alignment objective to align the LLM preference with different human preferences uniformly, aiming to optimize LLM performance in real-world, domain-specific QA settings. Adequate experiments and comprehensive comparisons with 15 baseline methods illustrate that our KnowPAT is a superior pipeline for real-scenario domain-specific QA with LLMs.\",\n}\n",
    "authors": [
        "Yichi Zhang",
        "Zhuo Chen",
        "Yin Fang",
        "Yanxi Lu",
        "Li Fangming",
        "Wen Zhang",
        "Huajun Chen"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.52.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8c494b48-9a50-58b0-99d4-6c0a03a6f481.pdf",
    "abstract": "Deploying large language models (LLMs) to real scenarios for domain-specific question answering (QA) is a key thrust for LLM applications, which poses numerous challenges, especially in ensuring that responses are both accommodating to user requirements and appropriately leveraging domain-specific knowledge bases. They are the two major difficulties for LLM application as vanilla fine-tuning falls short of addressing. Combining these requirements, we conceive of them as the requirement for the model’s preference to be harmoniously aligned with humans’. Thus, we introduce Knowledgeable Preference AlignmenT (KnowPAT), which constructs two kinds of preference sets to tackle the two issues. Besides, we design a new alignment objective to align the LLM preference with different human preferences uniformly, aiming to optimize LLM performance in real-world, domain-specific QA settings. Adequate experiments and comprehensive comparisons with 15 baseline methods illustrate that our KnowPAT is a superior pipeline for real-scenario domain-specific QA with LLMs.",
    "num_pages": 14
}