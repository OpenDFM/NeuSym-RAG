{
    "uuid": "90b7a186-4867-5c3b-8b84-8199dbf171e4",
    "title": "TAM of SCNU at SemEval-2023 Task 1: FCLL: A Fine-grained Contrastive Language-Image Learning Model for Cross-language Visual Word Sense Disambiguation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{yang-etal-2023-tam,\n    title = \"{TAM} of {SCNU} at {S}em{E}val-2023 Task 1: {FCLL}: A Fine-grained Contrastive Language-Image Learning Model for Cross-language Visual Word Sense Disambiguation\",\n    author = \"Yang, Qihao  and\n      Li, Yong  and\n      Wang, Xuelin  and\n      Li, Shunhao  and\n      Hao, Tianyong\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.70\",\n    doi = \"10.18653/v1/2023.semeval-1.70\",\n    pages = \"506--511\",\n    abstract = \"Visual Word Sense Disambiguation (WSD), as a fine-grained image-text retrieval task, aims to identify the images that are relevant to ambiguous target words or phrases. However, the difficulties of limited contextual information and cross-linguistic background knowledge in text processing make this task challenging. To alleviate this issue, we propose a Fine-grained Contrastive Language-Image Learning (FCLL) model, which learns fine-grained image-text knowledge by employing a new fine-grained contrastive learning mechanism and enriches contextual information by establishing relationship between concepts and sentences. In addition, a new multimodal-multilingual knowledge base involving ambiguous target words is constructed for visual WSD. Experiment results on the benchmark datasets from SemEval-2023 Task 1 show that our FCLL ranks at the first in overall evaluation with an average H@1 of 72.56{\\textbackslash}{\\%} and an average MRR of 82.22{\\textbackslash}{\\%}. The results demonstrate that FCLL is effective in inference on fine-grained language-vision knowledge. Source codes and the knowledge base are publicly available at \\url{https://github.com/CharlesYang030/FCLL}.\",\n}\n",
    "authors": [
        "Qihao Yang",
        "Yong Li",
        "Xuelin Wang",
        "Shunhao Li",
        "Tianyong Hao"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.70.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/90b7a186-4867-5c3b-8b84-8199dbf171e4.pdf",
    "abstract": "Visual Word Sense Disambiguation (WSD), as a fine-grained image-text retrieval task, aims to identify the images that are relevant to ambiguous target words or phrases. However, the difficulties of limited contextual information and cross-linguistic background knowledge in text processing make this task challenging. To alleviate this issue, we propose a Fine-grained Contrastive Language-Image Learning (FCLL) model, which learns fine-grained image-text knowledge by employing a new fine-grained contrastive learning mechanism and enriches contextual information by establishing relationship between concepts and sentences. In addition, a new multimodal-multilingual knowledge base involving ambiguous target words is constructed for visual WSD. Experiment results on the benchmark datasets from SemEval-2023 Task 1 show that our FCLL ranks at the first in overall evaluation with an average H@1 of 72.56\\% and an average MRR of 82.22\\%. The results demonstrate that FCLL is effective in inference on fine-grained language-vision knowledge. Source codes and the knowledge base are publicly available at https://github.com/CharlesYang030/FCLL.",
    "num_pages": 6
}