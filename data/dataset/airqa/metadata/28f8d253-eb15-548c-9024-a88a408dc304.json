{
    "uuid": "28f8d253-eb15-548c-9024-a88a408dc304",
    "title": "Generating and Evaluating Plausible Explanations for Knowledge Graph Completion",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{di-mauro-etal-2024-generating,\n    title = \"Generating and Evaluating Plausible Explanations for Knowledge Graph Completion\",\n    author = \"Di Mauro, Antonio  and\n      Xu, Zhao  and\n      Ben Rim, Wiem  and\n      Sztyler, Timo  and\n      Lawrence, Carolin\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.654\",\n    doi = \"10.18653/v1/2024.acl-long.654\",\n    pages = \"12106--12118\",\n    abstract = \"Explanations for AI should aid human users, yet this ultimate goal remains under-explored. This paper aims to bridge this gap by investigating the specific explanatory needs of human users in the context of Knowledge Graph Completion (KGC) systems. In contrast to the prevailing approaches that primarily focus on mathematical theories, we recognize the potential limitations of explanations that may end up being overly complex or nonsensical for users. Through in-depth user interviews, we gain valuable insights into the types of KGC explanations users seek. Building upon these insights, we introduce GradPath, a novel path-based explanation method designed to meet human-centric explainability constraints and enhance plausibility. Additionally, GradPath harnesses the gradients of the trained KGC model to maintain a certain level of faithfulness. We verify the effectiveness of GradPath through well-designed human-centric evaluations. The results confirm that our method provides explanations that users consider more plausible than previous ones.\",\n}\n",
    "authors": [
        "Antonio Di Mauro",
        "Zhao Xu",
        "Wiem Ben Rim",
        "Timo Sztyler",
        "Carolin Lawrence"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.654.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/28f8d253-eb15-548c-9024-a88a408dc304.pdf",
    "abstract": "Explanations for AI should aid human users, yet this ultimate goal remains under-explored. This paper aims to bridge this gap by investigating the specific explanatory needs of human users in the context of Knowledge Graph Completion (KGC) systems. In contrast to the prevailing approaches that primarily focus on mathematical theories, we recognize the potential limitations of explanations that may end up being overly complex or nonsensical for users. Through in-depth user interviews, we gain valuable insights into the types of KGC explanations users seek. Building upon these insights, we introduce GradPath, a novel path-based explanation method designed to meet human-centric explainability constraints and enhance plausibility. Additionally, GradPath harnesses the gradients of the trained KGC model to maintain a certain level of faithfulness. We verify the effectiveness of GradPath through well-designed human-centric evaluations. The results confirm that our method provides explanations that users consider more plausible than previous ones.",
    "num_pages": 13
}