{
    "uuid": "a69c2e10-75cd-5467-9f49-833849c587f4",
    "title": "EPFL-MAKE at “Discharge Me!”: An LLM System for Automatically Generating Discharge Summaries of Clinical Electronic Health Record",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{wu-etal-2024-epfl,\n    title = \"{EPFL}-{MAKE} at {``}Discharge Me!{''}: An {LLM} System for Automatically Generating Discharge Summaries of Clinical Electronic Health Record\",\n    author = \"Wu, Haotian  and\n      Boulenger, Paul  and\n      Faure, Antonin  and\n      C{\\'e}spedes, Berta  and\n      Boukil, Farouk  and\n      Morel, Nastasia  and\n      Chen, Zeming  and\n      Bosselut, Antoine\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.61\",\n    doi = \"10.18653/v1/2024.bionlp-1.61\",\n    pages = \"696--711\",\n    abstract = \"This paper presents our contribution to the Streamlining Discharge Documentation shared task organized as part of the ACL{'}24 workshop. We propose MEDISCHARGE (Meditron-7B Based Medical Summary Generation System for Discharge Me), an LLM-based system to generate Brief Hospital Course and Discharge Instruction summaries based on a patient{'}s Electronic Health Record. Our system is build on a Meditron-7B with context window extension, ensuring the system can handle cases of variable lengths with high quality. When the length of the input exceeds the system input limitation, we use a dynamic information selection framework to automatically extract important sections from the full discharge text. Then, extracted sections are removed in increasing order of importance until the input length requirement is met. We demonstrate our approach outperforms tripling the size of the context window of the model. Our system obtains a 0.289 overall score in the leaderboard, an improvement of 183{\\%} compared to the baseline, and a ROUGE-1 score of 0.444, achieving a second place performance in the shared task.\",\n}\n",
    "authors": [
        "Haotian Wu",
        "Paul Boulenger",
        "Antonin Faure",
        "Berta Céspedes",
        "Farouk Boukil",
        "Nastasia Morel",
        "Zeming Chen",
        "Antoine Bosselut"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.61.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a69c2e10-75cd-5467-9f49-833849c587f4.pdf",
    "abstract": "This paper presents our contribution to the Streamlining Discharge Documentation shared task organized as part of the ACL’24 workshop. We propose MEDISCHARGE (Meditron-7B Based Medical Summary Generation System for Discharge Me), an LLM-based system to generate Brief Hospital Course and Discharge Instruction summaries based on a patient’s Electronic Health Record. Our system is build on a Meditron-7B with context window extension, ensuring the system can handle cases of variable lengths with high quality. When the length of the input exceeds the system input limitation, we use a dynamic information selection framework to automatically extract important sections from the full discharge text. Then, extracted sections are removed in increasing order of importance until the input length requirement is met. We demonstrate our approach outperforms tripling the size of the context window of the model. Our system obtains a 0.289 overall score in the leaderboard, an improvement of 183% compared to the baseline, and a ROUGE-1 score of 0.444, achieving a second place performance in the shared task.",
    "num_pages": 16
}