{
    "uuid": "884cc9b4-b494-5309-9b34-eadde4bd3c32",
    "title": "Targeted Data Generation: Finding and Fixing Model Weaknesses",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{he-etal-2023-targeted,\n    title = \"Targeted Data Generation: Finding and Fixing Model Weaknesses\",\n    author = \"He, Zexue  and\n      Ribeiro, Marco Tulio  and\n      Khani, Fereshte\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.474\",\n    doi = \"10.18653/v1/2023.acl-long.474\",\n    pages = \"8506--8520\",\n    abstract = \"Even when aggregate accuracy is high, state-of-the-art NLP models often fail systematically on specific subgroups of data, resulting in unfair outcomes and eroding user trust. Additional data collection may not help in addressing these weaknesses, as such challenging subgroups may be unknown to users, and underrepresented in the existing and new data. We propose Targeted Data Generation (TDG), a framework that automatically identifies challenging subgroups, and generates new data for those subgroups using large language models (LLMs) with a human in the loop. TDG estimates the expected benefit and potential harm of data augmentation for each subgroup, and selects the ones most likely to improve within-group performance without hurting overall performance. In our experiments, TDG significantly improves the accuracy on challenging subgroups for state-of-the-art sentiment analysis and natural language inference models, while also improving overall test accuracy.\",\n}\n",
    "authors": [
        "Zexue He",
        "Marco Tulio Ribeiro",
        "Fereshte Khani"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.474.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/884cc9b4-b494-5309-9b34-eadde4bd3c32.pdf",
    "abstract": "Even when aggregate accuracy is high, state-of-the-art NLP models often fail systematically on specific subgroups of data, resulting in unfair outcomes and eroding user trust. Additional data collection may not help in addressing these weaknesses, as such challenging subgroups may be unknown to users, and underrepresented in the existing and new data. We propose Targeted Data Generation (TDG), a framework that automatically identifies challenging subgroups, and generates new data for those subgroups using large language models (LLMs) with a human in the loop. TDG estimates the expected benefit and potential harm of data augmentation for each subgroup, and selects the ones most likely to improve within-group performance without hurting overall performance. In our experiments, TDG significantly improves the accuracy on challenging subgroups for state-of-the-art sentiment analysis and natural language inference models, while also improving overall test accuracy.",
    "num_pages": 15
}