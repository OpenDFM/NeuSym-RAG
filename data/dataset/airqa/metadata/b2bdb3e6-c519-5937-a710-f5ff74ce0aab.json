{
    "uuid": "b2bdb3e6-c519-5937-a710-f5ff74ce0aab",
    "title": "Scaling in Cognitive Modelling: a Multilingual Approach to Human Reading Times",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{de-varda-marelli-2023-scaling,\n    title = \"Scaling in Cognitive Modelling: a Multilingual Approach to Human Reading Times\",\n    author = \"de Varda, Andrea  and\n      Marelli, Marco\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.14\",\n    doi = \"10.18653/v1/2023.acl-short.14\",\n    pages = \"139--149\",\n    abstract = \"Neural language models are increasingly valued in computational psycholinguistics, due to their ability to provide conditional probability distributions over the lexicon that are predictive of human processing times. Given the vast array of available models, it is of both theoretical and methodological importance to assess what features of a model influence its psychometric quality. In this work we focus on parameter size, showing that larger Transformer-based language models generate probabilistic estimates that are less predictive of early eye-tracking measurements reflecting lexical access and early semantic integration. However, relatively bigger models show an advantage in capturing late eye-tracking measurements that reflect the full semantic and syntactic integration of a word into the current language context. Our results are supported by eye movement data in ten languages and consider four models, spanning from 564M to 4.5B parameters.\",\n}\n",
    "authors": [
        "Andrea de Varda",
        "Marco Marelli"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.14.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b2bdb3e6-c519-5937-a710-f5ff74ce0aab.pdf",
    "abstract": "Neural language models are increasingly valued in computational psycholinguistics, due to their ability to provide conditional probability distributions over the lexicon that are predictive of human processing times. Given the vast array of available models, it is of both theoretical and methodological importance to assess what features of a model influence its psychometric quality. In this work we focus on parameter size, showing that larger Transformer-based language models generate probabilistic estimates that are less predictive of early eye-tracking measurements reflecting lexical access and early semantic integration. However, relatively bigger models show an advantage in capturing late eye-tracking measurements that reflect the full semantic and syntactic integration of a word into the current language context. Our results are supported by eye movement data in ten languages and consider four models, spanning from 564M to 4.5B parameters.",
    "num_pages": 11
}