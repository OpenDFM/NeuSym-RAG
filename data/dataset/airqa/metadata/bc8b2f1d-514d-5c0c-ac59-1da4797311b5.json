{
    "uuid": "bc8b2f1d-514d-5c0c-ac59-1da4797311b5",
    "title": "Efficient Shapley Values Estimation by Amortization for Text Classification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{yang-etal-2023-efficient,\n    title = \"Efficient Shapley Values Estimation by Amortization for Text Classification\",\n    author = \"Yang, Chenghao  and\n      Yin, Fan  and\n      He, He  and\n      Chang, Kai-Wei  and\n      Ma, Xiaofei  and\n      Xiang, Bing\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.483\",\n    doi = \"10.18653/v1/2023.acl-long.483\",\n    pages = \"8666--8680\",\n    abstract = \"Despite the popularity of Shapley Values in explaining neural text classification models, computing them is prohibitive for large pretrained models due to a large number of model evaluations. In practice, Shapley Values are often estimated with a small number of stochastic model evaluations. However, we show that the estimated Shapley Values are sensitive to random seed choices {--} the top-ranked features often have little overlap across different seeds, especially on examples with longer input texts. This can only be mitigated by aggregating thousands of model evaluations, which on the other hand, induces substantial computational overheads. To mitigate the trade-off between stability and efficiency, we develop an amortized model that directly predicts each input feature{'}s Shapley Value without additional model evaluations. It is trained on a set of examples whose Shapley Values are estimated from a large number of model evaluations to ensure stability. Experimental results on two text classification datasets demonstrate that our amortized model estimates Shapley Values accurately with up to 60 times speedup compared to traditional methods. Further, our model does not suffer from stability issues as inference is deterministic. We release our code at \\url{https://github.com/yangalan123/Amortized-Interpretability}.\",\n}\n",
    "authors": [
        "Chenghao Yang",
        "Fan Yin",
        "He He",
        "Kai-Wei Chang",
        "Xiaofei Ma",
        "Bing Xiang"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.483.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/bc8b2f1d-514d-5c0c-ac59-1da4797311b5.pdf",
    "abstract": "Despite the popularity of Shapley Values in explaining neural text classification models, computing them is prohibitive for large pretrained models due to a large number of model evaluations. In practice, Shapley Values are often estimated with a small number of stochastic model evaluations. However, we show that the estimated Shapley Values are sensitive to random seed choices – the top-ranked features often have little overlap across different seeds, especially on examples with longer input texts. This can only be mitigated by aggregating thousands of model evaluations, which on the other hand, induces substantial computational overheads. To mitigate the trade-off between stability and efficiency, we develop an amortized model that directly predicts each input feature’s Shapley Value without additional model evaluations. It is trained on a set of examples whose Shapley Values are estimated from a large number of model evaluations to ensure stability. Experimental results on two text classification datasets demonstrate that our amortized model estimates Shapley Values accurately with up to 60 times speedup compared to traditional methods. Further, our model does not suffer from stability issues as inference is deterministic. We release our code at https://github.com/yangalan123/Amortized-Interpretability.",
    "num_pages": 15
}