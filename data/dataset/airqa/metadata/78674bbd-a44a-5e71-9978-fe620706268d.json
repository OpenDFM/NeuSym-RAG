{
    "uuid": "78674bbd-a44a-5e71-9978-fe620706268d",
    "title": "Smart Lexical Search for Label Flipping Adversial Attack",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Fifth Workshop on Privacy in Natural Language Processing",
    "bibtex": "@inproceedings{gutierrez-megias-etal-2024-smart,\n    title = \"Smart Lexical Search for Label Flipping Adversial Attack\",\n    author = \"Guti{\\'e}rrez-Meg{\\'\\i}as, Alberto  and\n      Jim{\\'e}nez-Zafra, Salud Mar{\\'\\i}a  and\n      Ure{\\~n}a, L. Alfonso  and\n      Mart{\\'\\i}nez-C{\\'a}mara, Eugenio\",\n    editor = \"Habernal, Ivan  and\n      Ghanavati, Sepideh  and\n      Ravichander, Abhilasha  and\n      Jain, Vijayanta  and\n      Thaine, Patricia  and\n      Igamberdiev, Timour  and\n      Mireshghallah, Niloofar  and\n      Feyisetan, Oluwaseyi\",\n    booktitle = \"Proceedings of the Fifth Workshop on Privacy in Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.privatenlp-1.11\",\n    pages = \"97--106\",\n    abstract = \"Language models are susceptible to vulnerability through adversarial attacks, using manipulations of the input data to disrupt their performance. Accordingly, it represents a cibersecurity leak. Data manipulations are intended to be unidentifiable by the learning model and by humans, small changes can disturb the final label of a classification task. Hence, we propose a novel attack built upon explainability methods to identify the salient lexical units to alter in order to flip the classification label. We asses our proposal on a disinformation dataset, and we show that our attack reaches high balance among stealthiness and efficiency.\",\n}\n",
    "authors": [
        "Alberto Gutiérrez-Megías",
        "Salud María Jiménez-Zafra",
        "L. Alfonso Ureña",
        "Eugenio Martínez-Cámara"
    ],
    "pdf_url": "https://aclanthology.org/2024.privatenlp-1.11.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/78674bbd-a44a-5e71-9978-fe620706268d.pdf",
    "abstract": "Language models are susceptible to vulnerability through adversarial attacks, using manipulations of the input data to disrupt their performance. Accordingly, it represents a cibersecurity leak. Data manipulations are intended to be unidentifiable by the learning model and by humans, small changes can disturb the final label of a classification task. Hence, we propose a novel attack built upon explainability methods to identify the salient lexical units to alter in order to flip the classification label. We asses our proposal on a disinformation dataset, and we show that our attack reaches high balance among stealthiness and efficiency.",
    "num_pages": 10
}