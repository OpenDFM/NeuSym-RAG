{
    "uuid": "ea84b82d-3ee8-5a82-9f0f-55b183cf7fc9",
    "title": "Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{li-etal-2024-selective,\n    title = \"Selective Reflection-Tuning: Student-Selected Data Recycling for {LLM} Instruction-Tuning\",\n    author = \"Li, Ming  and\n      Chen, Lichang  and\n      Chen, Jiuhai  and\n      He, Shwai  and\n      Gu, Jiuxiang  and\n      Zhou, Tianyi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.958\",\n    doi = \"10.18653/v1/2024.findings-acl.958\",\n    pages = \"16189--16211\",\n    abstract = \"Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the data with the student model being finetuned. This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLM{'}s reflection and introspection for improving existing data quality with the data selection capability of the student LLM, to automatically refine existing instruction-tuning data. This teacher-student collaboration produces high-quality and student-compatible instruction-response pairs, resulting in sample-efficient instruction tuning and LLMs of superior performance. Selective Reflection-Tuning is a data augmentation and synthesis that generally improves LLM finetuning and self-improvement without collecting brand-new data. We apply our method to Alpaca and WizardLM data and achieve much stronger and top-tier 7B and 13B LLMs.\",\n}\n",
    "authors": [
        "Ming Li",
        "Lichang Chen",
        "Jiuhai Chen",
        "Shwai He",
        "Jiuxiang Gu",
        "Tianyi Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.958.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ea84b82d-3ee8-5a82-9f0f-55b183cf7fc9.pdf",
    "abstract": "Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the data with the student model being finetuned. This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLMâ€™s reflection and introspection for improving existing data quality with the data selection capability of the student LLM, to automatically refine existing instruction-tuning data. This teacher-student collaboration produces high-quality and student-compatible instruction-response pairs, resulting in sample-efficient instruction tuning and LLMs of superior performance. Selective Reflection-Tuning is a data augmentation and synthesis that generally improves LLM finetuning and self-improvement without collecting brand-new data. We apply our method to Alpaca and WizardLM data and achieve much stronger and top-tier 7B and 13B LLMs.",
    "num_pages": 23
}