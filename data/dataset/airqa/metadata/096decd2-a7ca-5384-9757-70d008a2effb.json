{
    "uuid": "096decd2-a7ca-5384-9757-70d008a2effb",
    "title": "Aligning Unstructured Paris Agreement Climate Plans with Sustainable Development Goals",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024)",
    "bibtex": "@inproceedings{spokoyny-etal-2024-aligning,\n    title = \"Aligning Unstructured {P}aris Agreement Climate Plans with Sustainable Development Goals\",\n    author = \"Spokoyny, Daniel  and\n      Cai, Janelle  and\n      Corringham, Tom  and\n      Berg-Kirkpatrick, Taylor\",\n    editor = \"Stammbach, Dominik  and\n      Ni, Jingwei  and\n      Schimanski, Tobias  and\n      Dutia, Kalyan  and\n      Singh, Alok  and\n      Bingler, Julia  and\n      Christiaen, Christophe  and\n      Kushwaha, Neetu  and\n      Muccione, Veruska  and\n      A. Vaghefi, Saeid  and\n      Leippold, Markus\",\n    booktitle = \"Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.climatenlp-1.17\",\n    doi = \"10.18653/v1/2024.climatenlp-1.17\",\n    pages = \"223--232\",\n    abstract = \"Aligning unstructured climate policy documents according to a particular classification taxonomy with little to no labeled examples is challenging and requires manual effort of climate policy researchers. In this work we examine whether large language models (LLMs) can act as an effective substitute or assist in the annotation process. Utilizing a large set of text spans from Paris Agreement Nationally Determined Contributions (NDCs) linked to United Nations Sustainable Development Goals (SDGs) and targets contained in the Climate Watch dataset from the World Resources Institute in combination with our own annotated data, we validate our approaches and establish a benchmark for model performance evaluation on this task. With our evaluation benchmarking we quantify the effectiveness of using zero-shot or few-shot prompted LLMs to align these documents.\",\n}\n",
    "authors": [
        "Daniel Spokoyny",
        "Janelle Cai",
        "Tom Corringham",
        "Taylor Berg-Kirkpatrick"
    ],
    "pdf_url": "https://aclanthology.org/2024.climatenlp-1.17.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/096decd2-a7ca-5384-9757-70d008a2effb.pdf",
    "abstract": "Aligning unstructured climate policy documents according to a particular classification taxonomy with little to no labeled examples is challenging and requires manual effort of climate policy researchers. In this work we examine whether large language models (LLMs) can act as an effective substitute or assist in the annotation process. Utilizing a large set of text spans from Paris Agreement Nationally Determined Contributions (NDCs) linked to United Nations Sustainable Development Goals (SDGs) and targets contained in the Climate Watch dataset from the World Resources Institute in combination with our own annotated data, we validate our approaches and establish a benchmark for model performance evaluation on this task. With our evaluation benchmarking we quantify the effectiveness of using zero-shot or few-shot prompted LLMs to align these documents.",
    "num_pages": 10
}