{
    "uuid": "aaa2de61-042f-5cd8-be60-10f559d533ac",
    "title": "Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{zhang-etal-2024-model,\n    title = \"Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders\",\n    author = \"Zhang, Yuwei  and\n      Singh, Siffi  and\n      Sengupta, Sailik  and\n      Shalyminov, Igor  and\n      Su, Hang  and\n      Song, Hwanjun  and\n      Mansour, Saab\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.33\",\n    doi = \"10.18653/v1/2024.acl-long.33\",\n    pages = \"552--567\",\n    abstract = \"Conversational systems often rely on embedding models for intent classification and intent clustering tasks. The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for these downstream conversational tasks. However, traditional evaluation benchmarks rely solely on task metrics that don{'}t particularly measure gaps related to semantic understanding. Thus, we propose an intent semantic toolkit that gives a more holistic view of intent embedding models by considering three tasks{--} (1) intent classification, (2) intent clustering, and (3) a novel triplet task. The triplet task gauges the model{'}s understanding of two semantic concepts paramount in real-world conversational systems{--} negation and implicature. We observe that current embedding models fare poorly in semantic understanding of these concepts. To address this, we propose a pre-training approach to improve the embedding model by leveraging augmentation with data generated by an auto-regressive model and a contrastive loss term. Our approach improves the semantic understanding of the intent embedding model on the aforementioned linguistic dimensions while slightly effecting their performance on downstream task metrics.\",\n}\n",
    "authors": [
        "Yuwei Zhang",
        "Siffi Singh",
        "Sailik Sengupta",
        "Igor Shalyminov",
        "Hang Su",
        "Hwanjun Song",
        "Saab Mansour"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.33.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/aaa2de61-042f-5cd8-be60-10f559d533ac.pdf",
    "abstract": "Conversational systems often rely on embedding models for intent classification and intent clustering tasks. The advent of Large Language Models (LLMs), which enable instructional embeddings allowing one to adjust semantics over the embedding space using prompts, are being viewed as a panacea for these downstream conversational tasks. However, traditional evaluation benchmarks rely solely on task metrics that don’t particularly measure gaps related to semantic understanding. Thus, we propose an intent semantic toolkit that gives a more holistic view of intent embedding models by considering three tasks– (1) intent classification, (2) intent clustering, and (3) a novel triplet task. The triplet task gauges the model’s understanding of two semantic concepts paramount in real-world conversational systems– negation and implicature. We observe that current embedding models fare poorly in semantic understanding of these concepts. To address this, we propose a pre-training approach to improve the embedding model by leveraging augmentation with data generated by an auto-regressive model and a contrastive loss term. Our approach improves the semantic understanding of the intent embedding model on the aforementioned linguistic dimensions while slightly effecting their performance on downstream task metrics.",
    "num_pages": 16
}