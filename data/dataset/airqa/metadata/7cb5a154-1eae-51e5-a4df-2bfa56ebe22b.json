{
    "uuid": "7cb5a154-1eae-51e5-a4df-2bfa56ebe22b",
    "title": "PMCoders at SemEval-2023 Task 1: RAltCLIP: Use Relative AltCLIP Features to Rank",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{pirhadi-etal-2023-pmcoders,\n    title = \"{PMC}oders at {S}em{E}val-2023 Task 1: {RA}lt{CLIP}: Use Relative {A}lt{CLIP} Features to Rank\",\n    author = \"Pirhadi, Mohammad Javad  and\n      Mirzaei, Motahhare  and\n      Mohammadi, Mohammad Reza  and\n      Eetemadi, Sauleh\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.242\",\n    doi = \"10.18653/v1/2023.semeval-1.242\",\n    pages = \"1751--1755\",\n    abstract = \"Visual Word Sense Disambiguation (VWSD) task aims to find the most related image among 10 images to an ambiguous word in some limited textual context. In this work, we use AltCLIP features and a 3-layer standard transformer encoder to compare the cosine similarity between the given phrase and different images. Also, we improve our model{'}s generalization by using a subset of LAION-5B. The best official baseline achieves 37.20{\\%} and 54.39{\\%} macro-averaged hit rate and MRR (Mean Reciprocal Rank) respectively. Our best configuration reaches 39.61{\\%} and 56.78{\\%} macro-averaged hit rate and MRR respectively. The code will be made publicly available on GitHub.\",\n}\n",
    "authors": [
        "Mohammad Javad Pirhadi",
        "Motahhare Mirzaei",
        "Mohammad Reza Mohammadi",
        "Sauleh Eetemadi"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.242.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/7cb5a154-1eae-51e5-a4df-2bfa56ebe22b.pdf",
    "abstract": "Visual Word Sense Disambiguation (VWSD) task aims to find the most related image among 10 images to an ambiguous word in some limited textual context. In this work, we use AltCLIP features and a 3-layer standard transformer encoder to compare the cosine similarity between the given phrase and different images. Also, we improve our modelâ€™s generalization by using a subset of LAION-5B. The best official baseline achieves 37.20% and 54.39% macro-averaged hit rate and MRR (Mean Reciprocal Rank) respectively. Our best configuration reaches 39.61% and 56.78% macro-averaged hit rate and MRR respectively. The code will be made publicly available on GitHub.",
    "num_pages": 5
}