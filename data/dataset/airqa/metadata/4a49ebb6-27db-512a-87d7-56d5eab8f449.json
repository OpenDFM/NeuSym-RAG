{
    "uuid": "4a49ebb6-27db-512a-87d7-56d5eab8f449",
    "title": "Semantic Accuracy in Natural Language Generation: A Thesis Proposal",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",
    "bibtex": "@inproceedings{schmidtova-2023-semantic,\n    title = \"Semantic Accuracy in Natural Language Generation: A Thesis Proposal\",\n    author = \"Schmidtova, Patricia\",\n    editor = \"Padmakumar, Vishakh  and\n      Vallejo, Gisela  and\n      Fu, Yao\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-srw.48\",\n    doi = \"10.18653/v1/2023.acl-srw.48\",\n    pages = \"352--361\",\n    abstract = \"With the fast-growing popularity of current large pre-trained language models (LLMs), it is necessary to dedicate efforts to making them more reliable. In this thesis proposal, we aim to improve the reliability of natural language generation systems (NLG) by researching the semantic accuracy of their outputs. We look at this problem from the outside (evaluation) and from the inside (interpretability). We propose a novel method for evaluating semantic accuracy and discuss the importance of working towards a unified and objective benchmark for NLG metrics. We also review interpretability approaches which could help us pinpoint the sources of inaccuracies within the models and explore potential mitigation strategies.\",\n}\n",
    "authors": [
        "Patricia Schmidtova"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-srw.48.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4a49ebb6-27db-512a-87d7-56d5eab8f449.pdf",
    "abstract": "With the fast-growing popularity of current large pre-trained language models (LLMs), it is necessary to dedicate efforts to making them more reliable. In this thesis proposal, we aim to improve the reliability of natural language generation systems (NLG) by researching the semantic accuracy of their outputs. We look at this problem from the outside (evaluation) and from the inside (interpretability). We propose a novel method for evaluating semantic accuracy and discuss the importance of working towards a unified and objective benchmark for NLG metrics. We also review interpretability approaches which could help us pinpoint the sources of inaccuracies within the models and explore potential mitigation strategies.",
    "num_pages": 10
}