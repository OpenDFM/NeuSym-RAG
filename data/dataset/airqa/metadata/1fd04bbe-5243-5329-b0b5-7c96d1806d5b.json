{
    "uuid": "1fd04bbe-5243-5329-b0b5-7c96d1806d5b",
    "title": "StFX NLP at SemEval-2023 Task 1: Multimodal Encoding-based Methods for Visual Word Sense Disambiguation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    "bibtex": "@inproceedings{wei-king-2023-stfx,\n    title = \"{S}t{FX} {NLP} at {S}em{E}val-2023 Task 1: Multimodal Encoding-based Methods for Visual Word Sense Disambiguation\",\n    author = \"Wei, Yuchen  and\n      King, Milton\",\n    editor = {Ojha, Atul Kr.  and\n      Do{\\u{g}}ru{\\\"o}z, A. Seza  and\n      Da San Martino, Giovanni  and\n      Tayyar Madabushi, Harish  and\n      Kumar, Ritesh  and\n      Sartori, Elisa},\n    booktitle = \"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.semeval-1.55\",\n    doi = \"10.18653/v1/2023.semeval-1.55\",\n    pages = \"409--414\",\n    abstract = \"SemEval-2023{'}s Task 1, Visual Word Sense Disambiguation, a task about text semantics and visual semantics, selecting an image from a list of candidates, that best exhibits a given target word in a small context. We tried several methods, including the image captioning method and CLIP methods, and submitted our predictions in the competition for this task. This paper describes the methods we used and their performance and provides an analysis and discussion of the performance.\",\n}\n",
    "authors": [
        "Yuchen Wei",
        "Milton King"
    ],
    "pdf_url": "https://aclanthology.org/2023.semeval-1.55.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/1fd04bbe-5243-5329-b0b5-7c96d1806d5b.pdf",
    "abstract": "SemEval-2023â€™s Task 1, Visual Word Sense Disambiguation, a task about text semantics and visual semantics, selecting an image from a list of candidates, that best exhibits a given target word in a small context. We tried several methods, including the image captioning method and CLIP methods, and submitted our predictions in the competition for this task. This paper describes the methods we used and their performance and provides an analysis and discussion of the performance.",
    "num_pages": 6
}