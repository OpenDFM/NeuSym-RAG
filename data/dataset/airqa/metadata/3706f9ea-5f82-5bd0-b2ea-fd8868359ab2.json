{
    "uuid": "3706f9ea-5f82-5bd0-b2ea-fd8868359ab2",
    "title": "Verifiable Generation with Subsentence-Level Fine-Grained Citations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{cao-wang-2024-verifiable,\n    title = \"Verifiable Generation with Subsentence-Level Fine-Grained Citations\",\n    author = \"Cao, Shuyang  and\n      Wang, Lu\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.920\",\n    doi = \"10.18653/v1/2024.findings-acl.920\",\n    pages = \"15584--15596\",\n    abstract = \"Verifiable generation requires large language models (LLMs) to cite source documents supporting their outputs, thereby improve output transparency and trustworthiness. Yet, previous work mainly targets the generation of sentence-level citations, lacking specificity about which parts of a sentence are backed by the cited sources. This work studies verifiable generation with subsentence-level fine-grained citations for more precise location of generated content supported by the cited sources. We first present a dataset, SCiFi, comprising 10K Wikipedia paragraphs with subsentence-level citations. Each paragraph is paired with a set of candidate source documents for citation and a query that triggers the generation of the paragraph content. On SCiFi, we evaluate the performance of state-of-the-art LLMs and strategies for processing long documents designed for these models. Our experiment results reveals key factors that could enhance the quality of citations, including the expansion of the source documents{'} context accessible to the models and the implementation of specialized model tuning.\",\n}\n",
    "authors": [
        "Shuyang Cao",
        "Lu Wang"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.920.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3706f9ea-5f82-5bd0-b2ea-fd8868359ab2.pdf",
    "abstract": "Verifiable generation requires large language models (LLMs) to cite source documents supporting their outputs, thereby improve output transparency and trustworthiness. Yet, previous work mainly targets the generation of sentence-level citations, lacking specificity about which parts of a sentence are backed by the cited sources. This work studies verifiable generation with subsentence-level fine-grained citations for more precise location of generated content supported by the cited sources. We first present a dataset, SCiFi, comprising 10K Wikipedia paragraphs with subsentence-level citations. Each paragraph is paired with a set of candidate source documents for citation and a query that triggers the generation of the paragraph content. On SCiFi, we evaluate the performance of state-of-the-art LLMs and strategies for processing long documents designed for these models. Our experiment results reveals key factors that could enhance the quality of citations, including the expansion of the source documentsâ€™ context accessible to the models and the implementation of specialized model tuning.",
    "num_pages": 13
}