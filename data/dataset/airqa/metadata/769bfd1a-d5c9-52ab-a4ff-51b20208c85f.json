{
    "uuid": "769bfd1a-d5c9-52ab-a4ff-51b20208c85f",
    "title": "Are LLM-based Evaluators Confusing NLG Quality Criteria?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{hu-etal-2024-llm,\n    title = \"Are {LLM}-based Evaluators Confusing {NLG} Quality Criteria?\",\n    author = \"Hu, Xinyu  and\n      Gao, Mingqi  and\n      Hu, Sen  and\n      Zhang, Yang  and\n      Chen, Yicheng  and\n      Xu, Teng  and\n      Wan, Xiaojun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.516\",\n    doi = \"10.18653/v1/2024.acl-long.516\",\n    pages = \"9530--9570\",\n    abstract = \"Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies involved. Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs. We also conduct human annotations beyond the guidance of the classification system to validate the impact of the perturbations. Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further research and improvements for LLM-based evaluation.\",\n}\n",
    "authors": [
        "Xinyu Hu",
        "Mingqi Gao",
        "Sen Hu",
        "Yang Zhang",
        "Yicheng Chen",
        "Teng Xu",
        "Xiaojun Wan"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.516.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/769bfd1a-d5c9-52ab-a4ff-51b20208c85f.pdf",
    "abstract": "Some prior work has shown that LLMs perform well in NLG evaluation for different tasks. However, we discover that LLMs seem to confuse different evaluation criteria, which reduces their reliability. For further verification, we first consider avoiding issues of inconsistent conceptualization and vague expression in existing NLG quality criteria themselves. So we summarize a clear hierarchical classification system for 11 common aspects with corresponding different criteria from previous studies involved. Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs. We also conduct human annotations beyond the guidance of the classification system to validate the impact of the perturbations. Our experimental results reveal confusion issues inherent in LLMs, as well as other noteworthy phenomena, and necessitate further research and improvements for LLM-based evaluation.",
    "num_pages": 41
}