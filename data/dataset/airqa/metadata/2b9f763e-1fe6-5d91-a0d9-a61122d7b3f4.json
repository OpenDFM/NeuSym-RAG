{
    "uuid": "2b9f763e-1fe6-5d91-a0d9-a61122d7b3f4",
    "title": "Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{kim-etal-2023-pseudo,\n    title = \"Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers\",\n    author = \"Kim, Jaeyoung  and\n      Jung, Kyuheon  and\n      Na, Dongbin  and\n      Jang, Sion  and\n      Park, Eunbin  and\n      Choi, Sungchul\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.95\",\n    doi = \"10.18653/v1/2023.findings-acl.95\",\n    pages = \"1469--1482\",\n    abstract = \"For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold.A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers.A comprehensive comparison with state-of-the-art algorithms demonstrates POE{'}s competitiveness on several text classification benchmarks.\",\n}\n",
    "authors": [
        "Jaeyoung Kim",
        "Kyuheon Jung",
        "Dongbin Na",
        "Sion Jang",
        "Eunbin Park",
        "Sungchul Choi"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.95.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/2b9f763e-1fe6-5d91-a0d9-a61122d7b3f4.pdf",
    "abstract": "For real-world language applications, detecting an out-of-distribution (OOD) sample is helpful to alert users or reject such unreliable samples. However, modern over-parameterized language models often produce overconfident predictions for both in-distribution (ID) and OOD samples. In particular, language models suffer from OOD samples with a similar semantic representation to ID samples since these OOD samples lie near the ID manifold.A rejection network can be trained with ID and diverse outlier samples to detect test OOD samples, but explicitly collecting auxiliary OOD datasets brings an additional burden for data collection. In this paper, we propose a simple but effective method called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD dataset by sequentially masking tokens related to ID classes. The surrogate OOD sample introduced by POE shows a similar representation to ID data, which is most effective in training a rejection network. Our method does not require any external OOD data and can be easily implemented within off-the-shelf Transformers.A comprehensive comparison with state-of-the-art algorithms demonstrates POEâ€™s competitiveness on several text classification benchmarks.",
    "num_pages": 14
}