{
    "uuid": "51517710-ee2c-5572-b5f0-c065b50cd590",
    "title": "NCUEE-NLP at BioLaySumm Task 2: Readability-Controlled Summarization of Biomedical Articles Using the PRIMERA Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks",
    "bibtex": "@inproceedings{chen-etal-2023-ncuee,\n    title = \"{NCUEE}-{NLP} at {B}io{L}ay{S}umm Task 2: Readability-Controlled Summarization of Biomedical Articles Using the {PRIMERA} Models\",\n    author = \"Chen, Chao-Yi  and\n      Yang, Jen-Hao  and\n      Lee, Lung-Hao\",\n    editor = \"Demner-fushman, Dina  and\n      Ananiadou, Sophia  and\n      Cohen, Kevin\",\n    booktitle = \"The 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bionlp-1.62\",\n    doi = \"10.18653/v1/2023.bionlp-1.62\",\n    pages = \"586--591\",\n    abstract = \"This study describes the model design of the NCUEE-NLP system for BioLaySumm Task 2 at the BioNLP 2023 workshop. We separately fine-tune pretrained PRIMERA models to independently generate technical abstracts and lay summaries of biomedical articles. A total of seven evaluation metrics across three criteria were used to compare system performance. Our best submission was ranked first for relevance, second for readability, and fourth for factuality, tying first for overall performance.\",\n}\n",
    "authors": [
        "Chao-Yi Chen",
        "Jen-Hao Yang",
        "Lung-Hao Lee"
    ],
    "pdf_url": "https://aclanthology.org/2023.bionlp-1.62.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/51517710-ee2c-5572-b5f0-c065b50cd590.pdf",
    "abstract": "This study describes the model design of the NCUEE-NLP system for BioLaySumm Task 2 at the BioNLP 2023 workshop. We separately fine-tune pretrained PRIMERA models to independently generate technical abstracts and lay summaries of biomedical articles. A total of seven evaluation metrics across three criteria were used to compare system performance. Our best submission was ranked first for relevance, second for readability, and fourth for factuality, tying first for overall performance.",
    "num_pages": 6
}