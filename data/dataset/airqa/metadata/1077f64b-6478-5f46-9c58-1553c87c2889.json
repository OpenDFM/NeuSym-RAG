{
    "uuid": "1077f64b-6478-5f46-9c58-1553c87c2889",
    "title": "SummQA at MEDIQA-Chat 2023: In-Context Learning with GPT-4 for Medical Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{mathur-etal-2023-summqa,\n    title = \"{S}umm{QA} at {MEDIQA}-Chat 2023: In-Context Learning with {GPT}-4 for Medical Summarization\",\n    author = \"Mathur, Yash  and\n      Rangreji, Sanketh  and\n      Kapoor, Raghav  and\n      Palavalli, Medha  and\n      Bertsch, Amanda  and\n      Gormley, Matthew\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.51\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.51\",\n    pages = \"490--502\",\n    abstract = \"Medical dialogue summarization is challenging due to the unstructured nature of medical conversations, the use of medical terminologyin gold summaries, and the need to identify key information across multiple symptom sets. We present a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task. Our approach for sectionwise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1. We achieved 3rd place in Task A (2nd among all teams), 4th place in Task B Division Wise Summarization (2nd among all teams), 15th place in Task A Section Header Classification (9th among all teams), and 8th place among all teams in Task B. Our results highlight the effectiveness of few-shot prompting for this task, though we also identify several weaknesses of prompting-based approaches. We compare GPT-4 performance with several finetuned baselines. We find that GPT-4 summaries are more abstractive and shorter. We make our code publicly available.\",\n}\n",
    "authors": [
        "Yash Mathur",
        "Sanketh Rangreji",
        "Raghav Kapoor",
        "Medha Palavalli",
        "Amanda Bertsch",
        "Matthew Gormley"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.51.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/1077f64b-6478-5f46-9c58-1553c87c2889.pdf",
    "abstract": "Medical dialogue summarization is challenging due to the unstructured nature of medical conversations, the use of medical terminologyin gold summaries, and the need to identify key information across multiple symptom sets. We present a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task. Our approach for sectionwise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1. We achieved 3rd place in Task A (2nd among all teams), 4th place in Task B Division Wise Summarization (2nd among all teams), 15th place in Task A Section Header Classification (9th among all teams), and 8th place among all teams in Task B. Our results highlight the effectiveness of few-shot prompting for this task, though we also identify several weaknesses of prompting-based approaches. We compare GPT-4 performance with several finetuned baselines. We find that GPT-4 summaries are more abstractive and shorter. We make our code publicly available.",
    "num_pages": 13
}