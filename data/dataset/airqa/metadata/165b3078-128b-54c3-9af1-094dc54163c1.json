{
    "uuid": "165b3078-128b-54c3-9af1-094dc54163c1",
    "title": "Content Moderation for Evolving Policies using Binary Question Answering",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
    "bibtex": "@inproceedings{mullick-etal-2023-content,\n    title = \"Content Moderation for Evolving Policies using Binary Question Answering\",\n    author = \"Mullick, Sankha Subhra  and\n      Bhambhani, Mohan  and\n      Sinha, Suhit  and\n      Mathur, Akshat  and\n      Gupta, Somya  and\n      Shah, Jidnya\",\n    editor = \"Sitaram, Sunayana  and\n      Beigman Klebanov, Beata  and\n      Williams, Jason D\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-industry.54\",\n    doi = \"10.18653/v1/2023.acl-industry.54\",\n    pages = \"561--573\",\n    abstract = \"Content moderation on social media is governed by policies that are intricate and frequently updated with evolving world events. However, automated content moderation systems often restrict easy adaptation to policy changes and are expected to learn policy intricacies from limited amounts of labeled data, which make effective policy compliance challenging. We propose to model content moderation as a binary question answering problem where the questions validate the loosely coupled themes constituting a policy. A decision logic is applied on top to aggregate the theme-specific validations. This way the questions pass theme information to a transformer network as explicit policy prompts, that in turn enables explainability. This setting further allows for faster adaptation to policy updates by leveraging zero-shot capabilities of pre-trained transformers. We showcase improved recall for our proposed method at 95{\\textbackslash}{\\%} precision on two proprietary datasets of social media posts and comments respectively annotated under curated Hate Speech and Commercial Spam policies.\",\n}\n",
    "authors": [
        "Sankha Subhra Mullick",
        "Mohan Bhambhani",
        "Suhit Sinha",
        "Akshat Mathur",
        "Somya Gupta",
        "Jidnya Shah"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-industry.54.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/165b3078-128b-54c3-9af1-094dc54163c1.pdf",
    "abstract": "Content moderation on social media is governed by policies that are intricate and frequently updated with evolving world events. However, automated content moderation systems often restrict easy adaptation to policy changes and are expected to learn policy intricacies from limited amounts of labeled data, which make effective policy compliance challenging. We propose to model content moderation as a binary question answering problem where the questions validate the loosely coupled themes constituting a policy. A decision logic is applied on top to aggregate the theme-specific validations. This way the questions pass theme information to a transformer network as explicit policy prompts, that in turn enables explainability. This setting further allows for faster adaptation to policy updates by leveraging zero-shot capabilities of pre-trained transformers. We showcase improved recall for our proposed method at 95\\% precision on two proprietary datasets of social media posts and comments respectively annotated under curated Hate Speech and Commercial Spam policies.",
    "num_pages": 13
}