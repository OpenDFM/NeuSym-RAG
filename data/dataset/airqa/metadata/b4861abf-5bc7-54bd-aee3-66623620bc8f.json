{
    "uuid": "b4861abf-5bc7-54bd-aee3-66623620bc8f",
    "title": "Beyond Abstracts: A New Dataset, Prompt Design Strategy and Method for Biomedical Synthesis Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)",
    "bibtex": "@inproceedings{odoherty-etal-2024-beyond,\n    title = \"Beyond Abstracts: A New Dataset, Prompt Design Strategy and Method for Biomedical Synthesis Generation\",\n    author = \"O{'}Doherty, James  and\n      Nolan, Cian  and\n      Hou, Yufang  and\n      Belz, Anya\",\n    editor = \"Fu, Xiyan  and\n      Fleisig, Eve\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-srw.42\",\n    doi = \"10.18653/v1/2024.acl-srw.42\",\n    pages = \"358--377\",\n    abstract = \"The biomedical field relies on cost and time intensive systematic reviews of papers to enable practitioners to keep up to date with research. Impressive recent advances in large language models (LLMs) have made the task of automating at least part of the systematic review process feasible, but progress is slow. This paper identifies some factors that may have been holding research back, and proposes a new, enhanced dataset and prompting-based method for automatic synthesis generation, the most challenging step for automation. We test different models and types of information from and about biomedical studies for their usefulness in obtaining high-quality results.We find that, surprisingly, inclusion of paper abstracts can worsens results. Instead, study summary information, and system instructions informed by domain knowledge, are key to producing high-quality syntheses.\",\n}\n",
    "authors": [
        "James Oâ€™Doherty",
        "Cian Nolan",
        "Yufang Hou",
        "Anya Belz"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-srw.42.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b4861abf-5bc7-54bd-aee3-66623620bc8f.pdf",
    "abstract": "The biomedical field relies on cost and time intensive systematic reviews of papers to enable practitioners to keep up to date with research. Impressive recent advances in large language models (LLMs) have made the task of automating at least part of the systematic review process feasible, but progress is slow. This paper identifies some factors that may have been holding research back, and proposes a new, enhanced dataset and prompting-based method for automatic synthesis generation, the most challenging step for automation. We test different models and types of information from and about biomedical studies for their usefulness in obtaining high-quality results.We find that, surprisingly, inclusion of paper abstracts can worsens results. Instead, study summary information, and system instructions informed by domain knowledge, are key to producing high-quality syntheses.",
    "num_pages": 20
}