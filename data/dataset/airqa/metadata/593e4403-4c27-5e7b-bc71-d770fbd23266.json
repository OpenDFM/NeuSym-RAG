{
    "uuid": "593e4403-4c27-5e7b-bc71-d770fbd23266",
    "title": "Speech-to-Speech Translation for a Real-world Unwritten Language",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{chen-etal-2023-speech,\n    title = \"Speech-to-Speech Translation for a Real-world Unwritten Language\",\n    author = \"Chen, Peng-Jen  and\n      Tran, Kevin  and\n      Yang, Yilin  and\n      Du, Jingfei  and\n      Kao, Justine  and\n      Chung, Yu-An  and\n      Tomasello, Paden  and\n      Duquenne, Paul-Ambroise  and\n      Schwenk, Holger  and\n      Gong, Hongyu  and\n      Inaguma, Hirofumi  and\n      Popuri, Sravya  and\n      Wang, Changhan  and\n      Pino, Juan  and\n      Hsu, Wei-Ning  and\n      Lee, Ann\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.307\",\n    doi = \"10.18653/v1/2023.findings-acl.307\",\n    pages = \"4969--4983\",\n    abstract = \"We study speech-to-speech translation (S2ST) that translates speech from one language into another language and focuses on building systems to support languages without standard text writing systems. We use English-Taiwanese Hokkien as a case study, and present an end-to-end solution from training data collection, modeling choices to benchmark dataset release. First, we present efforts on creating human annotated data, automatically mining data from large unlabeled speech datasets, and adopting pseudo-labeling to produce weakly supervised data. On the modeling, we take advantage of recent advances in applying self-supervised discrete representations as target for prediction in S2ST and show the effectiveness of leveraging additional text supervision from Mandarin, a language similar to Hokkien, in model training. Finally, we release an S2ST benchmark set to facilitate future research in this field.\",\n}\n",
    "authors": [
        "Peng-Jen Chen",
        "Kevin Tran",
        "Yilin Yang",
        "Jingfei Du",
        "Justine Kao",
        "Yu-An Chung",
        "Paden Tomasello",
        "Paul-Ambroise Duquenne",
        "Holger Schwenk",
        "Hongyu Gong",
        "Hirofumi Inaguma",
        "Sravya Popuri",
        "Changhan Wang",
        "Juan Pino",
        "Wei-Ning Hsu",
        "Ann Lee"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.307.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/593e4403-4c27-5e7b-bc71-d770fbd23266.pdf",
    "abstract": "We study speech-to-speech translation (S2ST) that translates speech from one language into another language and focuses on building systems to support languages without standard text writing systems. We use English-Taiwanese Hokkien as a case study, and present an end-to-end solution from training data collection, modeling choices to benchmark dataset release. First, we present efforts on creating human annotated data, automatically mining data from large unlabeled speech datasets, and adopting pseudo-labeling to produce weakly supervised data. On the modeling, we take advantage of recent advances in applying self-supervised discrete representations as target for prediction in S2ST and show the effectiveness of leveraging additional text supervision from Mandarin, a language similar to Hokkien, in model training. Finally, we release an S2ST benchmark set to facilitate future research in this field.",
    "num_pages": 15
}