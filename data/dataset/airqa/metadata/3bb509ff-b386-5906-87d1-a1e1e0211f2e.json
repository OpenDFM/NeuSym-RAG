{
    "uuid": "3bb509ff-b386-5906-87d1-a1e1e0211f2e",
    "title": "Mitigating Data Scarcity in Semantic Parsing across Languages with the Multilingual Semantic Layer and its Dataset",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{martinez-lorenzo-etal-2024-mitigating,\n    title = \"Mitigating Data Scarcity in Semantic Parsing across Languages with the Multilingual Semantic Layer and its Dataset\",\n    author = \"Martinez Lorenzo, Abelardo Carlos  and\n      Huguet Cabot, Pere-Llu{\\'\\i}s  and\n      Ghonim, Karim  and\n      Xu, Lu  and\n      Choi, Hee-Soo  and\n      Fern{\\'a}ndez-Castro, Alberte  and\n      Navigli, Roberto\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.836\",\n    doi = \"10.18653/v1/2024.findings-acl.836\",\n    pages = \"14056--14080\",\n    abstract = \"Data scarcity is a prevalent challenge in the era of Large Language Models (LLMs). The insatiable hunger of LLMs for large corpora becomes even more pronounced when dealing with non-English and low-resource languages. The issue is particularly exacerbated in Semantic Parsing (SP), i.e. the task of converting text into a formal representation. The complexity of semantic formalisms makes training human annotators and subsequent data annotation unfeasible on a large scale, especially across languages. To mitigate this, we first introduce the Multilingual Semantic Layer (MSL), a conceptual evolution of previous formalisms, which decouples from disambiguation and external inventories and simplifies the task. MSL provides the necessary tools to encode the meaning across languages, paving the way for developing a high-quality semantic parsing dataset across different languages in a semi-automatic strategy. Subsequently, we manually refine a portion of this dataset and fine-tune GPT-3.5 to propagate these refinements across the dataset. Then, we manually annotate 1,100 sentences in eleven languages, including low-resource ones. Finally, we assess our dataset{'}s quality, showcasing the performance gap reduction across languages in Semantic Parsing.\",\n}\n",
    "authors": [
        "Abelardo Carlos Martinez Lorenzo",
        "Pere-Lluís Huguet Cabot",
        "Karim Ghonim",
        "Lu Xu",
        "Hee-Soo Choi",
        "Alberte Fernández-Castro",
        "Roberto Navigli"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.836.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3bb509ff-b386-5906-87d1-a1e1e0211f2e.pdf",
    "abstract": "Data scarcity is a prevalent challenge in the era of Large Language Models (LLMs). The insatiable hunger of LLMs for large corpora becomes even more pronounced when dealing with non-English and low-resource languages. The issue is particularly exacerbated in Semantic Parsing (SP), i.e. the task of converting text into a formal representation. The complexity of semantic formalisms makes training human annotators and subsequent data annotation unfeasible on a large scale, especially across languages. To mitigate this, we first introduce the Multilingual Semantic Layer (MSL), a conceptual evolution of previous formalisms, which decouples from disambiguation and external inventories and simplifies the task. MSL provides the necessary tools to encode the meaning across languages, paving the way for developing a high-quality semantic parsing dataset across different languages in a semi-automatic strategy. Subsequently, we manually refine a portion of this dataset and fine-tune GPT-3.5 to propagate these refinements across the dataset. Then, we manually annotate 1,100 sentences in eleven languages, including low-resource ones. Finally, we assess our dataset’s quality, showcasing the performance gap reduction across languages in Semantic Parsing.",
    "num_pages": 25
}