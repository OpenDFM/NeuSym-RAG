{
    "uuid": "b6669a77-8fd8-5989-b270-87cfc00b7b75",
    "title": "SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{lin-morency-2023-sentecon,\n    title = \"{S}ente{C}on: Leveraging Lexicons to Learn Human-Interpretable Language Representations\",\n    author = \"Lin, Victoria  and\n      Morency, Louis-Philippe\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.264\",\n    doi = \"10.18653/v1/2023.findings-acl.264\",\n    pages = \"4312--4331\",\n    abstract = \"Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model{'}s decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.\",\n}\n",
    "authors": [
        "Victoria Lin",
        "Louis-Philippe Morency"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.264.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/b6669a77-8fd8-5989-b270-87cfc00b7b75.pdf",
    "abstract": "Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a modelâ€™s decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.",
    "num_pages": 20
}