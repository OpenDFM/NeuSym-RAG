{
    "uuid": "42e61d91-71ac-5856-9b5a-2a1aedeb3c76",
    "title": "“Geen makkie”: Interpretable Classification and Simplification of Dutch Text Complexity",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
    "bibtex": "@inproceedings{hobo-etal-2023-geen,\n    title = \"{``}Geen makkie{''}: Interpretable Classification and Simplification of {D}utch Text Complexity\",\n    author = \"Hobo, Eliza  and\n      Pouw, Charlotte  and\n      Beinborn, Lisa\",\n    editor = {Kochmar, Ekaterina  and\n      Burstein, Jill  and\n      Horbach, Andrea  and\n      Laarmann-Quante, Ronja  and\n      Madnani, Nitin  and\n      Tack, Ana{\\\"\\i}s  and\n      Yaneva, Victoria  and\n      Yuan, Zheng  and\n      Zesch, Torsten},\n    booktitle = \"Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bea-1.42\",\n    doi = \"10.18653/v1/2023.bea-1.42\",\n    pages = \"503--517\",\n    abstract = \"An inclusive society needs to facilitate access to information for all of its members, including citizens with low literacy and with non-native language skills. We present an approach to assess Dutch text complexity on the sentence level and conduct an interpretability analysis to explore the link between neural models and linguistic complexity features. Building on these findings, we develop the first contextual lexical simplification model for Dutch and publish a pilot dataset for evaluation. We go beyondprevious work which primarily targeted lexical substitution and propose strategies for adjusting the model{'}s linguistic register to generate simpler candidates. Our results indicate that continual pre-training and multi-task learning with conceptually related tasks are promising directions for ensuring the simplicity of the generated substitutions.\",\n}\n",
    "authors": [
        "Eliza Hobo",
        "Charlotte Pouw",
        "Lisa Beinborn"
    ],
    "pdf_url": "https://aclanthology.org/2023.bea-1.42.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/42e61d91-71ac-5856-9b5a-2a1aedeb3c76.pdf",
    "abstract": "An inclusive society needs to facilitate access to information for all of its members, including citizens with low literacy and with non-native language skills. We present an approach to assess Dutch text complexity on the sentence level and conduct an interpretability analysis to explore the link between neural models and linguistic complexity features. Building on these findings, we develop the first contextual lexical simplification model for Dutch and publish a pilot dataset for evaluation. We go beyondprevious work which primarily targeted lexical substitution and propose strategies for adjusting the model’s linguistic register to generate simpler candidates. Our results indicate that continual pre-training and multi-task learning with conceptually related tasks are promising directions for ensuring the simplicity of the generated substitutions.",
    "num_pages": 15
}