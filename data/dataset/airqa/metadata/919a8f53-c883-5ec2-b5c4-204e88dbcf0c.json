{
    "uuid": "919a8f53-c883-5ec2-b5c4-204e88dbcf0c",
    "title": "Disagreeable, Slovenly, Honest and Un-named Women? Investigating Gender Bias in English Educational Resources by Extending Existing Gender Bias Taxonomies",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
    "bibtex": "@inproceedings{zhu-etal-2024-disagreeable,\n    title = \"Disagreeable, Slovenly, Honest and Un-named Women? Investigating Gender Bias in {E}nglish Educational Resources by Extending Existing Gender Bias Taxonomies\",\n    author = \"Zhu, Haotian  and\n      Gao, Kexin  and\n      Xia, Fei  and\n      Ostendorf, Mari\",\n    editor = \"Fale{\\'n}ska, Agnieszka  and\n      Basta, Christine  and\n      Costa-juss{\\`a}, Marta  and\n      Goldfarb-Tarrant, Seraphina  and\n      Nozza, Debora\",\n    booktitle = \"Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.gebnlp-1.14\",\n    doi = \"10.18653/v1/2024.gebnlp-1.14\",\n    pages = \"219--236\",\n    abstract = \"Gender bias has been extensively studied in both the educational field and the Natural Language Processing (NLP) field, the former using human coding to identify patterns associated with and causes of gender bias in text and the latter to detect, measure and mitigate gender bias in NLP output and models. This work aims to use NLP to facilitate automatic, quantitative analysis of educational text within the framework of a gender bias taxonomy. Analyses of both educational texts and a lexical resource (WordNet) reveal patterns of bias that can inform and aid educators in updating textbooks and lexical resources and in designing assessment items.\",\n}\n",
    "authors": [
        "Haotian Zhu",
        "Kexin Gao",
        "Fei Xia",
        "Mari Ostendorf"
    ],
    "pdf_url": "https://aclanthology.org/2024.gebnlp-1.14.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/919a8f53-c883-5ec2-b5c4-204e88dbcf0c.pdf",
    "abstract": "Gender bias has been extensively studied in both the educational field and the Natural Language Processing (NLP) field, the former using human coding to identify patterns associated with and causes of gender bias in text and the latter to detect, measure and mitigate gender bias in NLP output and models. This work aims to use NLP to facilitate automatic, quantitative analysis of educational text within the framework of a gender bias taxonomy. Analyses of both educational texts and a lexical resource (WordNet) reveal patterns of bias that can inform and aid educators in updating textbooks and lexical resources and in designing assessment items.",
    "num_pages": 18
}