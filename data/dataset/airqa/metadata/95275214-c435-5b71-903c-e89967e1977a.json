{
    "uuid": "95275214-c435-5b71-903c-e89967e1977a",
    "title": "CID at RRG24: Attempting in a Conditionally Initiated Decoding of Radiology Report Generation with Clinical Entities",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{liao-etal-2024-cid,\n    title = \"{CID} at {RRG}24: Attempting in a Conditionally Initiated Decoding of Radiology Report Generation with Clinical Entities\",\n    author = \"Liao, Yuxiang  and\n      Liang, Yuanbang  and\n      Qin, Yipeng  and\n      Liu, Hantao  and\n      Spasic, Irena\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.49\",\n    doi = \"10.18653/v1/2024.bionlp-1.49\",\n    pages = \"591--596\",\n    abstract = \"Radiology Report Generation (RRG) seeks to leverage deep learning techniques to automate the reporting process of radiologists. Current methods are typically modelling RRG as an image-to-text generation task that takes X-ray images as input and generates textual reports describing the corresponding clinical observations. However, the wording of the same clinical observation could have been influenced by the expression preference of radiologists. Nevertheless, such variability can be mitigated by normalizing textual reports into structured representations such as a graph structure. In this study, we attempt a novel paradigm for incorporating graph structural data into the RRG model. Our approach involves predicting graph labels based on visual features and subsequently initiating the decoding process through a template injection conditioned on the predicted labels. We trained and evaluated our model on the BioNLP 2024 Shared Task on Large-Scale Radiology Report Generation and submitted our results to the ViLMedic RRG leaderboard. Although our model showed a moderate ranking on the leaderboard, the results provide preliminary evidence for the feasibility of this new paradigm, warranting further exploration and refinement.\",\n}\n",
    "authors": [
        "Yuxiang Liao",
        "Yuanbang Liang",
        "Yipeng Qin",
        "Hantao Liu",
        "Irena Spasic"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.49.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/95275214-c435-5b71-903c-e89967e1977a.pdf",
    "abstract": "Radiology Report Generation (RRG) seeks to leverage deep learning techniques to automate the reporting process of radiologists. Current methods are typically modelling RRG as an image-to-text generation task that takes X-ray images as input and generates textual reports describing the corresponding clinical observations. However, the wording of the same clinical observation could have been influenced by the expression preference of radiologists. Nevertheless, such variability can be mitigated by normalizing textual reports into structured representations such as a graph structure. In this study, we attempt a novel paradigm for incorporating graph structural data into the RRG model. Our approach involves predicting graph labels based on visual features and subsequently initiating the decoding process through a template injection conditioned on the predicted labels. We trained and evaluated our model on the BioNLP 2024 Shared Task on Large-Scale Radiology Report Generation and submitted our results to the ViLMedic RRG leaderboard. Although our model showed a moderate ranking on the leaderboard, the results provide preliminary evidence for the feasibility of this new paradigm, warranting further exploration and refinement.",
    "num_pages": 6
}