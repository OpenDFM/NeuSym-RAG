{
    "uuid": "50d10cf6-4e19-535a-bcd2-75da315ced51",
    "title": "Evaluating Paraphrastic Robustness in Textual Entailment Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{verma-etal-2023-evaluating,\n    title = \"Evaluating Paraphrastic Robustness in Textual Entailment Models\",\n    author = \"Verma, Dhruv  and\n      Lal, Yash Kumar  and\n      Sinha, Shreyashee  and\n      Van Durme, Benjamin  and\n      Poliak, Adam\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.76\",\n    doi = \"10.18653/v1/2023.acl-short.76\",\n    pages = \"880--892\",\n    abstract = \"We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE models{'} predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16{\\%} of paraphrased examples, indicating that there is still room for improvement.\",\n}\n",
    "authors": [
        "Dhruv Verma",
        "Yash Kumar Lal",
        "Shreyashee Sinha",
        "Benjamin Van Durme",
        "Adam Poliak"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-short.76.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/50d10cf6-4e19-535a-bcd2-75da315ced51.pdf",
    "abstract": "We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE modelsâ€™ predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16% of paraphrased examples, indicating that there is still room for improvement.",
    "num_pages": 13
}