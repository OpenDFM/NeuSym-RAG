{
    "uuid": "d2b04419-d4a8-5aae-a7ea-e1760317a0e6",
    "title": "Can Large Language Models Safely Address Patient Questions Following Cataract Surgery?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{chowdhury-etal-2023-large,\n    title = \"Can Large Language Models Safely Address Patient Questions Following Cataract Surgery?\",\n    author = \"Chowdhury, Mohita  and\n      Lim, Ernest  and\n      Higham, Aisling  and\n      McKinnon, Rory  and\n      Ventoura, Nikoletta  and\n      He, Yajie  and\n      De Pennington, Nick\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.17\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.17\",\n    pages = \"131--137\",\n    abstract = \"Recent advances in large language models (LLMs) have generated significant interest in their application across various domains including healthcare. However, there is limited data on their safety and performance in real-world scenarios. This study uses data collected using an autonomous telemedicine clinical assistant. The assistant asks symptom-based questions to elicit patient concerns and allows patients to ask questions about their post-operative recovery. We utilise real-world postoperative questions posed to the assistant by a cohort of 120 patients to examine the safety and appropriateness of responses generated by a recent popular LLM by OpenAI, ChatGPT. We demonstrate that LLMs have the potential to helpfully address routine patient queries following routine surgery. However, important limitations around the safety of today{'}s models exist which must be considered.\",\n}\n",
    "authors": [
        "Mohita Chowdhury",
        "Ernest Lim",
        "Aisling Higham",
        "Rory McKinnon",
        "Nikoletta Ventoura",
        "Yajie He",
        "Nick De Pennington"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.17.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/d2b04419-d4a8-5aae-a7ea-e1760317a0e6.pdf",
    "abstract": "Recent advances in large language models (LLMs) have generated significant interest in their application across various domains including healthcare. However, there is limited data on their safety and performance in real-world scenarios. This study uses data collected using an autonomous telemedicine clinical assistant. The assistant asks symptom-based questions to elicit patient concerns and allows patients to ask questions about their post-operative recovery. We utilise real-world postoperative questions posed to the assistant by a cohort of 120 patients to examine the safety and appropriateness of responses generated by a recent popular LLM by OpenAI, ChatGPT. We demonstrate that LLMs have the potential to helpfully address routine patient queries following routine surgery. However, important limitations around the safety of todayâ€™s models exist which must be considered.",
    "num_pages": 7
}