{
    "uuid": "9a6c0c8a-1d60-54d7-b601-234e10de40bb",
    "title": "Improving Mathematics Tutoring With A Code Scratchpad",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)",
    "bibtex": "@inproceedings{upadhyay-etal-2023-improving,\n    title = \"Improving Mathematics Tutoring With A Code Scratchpad\",\n    author = \"Upadhyay, Shriyash  and\n      Ginsberg, Etan  and\n      Callison-Burch, Chris\",\n    editor = {Kochmar, Ekaterina  and\n      Burstein, Jill  and\n      Horbach, Andrea  and\n      Laarmann-Quante, Ronja  and\n      Madnani, Nitin  and\n      Tack, Ana{\\\"\\i}s  and\n      Yaneva, Victoria  and\n      Yuan, Zheng  and\n      Zesch, Torsten},\n    booktitle = \"Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.bea-1.2\",\n    doi = \"10.18653/v1/2023.bea-1.2\",\n    pages = \"20--28\",\n    abstract = \"Large language models can solve reasoning tasks (like math problems) more effectively when they are allowed to generate rationales. However, a good tutoring system should not just generate solutions, but should also generate explanations and should be able to correct and guide students. We show that providing a code scratchpad improves performance on each tutoring step with a gradeschool mathematics dataset. On these tutoring tasks, GPT-3 models provided with a code scratchpad significantly outperform those given only a language scratchpad (77.7{\\%} vs 48.7{\\%} cumulative accuracy).\",\n}\n",
    "authors": [
        "Shriyash Upadhyay",
        "Etan Ginsberg",
        "Chris Callison-Burch"
    ],
    "pdf_url": "https://aclanthology.org/2023.bea-1.2.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/9a6c0c8a-1d60-54d7-b601-234e10de40bb.pdf",
    "abstract": "Large language models can solve reasoning tasks (like math problems) more effectively when they are allowed to generate rationales. However, a good tutoring system should not just generate solutions, but should also generate explanations and should be able to correct and guide students. We show that providing a code scratchpad improves performance on each tutoring step with a gradeschool mathematics dataset. On these tutoring tasks, GPT-3 models provided with a code scratchpad significantly outperform those given only a language scratchpad (77.7% vs 48.7% cumulative accuracy).",
    "num_pages": 9
}