{
    "uuid": "8d542a4c-2a41-5658-bd08-59c8c16692e4",
    "title": "MAGE: Machine-generated Text Detection in the Wild",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{li-etal-2024-mage,\n    title = \"{MAGE}: Machine-generated Text Detection in the Wild\",\n    author = \"Li, Yafu  and\n      Li, Qintong  and\n      Cui, Leyang  and\n      Bi, Wei  and\n      Wang, Zhilin  and\n      Wang, Longyue  and\n      Yang, Linyi  and\n      Shi, Shuming  and\n      Zhang, Yue\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.3\",\n    doi = \"10.18653/v1/2024.acl-long.3\",\n    pages = \"36--53\",\n    abstract = \"Large language models (LLMs) have achieved human-level text generation, emphasizing the need for effective deepfake text detection to mitigate risks like the spread of fake news and plagiarism. Existing research has been constrained by evaluating detection methods o specific domains or particular language models. In practical scenarios, however, the detector faces texts from various domains or LLMs without knowing their sources. To this end, we build a comprehensive testbed by gathering texts from diverse human writings and deepfake texts generated by different LLMs. Empirical results on mainstream detection methods demonstrate the difficulties associated with detecting deepfake text in a wide-ranging testbed, particularly in out-of-distribution scenarios. Such difficulties align with the diminishing linguistic differences between the two text sources. Despite challenges, the top-performing detector can identify 84.12{\\%} out-of-domain texts generated by a new LLM, indicating the feasibility for application scenarios.\",\n}\n",
    "authors": [
        "Yafu Li",
        "Qintong Li",
        "Leyang Cui",
        "Wei Bi",
        "Zhilin Wang",
        "Longyue Wang",
        "Linyi Yang",
        "Shuming Shi",
        "Yue Zhang"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.3.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/8d542a4c-2a41-5658-bd08-59c8c16692e4.pdf",
    "abstract": "Large language models (LLMs) have achieved human-level text generation, emphasizing the need for effective deepfake text detection to mitigate risks like the spread of fake news and plagiarism. Existing research has been constrained by evaluating detection methods o specific domains or particular language models. In practical scenarios, however, the detector faces texts from various domains or LLMs without knowing their sources. To this end, we build a comprehensive testbed by gathering texts from diverse human writings and deepfake texts generated by different LLMs. Empirical results on mainstream detection methods demonstrate the difficulties associated with detecting deepfake text in a wide-ranging testbed, particularly in out-of-distribution scenarios. Such difficulties align with the diminishing linguistic differences between the two text sources. Despite challenges, the top-performing detector can identify 84.12% out-of-domain texts generated by a new LLM, indicating the feasibility for application scenarios.",
    "num_pages": 18
}