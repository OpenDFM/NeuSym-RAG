{
    "uuid": "599176cb-c9bb-540f-9525-69f30efc5da6",
    "title": "Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{roit-etal-2023-factually,\n    title = \"Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback\",\n    author = \"Roit, Paul  and\n      Ferret, Johan  and\n      Shani, Lior  and\n      Aharoni, Roee  and\n      Cideron, Geoffrey  and\n      Dadashi, Robert  and\n      Geist, Matthieu  and\n      Girgin, Sertan  and\n      Hussenot, Leonard  and\n      Keller, Orgad  and\n      Momchev, Nikola  and\n      Ramos Garea, Sabela  and\n      Stanczyk, Piotr  and\n      Vieillard, Nino  and\n      Bachem, Olivier  and\n      Elidan, Gal  and\n      Hassidim, Avinatan  and\n      Pietquin, Olivier  and\n      Szpektor, Idan\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.344\",\n    doi = \"10.18653/v1/2023.acl-long.344\",\n    pages = \"6252--6272\",\n    abstract = \"Despite the seeming success of contemporary grounded text generation systems, they often tend to generate factually inconsistent text with respect to their input. This phenomenon is emphasized in tasks like summarization, in which the generated summaries should be corroborated by their source article. In this work we leverage recent progress on textual entailment models to directly address this problem for abstractive summarization systems. We use reinforcement learning with reference-free, textual-entailment rewards to optimize for factual consistency and explore the ensuing trade-offs, as improved consistency may come at the cost of less informative or more extractive summaries. Our results, according to both automatic metrics and human evaluation, show that our method considerably improves the faithfulness, salience and conciseness of the generated summaries.\",\n}\n",
    "authors": [
        "Paul Roit",
        "Johan Ferret",
        "Lior Shani",
        "Roee Aharoni",
        "Geoffrey Cideron",
        "Robert Dadashi",
        "Matthieu Geist",
        "Sertan Girgin",
        "Leonard Hussenot",
        "Orgad Keller",
        "Nikola Momchev",
        "Sabela Ramos Garea",
        "Piotr Stanczyk",
        "Nino Vieillard",
        "Olivier Bachem",
        "Gal Elidan",
        "Avinatan Hassidim",
        "Olivier Pietquin",
        "Idan Szpektor"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.344.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/599176cb-c9bb-540f-9525-69f30efc5da6.pdf",
    "abstract": "Despite the seeming success of contemporary grounded text generation systems, they often tend to generate factually inconsistent text with respect to their input. This phenomenon is emphasized in tasks like summarization, in which the generated summaries should be corroborated by their source article. In this work we leverage recent progress on textual entailment models to directly address this problem for abstractive summarization systems. We use reinforcement learning with reference-free, textual-entailment rewards to optimize for factual consistency and explore the ensuing trade-offs, as improved consistency may come at the cost of less informative or more extractive summaries. Our results, according to both automatic metrics and human evaluation, show that our method considerably improves the faithfulness, salience and conciseness of the generated summaries.",
    "num_pages": 21
}