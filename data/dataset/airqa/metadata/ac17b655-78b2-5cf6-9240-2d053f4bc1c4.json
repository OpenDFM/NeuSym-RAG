{
    "uuid": "ac17b655-78b2-5cf6-9240-2d053f4bc1c4",
    "title": "BIG-C: a Multimodal Multi-Purpose Dataset for Bemba",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{sikasote-etal-2023-big,\n    title = \"{BIG}-{C}: a Multimodal Multi-Purpose Dataset for {B}emba\",\n    author = \"Sikasote, Claytone  and\n      Mukonde, Eunice  and\n      Alam, Md Mahfuz Ibn  and\n      Anastasopoulos, Antonios\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.115\",\n    doi = \"10.18653/v1/2023.acl-long.115\",\n    pages = \"2062--2078\",\n    abstract = \"We present BIG-C (Bemba Image Grounded Conversations), a large multimodal dataset for Bemba. While Bemba is the most populous language of Zambia, it exhibits a dearth of resources which render the development of language technologies or language processing research almost impossible. The dataset is comprised of multi-turn dialogues between Bemba speakers based on images, transcribed and translated into English. There are more than 92,000 utterances/sentences, amounting to more than 180 hours of audio data with corresponding transcriptions and English translations. We also provide baselines on speech recognition (ASR), machine translation (MT) and speech translation (ST) tasks, and sketch out other potential future multimodal uses of our dataset. We hope that by making the dataset available to the research community, this work will foster research and encourage collaboration across the language, speech, and vision communities especially for languages outside the {``}traditionally{''} used high-resourced ones. All data and code are publicly available: [\\url{https://github.com/csikasote/bigc}](\\url{https://github.com/csikasote/bigc}).\",\n}\n",
    "authors": [
        "Claytone Sikasote",
        "Eunice Mukonde",
        "Md Mahfuz Ibn Alam",
        "Antonios Anastasopoulos"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.115.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/ac17b655-78b2-5cf6-9240-2d053f4bc1c4.pdf",
    "abstract": "We present BIG-C (Bemba Image Grounded Conversations), a large multimodal dataset for Bemba. While Bemba is the most populous language of Zambia, it exhibits a dearth of resources which render the development of language technologies or language processing research almost impossible. The dataset is comprised of multi-turn dialogues between Bemba speakers based on images, transcribed and translated into English. There are more than 92,000 utterances/sentences, amounting to more than 180 hours of audio data with corresponding transcriptions and English translations. We also provide baselines on speech recognition (ASR), machine translation (MT) and speech translation (ST) tasks, and sketch out other potential future multimodal uses of our dataset. We hope that by making the dataset available to the research community, this work will foster research and encourage collaboration across the language, speech, and vision communities especially for languages outside the “traditionally” used high-resourced ones. All data and code are publicly available: [https://github.com/csikasote/bigc](https://github.com/csikasote/bigc).",
    "num_pages": 17
}