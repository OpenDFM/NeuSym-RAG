{
    "uuid": "a542ea98-bd09-5984-9d93-2f47c88ee2e9",
    "title": "A Dataset for Physical and Abstract Plausibility and Sources of Human Disagreement",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)",
    "bibtex": "@inproceedings{eichel-schulte-im-walde-2023-dataset,\n    title = \"A Dataset for Physical and Abstract Plausibility and Sources of Human Disagreement\",\n    author = \"Eichel, Annerose  and\n      Schulte Im Walde, Sabine\",\n    editor = \"Prange, Jakob  and\n      Friedrich, Annemarie\",\n    booktitle = \"Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.law-1.4\",\n    doi = \"10.18653/v1/2023.law-1.4\",\n    pages = \"31--45\",\n    abstract = \"We present a novel dataset for physical and abstract plausibility of events in English. Based on naturally occurring sentences extracted from Wikipedia, we infiltrate degrees of abstractness, and automatically generate perturbed pseudo-implausible events. We annotate a filtered and balanced subset for plausibility using crowd-sourcing, and perform extensive cleansing to ensure annotation quality. In-depth quantitative analyses indicate that annotators favor plausibility over implausibility and disagree more on implausible events. Furthermore, our plausibility dataset is the first to capture abstractness in events to the same extent as concreteness, and we find that event abstractness has an impact on plausibility ratings: more concrete event participants trigger a perception of implausibility.\",\n}\n",
    "authors": [
        "Annerose Eichel",
        "Sabine Schulte Im Walde"
    ],
    "pdf_url": "https://aclanthology.org/2023.law-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/a542ea98-bd09-5984-9d93-2f47c88ee2e9.pdf",
    "abstract": "We present a novel dataset for physical and abstract plausibility of events in English. Based on naturally occurring sentences extracted from Wikipedia, we infiltrate degrees of abstractness, and automatically generate perturbed pseudo-implausible events. We annotate a filtered and balanced subset for plausibility using crowd-sourcing, and perform extensive cleansing to ensure annotation quality. In-depth quantitative analyses indicate that annotators favor plausibility over implausibility and disagree more on implausible events. Furthermore, our plausibility dataset is the first to capture abstractness in events to the same extent as concreteness, and we find that event abstractness has an impact on plausibility ratings: more concrete event participants trigger a perception of implausibility.",
    "num_pages": 15
}