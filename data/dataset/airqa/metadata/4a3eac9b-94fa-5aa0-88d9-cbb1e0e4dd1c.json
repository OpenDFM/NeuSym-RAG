{
    "uuid": "4a3eac9b-94fa-5aa0-88d9-cbb1e0e4dd1c",
    "title": "Unified Contextual Query Rewriting",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
    "bibtex": "@inproceedings{zhou-etal-2023-unified,\n    title = \"Unified Contextual Query Rewriting\",\n    author = \"Zhou, Yingxue  and\n      Hao, Jie  and\n      Rungta, Mukund  and\n      Liu, Yang  and\n      Cho, Eunah  and\n      Fan, Xing  and\n      Lu, Yanbin  and\n      Vasudevan, Vishal  and\n      Gillespie, Kellen  and\n      Raeesy, Zeynab\",\n    editor = \"Sitaram, Sunayana  and\n      Beigman Klebanov, Beata  and\n      Williams, Jason D\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-industry.58\",\n    doi = \"10.18653/v1/2023.acl-industry.58\",\n    pages = \"608--615\",\n    abstract = \"Query rewriting (QR) is an important technique for user friction (i.e. recovering ASR error or system error) reduction and contextual carryover (i.e. ellipsis and co-reference) in conversational AI systems. Recently, generation-based QR models have achieved promising results on these two tasks separately. Although these two tasks have many similarities such as they both use the previous dialogue along with the current request as model input, there is no unified model to solve them jointly. To this end, we propose a unified contextual query rewriting model that unifies QR for both reducing friction and contextual carryover purpose. Moreover, we involve multiple auxiliary tasks such as trigger prediction and NLU interpretation tasks to boost the performance of the rewrite. We leverage the text-to-text unified framework which uses independent tasks with weighted loss to account for task importance. Then we propose new unified multitask learning strategies including a sequential model which outputs one sentence for multi-tasks, and a hybrid model where some tasks are independent and some tasks are sequentially generated. Our experimental results demonstrate the effectiveness of the proposed unified learning methods.\",\n}\n",
    "authors": [
        "Yingxue Zhou",
        "Jie Hao",
        "Mukund Rungta",
        "Yang Liu",
        "Eunah Cho",
        "Xing Fan",
        "Yanbin Lu",
        "Vishal Vasudevan",
        "Kellen Gillespie",
        "Zeynab Raeesy"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-industry.58.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4a3eac9b-94fa-5aa0-88d9-cbb1e0e4dd1c.pdf",
    "abstract": "Query rewriting (QR) is an important technique for user friction (i.e. recovering ASR error or system error) reduction and contextual carryover (i.e. ellipsis and co-reference) in conversational AI systems. Recently, generation-based QR models have achieved promising results on these two tasks separately. Although these two tasks have many similarities such as they both use the previous dialogue along with the current request as model input, there is no unified model to solve them jointly. To this end, we propose a unified contextual query rewriting model that unifies QR for both reducing friction and contextual carryover purpose. Moreover, we involve multiple auxiliary tasks such as trigger prediction and NLU interpretation tasks to boost the performance of the rewrite. We leverage the text-to-text unified framework which uses independent tasks with weighted loss to account for task importance. Then we propose new unified multitask learning strategies including a sequential model which outputs one sentence for multi-tasks, and a hybrid model where some tasks are independent and some tasks are sequentially generated. Our experimental results demonstrate the effectiveness of the proposed unified learning methods.",
    "num_pages": 8
}