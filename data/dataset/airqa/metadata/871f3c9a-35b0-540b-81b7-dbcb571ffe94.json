{
    "uuid": "871f3c9a-35b0-540b-81b7-dbcb571ffe94",
    "title": "Factual or Contextual? Disentangling Error Types in Entity Description Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{goyal-etal-2023-factual,\n    title = \"Factual or Contextual? Disentangling Error Types in Entity Description Generation\",\n    author = \"Goyal, Navita  and\n      Nenkova, Ani  and\n      Daum{\\'e} III, Hal\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.463\",\n    doi = \"10.18653/v1/2023.acl-long.463\",\n    pages = \"8322--8340\",\n    abstract = \"In the task of entity description generation, given a context and a specified entity, a model must describe that entity correctly and in a contextually-relevant way. In this task, as well as broader language generation tasks, the generation of a nonfactual description (factual error) versus an incongruous description (contextual error) is fundamentally different, yet often conflated. We develop an evaluation paradigm that enables us to disentangle these two types of errors in naturally occurring textual contexts. We find that factuality and congruity are often at odds, and that models specifically struggle with accurate descriptions of entities that are less familiar to people. This shortcoming of language models raises concerns around the trustworthiness of such models, since factual errors on less well-known entities are exactly those that a human reader will not recognize.\",\n}\n",
    "authors": [
        "Navita Goyal",
        "Ani Nenkova",
        "Hal Daum√© III"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.463.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/871f3c9a-35b0-540b-81b7-dbcb571ffe94.pdf",
    "abstract": "In the task of entity description generation, given a context and a specified entity, a model must describe that entity correctly and in a contextually-relevant way. In this task, as well as broader language generation tasks, the generation of a nonfactual description (factual error) versus an incongruous description (contextual error) is fundamentally different, yet often conflated. We develop an evaluation paradigm that enables us to disentangle these two types of errors in naturally occurring textual contexts. We find that factuality and congruity are often at odds, and that models specifically struggle with accurate descriptions of entities that are less familiar to people. This shortcoming of language models raises concerns around the trustworthiness of such models, since factual errors on less well-known entities are exactly those that a human reader will not recognize.",
    "num_pages": 19
}