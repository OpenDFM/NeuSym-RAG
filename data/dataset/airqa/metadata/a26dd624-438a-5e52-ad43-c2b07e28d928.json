{
    "uuid": "a26dd624-438a-5e52-ad43-c2b07e28d928",
    "title": "AIRI at RRG24: LLaVa with specialised encoder and decoder",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{munkhoeva-etal-2024-airi,\n    title = \"{AIRI} at {RRG}24: {LL}a{V}a with specialised encoder and decoder\",\n    author = \"Munkhoeva, Marina  and\n      Umerenkov, Dmitry  and\n      Samokhin, Valentin\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.51\",\n    doi = \"10.18653/v1/2024.bionlp-1.51\",\n    pages = \"603--607\",\n    abstract = \"We present a new approach to generating the {`}Findings{'} and {`}Impression{'} sections in the chest X-rays radiology reports, developed as part of the shared radiology task at BioNLP 2024. By integrating a DINOv2 vision encoder trained on medical data with specialized biomedical large language model using the LLaVA framework, our method addresses complex medical semantics and diverse findings in imaging. We use datasets from PadChest, BIMCV-COVID19, CheXpert, OpenI, and MIMIC-CXR. The evaluation metrics demonstrate our method{'}s effectiveness and the potential for automating the generation of radiology reports.\",\n}\n",
    "authors": [
        "Marina Munkhoeva",
        "Dmitry Umerenkov",
        "Valentin Samokhin"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.51.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a26dd624-438a-5e52-ad43-c2b07e28d928.pdf",
    "abstract": "We present a new approach to generating the ‘Findings’ and ‘Impression’ sections in the chest X-rays radiology reports, developed as part of the shared radiology task at BioNLP 2024. By integrating a DINOv2 vision encoder trained on medical data with specialized biomedical large language model using the LLaVA framework, our method addresses complex medical semantics and diverse findings in imaging. We use datasets from PadChest, BIMCV-COVID19, CheXpert, OpenI, and MIMIC-CXR. The evaluation metrics demonstrate our method’s effectiveness and the potential for automating the generation of radiology reports.",
    "num_pages": 5
}