{
    "uuid": "980db414-3a9d-5645-a523-36abafcc44c1",
    "title": "Challenges in Urdu Machine Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Seventh Workshop on Technologies for Machine Translation of Low-Resource Languages (LoResMT 2024)",
    "bibtex": "@inproceedings{basit-etal-2024-challenges,\n    title = \"Challenges in {U}rdu Machine Translation\",\n    author = \"Basit, Abdul  and\n      Azeemi, Abdul Hameed  and\n      Raza, Agha Ali\",\n    editor = \"Ojha, Atul Kr.  and\n      Liu, Chao-hong  and\n      Vylomova, Ekaterina  and\n      Pirinen, Flammie  and\n      Abbott, Jade  and\n      Washington, Jonathan  and\n      Oco, Nathaniel  and\n      Malykh, Valentin  and\n      Logacheva, Varvara  and\n      Zhao, Xiaobing\",\n    booktitle = \"Proceedings of the Seventh Workshop on Technologies for Machine Translation of Low-Resource Languages (LoResMT 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.loresmt-1.4\",\n    doi = \"10.18653/v1/2024.loresmt-1.4\",\n    pages = \"44--49\",\n    abstract = \"Recent advancements in Neural Machine Translation (NMT) systems have significantly improved model performance on various translation benchmarks. However, these systems still face numerous challenges when translating low-resource languages such as Urdu. In this work, we highlight the specific issues faced by machine translation systems when translating Urdu language. We first conduct a comprehensive evaluation of English to Urdu Machine Translation with four diverse models: GPT-3.5 (a large language model), opus-mt-en-ur (a bilingual translation model), NLLB (a model trained for translating 200 languages), and IndicTrans2 (a specialized model for translating low-resource Indic languages). The results demonstrate that IndicTrans2 significantly outperforms other models in Urdu Machine Translation. To understand the differences in the performance of these models, we analyze the Urdu word distribution in different training datasets and compare the training methodologies. Finally, we uncover the specific translation issues and provide suggestions for improvements in Urdu machine translation systems.\",\n}\n",
    "authors": [
        "Abdul Basit",
        "Abdul Hameed Azeemi",
        "Agha Ali Raza"
    ],
    "pdf_url": "https://aclanthology.org/2024.loresmt-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/980db414-3a9d-5645-a523-36abafcc44c1.pdf",
    "abstract": "Recent advancements in Neural Machine Translation (NMT) systems have significantly improved model performance on various translation benchmarks. However, these systems still face numerous challenges when translating low-resource languages such as Urdu. In this work, we highlight the specific issues faced by machine translation systems when translating Urdu language. We first conduct a comprehensive evaluation of English to Urdu Machine Translation with four diverse models: GPT-3.5 (a large language model), opus-mt-en-ur (a bilingual translation model), NLLB (a model trained for translating 200 languages), and IndicTrans2 (a specialized model for translating low-resource Indic languages). The results demonstrate that IndicTrans2 significantly outperforms other models in Urdu Machine Translation. To understand the differences in the performance of these models, we analyze the Urdu word distribution in different training datasets and compare the training methodologies. Finally, we uncover the specific translation issues and provide suggestions for improvements in Urdu machine translation systems.",
    "num_pages": 6
}