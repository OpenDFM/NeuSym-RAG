{
    "uuid": "3a5e3487-5844-56c2-bd88-c169609294ee",
    "title": "Generative Debunking of Climate Misinformation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024)",
    "bibtex": "@inproceedings{zanartu-etal-2024-generative,\n    title = \"Generative Debunking of Climate Misinformation\",\n    author = \"Zanartu, Francisco  and\n      Otmakhova, Yulia  and\n      Cook, John  and\n      Frermann, Lea\",\n    editor = \"Stammbach, Dominik  and\n      Ni, Jingwei  and\n      Schimanski, Tobias  and\n      Dutia, Kalyan  and\n      Singh, Alok  and\n      Bingler, Julia  and\n      Christiaen, Christophe  and\n      Kushwaha, Neetu  and\n      Muccione, Veruska  and\n      A. Vaghefi, Saeid  and\n      Leippold, Markus\",\n    booktitle = \"Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.climatenlp-1.4\",\n    doi = \"10.18653/v1/2024.climatenlp-1.4\",\n    pages = \"46--62\",\n    abstract = \"Misinformation about climate change causes numerous negative impacts, necessitating corrective responses. Psychological research has offered various strategies for reducing the influence of climate misinformation, such as the fact-myth-fallacy-fact-structure. However, practically implementing corrective interventions at scale represents a challenge. Automatic detection and correction of misinformation offers a solution to the misinformation problem. This study documents the development of large language models that accept as input a climate myth and produce a debunking that adheres to the fact-myth-fallacy-fact ({``}truth sandwich{''}) structure, by incorporating contrarian claim classification and fallacy detection into an LLM prompting framework. We combine open (Mixtral, Palm2) and proprietary (GPT-4) LLMs with prompting strategies of varying complexity. Experiments reveal promising performance of GPT-4 and Mixtral if combined with structured prompts. We identify specific challenges of debunking generation and human evaluation, and map out avenues for future work. We release a dataset of high-quality truth-sandwich debunkings, source code and a demo of the debunking system.\",\n}\n",
    "authors": [
        "Francisco Zanartu",
        "Yulia Otmakhova",
        "John Cook",
        "Lea Frermann"
    ],
    "pdf_url": "https://aclanthology.org/2024.climatenlp-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/3a5e3487-5844-56c2-bd88-c169609294ee.pdf",
    "abstract": "Misinformation about climate change causes numerous negative impacts, necessitating corrective responses. Psychological research has offered various strategies for reducing the influence of climate misinformation, such as the fact-myth-fallacy-fact-structure. However, practically implementing corrective interventions at scale represents a challenge. Automatic detection and correction of misinformation offers a solution to the misinformation problem. This study documents the development of large language models that accept as input a climate myth and produce a debunking that adheres to the fact-myth-fallacy-fact (“truth sandwich”) structure, by incorporating contrarian claim classification and fallacy detection into an LLM prompting framework. We combine open (Mixtral, Palm2) and proprietary (GPT-4) LLMs with prompting strategies of varying complexity. Experiments reveal promising performance of GPT-4 and Mixtral if combined with structured prompts. We identify specific challenges of debunking generation and human evaluation, and map out avenues for future work. We release a dataset of high-quality truth-sandwich debunkings, source code and a demo of the debunking system.",
    "num_pages": 17
}