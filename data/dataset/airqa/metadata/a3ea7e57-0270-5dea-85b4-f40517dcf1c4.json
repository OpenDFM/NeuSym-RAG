{
    "uuid": "a3ea7e57-0270-5dea-85b4-f40517dcf1c4",
    "title": "Error-preserving Automatic Speech Recognition of Young English Learners’ Language",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{michot-etal-2024-error,\n    title = \"Error-preserving Automatic Speech Recognition of Young {E}nglish Learners{'} Language\",\n    author = {Michot, Janick  and\n      H{\\\"u}rlimann, Manuela  and\n      Deriu, Jan  and\n      Sauer, Luzia  and\n      Mlynchyk, Katsiaryna  and\n      Cieliebak, Mark},\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.348\",\n    doi = \"10.18653/v1/2024.acl-long.348\",\n    pages = \"6444--6454\",\n    abstract = \"One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. The recent advances in speech technology and natural language processing allow the creation of novel tools to practice their speaking skills. In this work, we tackle the first component of such a pipeline, namely, the automated speech recognition module (ASR). State-of-the-art models are often trained on adult read-aloud data by native speakers and do not transfer well to young language learners{'} speech. Second, most ASR systems contain a powerful language model, which smooths out mistakes made by the speakers. To give corrective feedback, which is a crucial part of language learning, the ASR systems in our setting need to preserve the mistakes made by the language learners. In this work, we build an ASR system that satisfies these requirements: it works on spontaneous speech by young language learners and preserves their mistakes. For this, we collected a corpus containing around 85 hours of English audio spoken by Swiss learners from grades 4 to 6 on different language learning tasks, which we used to train an ASR model. Our experiments show that our model benefits from direct fine-tuning of children{'}s voices and has a much higher error preservation rate.\",\n}\n",
    "authors": [
        "Janick Michot",
        "Manuela Hürlimann",
        "Jan Deriu",
        "Luzia Sauer",
        "Katsiaryna Mlynchyk",
        "Mark Cieliebak"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.348.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/a3ea7e57-0270-5dea-85b4-f40517dcf1c4.pdf",
    "abstract": "One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. The recent advances in speech technology and natural language processing allow the creation of novel tools to practice their speaking skills. In this work, we tackle the first component of such a pipeline, namely, the automated speech recognition module (ASR). State-of-the-art models are often trained on adult read-aloud data by native speakers and do not transfer well to young language learners’ speech. Second, most ASR systems contain a powerful language model, which smooths out mistakes made by the speakers. To give corrective feedback, which is a crucial part of language learning, the ASR systems in our setting need to preserve the mistakes made by the language learners. In this work, we build an ASR system that satisfies these requirements: it works on spontaneous speech by young language learners and preserves their mistakes. For this, we collected a corpus containing around 85 hours of English audio spoken by Swiss learners from grades 4 to 6 on different language learning tasks, which we used to train an ASR model. Our experiments show that our model benefits from direct fine-tuning of children’s voices and has a much higher error preservation rate.",
    "num_pages": 11
}