{
    "uuid": "70d03fa7-262b-5c3d-8297-998e88def386",
    "title": "Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{sun-etal-2024-prompt,\n    title = \"Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization\",\n    author = \"Sun, Shichao  and\n      Yuan, Ruifeng  and\n      Cao, Ziqiang  and\n      Li, Wenjie  and\n      Liu, Pengfei\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.449\",\n    doi = \"10.18653/v1/2024.findings-acl.449\",\n    pages = \"7551--7558\",\n}\n",
    "authors": [
        "Shichao Sun",
        "Ruifeng Yuan",
        "Ziqiang Cao",
        "Wenjie Li",
        "Pengfei Liu"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.449.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/70d03fa7-262b-5c3d-8297-998e88def386.pdf",
    "abstract": "Large language models (LLMs) have demonstrated the capacity to improve summary quality by mirroring a human-like iterative process of critique and refinement starting from the initial draft. Two strategies are designed to perform this iterative process: Prompt Chaining and Stepwise Prompt. Prompt chaining orchestrates the drafting, critiquing, and refining phases through a series of three discrete prompts, while Stepwise prompt integrates these phases within a single prompt. However, the relative effectiveness of the two methods has not been extensively studied. This paper is dedicated to examining and comparing these two methods in the context of text summarization to ascertain which method stands out as the most effective. Experimental results show that the prompt chaining method can produce a more favorable outcome. This might be because stepwise prompt might produce a simulated refinement process according to our various experiments. Since refinement is adaptable to diverse tasks, our conclusions have the potential to be extrapolated to other applications, thereby offering insights that may contribute to the broader development of LLMs.",
    "num_pages": 8
}