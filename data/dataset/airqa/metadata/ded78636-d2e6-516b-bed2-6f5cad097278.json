{
    "uuid": "ded78636-d2e6-516b-bed2-6f5cad097278",
    "title": "Conditioning LLMs with Emotion in Neural Machine Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
    "bibtex": "@inproceedings{brazier-rouas-2024-conditioning,\n    title = \"Conditioning {LLM}s with Emotion in Neural Machine Translation\",\n    author = \"Brazier, Charles  and\n      Rouas, Jean-Luc\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.iwslt-1.5\",\n    doi = \"10.18653/v1/2024.iwslt-1.5\",\n    pages = \"33--38\",\n    abstract = \"Large Language Models (LLMs) have shown remarkable performance in Natural Language Processing tasks, including Machine Translation (MT). In this work, we propose a novel MT pipeline that integrates emotion information extracted from a Speech Emotion Recognition (SER) model into LLMs to enhance translation quality. We first fine-tune five existing LLMs on the Libri-trans dataset and select the most performant model. Subsequently, we augment LLM prompts with different dimensional emotions and train the selected LLM under these different configurations. Our experiments reveal that integrating emotion information, especially arousal, into LLM prompts leads to notable improvements in translation quality.\",\n}\n",
    "authors": [
        "Charles Brazier",
        "Jean-Luc Rouas"
    ],
    "pdf_url": "https://aclanthology.org/2024.iwslt-1.5.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ded78636-d2e6-516b-bed2-6f5cad097278.pdf",
    "abstract": "Large Language Models (LLMs) have shown remarkable performance in Natural Language Processing tasks, including Machine Translation (MT). In this work, we propose a novel MT pipeline that integrates emotion information extracted from a Speech Emotion Recognition (SER) model into LLMs to enhance translation quality. We first fine-tune five existing LLMs on the Libri-trans dataset and select the most performant model. Subsequently, we augment LLM prompts with different dimensional emotions and train the selected LLM under these different configurations. Our experiments reveal that integrating emotion information, especially arousal, into LLM prompts leads to notable improvements in translation quality.",
    "num_pages": 6
}