{
    "uuid": "34aaa3a4-c08d-5f18-8761-ddfe0c538d50",
    "title": "Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{zhang-etal-2024-revisiting-opro,\n    title = \"Revisiting {OPRO}: The Limitations of Small-Scale {LLM}s as Optimizers\",\n    author = \"Zhang, Tuo  and\n      Yuan, Jinyue  and\n      Avestimehr, Salman\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.100\",\n    doi = \"10.18653/v1/2024.findings-acl.100\",\n    pages = \"1727--1735\",\n    abstract = \"Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy. In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B. Our investigation reveals that OPRO shows limited effectiveness in small-scale LLMs, with limited inference capabilities constraining optimization ability. We suggest future automatic prompting engineering to consider both model capabilities and computational costs. Additionally, for small-scale LLMs, we recommend direct instructions that clearly outline objectives and methodologies as robust prompt baselines, ensuring efficient and effective prompt engineering in ongoing research.\",\n}\n",
    "authors": [
        "Tuo Zhang",
        "Jinyue Yuan",
        "Salman Avestimehr"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.100.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/34aaa3a4-c08d-5f18-8761-ddfe0c538d50.pdf",
    "abstract": "Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy. In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B. Our investigation reveals that OPRO shows limited effectiveness in small-scale LLMs, with limited inference capabilities constraining optimization ability. We suggest future automatic prompting engineering to consider both model capabilities and computational costs. Additionally, for small-scale LLMs, we recommend direct instructions that clearly outline objectives and methodologies as robust prompt baselines, ensuring efficient and effective prompt engineering in ongoing research.",
    "num_pages": 9
}