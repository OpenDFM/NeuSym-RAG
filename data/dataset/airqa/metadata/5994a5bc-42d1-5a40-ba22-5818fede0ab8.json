{
    "uuid": "5994a5bc-42d1-5a40-ba22-5818fede0ab8",
    "title": "Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{jiang-etal-2023-text,\n    title = \"Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models\",\n    author = \"Jiang, Pengcheng  and\n      Agarwal, Shivam  and\n      Jin, Bowen  and\n      Wang, Xuan  and\n      Sun, Jimeng  and\n      Han, Jiawei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.709\",\n    doi = \"10.18653/v1/2023.findings-acl.709\",\n    pages = \"11161--11180\",\n    abstract = \"The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TagReal that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TagReal achieves state-of-the-art performance on two benchmark datasets. We find that TagReal has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.\",\n}\n",
    "authors": [
        "Pengcheng Jiang",
        "Shivam Agarwal",
        "Bowen Jin",
        "Xuan Wang",
        "Jimeng Sun",
        "Jiawei Han"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.709.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/5994a5bc-42d1-5a40-ba22-5818fede0ab8.pdf",
    "abstract": "The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TagReal that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TagReal achieves state-of-the-art performance on two benchmark datasets. We find that TagReal has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods.",
    "num_pages": 20
}