{
    "uuid": "fbcce349-1253-576f-bec4-95cf3b7da743",
    "title": "Epistemology of Language Models: Do Language Models Have Holistic Knowledge?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{kim-thorne-2024-epistemology,\n    title = \"Epistemology of Language Models: Do Language Models Have Holistic Knowledge?\",\n    author = \"Kim, Minsu  and\n      Thorne, James\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.751\",\n    doi = \"10.18653/v1/2024.findings-acl.751\",\n    pages = \"12644--12669\",\n    abstract = \"This paper investigates the inherent knowledge in language models from the perspective of epistemological holism. The purpose of this paper is to explore whether LLMs exhibit characteristics consistent with epistemological holism. These characteristics suggest that core knowledge, such as commonsense, general, and specific knowledge, each plays a specific role, serving as the foundation of our knowledge system and being difficult to revise. To assess these traits related to holism, we created a scientific reasoning dataset and examined the epistemology of language models through three tasks: Abduction, Revision, and Argument Generation. In the abduction task, the language models explained situations while avoiding revising the core knowledge. However, in other tasks, the language models were revealed not to distinguish between core and peripheral knowledge, showing an incomplete alignment with holistic knowledge principles.\",\n}\n",
    "authors": [
        "Minsu Kim",
        "James Thorne"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.751.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/fbcce349-1253-576f-bec4-95cf3b7da743.pdf",
    "abstract": "This paper investigates the inherent knowledge in language models from the perspective of epistemological holism. The purpose of this paper is to explore whether LLMs exhibit characteristics consistent with epistemological holism. These characteristics suggest that core knowledge, such as commonsense, general, and specific knowledge, each plays a specific role, serving as the foundation of our knowledge system and being difficult to revise. To assess these traits related to holism, we created a scientific reasoning dataset and examined the epistemology of language models through three tasks: Abduction, Revision, and Argument Generation. In the abduction task, the language models explained situations while avoiding revising the core knowledge. However, in other tasks, the language models were revealed not to distinguish between core and peripheral knowledge, showing an incomplete alignment with holistic knowledge principles.",
    "num_pages": 26
}