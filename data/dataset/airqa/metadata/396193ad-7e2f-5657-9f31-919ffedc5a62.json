{
    "uuid": "396193ad-7e2f-5657-9f31-919ffedc5a62",
    "title": "Multi-Objective Linguistic Control of Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{nguyen-etal-2024-multi,\n    title = \"Multi-Objective Linguistic Control of Large Language Models\",\n    author = \"Nguyen, Dang  and\n      Chen, Jiuhai  and\n      Zhou, Tianyi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.257\",\n    doi = \"10.18653/v1/2024.findings-acl.257\",\n    pages = \"4336--4347\",\n    abstract = \"Large language models (LLMs), despite their breakthroughs on many challenging benchmark tasks, prefer to generate verbose responses and lack the controllability of output complexity, which is usually preferred by human users in practice. In this paper, we study how to precisely control multiple linguistic complexities of LLM output by finetuning using off-the-shelf data. To this end, we propose multi-control tuning (MCTune), which includes multiple linguistic complexity values of ground-truth responses as controls in the input for instruction tuning. We finetune LLaMA2-7B on Alpaca-GPT4 and WizardLM datasets. Evaluations on widely used benchmarks demonstrate that our method does not only improve LLMs{'} multi-complexity controllability substantially but also retains or even enhances the quality of the responses as a side benefit.\",\n}\n",
    "authors": [
        "Dang Nguyen",
        "Jiuhai Chen",
        "Tianyi Zhou"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.257.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/396193ad-7e2f-5657-9f31-919ffedc5a62.pdf",
    "abstract": "Large language models (LLMs), despite their breakthroughs on many challenging benchmark tasks, prefer to generate verbose responses and lack the controllability of output complexity, which is usually preferred by human users in practice. In this paper, we study how to precisely control multiple linguistic complexities of LLM output by finetuning using off-the-shelf data. To this end, we propose multi-control tuning (MCTune), which includes multiple linguistic complexity values of ground-truth responses as controls in the input for instruction tuning. We finetune LLaMA2-7B on Alpaca-GPT4 and WizardLM datasets. Evaluations on widely used benchmarks demonstrate that our method does not only improve LLMsâ€™ multi-complexity controllability substantially but also retains or even enhances the quality of the responses as a side benefit.",
    "num_pages": 12
}