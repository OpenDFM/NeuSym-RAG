{
    "uuid": "2ed9eb33-af6c-509e-8ff7-481efc2e0a6c",
    "title": "Faking Fake News for Real Fake News Detection: Propaganda-Loaded Training Data Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{huang-etal-2023-faking,\n    title = \"Faking Fake News for Real Fake News Detection: Propaganda-Loaded Training Data Generation\",\n    author = \"Huang, Kung-Hsiang  and\n      McKeown, Kathleen  and\n      Nakov, Preslav  and\n      Choi, Yejin  and\n      Ji, Heng\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.815\",\n    doi = \"10.18653/v1/2023.acl-long.815\",\n    pages = \"14571--14589\",\n    abstract = \"Despite recent advances in detecting fake news generated by neural models, their results are not readily applicable to effective detection of human-written disinformation. What limits the successful transfer between them is the sizable gap between machine-generated fake news and human-authored ones, including the notable differences in terms of style and underlying intent. With this in mind, we propose a novel framework for generating training examples that are informed by the known styles and strategies of human-authored propaganda. Specifically, we perform self-critical sequence training guided by natural language inference to ensure the validity of the generated articles, while also incorporating propaganda techniques, such as appeal to authority and loaded language. In particular, we create a new training dataset, PropaNews, with 2,256 examples, which we release for future use. Our experimental results show that fake news detectors trained on PropaNews are better at detecting human-written disinformation by 3.62{--}7.69{\\%} F1 score on two public datasets.\",\n}\n",
    "authors": [
        "Kung-Hsiang Huang",
        "Kathleen McKeown",
        "Preslav Nakov",
        "Yejin Choi",
        "Heng Ji"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.815.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/2ed9eb33-af6c-509e-8ff7-481efc2e0a6c.pdf",
    "abstract": "Despite recent advances in detecting fake news generated by neural models, their results are not readily applicable to effective detection of human-written disinformation. What limits the successful transfer between them is the sizable gap between machine-generated fake news and human-authored ones, including the notable differences in terms of style and underlying intent. With this in mind, we propose a novel framework for generating training examples that are informed by the known styles and strategies of human-authored propaganda. Specifically, we perform self-critical sequence training guided by natural language inference to ensure the validity of the generated articles, while also incorporating propaganda techniques, such as appeal to authority and loaded language. In particular, we create a new training dataset, PropaNews, with 2,256 examples, which we release for future use. Our experimental results show that fake news detectors trained on PropaNews are better at detecting human-written disinformation by 3.62â€“7.69% F1 score on two public datasets.",
    "num_pages": 19
}