{
    "uuid": "560d890f-2fc5-567f-8886-801210973355",
    "title": "Efficient OCR for Building a Diverse Digital History",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{carlson-etal-2024-efficient,\n    title = \"Efficient {OCR} for Building a Diverse Digital History\",\n    author = \"Carlson, Jacob  and\n      Bryan, Tom  and\n      Dell, Melissa\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.440\",\n    doi = \"10.18653/v1/2024.acl-long.440\",\n    pages = \"8105--8115\",\n    abstract = \"Many users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history. The sequence-to-sequence architecture typically used for optical character recognition (OCR) {--} which jointly learns a vision and language model {--} is poorly extensible to low-resource document collections, as learning a language-vision model requires extensive labeled sequences and compute. This study models OCR as a character level image retrieval problem, using a contrastively trained vision encoder. Because the model only learns characters{'} visual features, it is more sample efficient and extensible than existing architectures, enabling accurate OCR in settings where existing solutions fail. Crucially, it opens new avenues for community engagement in making digital history more representative of documentary history.\",\n}\n",
    "authors": [
        "Jacob Carlson",
        "Tom Bryan",
        "Melissa Dell"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.440.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/560d890f-2fc5-567f-8886-801210973355.pdf",
    "abstract": "Many users consult digital archives daily, but the information they can access is unrepresentative of the diversity of documentary history. The sequence-to-sequence architecture typically used for optical character recognition (OCR) – which jointly learns a vision and language model – is poorly extensible to low-resource document collections, as learning a language-vision model requires extensive labeled sequences and compute. This study models OCR as a character level image retrieval problem, using a contrastively trained vision encoder. Because the model only learns characters’ visual features, it is more sample efficient and extensible than existing architectures, enabling accurate OCR in settings where existing solutions fail. Crucially, it opens new avenues for community engagement in making digital history more representative of documentary history.",
    "num_pages": 11
}