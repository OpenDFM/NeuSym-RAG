{
    "uuid": "2e0432ac-3857-54e5-96b1-6dab5ed3d3a5",
    "title": "IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation Metrics for Indian Languages",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{sai-b-etal-2023-indicmt,\n    title = \"{I}ndic{MT} Eval: A Dataset to Meta-Evaluate Machine Translation Metrics for {I}ndian Languages\",\n    author = \"Sai B, Ananya  and\n      Dixit, Tanay  and\n      Nagarajan, Vignesh  and\n      Kunchukuttan, Anoop  and\n      Kumar, Pratyush  and\n      Khapra, Mitesh M.  and\n      Dabre, Raj\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.795\",\n    doi = \"10.18653/v1/2023.acl-long.795\",\n    pages = \"14210--14228\",\n    abstract = \"The rapid growth of machine translation (MT) systems necessitates meta-evaluations of evaluation metrics to enable selection of those that best reflect MT quality. Unfortunately, most meta-evaluation studies focus on European languages, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from them, and to date, there are no such systematic studies focused solely on English to Indian language MT. This paper fills this gap through a Multidimensional Quality Metric (MQM) dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems. We evaluate 16 metrics and show that, pre-trained metrics like COMET have the highest correlations with annotator scores as opposed to n-gram metrics like BLEU. We further leverage our MQM annotations to develop an Indic-COMET metric and show that it outperforms COMET counterparts in both human scores correlations and robustness scores in Indian languages. Additionally, we show that the Indic-COMET can outperform COMET on some unseen Indian languages. We hope that our dataset and analysis will facilitate further research in Indic MT evaluation.\",\n}\n",
    "authors": [
        "Ananya Sai B",
        "Tanay Dixit",
        "Vignesh Nagarajan",
        "Anoop Kunchukuttan",
        "Pratyush Kumar",
        "Mitesh M. Khapra",
        "Raj Dabre"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.795.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/2e0432ac-3857-54e5-96b1-6dab5ed3d3a5.pdf",
    "abstract": "The rapid growth of machine translation (MT) systems necessitates meta-evaluations of evaluation metrics to enable selection of those that best reflect MT quality. Unfortunately, most meta-evaluation studies focus on European languages, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from them, and to date, there are no such systematic studies focused solely on English to Indian language MT. This paper fills this gap through a Multidimensional Quality Metric (MQM) dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems. We evaluate 16 metrics and show that, pre-trained metrics like COMET have the highest correlations with annotator scores as opposed to n-gram metrics like BLEU. We further leverage our MQM annotations to develop an Indic-COMET metric and show that it outperforms COMET counterparts in both human scores correlations and robustness scores in Indian languages. Additionally, we show that the Indic-COMET can outperform COMET on some unseen Indian languages. We hope that our dataset and analysis will facilitate further research in Indic MT evaluation.",
    "num_pages": 19
}