{
    "uuid": "77a6ac37-f7cc-5e9d-9700-a06f79438197",
    "title": "Enhanced Training Methods for Multiple Languages",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering",
    "bibtex": "@inproceedings{li-li-2023-enhanced,\n    title = \"Enhanced Training Methods for Multiple Languages\",\n    author = \"Li, Hai  and\n      Li, Yang\",\n    editor = \"Muresan, Smaranda  and\n      Chen, Vivian  and\n      Casey, Kennington  and\n      David, Vandyke  and\n      Nina, Dethlefs  and\n      Koji, Inoue  and\n      Erik, Ekstedt  and\n      Stefan, Ultes\",\n    booktitle = \"Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.dialdoc-1.6\",\n    doi = \"10.18653/v1/2023.dialdoc-1.6\",\n    pages = \"52--56\",\n    abstract = \"Document-grounded dialogue generation based on multilingual is a challenging and realistic task. Unlike previous tasks, it need to tackle with multiple high-resource languages facilitating low-resource languages. This paper summarizes our research based on a three-stage pipeline that includes retrieval, re-rank and generation where each component is individually optimized. In different languages with limited data scenarios, we mainly improve the robustness of the pipeline through data augmentation and embedding perturbation with purpose of improving the performance designing three training methods: cross-language enhancement training, weighted training with neighborhood distribution augmentation, and ensemble adversarial training, all of that can be used as plug and play modules. Through experiments with different settings, it has been shown that our methods can effectively improve the generalization performance of pipeline with score ranking 6th among the public submissions on leaderboards.\",\n}\n",
    "authors": [
        "Hai Li",
        "Yang Li"
    ],
    "pdf_url": "https://aclanthology.org/2023.dialdoc-1.6.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/77a6ac37-f7cc-5e9d-9700-a06f79438197.pdf",
    "abstract": "Document-grounded dialogue generation based on multilingual is a challenging and realistic task. Unlike previous tasks, it need to tackle with multiple high-resource languages facilitating low-resource languages. This paper summarizes our research based on a three-stage pipeline that includes retrieval, re-rank and generation where each component is individually optimized. In different languages with limited data scenarios, we mainly improve the robustness of the pipeline through data augmentation and embedding perturbation with purpose of improving the performance designing three training methods: cross-language enhancement training, weighted training with neighborhood distribution augmentation, and ensemble adversarial training, all of that can be used as plug and play modules. Through experiments with different settings, it has been shown that our methods can effectively improve the generalization performance of pipeline with score ranking 6th among the public submissions on leaderboards.",
    "num_pages": 5
}