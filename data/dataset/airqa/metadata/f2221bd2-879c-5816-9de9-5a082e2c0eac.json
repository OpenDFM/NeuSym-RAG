{
    "uuid": "f2221bd2-879c-5816-9de9-5a082e2c0eac",
    "title": "MTR: A Dataset Fusing Inductive, Deductive, and Defeasible Reasoning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{li-etal-2023-mtr,\n    title = \"{MTR}: A Dataset Fusing Inductive, Deductive, and Defeasible Reasoning\",\n    author = \"Li, Yitian  and\n      Tian, Jidong  and\n      Fan, Caoyun  and\n      Chen, Wenqing  and\n      He, Hao  and\n      Jin, Yaohui\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.640\",\n    doi = \"10.18653/v1/2023.findings-acl.640\",\n    pages = \"10078--10089\",\n    abstract = \"A long-standing difficulty in AI is the introduction of human-like reasoning in machine reading comprehension. Since algorithmic models can already perform as well as humans on simple quality assurance tasks thanks to the development of deep learning techniques, more difficult reasoning datasets have been presented. However, these datasets mainly focus on a single type of reasoning. There are still significant gaps in the studies when compared to the complex reasoning used in daily life. In this work, we introduce a brand-new dataset, named MTR. There are two parts to it: the first combines deductive and inductive reasoning, and the second does the same with inductive and defeasible reasoning. It consists of more than 30k QA instances, inferring relations between characters in short stories. Results show that state-of-the-art neural models do noticeably worse than expected. Our empirical results highlight the gap in the models{'} ability to handle sophisticated inference.\",\n}\n",
    "authors": [
        "Yitian Li",
        "Jidong Tian",
        "Caoyun Fan",
        "Wenqing Chen",
        "Hao He",
        "Yaohui Jin"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.640.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/f2221bd2-879c-5816-9de9-5a082e2c0eac.pdf",
    "abstract": "A long-standing difficulty in AI is the introduction of human-like reasoning in machine reading comprehension. Since algorithmic models can already perform as well as humans on simple quality assurance tasks thanks to the development of deep learning techniques, more difficult reasoning datasets have been presented. However, these datasets mainly focus on a single type of reasoning. There are still significant gaps in the studies when compared to the complex reasoning used in daily life. In this work, we introduce a brand-new dataset, named MTR. There are two parts to it: the first combines deductive and inductive reasoning, and the second does the same with inductive and defeasible reasoning. It consists of more than 30k QA instances, inferring relations between characters in short stories. Results show that state-of-the-art neural models do noticeably worse than expected. Our empirical results highlight the gap in the modelsâ€™ ability to handle sophisticated inference.",
    "num_pages": 12
}