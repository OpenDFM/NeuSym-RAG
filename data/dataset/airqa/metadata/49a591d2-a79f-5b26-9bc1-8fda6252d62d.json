{
    "uuid": "49a591d2-a79f-5b26-9bc1-8fda6252d62d",
    "title": "Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Fifth Workshop on Privacy in Natural Language Processing",
    "bibtex": "@inproceedings{pissarra-etal-2024-unlocking,\n    title = \"Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study\",\n    author = \"Pissarra, David  and\n      Curioso, Isabel  and\n      Alveira, Jo{\\~a}o  and\n      Pereira, Duarte  and\n      Ribeiro, Bruno  and\n      Souper, Tom{\\'a}s  and\n      Gomes, Vasco  and\n      Carreiro, Andr{\\'e}  and\n      Rolla, Vitor\",\n    editor = \"Habernal, Ivan  and\n      Ghanavati, Sepideh  and\n      Ravichander, Abhilasha  and\n      Jain, Vijayanta  and\n      Thaine, Patricia  and\n      Igamberdiev, Timour  and\n      Mireshghallah, Niloofar  and\n      Feyisetan, Oluwaseyi\",\n    booktitle = \"Proceedings of the Fifth Workshop on Privacy in Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.privatenlp-1.8\",\n    pages = \"74--84\",\n    abstract = \"Automated clinical text anonymization has the potential to unlock the widespread sharing of textual health data for secondary usage while assuring patient privacy. Despite the proposal of many complex and theoretically successful anonymization solutions in literature, these techniques remain flawed. As such, clinical institutions are still reluctant to apply them for open access to their data. Recent advances in developing Large Language Models (LLMs) pose a promising opportunity to further the field, given their capability to perform various tasks. This paper proposes six new evaluation metrics tailored to the challenges of generative anonymization with LLMs. Moreover, we present a comparative study of LLM-based methods, testing them against two baseline techniques. Our results establish LLM-based models as a reliable alternative to common approaches, paving the way toward trustworthy anonymization of clinical text.\",\n}\n",
    "authors": [
        "David Pissarra",
        "Isabel Curioso",
        "João Alveira",
        "Duarte Pereira",
        "Bruno Ribeiro",
        "Tomás Souper",
        "Vasco Gomes",
        "André Carreiro",
        "Vitor Rolla"
    ],
    "pdf_url": "https://aclanthology.org/2024.privatenlp-1.8.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/49a591d2-a79f-5b26-9bc1-8fda6252d62d.pdf",
    "abstract": "Automated clinical text anonymization has the potential to unlock the widespread sharing of textual health data for secondary usage while assuring patient privacy. Despite the proposal of many complex and theoretically successful anonymization solutions in literature, these techniques remain flawed. As such, clinical institutions are still reluctant to apply them for open access to their data. Recent advances in developing Large Language Models (LLMs) pose a promising opportunity to further the field, given their capability to perform various tasks. This paper proposes six new evaluation metrics tailored to the challenges of generative anonymization with LLMs. Moreover, we present a comparative study of LLM-based methods, testing them against two baseline techniques. Our results establish LLM-based models as a reliable alternative to common approaches, paving the way toward trustworthy anonymization of clinical text.",
    "num_pages": 11
}