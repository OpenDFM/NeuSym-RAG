{
    "uuid": "9ebe7eaa-c980-52ef-a481-c30caa5567ad",
    "title": "Aligning Factual Consistency for Clinical Studies Summarization through Reinforcement Learning",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 5th Clinical Natural Language Processing Workshop",
    "bibtex": "@inproceedings{tang-etal-2023-aligning,\n    title = \"Aligning Factual Consistency for Clinical Studies Summarization through Reinforcement Learning\",\n    author = \"Tang, Xiangru  and\n      Cohan, Arman  and\n      Gerstein, Mark\",\n    editor = \"Naumann, Tristan  and\n      Ben Abacha, Asma  and\n      Bethard, Steven  and\n      Roberts, Kirk  and\n      Rumshisky, Anna\",\n    booktitle = \"Proceedings of the 5th Clinical Natural Language Processing Workshop\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.clinicalnlp-1.7\",\n    doi = \"10.18653/v1/2023.clinicalnlp-1.7\",\n    pages = \"48--58\",\n    abstract = \"In the rapidly evolving landscape of medical research, accurate and concise summarization of clinical studies is crucial to support evidence-based practice. This paper presents a novel approach to clinical studies summarization, leveraging reinforcement learning to enhance factual consistency and align with human annotator preferences. Our work focuses on two tasks: Conclusion Generation and Review Generation. We train a CONFIT summarization model that outperforms GPT-3 and previous state-of-the-art models on the same datasets and collects expert and crowd-worker annotations to evaluate the quality and factual consistency of the generated summaries. These annotations enable us to measure the correlation of various automatic metrics, including modern factual evaluation metrics like QAFactEval, with human-assessed factual consistency. By employing top-correlated metrics as objectives for a reinforcement learning model, we demonstrate improved factuality in generated summaries that are preferred by human annotators.\",\n}\n",
    "authors": [
        "Xiangru Tang",
        "Arman Cohan",
        "Mark Gerstein"
    ],
    "pdf_url": "https://aclanthology.org/2023.clinicalnlp-1.7.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/9ebe7eaa-c980-52ef-a481-c30caa5567ad.pdf",
    "abstract": "In the rapidly evolving landscape of medical research, accurate and concise summarization of clinical studies is crucial to support evidence-based practice. This paper presents a novel approach to clinical studies summarization, leveraging reinforcement learning to enhance factual consistency and align with human annotator preferences. Our work focuses on two tasks: Conclusion Generation and Review Generation. We train a CONFIT summarization model that outperforms GPT-3 and previous state-of-the-art models on the same datasets and collects expert and crowd-worker annotations to evaluate the quality and factual consistency of the generated summaries. These annotations enable us to measure the correlation of various automatic metrics, including modern factual evaluation metrics like QAFactEval, with human-assessed factual consistency. By employing top-correlated metrics as objectives for a reinforcement learning model, we demonstrate improved factuality in generated summaries that are preferred by human annotators.",
    "num_pages": 11
}