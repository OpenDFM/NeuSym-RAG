{
    "uuid": "973892ec-f9d7-5dbc-8e1b-ed31df8fbfda",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP",
    "bibtex": "@inproceedings{nie-etal-2024-multilingual,\n    title = \"Do Multilingual Large Language Models Mitigate Stereotype Bias?\",\n    author = {Nie, Shangrui  and\n      Fromm, Michael  and\n      Welch, Charles  and\n      G{\\\"o}rge, Rebekka  and\n      Karimi, Akbar  and\n      Plepi, Joan  and\n      Mowmita, Nazia  and\n      Flores-Herr, Nicolas  and\n      Ali, Mehdi  and\n      Flek, Lucie},\n    editor = \"Prabhakaran, Vinodkumar  and\n      Dev, Sunipa  and\n      Benotti, Luciana  and\n      Hershcovich, Daniel  and\n      Cabello, Laura  and\n      Cao, Yong  and\n      Adebara, Ife  and\n      Zhou, Li\",\n    booktitle = \"Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.c3nlp-1.6\",\n    doi = \"10.18653/v1/2024.c3nlp-1.6\",\n    pages = \"65--83\",\n    abstract = \"While preliminary findings indicate that multilingual LLMs exhibit reduced bias compared to monolingual ones, a comprehensive understanding of the effect of multilingual training on bias mitigation, is lacking. This study addresses this gap by systematically training six LLMs of identical size (2.6B parameters) and architecture: five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model trained on an equal distribution of data across these languages, all using publicly available data. To ensure robust evaluation, standard bias benchmarks were automatically translated into the five target languages and verified for both translation quality and bias preservation by human annotators. Our results consistently demonstrate that multilingual training effectively mitigates bias. Moreover, we observe that multilingual models achieve not only lower bias but also superior prediction accuracy when compared to monolingual models with the same amount of training data, model architecture, and size.\",\n}\n",
    "authors": [
        "Shangrui Nie",
        "Michael Fromm",
        "Charles Welch",
        "Rebekka GÃ¶rge",
        "Akbar Karimi",
        "Joan Plepi",
        "Nazia Mowmita",
        "Nicolas Flores-Herr",
        "Mehdi Ali",
        "Lucie Flek"
    ],
    "pdf_url": "https://aclanthology.org/2024.c3nlp-1.6.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/973892ec-f9d7-5dbc-8e1b-ed31df8fbfda.pdf",
    "abstract": "While preliminary findings indicate that multilingual LLMs exhibit reduced bias compared to monolingual ones, a comprehensive understanding of the effect of multilingual training on bias mitigation, is lacking. This study addresses this gap by systematically training six LLMs of identical size (2.6B parameters) and architecture: five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model trained on an equal distribution of data across these languages, all using publicly available data. To ensure robust evaluation, standard bias benchmarks were automatically translated into the five target languages and verified for both translation quality and bias preservation by human annotators. Our results consistently demonstrate that multilingual training effectively mitigates bias. Moreover, we observe that multilingual models achieve not only lower bias but also superior prediction accuracy when compared to monolingual models with the same amount of training data, model architecture, and size.",
    "num_pages": 19
}