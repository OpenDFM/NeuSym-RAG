{
    "uuid": "cc9d1d69-89e3-55e6-adc4-b3dc68bd2aa3",
    "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{wen-etal-2024-mindmap,\n    title = \"{M}ind{M}ap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models\",\n    author = \"Wen, Yilin  and\n      Wang, Zifeng  and\n      Sun, Jimeng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.558\",\n    doi = \"10.18653/v1/2024.acl-long.558\",\n    pages = \"10370--10388\",\n    abstract = \"Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named MindMap, that leverages knowledge graphs (KGs) to enhance LLMs{'} inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question {\\&} answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference.\",\n}\n",
    "authors": [
        "Yilin Wen",
        "Zifeng Wang",
        "Jimeng Sun"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.558.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/cc9d1d69-89e3-55e6-adc4-b3dc68bd2aa3.pdf",
    "abstract": "Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named MindMap, that leverages knowledge graphs (KGs) to enhance LLMsâ€™ inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question & answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference.",
    "num_pages": 19
}