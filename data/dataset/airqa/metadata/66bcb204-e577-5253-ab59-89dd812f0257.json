{
    "uuid": "66bcb204-e577-5253-ab59-89dd812f0257",
    "title": "SORTIE: Dependency-Aware Symbolic Reasoning for Logical Data-to-text Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{zhao-etal-2023-sortie,\n    title = \"{SORTIE}: Dependency-Aware Symbolic Reasoning for Logical Data-to-text Generation\",\n    author = \"Zhao, Xueliang  and\n      Fu, Tingchen  and\n      Liu, Lemao  and\n      Kong, Lingpeng  and\n      Shi, Shuming  and\n      Yan, Rui\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.715\",\n    doi = \"10.18653/v1/2023.findings-acl.715\",\n    pages = \"11247--11266\",\n    abstract = \"Logical data-to-text generation is a representative task in measuring the capabilities of both language generation and complex reasoning. Despite the introduction of reasoning skills in generation, existing works still rely on neural language models to output the final table description. However, due to the inefficacy of neural language models in complex reasoning, these methods inevitably have difficulty working out key entities in the description and might produce unfaithful descriptions. To alleviate these issues, we propose a dependency-aware symbolic reasoning framework that reasons out each entity in the table description with our designed table-compatible programming language. To figure out the dependency relationship among entities, we devise an entity scheduling mechanism to determine the order of programme synthesis such that the reasoning of an entity only relies on other {``}resolved{''} entities. Experiments on three datasets and three backbones show that ours outperforms previous methods not only in surface-level fidelity but also in logical fidelity. Notably, the proposed framework enhances GPT-2, BART and T5 with an absolute improvement of 5.7{\\%}{\\textasciitilde}11.5{\\%} on SP-Acc.\",\n}\n",
    "authors": [
        "Xueliang Zhao",
        "Tingchen Fu",
        "Lemao Liu",
        "Lingpeng Kong",
        "Shuming Shi",
        "Rui Yan"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.715.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/66bcb204-e577-5253-ab59-89dd812f0257.pdf",
    "abstract": "Logical data-to-text generation is a representative task in measuring the capabilities of both language generation and complex reasoning. Despite the introduction of reasoning skills in generation, existing works still rely on neural language models to output the final table description. However, due to the inefficacy of neural language models in complex reasoning, these methods inevitably have difficulty working out key entities in the description and might produce unfaithful descriptions. To alleviate these issues, we propose a dependency-aware symbolic reasoning framework that reasons out each entity in the table description with our designed table-compatible programming language. To figure out the dependency relationship among entities, we devise an entity scheduling mechanism to determine the order of programme synthesis such that the reasoning of an entity only relies on other “resolved” entities. Experiments on three datasets and three backbones show that ours outperforms previous methods not only in surface-level fidelity but also in logical fidelity. Notably, the proposed framework enhances GPT-2, BART and T5 with an absolute improvement of 5.7%~11.5% on SP-Acc.",
    "num_pages": 20
}