{
    "uuid": "dacdc850-7d96-5438-a041-dc8211ef201a",
    "title": "Curtin OCAI at WASSA 2023 Empathy, Emotion and Personality Shared Task: Demographic-Aware Prediction Using Multiple Transformers",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis",
    "bibtex": "@inproceedings{hasan-etal-2023-curtin,\n    title = \"Curtin {OCAI} at {WASSA} 2023 Empathy, Emotion and Personality Shared Task: Demographic-Aware Prediction Using Multiple Transformers\",\n    author = \"Hasan, Md Rakibul  and\n      Hossain, Md Zakir  and\n      Gedeon, Tom  and\n      Soon, Susannah  and\n      Rahman, Shafin\",\n    editor = \"Barnes, Jeremy  and\n      De Clercq, Orph{\\'e}e  and\n      Klinger, Roman\",\n    booktitle = \"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\\&} Social Media Analysis\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.wassa-1.47\",\n    doi = \"10.18653/v1/2023.wassa-1.47\",\n    pages = \"536--541\",\n    abstract = \"The WASSA 2023 shared task on predicting empathy, emotion and other personality traits consists of essays, conversations and articles in textual form and participants{'} demographic information in numerical form. To address the tasks, our contributions include (1) converting numerical information into meaningful text information using appropriate templates, (2) summarising lengthy articles, and (3) augmenting training data by paraphrasing. To achieve these contributions, we leveraged two separate T5-based pre-trained transformers. We then fine-tuned pre-trained BERT, DistilBERT and ALBERT for predicting empathy and personality traits. We used the Optuna hyperparameter optimisation framework to fine-tune learning rates, batch sizes and weight initialisation. Our proposed system achieved its highest performance {--} a Pearson correlation coefficient of 0.750 {--} on the onversation-level empathy prediction task1 . The system implementation is publicly available at https: //github.com/hasan-rakibul/WASSA23-empathy-emotion.\",\n}\n",
    "authors": [
        "Md Rakibul Hasan",
        "Md Zakir Hossain",
        "Tom Gedeon",
        "Susannah Soon",
        "Shafin Rahman"
    ],
    "pdf_url": "https://aclanthology.org/2023.wassa-1.47.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/dacdc850-7d96-5438-a041-dc8211ef201a.pdf",
    "abstract": "The WASSA 2023 shared task on predicting empathy, emotion and other personality traits consists of essays, conversations and articles in textual form and participants’ demographic information in numerical form. To address the tasks, our contributions include (1) converting numerical information into meaningful text information using appropriate templates, (2) summarising lengthy articles, and (3) augmenting training data by paraphrasing. To achieve these contributions, we leveraged two separate T5-based pre-trained transformers. We then fine-tuned pre-trained BERT, DistilBERT and ALBERT for predicting empathy and personality traits. We used the Optuna hyperparameter optimisation framework to fine-tune learning rates, batch sizes and weight initialisation. Our proposed system achieved its highest performance – a Pearson correlation coefficient of 0.750 – on the onversation-level empathy prediction task1 . The system implementation is publicly available at https: //github.com/hasan-rakibul/WASSA23-empathy-emotion.",
    "num_pages": 6
}