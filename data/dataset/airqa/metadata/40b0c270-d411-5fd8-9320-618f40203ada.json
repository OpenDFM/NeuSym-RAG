{
    "uuid": "40b0c270-d411-5fd8-9320-618f40203ada",
    "title": "Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023)",
    "bibtex": "@inproceedings{bose-etal-2023-detoxifying,\n    title = \"Detoxifying Online Discourse: A Guided Response Generation Approach for Reducing Toxicity in User-Generated Text\",\n    author = \"Bose, Ritwik  and\n      Perera, Ian  and\n      Dorr, Bonnie\",\n    editor = \"Chawla, Kushal  and\n      Shi, Weiyan\",\n    booktitle = \"Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.sicon-1.2\",\n    doi = \"10.18653/v1/2023.sicon-1.2\",\n    pages = \"9--14\",\n    abstract = \"The expression of opinions, stances, and moral foundations on social media often coincide with toxic, divisive, or inflammatory language that can make constructive discourse across communities difficult. Natural language generation methods could provide a means to reframe or reword such expressions in a way that fosters more civil discourse, yet current Large Language Model (LLM) methods tend towards language that is too generic or formal to seem authentic for social media discussions. We present preliminary work on training LLMs to maintain authenticity while presenting a community{'}s ideas and values in a constructive, non-toxic manner.\",\n}\n",
    "authors": [
        "Ritwik Bose",
        "Ian Perera",
        "Bonnie Dorr"
    ],
    "pdf_url": "https://aclanthology.org/2023.sicon-1.2.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/40b0c270-d411-5fd8-9320-618f40203ada.pdf",
    "abstract": "The expression of opinions, stances, and moral foundations on social media often coincide with toxic, divisive, or inflammatory language that can make constructive discourse across communities difficult. Natural language generation methods could provide a means to reframe or reword such expressions in a way that fosters more civil discourse, yet current Large Language Model (LLM) methods tend towards language that is too generic or formal to seem authentic for social media discussions. We present preliminary work on training LLMs to maintain authenticity while presenting a communityâ€™s ideas and values in a constructive, non-toxic manner.",
    "num_pages": 6
}