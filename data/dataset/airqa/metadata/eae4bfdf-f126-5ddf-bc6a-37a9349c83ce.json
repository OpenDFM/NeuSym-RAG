{
    "uuid": "eae4bfdf-f126-5ddf-bc6a-37a9349c83ce",
    "title": "BiCAL: Bi-directional Contrastive Active Learning for Clinical Report Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing",
    "bibtex": "@inproceedings{wu-etal-2024-bical,\n    title = \"{B}i{CAL}: Bi-directional Contrastive Active Learning for Clinical Report Generation\",\n    author = \"Wu, Tianyi  and\n      Zhang, Jingqing  and\n      Bai, Wenjia  and\n      Sun, Kai\",\n    editor = \"Demner-Fushman, Dina  and\n      Ananiadou, Sophia  and\n      Miwa, Makoto  and\n      Roberts, Kirk  and\n      Tsujii, Junichi\",\n    booktitle = \"Proceedings of the 23rd Workshop on Biomedical Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.bionlp-1.25\",\n    doi = \"10.18653/v1/2024.bionlp-1.25\",\n    pages = \"328--341\",\n    abstract = \"State-of-the-art performance by large pre-trained models in computer vision (CV) and natural language processing (NLP) suggests their potential for domain-specific tasks. However, training these models requires vast amounts of labelled data, a challenge in many domains due to the cost and expertise required for data labelling. Active Learning (AL) can mitigate this by selecting minimal yet informative data for model training. While AL has been mainly applied to single-modal tasks in the fields of NLP and CV, its application in multi-modal tasks remains underexplored. In this work, we proposed a novel AL strategy, Bidirectional Contrastive Active Learning strategy (BiCAL), that used both image and text latent spaces to identify contrastive samples to select batches to query for labels. BiCAL was robust to class imbalance data problems by its design, which is a problem that is commonly seen in training domain-specific models. We assessed BiCAL{'}s performance in domain-specific learning on the clinical report generation tasks from chest X-ray images. Our experiments showed that BiCAL outperforms State-of-the-art methods in clinical efficacy metrics, improving recall by 2.4{\\%} and F1 score by 9.5{\\%}, showcasing its effectiveness in actively training domain-specific multi-modal models.\",\n}\n",
    "authors": [
        "Tianyi Wu",
        "Jingqing Zhang",
        "Wenjia Bai",
        "Kai Sun"
    ],
    "pdf_url": "https://aclanthology.org/2024.bionlp-1.25.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/eae4bfdf-f126-5ddf-bc6a-37a9349c83ce.pdf",
    "abstract": "State-of-the-art performance by large pre-trained models in computer vision (CV) and natural language processing (NLP) suggests their potential for domain-specific tasks. However, training these models requires vast amounts of labelled data, a challenge in many domains due to the cost and expertise required for data labelling. Active Learning (AL) can mitigate this by selecting minimal yet informative data for model training. While AL has been mainly applied to single-modal tasks in the fields of NLP and CV, its application in multi-modal tasks remains underexplored. In this work, we proposed a novel AL strategy, Bidirectional Contrastive Active Learning strategy (BiCAL), that used both image and text latent spaces to identify contrastive samples to select batches to query for labels. BiCAL was robust to class imbalance data problems by its design, which is a problem that is commonly seen in training domain-specific models. We assessed BiCALâ€™s performance in domain-specific learning on the clinical report generation tasks from chest X-ray images. Our experiments showed that BiCAL outperforms State-of-the-art methods in clinical efficacy metrics, improving recall by 2.4% and F1 score by 9.5%, showcasing its effectiveness in actively training domain-specific multi-modal models.",
    "num_pages": 14
}