{
    "uuid": "6942bb05-c495-5019-a82e-be58f1cef675",
    "title": "Do large language models resemble humans in language use?",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
    "bibtex": "@inproceedings{cai-etal-2024-large,\n    title = \"Do large language models resemble humans in language use?\",\n    author = \"Cai, Zhenguang  and\n      Duan, Xufeng  and\n      Haslett, David  and\n      Wang, Shuqi  and\n      Pickering, Martin\",\n    editor = \"Kuribayashi, Tatsuki  and\n      Rambelli, Giulia  and\n      Takmaz, Ece  and\n      Wicke, Philipp  and\n      Oseki, Yohei\",\n    booktitle = \"Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.cmcl-1.4\",\n    doi = \"10.18653/v1/2024.cmcl-1.4\",\n    pages = \"37--56\",\n    abstract = \"It is unclear whether large language models (LLMs) develop humanlike characteristics in language use. We subjected ChatGPT and Vicuna to 12 pre-registered psycholinguistic experiments ranging from sounds to dialogue. ChatGPT and Vicuna replicated the human pattern of language use in 10 and 7 out of the 12 experiments, respectively. The models associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, attributed causality as a function of verb semantics, and accessed different meanings and retrieved different words depending on an interlocutor{'}s identity. In addition, ChatGPT, but not Vicuna, nonliterally interpreted implausible sentences that were likely to have been corrupted by noise, drew reasonable inferences, and overlooked semantic fallacies in a sentence. Finally, unlike humans, neither model preferred using shorter words to convey less informative content, nor did they use context to resolve syntactic ambiguities. We discuss how these convergences and divergences may result from the transformer architecture. Overall, these experiments demonstrate that LLMs such as ChatGPT (and Vicuna to a lesser extent) are humanlike in many aspects of human language processing.\",\n}\n",
    "authors": [
        "Zhenguang Cai",
        "Xufeng Duan",
        "David Haslett",
        "Shuqi Wang",
        "Martin Pickering"
    ],
    "pdf_url": "https://aclanthology.org/2024.cmcl-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/6942bb05-c495-5019-a82e-be58f1cef675.pdf",
    "abstract": "It is unclear whether large language models (LLMs) develop humanlike characteristics in language use. We subjected ChatGPT and Vicuna to 12 pre-registered psycholinguistic experiments ranging from sounds to dialogue. ChatGPT and Vicuna replicated the human pattern of language use in 10 and 7 out of the 12 experiments, respectively. The models associated unfamiliar words with different meanings depending on their forms, continued to access recently encountered meanings of ambiguous words, reused recent sentence structures, attributed causality as a function of verb semantics, and accessed different meanings and retrieved different words depending on an interlocutorâ€™s identity. In addition, ChatGPT, but not Vicuna, nonliterally interpreted implausible sentences that were likely to have been corrupted by noise, drew reasonable inferences, and overlooked semantic fallacies in a sentence. Finally, unlike humans, neither model preferred using shorter words to convey less informative content, nor did they use context to resolve syntactic ambiguities. We discuss how these convergences and divergences may result from the transformer architecture. Overall, these experiments demonstrate that LLMs such as ChatGPT (and Vicuna to a lesser extent) are humanlike in many aspects of human language processing.",
    "num_pages": 20
}