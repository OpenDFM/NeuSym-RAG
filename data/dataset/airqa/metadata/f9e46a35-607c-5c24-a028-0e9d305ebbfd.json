{
    "uuid": "f9e46a35-607c-5c24-a028-0e9d305ebbfd",
    "title": "The KIT Speech Translation Systems for IWSLT 2024 Dialectal and Low-resource Track",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)",
    "bibtex": "@inproceedings{li-etal-2024-kit,\n    title = \"The {KIT} Speech Translation Systems for {IWSLT} 2024 Dialectal and Low-resource Track\",\n    author = \"Li, Zhaolin  and\n      Yavuz Ugan, Enes  and\n      Liu, Danni  and\n      Mullov, Carlos  and\n      Anh Dinh, Tu  and\n      Koneru, Sai  and\n      Waibel, Alexander  and\n      Niehues, Jan\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 21st International Conference on Spoken Language Translation (IWSLT 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.iwslt-1.27\",\n    doi = \"10.18653/v1/2024.iwslt-1.27\",\n    pages = \"221--228\",\n    abstract = \"This paper presents KIT{'}s submissions to the IWSLT 2024 dialectal and low-resource track. In this work, we build systems for translating into English from speech in Maltese, Bemba, and two Arabic dialects Tunisian and North Levantine. Under the unconstrained condition, we leverage the pre-trained multilingual models by fine-tuning them for the target language pairs to address data scarcity problems in this track. We build cascaded and end-to-end speech translation systems for different language pairs and show the cascaded system brings slightly better overall performance. Besides, we find utilizing additional data resources boosts speech recognition performance but slightly harms machine translation performance in cascaded systems. Lastly, we show that Minimum Bayes Risk is effective in improving speech translation performance by combining the cascaded and end-to-end systems, bringing a consistent improvement of around 1 BLUE point.\",\n}\n",
    "authors": [
        "Zhaolin Li",
        "Enes Yavuz Ugan",
        "Danni Liu",
        "Carlos Mullov",
        "Tu Anh Dinh",
        "Sai Koneru",
        "Alexander Waibel",
        "Jan Niehues"
    ],
    "pdf_url": "https://aclanthology.org/2024.iwslt-1.27.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/f9e46a35-607c-5c24-a028-0e9d305ebbfd.pdf",
    "abstract": "This paper presents KITâ€™s submissions to the IWSLT 2024 dialectal and low-resource track. In this work, we build systems for translating into English from speech in Maltese, Bemba, and two Arabic dialects Tunisian and North Levantine. Under the unconstrained condition, we leverage the pre-trained multilingual models by fine-tuning them for the target language pairs to address data scarcity problems in this track. We build cascaded and end-to-end speech translation systems for different language pairs and show the cascaded system brings slightly better overall performance. Besides, we find utilizing additional data resources boosts speech recognition performance but slightly harms machine translation performance in cascaded systems. Lastly, we show that Minimum Bayes Risk is effective in improving speech translation performance by combining the cascaded and end-to-end systems, bringing a consistent improvement of around 1 BLUE point.",
    "num_pages": 8
}