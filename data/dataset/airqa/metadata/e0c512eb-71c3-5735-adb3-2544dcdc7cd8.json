{
    "uuid": "e0c512eb-71c3-5735-adb3-2544dcdc7cd8",
    "title": "Question-Answering in a Low-resourced Language: Benchmark Dataset and Models for Tigrinya",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{gaim-etal-2023-question,\n    title = \"Question-Answering in a Low-resourced Language: Benchmark Dataset and Models for {T}igrinya\",\n    author = \"Gaim, Fitsum  and\n      Yang, Wonsuk  and\n      Park, Hancheol  and\n      Park, Jong\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.661\",\n    doi = \"10.18653/v1/2023.acl-long.661\",\n    pages = \"11857--11870\",\n    abstract = \"Question-Answering (QA) has seen significant advances recently, achieving near human-level performance over some benchmarks. However, these advances focus on high-resourced languages such as English, while the task remains unexplored for most other languages, mainly due to the lack of annotated datasets. This work presents a native QA dataset for an East African language, Tigrinya. The dataset contains 10.6K question-answer pairs spanning 572 paragraphs extracted from 290 news articles on various topics. The dataset construction method is discussed, which is applicable to constructing similar resources for related languages. We present comprehensive experiments and analyses of several resource-efficient approaches to QA, including monolingual, cross-lingual, and multilingual setups, along with comparisons against machine-translated silver data. Our strong baseline models reach 76{\\%} in the F1 score, while the estimated human performance is 92{\\%}, indicating that the benchmark presents a good challenge for future work. We make the dataset, models, and leaderboard publicly available.\",\n}\n",
    "authors": [
        "Fitsum Gaim",
        "Wonsuk Yang",
        "Hancheol Park",
        "Jong Park"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.661.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/e0c512eb-71c3-5735-adb3-2544dcdc7cd8.pdf",
    "abstract": "Question-Answering (QA) has seen significant advances recently, achieving near human-level performance over some benchmarks. However, these advances focus on high-resourced languages such as English, while the task remains unexplored for most other languages, mainly due to the lack of annotated datasets. This work presents a native QA dataset for an East African language, Tigrinya. The dataset contains 10.6K question-answer pairs spanning 572 paragraphs extracted from 290 news articles on various topics. The dataset construction method is discussed, which is applicable to constructing similar resources for related languages. We present comprehensive experiments and analyses of several resource-efficient approaches to QA, including monolingual, cross-lingual, and multilingual setups, along with comparisons against machine-translated silver data. Our strong baseline models reach 76% in the F1 score, while the estimated human performance is 92%, indicating that the benchmark presents a good challenge for future work. We make the dataset, models, and leaderboard publicly available.",
    "num_pages": 14
}