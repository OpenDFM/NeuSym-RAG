{
    "uuid": "b716e96d-9546-58cb-8436-5999d6f9f119",
    "title": "CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP",
    "bibtex": "@inproceedings{wang-etal-2024-cdeval,\n    title = \"{CDE}val: A Benchmark for Measuring the Cultural Dimensions of Large Language Models\",\n    author = \"Wang, Yuhang  and\n      Zhu, Yanxu  and\n      Kong, Chao  and\n      Wei, Shuyu  and\n      Yi, Xiaoyuan  and\n      Xie, Xing  and\n      Sang, Jitao\",\n    editor = \"Prabhakaran, Vinodkumar  and\n      Dev, Sunipa  and\n      Benotti, Luciana  and\n      Hershcovich, Daniel  and\n      Cabello, Laura  and\n      Cao, Yong  and\n      Adebara, Ife  and\n      Zhou, Li\",\n    booktitle = \"Proceedings of the 2nd Workshop on Cross-Cultural Considerations in NLP\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.c3nlp-1.1\",\n    doi = \"10.18653/v1/2024.c3nlp-1.1\",\n    pages = \"1--16\",\n    abstract = \"As the scaling of Large Language Models (LLMs) has dramatically enhanced their capabilities, there has been a growing focus on the alignment problem to ensure their responsible and ethical use. While existing alignment efforts predominantly concentrate on universal values such as the HHH principle, the aspect of culture, which is inherently pluralistic and diverse, has not received adequate attention. This work introduces a new benchmark, CDEval, aimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by incorporating both GPT-4{'}s automated generation and human verification, covering six cultural dimensions across seven domains. Our comprehensive experiments provide intriguing insights into the culture of mainstream LLMs, highlighting both consistencies and variations across different dimensions and domains. The findings underscore the importance of integrating cultural considerations in LLM development, particularly for applications in diverse cultural settings. This benchmark serves as a valuable resource for cultural studies in LLMs, paving the way for more culturally aware and sensitive models.\",\n}\n",
    "authors": [
        "Yuhang Wang",
        "Yanxu Zhu",
        "Chao Kong",
        "Shuyu Wei",
        "Xiaoyuan Yi",
        "Xing Xie",
        "Jitao Sang"
    ],
    "pdf_url": "https://aclanthology.org/2024.c3nlp-1.1.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/b716e96d-9546-58cb-8436-5999d6f9f119.pdf",
    "abstract": "As the scaling of Large Language Models (LLMs) has dramatically enhanced their capabilities, there has been a growing focus on the alignment problem to ensure their responsible and ethical use. While existing alignment efforts predominantly concentrate on universal values such as the HHH principle, the aspect of culture, which is inherently pluralistic and diverse, has not received adequate attention. This work introduces a new benchmark, CDEval, aimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by incorporating both GPT-4â€™s automated generation and human verification, covering six cultural dimensions across seven domains. Our comprehensive experiments provide intriguing insights into the culture of mainstream LLMs, highlighting both consistencies and variations across different dimensions and domains. The findings underscore the importance of integrating cultural considerations in LLM development, particularly for applications in diverse cultural settings. This benchmark serves as a valuable resource for cultural studies in LLMs, paving the way for more culturally aware and sensitive models.",
    "num_pages": 16
}