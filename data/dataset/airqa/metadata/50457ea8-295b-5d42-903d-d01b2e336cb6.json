{
    "uuid": "50457ea8-295b-5d42-903d-d01b2e336cb6",
    "title": "xPQA: Cross-Lingual Product Question Answering in 12 Languages",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)",
    "bibtex": "@inproceedings{shen-etal-2023-xpqa,\n    title = \"x{PQA}: Cross-Lingual Product Question Answering in 12 Languages\",\n    author = \"Shen, Xiaoyu  and\n      Asai, Akari  and\n      Byrne, Bill  and\n      De Gispert, Adria\",\n    editor = \"Sitaram, Sunayana  and\n      Beigman Klebanov, Beata  and\n      Williams, Jason D\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-industry.12\",\n    doi = \"10.18653/v1/2023.acl-industry.12\",\n    pages = \"103--115\",\n    abstract = \"Product Question Answering (PQA) systems are key in e-commerce applications as they provide responses to customers{'} questions as they shop for products. While existing work on PQA focuses mainly on English, in practice there is need to support multiple customer languages while leveraging product information available in English. To study this practical industrial task, we present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages, and report results in (1) candidate ranking, to select the best English candidate containing the information to answer a non-English question; and (2) answer generation, to generate a natural-sounding non-English answer based on the selected English candidate. We evaluate various approaches involving machine translation at runtime or offline, leveraging multilingual pre-trained LMs, and including or excluding xPQA training data. We find that in-domain data is essential as cross-lingual rankers trained on other domains perform poorly on the PQA task, and that translation-based approaches are most effective for candidate ranking while multilingual finetuning works best for answer generation. Still, there remains a significant performance gap between the English and the cross-lingual test sets.\",\n}\n",
    "authors": [
        "Xiaoyu Shen",
        "Akari Asai",
        "Bill Byrne",
        "Adria De Gispert"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-industry.12.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/50457ea8-295b-5d42-903d-d01b2e336cb6.pdf",
    "abstract": "Product Question Answering (PQA) systems are key in e-commerce applications as they provide responses to customersâ€™ questions as they shop for products. While existing work on PQA focuses mainly on English, in practice there is need to support multiple customer languages while leveraging product information available in English. To study this practical industrial task, we present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages, and report results in (1) candidate ranking, to select the best English candidate containing the information to answer a non-English question; and (2) answer generation, to generate a natural-sounding non-English answer based on the selected English candidate. We evaluate various approaches involving machine translation at runtime or offline, leveraging multilingual pre-trained LMs, and including or excluding xPQA training data. We find that in-domain data is essential as cross-lingual rankers trained on other domains perform poorly on the PQA task, and that translation-based approaches are most effective for candidate ranking while multilingual finetuning works best for answer generation. Still, there remains a significant performance gap between the English and the cross-lingual test sets.",
    "num_pages": 13
}