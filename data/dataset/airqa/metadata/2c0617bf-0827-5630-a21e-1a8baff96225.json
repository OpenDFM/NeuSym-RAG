{
    "uuid": "2c0617bf-0827-5630-a21e-1a8baff96225",
    "title": "Penetrative AI: Making LLMs Comprehend the Physical World",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{xu-etal-2024-penetrative,\n    title = \"Penetrative {AI}: Making {LLM}s Comprehend the Physical World\",\n    author = \"Xu, Huatao  and\n      Han, Liying  and\n      Yang, Qirui  and\n      Li, Mo  and\n      Srivastava, Mani\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.437\",\n    doi = \"10.18653/v1/2024.findings-acl.437\",\n    pages = \"7324--7341\",\n    abstract = \"Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term {``}Penetrative AI{''}. The paper explores such an extension at two levels of LLMs{'} ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the embedded world knowledge for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs beyond traditional text-based tasks, but also enables new ways of incorporating human knowledge in cyber-physical systems.\",\n}\n",
    "authors": [
        "Huatao Xu",
        "Liying Han",
        "Qirui Yang",
        "Mo Li",
        "Mani Srivastava"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.437.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/2c0617bf-0827-5630-a21e-1a8baff96225.pdf",
    "abstract": "Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term “Penetrative AI”. The paper explores such an extension at two levels of LLMs’ ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the embedded world knowledge for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs beyond traditional text-based tasks, but also enables new ways of incorporating human knowledge in cyber-physical systems.",
    "num_pages": 18
}