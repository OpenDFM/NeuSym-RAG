{
    "uuid": "9351e21b-9365-500a-9119-1d6f7dcf78f5",
    "title": "ImplicaTR: A Granular Dataset for Natural Language Inference and Pragmatic Reasoning in Turkish",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the First Workshop on Natural Language Processing for Turkic Languages (SIGTURK 2024)",
    "bibtex": "@inproceedings{halat-atlamaz-2024-implicatr,\n    title = \"{I}mplica{TR}: A Granular Dataset for Natural Language Inference and Pragmatic Reasoning in {T}urkish\",\n    author = {Halat, Mustafa  and\n      Atlamaz, {\\\"U}mit},\n    editor = {Ataman, Duygu  and\n      Derin, Mehmet Oguz  and\n      Ivanova, Sardana  and\n      K{\\\"o}ksal, Abdullatif  and\n      S{\\\"a}lev{\\\"a}, Jonne  and\n      Zeyrek, Deniz},\n    booktitle = \"Proceedings of the First Workshop on Natural Language Processing for Turkic Languages (SIGTURK 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand and Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sigturk-1.3\",\n    pages = \"29--41\",\n    abstract = \"We introduce ImplicaTR, a linguistically informed diagnostic dataset designed to evaluate semantic and pragmatic reasoning capabilities of Natural Language Inference (NLI) models in Turkish. Existing Turkish NLI datasets treat NLI as determining whether a sentence pair represents $\\textit{entailment}$, $\\textit{contradiction}$, or a $\\textit{neutral}$ relation. Such datasets do not distinguish between $\\textit{semantic entailment}$ and $\\textit{pragmatic implicature}$, which linguists have long recognized as separate inferences types. ImplicaTR addresses this by testing NLI models{'} ability to differentiate between $\\textit{entailment}$ and $\\textit{implicature}$, thus assessing their pragmatic reasoning skills. The dataset consists of 19,350 semi-automatically generated sentence pairs covering $\\textit{implicature, entailment, contradiction,}$ and $\\textit{neutral}$ relations. We evaluated various models (BERT, Gemma, Llama-2, and Mistral) on ImplicaTR and found out that these models can reach up to 98{\\%} accuracy on semantic and pragmatic reasoning. We also fine tuned various models on subsets of ImplicaTR to test the abilities of NLI models to generalize across unseen implicature contexts. Our results indicate that model performance is highly dependent on the diversity of linguistic expressions within each subset, highlighting a weakness in the abstract generalization capabilities of large language models regarding pragmatic reasoning. We share all the code, models, and the dataset.\",\n}\n",
    "authors": [
        "Mustafa Halat",
        "Ümit Atlamaz"
    ],
    "pdf_url": "https://aclanthology.org/2024.sigturk-1.3.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9351e21b-9365-500a-9119-1d6f7dcf78f5.pdf",
    "abstract": "We introduce ImplicaTR, a linguistically informed diagnostic dataset designed to evaluate semantic and pragmatic reasoning capabilities of Natural Language Inference (NLI) models in Turkish. Existing Turkish NLI datasets treat NLI as determining whether a sentence pair represents entailment, contradiction, or a neutral relation. Such datasets do not distinguish between semantic entailment and pragmatic implicature, which linguists have long recognized as separate inferences types. ImplicaTR addresses this by testing NLI models’ ability to differentiate between entailment and implicature, thus assessing their pragmatic reasoning skills. The dataset consists of 19,350 semi-automatically generated sentence pairs covering implicature, entailment, contradiction, and neutral relations. We evaluated various models (BERT, Gemma, Llama-2, and Mistral) on ImplicaTR and found out that these models can reach up to 98% accuracy on semantic and pragmatic reasoning. We also fine tuned various models on subsets of ImplicaTR to test the abilities of NLI models to generalize across unseen implicature contexts. Our results indicate that model performance is highly dependent on the diversity of linguistic expressions within each subset, highlighting a weakness in the abstract generalization capabilities of large language models regarding pragmatic reasoning. We share all the code, models, and the dataset.",
    "num_pages": 13
}