{
    "uuid": "eb176f10-b407-5fcc-ba75-5af40bb3b91d",
    "title": "Robust Natural Language Understanding with Residual Attention Debiasing",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{wang-etal-2023-robust,\n    title = \"Robust Natural Language Understanding with Residual Attention Debiasing\",\n    author = \"Wang, Fei  and\n      Huang, James Y.  and\n      Yan, Tianyi  and\n      Zhou, Wenxuan  and\n      Chen, Muhao\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.32\",\n    doi = \"10.18653/v1/2023.findings-acl.32\",\n    pages = \"504--519\",\n    abstract = \"Natural language understanding (NLU) models often suffer from unintended dataset biases. Among bias mitigation methods, ensemble-based debiasing methods, especially product-of-experts (PoE), have stood out for their impressive empirical success. However, previous ensemble-based debiasing methods typically apply debiasing on top-level logits without directly addressing biased attention patterns. Attention serves as the main media of feature interaction and aggregation in PLMs and plays a crucial role in providing robust prediction. In this paper, we propose REsidual Attention Debiasing (READ), an end-to-end debiasing method that mitigates unintended biases from attention. Experiments on three NLU benchmarks show that READ significantly improves the OOD performance of BERT-based models, including +12.9{\\%} accuracy on HANS, +11.0{\\%} accuracy on FEVER-Symmetric, and +2.7{\\%} F1 on PAWS. Detailed analyses demonstrate the crucial role of unbiased attention in robust NLU models and that READ effectively mitigates biases in attention.\",\n}\n",
    "authors": [
        "Fei Wang",
        "James Y. Huang",
        "Tianyi Yan",
        "Wenxuan Zhou",
        "Muhao Chen"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.32.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/eb176f10-b407-5fcc-ba75-5af40bb3b91d.pdf",
    "abstract": "Natural language understanding (NLU) models often suffer from unintended dataset biases. Among bias mitigation methods, ensemble-based debiasing methods, especially product-of-experts (PoE), have stood out for their impressive empirical success. However, previous ensemble-based debiasing methods typically apply debiasing on top-level logits without directly addressing biased attention patterns. Attention serves as the main media of feature interaction and aggregation in PLMs and plays a crucial role in providing robust prediction. In this paper, we propose REsidual Attention Debiasing (READ), an end-to-end debiasing method that mitigates unintended biases from attention. Experiments on three NLU benchmarks show that READ significantly improves the OOD performance of BERT-based models, including +12.9% accuracy on HANS, +11.0% accuracy on FEVER-Symmetric, and +2.7% F1 on PAWS. Detailed analyses demonstrate the crucial role of unbiased attention in robust NLU models and that READ effectively mitigates biases in attention.",
    "num_pages": 16
}