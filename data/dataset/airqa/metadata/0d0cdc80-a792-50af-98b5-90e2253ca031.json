{
    "uuid": "0d0cdc80-a792-50af-98b5-90e2253ca031",
    "title": "Evaluating Structural Generalization in Neural Machine Translation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{kumon-etal-2024-evaluating,\n    title = \"Evaluating Structural Generalization in Neural Machine Translation\",\n    author = \"Kumon, Ryoma  and\n      Matsuoka, Daiki  and\n      Yanaka, Hitomi\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.783\",\n    doi = \"10.18653/v1/2024.findings-acl.783\",\n    pages = \"13220--13239\",\n    abstract = \"Compositional generalization refers to the ability to generalize to novel combinations of previously observed words and syntactic structures.Since it is regarded as a desired property of neural models, recent work has assessed compositional generalization in machine translation as well as semantic parsing.However, previous evaluations with machine translation have focused mostly on lexical generalization (i.e., generalization to unseen combinations of known words).Thus, it remains unclear to what extent models can translate sentences that require structural generalization (i.e., generalization to different sorts of syntactic structures).To address this question, we construct SGET, a machine translation dataset covering various types of compositional generalization with control of words and sentence structures.We evaluate neural machine translation models on SGET and show that they struggle more in structural generalization than in lexical generalization.We also find different performance trends in semantic parsing and machine translation, which indicates the importance of evaluations across various tasks.\",\n}\n",
    "authors": [
        "Ryoma Kumon",
        "Daiki Matsuoka",
        "Hitomi Yanaka"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.783.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/0d0cdc80-a792-50af-98b5-90e2253ca031.pdf",
    "abstract": "Compositional generalization refers to the ability to generalize to novel combinations of previously observed words and syntactic structures.Since it is regarded as a desired property of neural models, recent work has assessed compositional generalization in machine translation as well as semantic parsing.However, previous evaluations with machine translation have focused mostly on lexical generalization (i.e., generalization to unseen combinations of known words).Thus, it remains unclear to what extent models can translate sentences that require structural generalization (i.e., generalization to different sorts of syntactic structures).To address this question, we construct SGET, a machine translation dataset covering various types of compositional generalization with control of words and sentence structures.We evaluate neural machine translation models on SGET and show that they struggle more in structural generalization than in lexical generalization.We also find different performance trends in semantic parsing and machine translation, which indicates the importance of evaluations across various tasks.",
    "num_pages": 20
}