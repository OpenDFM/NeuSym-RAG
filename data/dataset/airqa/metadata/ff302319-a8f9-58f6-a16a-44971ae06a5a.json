{
    "uuid": "ff302319-a8f9-58f6-a16a-44971ae06a5a",
    "title": "Protecting Privacy in Classifiers by Token Manipulation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the Fifth Workshop on Privacy in Natural Language Processing",
    "bibtex": "@inproceedings{harel-etal-2024-protecting,\n    title = \"Protecting Privacy in Classifiers by Token Manipulation\",\n    author = \"Harel, Re{'}em  and\n      Elboher, Yair  and\n      Pinter, Yuval\",\n    editor = \"Habernal, Ivan  and\n      Ghanavati, Sepideh  and\n      Ravichander, Abhilasha  and\n      Jain, Vijayanta  and\n      Thaine, Patricia  and\n      Igamberdiev, Timour  and\n      Mireshghallah, Niloofar  and\n      Feyisetan, Oluwaseyi\",\n    booktitle = \"Proceedings of the Fifth Workshop on Privacy in Natural Language Processing\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.privatenlp-1.4\",\n    pages = \"29--38\",\n    abstract = \"Using language models as a remote service entails sending private information to an untrusted provider. In addition, potential eavesdroppers can intercept the messages, thereby exposing the information. In this work, we explore the prospects of avoiding such data exposure at the level of text manipulation. We focus on text classification models, examining various token mapping and contextualized manipulation functions in order to see whether classifier accuracy may be maintained while keeping the original text unrecoverable. We find that although some token mapping functions are easy and straightforward to implement, they heavily influence performance on the downstream task, and via a sophisticated attacker can be reconstructed. In comparison, the contextualized manipulation provides an improvement in performance.\",\n}\n",
    "authors": [
        "Reâ€™em Harel",
        "Yair Elboher",
        "Yuval Pinter"
    ],
    "pdf_url": "https://aclanthology.org/2024.privatenlp-1.4.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ff302319-a8f9-58f6-a16a-44971ae06a5a.pdf",
    "abstract": "Using language models as a remote service entails sending private information to an untrusted provider. In addition, potential eavesdroppers can intercept the messages, thereby exposing the information. In this work, we explore the prospects of avoiding such data exposure at the level of text manipulation. We focus on text classification models, examining various token mapping and contextualized manipulation functions in order to see whether classifier accuracy may be maintained while keeping the original text unrecoverable. We find that although some token mapping functions are easy and straightforward to implement, they heavily influence performance on the downstream task, and via a sophisticated attacker can be reconstructed. In comparison, the contextualized manipulation provides an improvement in performance.",
    "num_pages": 10
}