{
    "uuid": "fea49d5f-203f-56c0-b580-e4726c764264",
    "title": "Label-Efficient Model Selection for Text Generation",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{ashury-tahan-etal-2024-label,\n    title = \"Label-Efficient Model Selection for Text Generation\",\n    author = \"Ashury Tahan, Shir  and\n      Gera, Ariel  and\n      Sznajder, Benjamin  and\n      Choshen, Leshem  and\n      Ein-Dor, Liat  and\n      Shnarch, Eyal\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.456\",\n    doi = \"10.18653/v1/2024.acl-long.456\",\n    pages = \"8384--8402\",\n    abstract = \"Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models based on preference annotations. DiffUse reduces the required amount of annotations, thus saving valuable time and resources in performing evaluation.DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any text generation model for selecting between models, prompts and configurations. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations {--} by up to 75{\\%} {--} while maintaining high evaluation reliability.\",\n}\n",
    "authors": [
        "Shir Ashury Tahan",
        "Ariel Gera",
        "Benjamin Sznajder",
        "Leshem Choshen",
        "Liat Ein-Dor",
        "Eyal Shnarch"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.456.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/fea49d5f-203f-56c0-b580-e4726c764264.pdf",
    "abstract": "Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models based on preference annotations. DiffUse reduces the required amount of annotations, thus saving valuable time and resources in performing evaluation.DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any text generation model for selecting between models, prompts and configurations. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations – by up to 75% – while maintaining high evaluation reliability.",
    "num_pages": 19
}