{
    "uuid": "03319c0d-7df2-519b-b979-f07c1704893c",
    "title": "Soft Knowledge Prompt: Help External Knowledge Become a Better Teacher to Instruct LLM in Knowledge-based VQA",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{wang-etal-2024-soft-knowledge,\n    title = \"Soft Knowledge Prompt: Help External Knowledge Become a Better Teacher to Instruct {LLM} in Knowledge-based {VQA}\",\n    author = \"Wang, Qunbo  and\n      Ji, Ruyi  and\n      Peng, Tianhao  and\n      Wu, Wenjun  and\n      Li, Zechao  and\n      Liu, Jing\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.332\",\n    doi = \"10.18653/v1/2024.acl-long.332\",\n    pages = \"6132--6143\",\n    abstract = \"LLM has achieved impressive performance on multi-modal tasks, which have received ever-increasing research attention. Recent research focuses on improving prediction performance and reliability (e.g., addressing the hallucination problem). They often prepend relevant external knowledge to the input text as an extra prompt. However, these methods would be affected by the noise in the knowledge and the context length limitation of LLM. In our work, we focus on making better use of external knowledge and propose a method to actively extract valuable information in the knowledge to produce the latent vector as a soft prompt, which is then fused with the image embedding to form a knowledge-enhanced context to instruct LLM. The experimental results on knowledge-based VQA benchmarks show that the proposed method enjoys better utilization of external knowledge and helps the model achieve better performance.\",\n}\n",
    "authors": [
        "Qunbo Wang",
        "Ruyi Ji",
        "Tianhao Peng",
        "Wenjun Wu",
        "Zechao Li",
        "Jing Liu"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.332.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/03319c0d-7df2-519b-b979-f07c1704893c.pdf",
    "abstract": "LLM has achieved impressive performance on multi-modal tasks, which have received ever-increasing research attention. Recent research focuses on improving prediction performance and reliability (e.g., addressing the hallucination problem). They often prepend relevant external knowledge to the input text as an extra prompt. However, these methods would be affected by the noise in the knowledge and the context length limitation of LLM. In our work, we focus on making better use of external knowledge and propose a method to actively extract valuable information in the knowledge to produce the latent vector as a soft prompt, which is then fused with the image embedding to form a knowledge-enhanced context to instruct LLM. The experimental results on knowledge-based VQA benchmarks show that the proposed method enjoys better utilization of external knowledge and helps the model achieve better performance.",
    "num_pages": 12
}