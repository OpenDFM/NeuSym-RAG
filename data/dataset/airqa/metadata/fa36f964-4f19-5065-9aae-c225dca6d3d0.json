{
    "uuid": "fa36f964-4f19-5065-9aae-c225dca6d3d0",
    "title": "KITâ€™s Multilingual Speech Translation System for IWSLT 2023",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)",
    "bibtex": "@inproceedings{liu-etal-2023-kits,\n    title = \"{KIT}{'}s Multilingual Speech Translation System for {IWSLT} 2023\",\n    author = \"Liu, Danni  and\n      Binh Nguyen, Thai  and\n      Koneru, Sai  and\n      Yavuz Ugan, Enes  and\n      Pham, Ngoc-Quan  and\n      Nam Nguyen, Tuan  and\n      Anh Dinh, Tu  and\n      Mullov, Carlos  and\n      Waibel, Alexander  and\n      Niehues, Jan\",\n    editor = \"Salesky, Elizabeth  and\n      Federico, Marcello  and\n      Carpuat, Marine\",\n    booktitle = \"Proceedings of the 20th International Conference on Spoken Language Translation (IWSLT 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada (in-person and online)\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.iwslt-1.6\",\n    doi = \"10.18653/v1/2023.iwslt-1.6\",\n    pages = \"113--122\",\n    abstract = \"Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach ($k$NN-MT) for effective adaptation ($+0.8$ BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.\",\n}\n",
    "authors": [
        "Danni Liu",
        "Thai Binh Nguyen",
        "Sai Koneru",
        "Enes Yavuz Ugan",
        "Ngoc-Quan Pham",
        "Tuan Nam Nguyen",
        "Tu Anh Dinh",
        "Carlos Mullov",
        "Alexander Waibel",
        "Jan Niehues"
    ],
    "pdf_url": "https://aclanthology.org/2023.iwslt-1.6.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/fa36f964-4f19-5065-9aae-c225dca6d3d0.pdf",
    "abstract": "Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.",
    "num_pages": 10
}