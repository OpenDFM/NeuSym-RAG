{
    "uuid": "9ee4eb54-dd21-55fc-aff9-5401ece79790",
    "title": "Fine-tuning after Prompting: an Explainable Way for Classification",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)",
    "bibtex": "@inproceedings{wang-etal-2024-fine,\n    title = \"Fine-tuning after Prompting: an Explainable Way for Classification\",\n    author = \"Wang, Zezhong  and\n      Ye, Luyao  and\n      Wang, Hongru  and\n      Xue, Boyang  and\n      Du, Yiming  and\n      Liang, Bin  and\n      Wong, Kam-Fai\",\n    editor = \"Wong, Kam-Fai  and\n      Zhang, Min  and\n      Xu, Ruifeng  and\n      Li, Jing  and\n      Wei, Zhongyu  and\n      Gui, Lin  and\n      Liang, Bin  and\n      Zhao, Runcong\",\n    booktitle = \"Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sighan-1.16\",\n    pages = \"133--142\",\n    abstract = \"Prompting is an alternative approach for utilizing pre-trained language models (PLMs) in classification tasks. In contrast to fine-tuning, prompting is more understandable for humans because it utilizes natural language to interact with the PLM, but it often falls short in terms of accuracy. While current research primarily focuses on enhancing the performance of prompting methods to compete with fine-tuning, we believe that these two approaches are not mutually exclusive, each having its strengths and weaknesses. In our study, we depart from the competitive view of prompting versus fine-tuning and instead combine them, introducing a novel method called F{\\&}P. This approach enables us to harness the advantages of \\textbf{F}ine-tuning for accuracy and the explainability of \\textbf{P}rompting simultaneously. Specifically, we reformulate the sample into a prompt and subsequently fine-tune a linear classifier on top of the PLM. Following this, we extract verbalizers according to the weight of this classifier. During the inference phase, we reformulate the sample in the same way and query the PLM. The PLM generates a word, which is then subject to a dictionary lookup by the verbalizer to obtain the prediction. Experiments show that keeping only 30 keywords for each class can achieve comparable performance as fine-tuning. On the other hand, both the prompt and verbalizers are constructed in natural language, making them fully understandable to humans. Hence, the F{\\&}P method offers an effective and transparent way to employ a PLM for classification tasks.\",\n}\n",
    "authors": [
        "Zezhong Wang",
        "Luyao Ye",
        "Hongru Wang",
        "Boyang Xue",
        "Yiming Du",
        "Bin Liang",
        "Kam-Fai Wong"
    ],
    "pdf_url": "https://aclanthology.org/2024.sighan-1.16.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/9ee4eb54-dd21-55fc-aff9-5401ece79790.pdf",
    "abstract": "Prompting is an alternative approach for utilizing pre-trained language models (PLMs) in classification tasks. In contrast to fine-tuning, prompting is more understandable for humans because it utilizes natural language to interact with the PLM, but it often falls short in terms of accuracy. While current research primarily focuses on enhancing the performance of prompting methods to compete with fine-tuning, we believe that these two approaches are not mutually exclusive, each having its strengths and weaknesses. In our study, we depart from the competitive view of prompting versus fine-tuning and instead combine them, introducing a novel method called F&P. This approach enables us to harness the advantages of Fine-tuning for accuracy and the explainability of Prompting simultaneously. Specifically, we reformulate the sample into a prompt and subsequently fine-tune a linear classifier on top of the PLM. Following this, we extract verbalizers according to the weight of this classifier. During the inference phase, we reformulate the sample in the same way and query the PLM. The PLM generates a word, which is then subject to a dictionary lookup by the verbalizer to obtain the prediction. Experiments show that keeping only 30 keywords for each class can achieve comparable performance as fine-tuning. On the other hand, both the prompt and verbalizers are constructed in natural language, making them fully understandable to humans. Hence, the F&P method offers an effective and transparent way to employ a PLM for classification tasks.",
    "num_pages": 10
}