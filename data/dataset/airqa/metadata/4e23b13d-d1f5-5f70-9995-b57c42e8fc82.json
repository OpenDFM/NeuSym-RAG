{
    "uuid": "4e23b13d-d1f5-5f70-9995-b57c42e8fc82",
    "title": "Explanation Regeneration via Information Bottleneck",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{li-etal-2023-explanation,\n    title = \"Explanation Regeneration via Information Bottleneck\",\n    author = \"Li, Qintong  and\n      Wu, Zhiyong  and\n      Kong, Lingpeng  and\n      Bi, Wei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.765\",\n    doi = \"10.18653/v1/2023.findings-acl.765\",\n    pages = \"12081--12102\",\n    abstract = \"Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Thanks to the superior generative capacity of large pretrained language models (PLM), recent work built on prompt engineering enables explanations generated without specific training. However, explanations generated through single-pass prompting often lack sufficiency and conciseness, due to the prompt complexity and hallucination issues. To discard the dross and take the essence of current PLM{'}s results, we propose to produce sufficient and concise explanations via the information bottleneck (EIB) theory. EIB regenerates explanations by polishing the single-pass output of PLM but retaining the information that supports the contents being explained by balancing two information bottleneck objectives. Experiments on two different tasks verify the effectiveness of EIB through automatic evaluation and thoroughly-conducted human evaluation.\",\n}\n",
    "authors": [
        "Qintong Li",
        "Zhiyong Wu",
        "Lingpeng Kong",
        "Wei Bi"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.765.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4e23b13d-d1f5-5f70-9995-b57c42e8fc82.pdf",
    "abstract": "Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Thanks to the superior generative capacity of large pretrained language models (PLM), recent work built on prompt engineering enables explanations generated without specific training. However, explanations generated through single-pass prompting often lack sufficiency and conciseness, due to the prompt complexity and hallucination issues. To discard the dross and take the essence of current PLMâ€™s results, we propose to produce sufficient and concise explanations via the information bottleneck (EIB) theory. EIB regenerates explanations by polishing the single-pass output of PLM but retaining the information that supports the contents being explained by balancing two information bottleneck objectives. Experiments on two different tasks verify the effectiveness of EIB through automatic evaluation and thoroughly-conducted human evaluation.",
    "num_pages": 22
}