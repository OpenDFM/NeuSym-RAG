{
    "uuid": "15bd7267-a473-5190-acb5-bbeeca1cc43c",
    "title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the First Workshop on Natural Language Processing for Turkic Languages (SIGTURK 2024)",
    "bibtex": "@inproceedings{oguz-etal-2024-llms,\n    title = \"Do {LLM}s Recognize me, When {I} is not me: Assessment of {LLM}s Understanding of {T}urkish Indexical Pronouns in Indexical Shift Contexts\",\n    author = \"O{\\u{g}}uz, Metehan  and\n      Ciftci, Yusuf  and\n      Bakman, Yavuz Faruk\",\n    editor = {Ataman, Duygu  and\n      Derin, Mehmet Oguz  and\n      Ivanova, Sardana  and\n      K{\\\"o}ksal, Abdullatif  and\n      S{\\\"a}lev{\\\"a}, Jonne  and\n      Zeyrek, Deniz},\n    booktitle = \"Proceedings of the First Workshop on Natural Language Processing for Turkic Languages (SIGTURK 2024)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand and Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.sigturk-1.5\",\n    pages = \"53--61\",\n    abstract = \"Large language models (LLMs) have shown impressive capabilities in tasks such as machine translation, text summarization, question answering, and solving complex mathematical problems. However, their primary training on data-rich languages like English limits their performance in low-resource languages. This study addresses this gap by focusing on the Indexical Shift problem in Turkish. The Indexical Shift problem involves resolving pronouns in indexical shift contexts, a grammatical challenge not present in high-resource languages like English. We present the first study examining indexical shift in any language, releasing a Turkish dataset specifically designed for this purpose. Our Indexical Shift Dataset consists of 156 multiple-choice questions, each annotated with necessary linguistic details, to evaluate LLMs in a few-shot setting. We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset. Our analysis reveals that even advanced models like GPT-4 struggle with the grammatical nuances of indexical shift in Turkish, achieving only moderate performance. These findings underscore the need for focused research on the grammatical challenges posed by low-resource languages. We released the dataset and code here.\",\n}\n",
    "authors": [
        "Metehan OÄŸuz",
        "Yusuf Ciftci",
        "Yavuz Faruk Bakman"
    ],
    "pdf_url": "https://aclanthology.org/2024.sigturk-1.5.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/15bd7267-a473-5190-acb5-bbeeca1cc43c.pdf",
    "abstract": "Large language models (LLMs) have shown impressive capabilities in tasks such as machine translation, text summarization, question answering, and solving complex mathematical problems. However, their primary training on data-rich languages like English limits their performance in low-resource languages. This study addresses this gap by focusing on the Indexical Shift problem in Turkish. The Indexical Shift problem involves resolving pronouns in indexical shift contexts, a grammatical challenge not present in high-resource languages like English. We present the first study examining indexical shift in any language, releasing a Turkish dataset specifically designed for this purpose. Our Indexical Shift Dataset consists of 156 multiple-choice questions, each annotated with necessary linguistic details, to evaluate LLMs in a few-shot setting. We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset. Our analysis reveals that even advanced models like GPT-4 struggle with the grammatical nuances of indexical shift in Turkish, achieving only moderate performance. These findings underscore the need for focused research on the grammatical challenges posed by low-resource languages. We released the dataset and code here.",
    "num_pages": 9
}