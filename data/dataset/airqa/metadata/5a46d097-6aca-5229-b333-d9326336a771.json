{
    "uuid": "5a46d097-6aca-5229-b333-d9326336a771",
    "title": "UTRad-NLP at #SMM4H 2024: Why LLM-Generated Texts Fail to Improve Text Classification Models",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of The 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks",
    "bibtex": "@inproceedings{yamagishi-nakamura-2024-utrad,\n    title = \"{UTR}ad-{NLP} at {\\#}{SMM}4{H} 2024: Why {LLM}-Generated Texts Fail to Improve Text Classification Models\",\n    author = \"Yamagishi, Yosuke  and\n      Nakamura, Yuta\",\n    editor = \"Xu, Dongfang  and\n      Gonzalez-Hernandez, Graciela\",\n    booktitle = \"Proceedings of The 9th Social Media Mining for Health Research and Applications (SMM4H 2024) Workshop and Shared Tasks\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.smm4h-1.10\",\n    pages = \"42--47\",\n    abstract = \"In this paper, we present our approach to addressing the binary classification tasks, Tasks 5 and 6, as part of the Social Media Mining for Health (SMM4H) text classification challenge. Both tasks involved working with imbalanced datasets that featured a scarcity of positive examples. To mitigate this imbalance, we employed a Large Language Model to generate synthetic texts with positive labels, aiming to augment the training data for our text classification models. Unfortunately, this method did not significantly improve model performance. Through clustering analysis using text embeddings, we discovered that the generated texts significantly lacked diversity compared to the raw data. This finding highlights the challenges of using synthetic text generation for enhancing model efficacy in real-world applications, specifically in the context of health-related social media data.\",\n}\n",
    "authors": [
        "Yosuke Yamagishi",
        "Yuta Nakamura"
    ],
    "pdf_url": "https://aclanthology.org/2024.smm4h-1.10.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/5a46d097-6aca-5229-b333-d9326336a771.pdf",
    "abstract": "In this paper, we present our approach to addressing the binary classification tasks, Tasks 5 and 6, as part of the Social Media Mining for Health (SMM4H) text classification challenge. Both tasks involved working with imbalanced datasets that featured a scarcity of positive examples. To mitigate this imbalance, we employed a Large Language Model to generate synthetic texts with positive labels, aiming to augment the training data for our text classification models. Unfortunately, this method did not significantly improve model performance. Through clustering analysis using text embeddings, we discovered that the generated texts significantly lacked diversity compared to the raw data. This finding highlights the challenges of using synthetic text generation for enhancing model efficacy in real-world applications, specifically in the context of health-related social media data.",
    "num_pages": 6
}