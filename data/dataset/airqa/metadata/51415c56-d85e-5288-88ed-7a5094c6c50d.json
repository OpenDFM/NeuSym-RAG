{
    "uuid": "51415c56-d85e-5288-88ed-7a5094c6c50d",
    "title": "Why Aren’t We NER Yet? Artifacts of ASR Errors in Named Entity Recognition in Spontaneous Speech Transcripts",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{szymanski-etal-2023-arent,\n    title = \"Why Aren{'}t We {NER} Yet? Artifacts of {ASR} Errors in Named Entity Recognition in Spontaneous Speech Transcripts\",\n    author = \"Szyma{\\'n}ski, Piotr  and\n      Augustyniak, Lukasz  and\n      Morzy, Mikolaj  and\n      Szymczak, Adrian  and\n      Surdyk, Krzysztof  and\n      {\\.Z}elasko, Piotr\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.98\",\n    doi = \"10.18653/v1/2023.acl-long.98\",\n    pages = \"1746--1761\",\n    abstract = \"Transcripts of spontaneous human speech present a significant obstacle for traditional NER models. The lack of grammatical structure of spoken utterances and word errors introduced by the ASR make downstream NLP tasks challenging. In this paper, we examine in detail the complex relationship between ASR and NER errors which limit the ability of NER models to recover entity mentions from spontaneous speech transcripts. Using publicly available benchmark datasets (SWNE, Earnings-21, OntoNotes), we present the full taxonomy of ASR-NER errors and measure their true impact on entity recognition. We find that NER models fail spectacularly even if no word errors are introduced by the ASR. We also show why the F1 score is inadequate to evaluate NER models on conversational transcripts.\",\n}\n",
    "authors": [
        "Piotr Szymański",
        "Lukasz Augustyniak",
        "Mikolaj Morzy",
        "Adrian Szymczak",
        "Krzysztof Surdyk",
        "Piotr Żelasko"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.98.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/51415c56-d85e-5288-88ed-7a5094c6c50d.pdf",
    "abstract": "Transcripts of spontaneous human speech present a significant obstacle for traditional NER models. The lack of grammatical structure of spoken utterances and word errors introduced by the ASR make downstream NLP tasks challenging. In this paper, we examine in detail the complex relationship between ASR and NER errors which limit the ability of NER models to recover entity mentions from spontaneous speech transcripts. Using publicly available benchmark datasets (SWNE, Earnings-21, OntoNotes), we present the full taxonomy of ASR-NER errors and measure their true impact on entity recognition. We find that NER models fail spectacularly even if no word errors are introduced by the ASR. We also show why the F1 score is inadequate to evaluate NER models on conversational transcripts.",
    "num_pages": 16
}