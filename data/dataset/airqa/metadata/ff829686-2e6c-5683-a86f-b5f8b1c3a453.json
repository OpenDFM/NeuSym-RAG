{
    "uuid": "ff829686-2e6c-5683-a86f-b5f8b1c3a453",
    "title": "IndicIRSuite: Multilingual Dataset and Neural Information Models for Indian Languages",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    "bibtex": "@inproceedings{haq-etal-2024-indicirsuite,\n    title = \"{I}ndic{IRS}uite: Multilingual Dataset and Neural Information Models for {I}ndian Languages\",\n    author = \"Haq, Saiful  and\n      Sharma, Ashutosh  and\n      Khattab, Omar  and\n      Chhaya, Niyati  and\n      Bhattacharyya, Pushpak\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-short.46\",\n    doi = \"10.18653/v1/2024.acl-short.46\",\n    pages = \"501--509\",\n    abstract = \"In this paper, we introduce Neural Information Retrieval resources for 11 widely spoken Indian Languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, and Telugu) from two major Indian language families (Indo-Aryan and Dravidian). These resources include (a) INDIC-MARCO, a multilingual version of the MS MARCO dataset in 11 Indian Languages created using Machine Translation, and (b) Indic-ColBERT, a collection of 11 distinct Monolingual Neural Information Retrieval models, each trained on one of the 11 languages in the INDIC-MARCO dataset. To the best of our knowledge, IndicIRSuite is the first attempt at building large-scale Neural Information Retrieval resources for a large number of Indian languages, and we hope that it will help accelerate research in Neural IR for Indian Languages. Experiments demonstrate that Indic-ColBERT achieves 47.47{\\%} improvement in the MRR@10 score averaged over the INDIC-MARCO baselines for all 11 Indian languages except Oriya, 12.26{\\%} improvement in the NDCG@10 score averaged over the MIRACL Bengali and Hindi Language baselines, and 20{\\%} improvement in the MRR@100 Score over the Mr. Tydi Bengali Language baseline.\",\n}\n",
    "authors": [
        "Saiful Haq",
        "Ashutosh Sharma",
        "Omar Khattab",
        "Niyati Chhaya",
        "Pushpak Bhattacharyya"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-short.46.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/ff829686-2e6c-5683-a86f-b5f8b1c3a453.pdf",
    "abstract": "In this paper, we introduce Neural Information Retrieval resources for 11 widely spoken Indian Languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, and Telugu) from two major Indian language families (Indo-Aryan and Dravidian). These resources include (a) INDIC-MARCO, a multilingual version of the MS MARCO dataset in 11 Indian Languages created using Machine Translation, and (b) Indic-ColBERT, a collection of 11 distinct Monolingual Neural Information Retrieval models, each trained on one of the 11 languages in the INDIC-MARCO dataset. To the best of our knowledge, IndicIRSuite is the first attempt at building large-scale Neural Information Retrieval resources for a large number of Indian languages, and we hope that it will help accelerate research in Neural IR for Indian Languages. Experiments demonstrate that Indic-ColBERT achieves 47.47% improvement in the MRR@10 score averaged over the INDIC-MARCO baselines for all 11 Indian languages except Oriya, 12.26% improvement in the NDCG@10 score averaged over the MIRACL Bengali and Hindi Language baselines, and 20% improvement in the MRR@100 Score over the Mr. Tydi Bengali Language baseline.",
    "num_pages": 9
}