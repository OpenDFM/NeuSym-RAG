{
    "uuid": "5a25407d-12ca-50ba-a4df-10937237bec3",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2024",
    "bibtex": "@inproceedings{li-etal-2024-exploring-mathematical,\n    title = \"Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data\",\n    author = \"Li, Haolong  and\n      Ma, Yu  and\n      Zhang, Yinqi  and\n      Ye, Chen  and\n      Chen, Jie\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.55\",\n    doi = \"10.18653/v1/2024.findings-acl.55\",\n    pages = \"936--946\",\n    abstract = \"While large language models (LLMs) have shown excellent capabilities in language understanding, text generation and many other tasks, they still struggle in complex multi-step reasoning problems such as mathematical reasoning. In this paper, through a newly proposed arithmetical puzzle problem, we show that the model can perform well on multi-step reasoning tasks via fine tuning on high-quality synthetic data. Experiments with the open-llama-3B model on three different test datasets show that not only the model can reach a zero-shot pass@1 at 0.44 on the in-domain dataset, it also demonstrates certain generalization capabilities on the out-of-domain datasets. Specifically, this paper has designed two out-of-domain datasets in the form of extending the numerical range and the composing components of the arithmetical puzzle problem separately. The fine-tuned model have shown encouraging performance on these two far more difficult tasks with the zero-shot pass@1 at 0.33 and 0.35 correspondingly.\",\n}\n",
    "authors": [
        "Haolong Li",
        "Yu Ma",
        "Yinqi Zhang",
        "Chen Ye",
        "Jie Chen"
    ],
    "pdf_url": "https://aclanthology.org/2024.findings-acl.55.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/5a25407d-12ca-50ba-a4df-10937237bec3.pdf",
    "abstract": "While large language models (LLMs) have shown excellent capabilities in language understanding, text generation and many other tasks, they still struggle in complex multi-step reasoning problems such as mathematical reasoning. In this paper, through a newly proposed arithmetical puzzle problem, we show that the model can perform well on multi-step reasoning tasks via fine tuning on high-quality synthetic data. Experiments with the open-llama-3B model on three different test datasets show that not only the model can reach a zero-shot pass@1 at 0.44 on the in-domain dataset, it also demonstrates certain generalization capabilities on the out-of-domain datasets. Specifically, this paper has designed two out-of-domain datasets in the form of extending the numerical range and the composing components of the arithmetical puzzle problem separately. The fine-tuned model have shown encouraging performance on these two far more difficult tasks with the zero-shot pass@1 at 0.33 and 0.35 correspondingly.",
    "num_pages": 11
}