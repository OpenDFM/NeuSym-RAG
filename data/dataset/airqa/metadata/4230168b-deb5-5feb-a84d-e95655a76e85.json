{
    "uuid": "4230168b-deb5-5feb-a84d-e95655a76e85",
    "title": "Werewolf Among Us: Multimodal Resources for Modeling Persuasion Behaviors in Social Deduction Games",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Findings of the Association for Computational Linguistics: ACL 2023",
    "bibtex": "@inproceedings{lai-etal-2023-werewolf,\n    title = \"Werewolf Among Us: Multimodal Resources for Modeling Persuasion Behaviors in Social Deduction Games\",\n    author = \"Lai, Bolin  and\n      Zhang, Hongxin  and\n      Liu, Miao  and\n      Pariani, Aryan  and\n      Ryan, Fiona  and\n      Jia, Wenqi  and\n      Hayati, Shirley Anugrah  and\n      Rehg, James  and\n      Yang, Diyi\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-acl.411\",\n    doi = \"10.18653/v1/2023.findings-acl.411\",\n    pages = \"6570--6588\",\n    abstract = \"Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset can be found at https://persuasion-deductiongame. socialai-data.org. The codes and models are available at \\url{https://github.com/SALT-NLP/PersuationGames}.\",\n}\n",
    "authors": [
        "Bolin Lai",
        "Hongxin Zhang",
        "Miao Liu",
        "Aryan Pariani",
        "Fiona Ryan",
        "Wenqi Jia",
        "Shirley Anugrah Hayati",
        "James Rehg",
        "Diyi Yang"
    ],
    "pdf_url": "https://aclanthology.org/2023.findings-acl.411.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/4230168b-deb5-5feb-a84d-e95655a76e85.pdf",
    "abstract": "Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset can be found at https://persuasion-deductiongame. socialai-data.org. The codes and models are available at https://github.com/SALT-NLP/PersuationGames.",
    "num_pages": 19
}