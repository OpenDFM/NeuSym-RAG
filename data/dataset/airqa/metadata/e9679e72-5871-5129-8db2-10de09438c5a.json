{
    "uuid": "e9679e72-5871-5129-8db2-10de09438c5a",
    "title": "Experiential Co-Learning of Software-Developing Agents",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2024,
    "volume": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{qian-etal-2024-experiential,\n    title = \"Experiential Co-Learning of Software-Developing Agents\",\n    author = \"Qian, Chen  and\n      Dang, Yufan  and\n      Li, Jiahao  and\n      Liu, Wei  and\n      Xie, Zihao  and\n      Wang, YiFei  and\n      Chen, Weize  and\n      Yang, Cheng  and\n      Cong, Xin  and\n      Che, Xiaoyin  and\n      Liu, Zhiyuan  and\n      Sun, Maosong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.305\",\n    doi = \"10.18653/v1/2024.acl-long.305\",\n    pages = \"5628--5640\",\n    abstract = \"Recent advancements in large language models (LLMs) have brought significant changes to various domains, especially through LLM-driven autonomous agents. A representative scenario is in software development, where LLM agents demonstrate efficient collaboration, task division, and assurance of software quality, markedly reducing the need for manual involvement. However, these agents frequently perform a variety of tasks independently, without benefiting from past experiences, which leads to repeated mistakes and inefficient attempts in multi-step task execution. To this end, we introduce Experiential Co-Learning, a novel LLM-agent learning framework in which instructor and assistant agents gather shortcut-oriented experiences from their historical trajectories and use these past experiences for future task execution. The extensive experiments demonstrate that the framework enables agents to tackle unseen software-developing tasks more effectively. We anticipate that our insights will guide LLM agents towards enhanced autonomy and contribute to their evolutionary growth in cooperative learning. The code and data are available at https://github.com/OpenBMB/ChatDev.\",\n}\n",
    "authors": [
        "Chen Qian",
        "Yufan Dang",
        "Jiahao Li",
        "Wei Liu",
        "Zihao Xie",
        "YiFei Wang",
        "Weize Chen",
        "Cheng Yang",
        "Xin Cong",
        "Xiaoyin Che",
        "Zhiyuan Liu",
        "Maosong Sun"
    ],
    "pdf_url": "https://aclanthology.org/2024.acl-long.305.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2024/e9679e72-5871-5129-8db2-10de09438c5a.pdf",
    "abstract": "Recent advancements in large language models (LLMs) have brought significant changes to various domains, especially through LLM-driven autonomous agents. A representative scenario is in software development, where LLM agents demonstrate efficient collaboration, task division, and assurance of software quality, markedly reducing the need for manual involvement. However, these agents frequently perform a variety of tasks independently, without benefiting from past experiences, which leads to repeated mistakes and inefficient attempts in multi-step task execution. To this end, we introduce Experiential Co-Learning, a novel LLM-agent learning framework in which instructor and assistant agents gather shortcut-oriented experiences from their historical trajectories and use these past experiences for future task execution. The extensive experiments demonstrate that the framework enables agents to tackle unseen software-developing tasks more effectively. We anticipate that our insights will guide LLM agents towards enhanced autonomy and contribute to their evolutionary growth in cooperative learning. The code and data are available at https://github.com/OpenBMB/ChatDev.",
    "num_pages": 13
}