{
    "uuid": "3ab88992-2a32-5d8b-b6d6-77b9aed0b8b9",
    "title": "OD-RTE: A One-Stage Object Detection Framework for Relational Triple Extraction",
    "conference_full": "Annual Meeting of the Association for Computational Linguistics",
    "conference": "ACL",
    "year": 2023,
    "volume": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "bibtex": "@inproceedings{ning-etal-2023-od,\n    title = \"{OD}-{RTE}: A One-Stage Object Detection Framework for Relational Triple Extraction\",\n    author = \"Ning, Jinzhong  and\n      Yang, Zhihao  and\n      Sun, Yuanyuan  and\n      Wang, Zhizheng  and\n      Lin, Hongfei\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.623\",\n    doi = \"10.18653/v1/2023.acl-long.623\",\n    pages = \"11120--11135\",\n    abstract = \"The Relational Triple Extraction (RTE) task is a fundamental and essential information extraction task. Recently, the table-filling RTE methods have received lots of attention. Despite their success, they suffer from some inherent problems such as underutilizing regional information of triple. In this work, we treat the RTE task based on table-filling method as an Object Detection task and propose a one-stage Object Detection framework for Relational Triple Extraction (OD-RTE). In this framework, the vertices-based bounding box detection, coupled with auxiliary global relational triple region detection, ensuring that regional information of triple could be fully utilized. Besides, our proposed decoding scheme could extract all types of triples. In addition, the negative sampling strategy of relations in the training stage improves the training efficiency while alleviating the imbalance of positive and negative relations. The experimental results show that 1) OD-RTE achieves the state-of-the-art performance on two widely used datasets (i.e., NYT and WebNLG). 2) Compared with the best performing table-filling method, OD-RTE achieves faster training and inference speed with lower GPU memory usage. To facilitate future research in this area, the codes are publicly available at \\url{https://github.com/NingJinzhong/ODRTE}.\",\n}\n",
    "authors": [
        "Jinzhong Ning",
        "Zhihao Yang",
        "Yuanyuan Sun",
        "Zhizheng Wang",
        "Hongfei Lin"
    ],
    "pdf_url": "https://aclanthology.org/2023.acl-long.623.pdf",
    "pdf_path": "data/dataset/airqa/papers/acl2023/3ab88992-2a32-5d8b-b6d6-77b9aed0b8b9.pdf",
    "abstract": "The Relational Triple Extraction (RTE) task is a fundamental and essential information extraction task. Recently, the table-filling RTE methods have received lots of attention. Despite their success, they suffer from some inherent problems such as underutilizing regional information of triple. In this work, we treat the RTE task based on table-filling method as an Object Detection task and propose a one-stage Object Detection framework for Relational Triple Extraction (OD-RTE). In this framework, the vertices-based bounding box detection, coupled with auxiliary global relational triple region detection, ensuring that regional information of triple could be fully utilized. Besides, our proposed decoding scheme could extract all types of triples. In addition, the negative sampling strategy of relations in the training stage improves the training efficiency while alleviating the imbalance of positive and negative relations. The experimental results show that 1) OD-RTE achieves the state-of-the-art performance on two widely used datasets (i.e., NYT and WebNLG). 2) Compared with the best performing table-filling method, OD-RTE achieves faster training and inference speed with lower GPU memory usage. To facilitate future research in this area, the codes are publicly available at https://github.com/NingJinzhong/ODRTE.",
    "num_pages": 16
}