{
    "uuid": "64af0618-461c-5713-a0ba-5a179e12f739",
    "title": "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Mathilde Caron",
        "Ishan Misra",
        "Julien Mairal",
        "Priya Goyal",
        "Piotr Bojanowski",
        "Armand Joulin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2006.09882v5",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\64af0618-461c-5713-a0ba-5a179e12f739.pdf",
    "bibtex": "@misc{caron2021unsupervisedlearningofvisualfeatures,\n    title = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},\n    author = {Mathilde Caron and Ishan Misra and Julien Mairal and Priya Goyal and Piotr Bojanowski and Armand Joulin},\n    year = {2021},\n    eprint = {2006.09882},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2006.09882},\n}",
    "abstract": "Unsupervised image representations have significantly reduced the gap with\nsupervised pretraining, notably with the recent achievements of contrastive\nlearning methods. These contrastive methods typically work online and rely on a\nlarge number of explicit pairwise feature comparisons, which is computationally\nchallenging. In this paper, we propose an online algorithm, SwAV, that takes\nadvantage of contrastive methods without requiring to compute pairwise\ncomparisons. Specifically, our method simultaneously clusters the data while\nenforcing consistency between cluster assignments produced for different\naugmentations (or views) of the same image, instead of comparing features\ndirectly as in contrastive learning. Simply put, we use a swapped prediction\nmechanism where we predict the cluster assignment of a view from the\nrepresentation of another view. Our method can be trained with large and small\nbatches and can scale to unlimited amounts of data. Compared to previous\ncontrastive methods, our method is more memory efficient since it does not\nrequire a large memory bank or a special momentum network. In addition, we also\npropose a new data augmentation strategy, multi-crop, that uses a mix of views\nwith different resolutions in place of two full-resolution views, without\nincreasing the memory or compute requirements much. We validate our findings by\nachieving 75.3% top-1 accuracy on ImageNet with ResNet-50, as well as\nsurpassing supervised pretraining on all the considered transfer tasks.",
    "num_pages": 23
}