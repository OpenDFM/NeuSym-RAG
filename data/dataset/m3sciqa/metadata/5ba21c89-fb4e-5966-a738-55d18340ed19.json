{
    "uuid": "5ba21c89-fb4e-5966-a738-55d18340ed19",
    "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Bogdan Gliwa",
        "Iwona Mochol",
        "Maciej Biesek",
        "Aleksander Wawer"
    ],
    "pdf_url": "http://arxiv.org/pdf/1911.12237v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\5ba21c89-fb4e-5966-a738-55d18340ed19.pdf",
    "bibtex": "@misc{gliwa2019samsumcorpusahumanannotateddialogue,\n    title = {SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization},\n    author = {Bogdan Gliwa and Iwona Mochol and Maciej Biesek and Aleksander Wawer},\n    year = {2019},\n    eprint = {1911.12237},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1911.12237},\n}",
    "abstract": "This paper introduces the SAMSum Corpus, a new dataset with abstractive\ndialogue summaries. We investigate the challenges it poses for automated\nsummarization by testing several models and comparing their results with those\nobtained on a corpus of news articles. We show that model-generated summaries\nof dialogues achieve higher ROUGE scores than the model-generated summaries of\nnews -- in contrast with human evaluators' judgement. This suggests that a\nchallenging task of abstractive dialogue summarization requires dedicated\nmodels and non-standard quality measures. To our knowledge, our study is the\nfirst attempt to introduce a high-quality chat-dialogues corpus, manually\nannotated with abstractive summarizations, which can be used by the research\ncommunity for further studies.",
    "num_pages": 10
}