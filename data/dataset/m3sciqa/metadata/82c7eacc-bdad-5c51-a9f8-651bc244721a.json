{
    "uuid": "82c7eacc-bdad-5c51-a9f8-651bc244721a",
    "title": "Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Libo Qin",
        "Xiao Xu",
        "Wanxiang Che",
        "Yue Zhang",
        "Ting Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.11019v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\82c7eacc-bdad-5c51-a9f8-651bc244721a.pdf",
    "bibtex": "@misc{qin2020dynamicfusionnetworkformultidomain,\n    title = {Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog},\n    author = {Libo Qin and Xiao Xu and Wanxiang Che and Yue Zhang and Ting Liu},\n    year = {2020},\n    eprint = {2004.11019},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2004.11019},\n}",
    "abstract": "Recent studies have shown remarkable success in end-to-end task-oriented\ndialog system. However, most neural models rely on large training data, which\nare only available for a certain number of task domains, such as navigation and\nscheduling.\n  This makes it difficult to scalable for a new domain with limited labeled\ndata. However, there has been relatively little research on how to effectively\nuse data from all domains to improve the performance of each domain and also\nunseen domains. To this end, we investigate methods that can make explicit use\nof domain knowledge and introduce a shared-private network to learn shared and\nspecific knowledge. In addition, we propose a novel Dynamic Fusion Network\n(DF-Net) which automatically exploit the relevance between the target domain\nand each domain. Results show that our model outperforms existing methods on\nmulti-domain dialogue, giving the state-of-the-art in the literature. Besides,\nwith little training data, we show its transferability by outperforming prior\nbest model by 13.9\\% on average.",
    "num_pages": 11
}