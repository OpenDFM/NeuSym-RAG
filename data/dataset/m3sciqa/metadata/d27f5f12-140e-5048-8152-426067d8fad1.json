{
    "uuid": "d27f5f12-140e-5048-8152-426067d8fad1",
    "title": "Constraint based Knowledge Base Distillation in End-to-End Task Oriented Dialogs",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Dinesh Raghu",
        "Atishya Jain",
        "Mausam",
        "Sachindra Joshi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2109.07396v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\d27f5f12-140e-5048-8152-426067d8fad1.pdf",
    "bibtex": "@misc{raghu2021constraintbasedknowledgebasedistillation,\n    title = {Constraint based Knowledge Base Distillation in End-to-End Task Oriented Dialogs},\n    author = {Dinesh Raghu and Atishya Jain and Mausam and Sachindra Joshi},\n    year = {2021},\n    eprint = {2109.07396},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2109.07396},\n}",
    "abstract": "End-to-End task-oriented dialogue systems generate responses based on dialog\nhistory and an accompanying knowledge base (KB). Inferring those KB entities\nthat are most relevant for an utterance is crucial for response generation.\nExisting state of the art scales to large KBs by softly filtering over\nirrelevant KB information. In this paper, we propose a novel filtering\ntechnique that consists of (1) a pairwise similarity based filter that\nidentifies relevant information by respecting the n-ary structure in a KB\nrecord. and, (2) an auxiliary loss that helps in separating contextually\nunrelated KB information. We also propose a new metric -- multiset entity F1\nwhich fixes a correctness issue in the existing entity F1 metric. Experimental\nresults on three publicly available task-oriented dialog datasets show that our\nproposed approach outperforms existing state-of-the-art models.",
    "num_pages": 11
}