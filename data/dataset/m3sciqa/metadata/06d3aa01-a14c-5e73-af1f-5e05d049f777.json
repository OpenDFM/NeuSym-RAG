{
    "uuid": "06d3aa01-a14c-5e73-af1f-5e05d049f777",
    "title": "Multimodal Few-Shot Learning with Frozen Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Maria Tsimpoukelli",
        "Jacob Menick",
        "Serkan Cabi",
        "S. M. Ali Eslami",
        "Oriol Vinyals",
        "Felix Hill"
    ],
    "pdf_url": "http://arxiv.org/pdf/2106.13884v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\06d3aa01-a14c-5e73-af1f-5e05d049f777.pdf",
    "bibtex": "@misc{tsimpoukelli2021multimodalfewshotlearningwithfrozen,\n    title = {Multimodal Few-Shot Learning with Frozen Language Models},\n    author = {Maria Tsimpoukelli and Jacob Menick and Serkan Cabi and S. M. Ali Eslami and Oriol Vinyals and Felix Hill},\n    year = {2021},\n    eprint = {2106.13884},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2106.13884},\n}",
    "abstract": "When trained at sufficient scale, auto-regressive language models exhibit the\nnotable ability to learn a new language task after being prompted with just a\nfew examples. Here, we present a simple, yet effective, approach for\ntransferring this few-shot learning ability to a multimodal setting (vision and\nlanguage). Using aligned image and caption data, we train a vision encoder to\nrepresent each image as a sequence of continuous embeddings, such that a\npre-trained, frozen language model prompted with this prefix generates the\nappropriate caption. The resulting system is a multimodal few-shot learner,\nwith the surprising ability to learn a variety of new tasks when conditioned on\nexamples, represented as a sequence of multiple interleaved image and text\nembeddings. We demonstrate that it can rapidly learn words for new objects and\nnovel visual categories, do visual question-answering with only a handful of\nexamples, and make use of outside knowledge, by measuring a single model on a\nvariety of established and new benchmarks.",
    "num_pages": 19
}