{
    "uuid": "d5c608af-3444-547a-aab9-659b9e73d036",
    "title": "Rethinking with Retrieval: Faithful Large Language Model Inference",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Hangfeng He",
        "Hongming Zhang",
        "Dan Roth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2301.00303v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\d5c608af-3444-547a-aab9-659b9e73d036.pdf",
    "bibtex": "@misc{he2022rethinkingwithretrievalfaithfullarge,\n    title = {Rethinking with Retrieval: Faithful Large Language Model Inference},\n    author = {Hangfeng He and Hongming Zhang and Dan Roth},\n    year = {2022},\n    eprint = {2301.00303},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2301.00303},\n}",
    "abstract": "Despite the success of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, the stored knowledge in these models may\ninevitably be incomplete, out-of-date, or incorrect. This motivates the need to\nutilize external knowledge to assist LLMs. Unfortunately, current methods for\nincorporating external knowledge often require additional training or\nfine-tuning, which can be costly and may not be feasible for LLMs. To address\nthis issue, we propose a novel post-processing approach, rethinking with\nretrieval (RR), which retrieves relevant external knowledge based on the\ndecomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\nThis lightweight approach does not require additional training or fine-tuning\nand is not limited by the input length of LLMs. We evaluate the effectiveness\nof RR through extensive experiments with GPT-3 on three complex reasoning\ntasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\nresults show that RR can produce more faithful explanations and improve the\nperformance of LLMs.",
    "num_pages": 15
}