{
    "uuid": "bd0d5234-9da1-5808-a85a-3e4c08824c1a",
    "title": "Perplexity from PLM Is Unreliable for Evaluating Text Quality",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Yequan Wang",
        "Jiawen Deng",
        "Aixin Sun",
        "Xuying Meng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2210.05892v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\bd0d5234-9da1-5808-a85a-3e4c08824c1a.pdf",
    "bibtex": "@misc{wang2023perplexityfromplmisunreliable,\n    title = {Perplexity from PLM Is Unreliable for Evaluating Text Quality},\n    author = {Yequan Wang and Jiawen Deng and Aixin Sun and Xuying Meng},\n    year = {2023},\n    eprint = {2210.05892},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2210.05892},\n}",
    "abstract": "Recently, amounts of works utilize perplexity~(PPL) to evaluate the quality\nof the generated text. They suppose that if the value of PPL is smaller, the\nquality(i.e. fluency) of the text to be evaluated is better. However, we find\nthat the PPL referee is unqualified and it cannot evaluate the generated text\nfairly for the following reasons: (i) The PPL of short text is larger than long\ntext, which goes against common sense, (ii) The repeated text span could damage\nthe performance of PPL, and (iii) The punctuation marks could affect the\nperformance of PPL heavily. Experiments show that the PPL is unreliable for\nevaluating the quality of given text. Last, we discuss the key problems with\nevaluating text quality using language models.",
    "num_pages": 7
}