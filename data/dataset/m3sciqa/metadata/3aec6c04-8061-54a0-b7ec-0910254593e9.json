{
    "uuid": "3aec6c04-8061-54a0-b7ec-0910254593e9",
    "title": "Rewarding Smatch: Transition-Based AMR Parsing with Reinforcement Learning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Tahira Naseem",
        "Abhishek Shah",
        "Hui Wan",
        "Radu Florian",
        "Salim Roukos",
        "Miguel Ballesteros"
    ],
    "pdf_url": "http://arxiv.org/pdf/1905.13370v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\3aec6c04-8061-54a0-b7ec-0910254593e9.pdf",
    "bibtex": "@misc{naseem2019rewardingsmatchtransitionbasedamrparsing,\n    title = {Rewarding Smatch: Transition-Based AMR Parsing with Reinforcement Learning},\n    author = {Tahira Naseem and Abhishek Shah and Hui Wan and Radu Florian and Salim Roukos and Miguel Ballesteros},\n    year = {2019},\n    eprint = {1905.13370},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1905.13370},\n}",
    "abstract": "Our work involves enriching the Stack-LSTM transition-based AMR parser\n(Ballesteros and Al-Onaizan, 2017) by augmenting training with Policy Learning\nand rewarding the Smatch score of sampled graphs. In addition, we also combined\nseveral AMR-to-text alignments with an attention mechanism and we supplemented\nthe parser with pre-processed concept identification, named entities and\ncontextualized embeddings. We achieve a highly competitive performance that is\ncomparable to the best published results. We show an in-depth study ablating\neach of the new components of the parser",
    "num_pages": 7
}