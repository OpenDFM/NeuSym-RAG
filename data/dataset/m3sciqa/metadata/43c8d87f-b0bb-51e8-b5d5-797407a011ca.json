{
    "uuid": "43c8d87f-b0bb-51e8-b5d5-797407a011ca",
    "title": "Learning to Generate Questions by Learning What not to Generate",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Bang Liu",
        "Mingjun Zhao",
        "Di Niu",
        "Kunfeng Lai",
        "Yancheng He",
        "Haojie Wei",
        "Yu Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/1902.10418v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\43c8d87f-b0bb-51e8-b5d5-797407a011ca.pdf",
    "bibtex": "@misc{liu2019learningtogeneratequestionsby,\n    title = {Learning to Generate Questions by Learning What not to Generate},\n    author = {Bang Liu and Mingjun Zhao and Di Niu and Kunfeng Lai and Yancheng He and Haojie Wei and Yu Xu},\n    year = {2019},\n    eprint = {1902.10418},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1902.10418},\n}",
    "abstract": "Automatic question generation is an important technique that can improve the\ntraining of question answering, help chatbots to start or continue a\nconversation with humans, and provide assessment materials for educational\npurposes. Existing neural question generation models are not sufficient mainly\ndue to their inability to properly model the process of how each word in the\nquestion is selected, i.e., whether repeating the given passage or being\ngenerated from a vocabulary. In this paper, we propose our Clue Guided Copy\nNetwork for Question Generation (CGC-QG), which is a sequence-to-sequence\ngenerative model with copying mechanism, yet employing a variety of novel\ncomponents and techniques to boost the performance of question generation. In\nCGC-QG, we design a multi-task labeling strategy to identify whether a question\nword should be copied from the input passage or be generated instead, guiding\nthe model to learn the accurate boundaries between copying and generation.\nFurthermore, our input passage encoder takes as input, among a diverse range of\nother features, the prediction made by a clue word predictor, which helps\nidentify whether each word in the input passage is a potential clue to be\ncopied into the target question. The clue word predictor is designed based on a\nnovel application of Graph Convolutional Networks onto a syntactic dependency\ntree representation of each passage, thus being able to predict clue words only\nbased on their context in the passage and their relative positions to the\nanswer in the tree. We jointly train the clue prediction as well as question\ngeneration with multi-task learning and a number of practical strategies to\nreduce the complexity. Extensive evaluations show that our model significantly\nimproves the performance of question generation and out-performs all previous\nstate-of-the-art neural question generation models by a substantial margin.",
    "num_pages": 11
}