{
    "uuid": "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9",
    "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Can Xu",
        "Qingfeng Sun",
        "Kai Zheng",
        "Xiubo Geng",
        "Pu Zhao",
        "Jiazhan Feng",
        "Chongyang Tao",
        "Daxin Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2304.12244v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\33abd7ca-d89c-51a6-93ab-bb734ec9dfd9.pdf",
    "bibtex": "@misc{xu2023wizardlmempoweringlargelanguagemodels,\n    title = {WizardLM: Empowering Large Language Models to Follow Complex Instructions},\n    author = {Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},\n    year = {2023},\n    eprint = {2304.12244},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2304.12244},\n}",
    "abstract": "Training large language models (LLMs) with open-domain instruction following\ndata brings colossal success. However, manually creating such instruction data\nis very time-consuming and labor-intensive. Moreover, humans may struggle to\nproduce high-complexity instructions. In this paper, we show an avenue for\ncreating large amounts of instruction data with varying levels of complexity\nusing LLM instead of humans. Starting with an initial set of instructions, we\nuse our proposed Evol-Instruct to rewrite them step by step into more complex\ninstructions. Then, we mix all generated instruction data to fine-tune LLaMA.\nWe call the resulting model WizardLM. Human evaluations on a\ncomplexity-balanced test bed and Vicuna's testset show that instructions from\nEvol-Instruct are superior to human-created ones. By analyzing the human\nevaluation results of the high complexity part, we demonstrate that outputs\nfrom our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4\nautomatic evaluation, WizardLM achieves more than 90\\% capacity of ChatGPT on\n17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some\naspects, our findings suggest that fine-tuning with AI-evolved instructions is\na promising direction for enhancing LLMs. Our code and data are public at\nhttps://github.com/nlpxucan/WizardLM",
    "num_pages": 41
}