{
    "uuid": "9d24c743-9966-5400-a5f9-6825eca1d557",
    "title": "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Myle Ott",
        "Sergey Edunov",
        "Alexei Baevski",
        "Angela Fan",
        "Sam Gross",
        "Nathan Ng",
        "David Grangier",
        "Michael Auli"
    ],
    "pdf_url": "http://arxiv.org/pdf/1904.01038v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\9d24c743-9966-5400-a5f9-6825eca1d557.pdf",
    "bibtex": "@misc{ott2019fairseqafastextensibletoolkit,\n    title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},\n    author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},\n    year = {2019},\n    eprint = {1904.01038},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1904.01038},\n}",
    "abstract": "fairseq is an open-source sequence modeling toolkit that allows researchers\nand developers to train custom models for translation, summarization, language\nmodeling, and other text generation tasks. The toolkit is based on PyTorch and\nsupports distributed training across multiple GPUs and machines. We also\nsupport fast mixed-precision training and inference on modern GPUs. A demo\nvideo can be found at https://www.youtube.com/watch?v=OtgDdWtHvto",
    "num_pages": 6
}