{
    "uuid": "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1",
    "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Hugo Berg",
        "Siobhan Mackenzie Hall",
        "Yash Bhalgat",
        "Wonsuk Yang",
        "Hannah Rose Kirk",
        "Aleksandar Shtedritski",
        "Max Bain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2203.11933v4",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\ce1df36e-abc0-55b7-96a8-99f14f1fe8b1.pdf",
    "bibtex": "@misc{berg2022apromptarraykeepsthe,\n    title = {A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning},\n    author = {Hugo Berg and Siobhan Mackenzie Hall and Yash Bhalgat and Wonsuk Yang and Hannah Rose Kirk and Aleksandar Shtedritski and Max Bain},\n    year = {2022},\n    eprint = {2203.11933},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2203.11933},\n}",
    "abstract": "Vision-language models can encode societal biases and stereotypes, but there\nare challenges to measuring and mitigating these multimodal harms due to\nlacking measurement robustness and feature degradation. To address these\nchallenges, we investigate bias measures and apply ranking metrics for\nimage-text representations. We then investigate debiasing methods and show that\nprepending learned embeddings to text queries that are jointly trained with\nadversarial debiasing and a contrastive loss reduces various bias measures with\nminimal degradation to the image-text representation.",
    "num_pages": 17
}