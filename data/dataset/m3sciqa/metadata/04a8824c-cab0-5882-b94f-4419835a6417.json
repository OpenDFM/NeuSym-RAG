{
    "uuid": "04a8824c-cab0-5882-b94f-4419835a6417",
    "title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Sina J. Semnani",
        "Violet Z. Yao",
        "Heidi C. Zhang",
        "Monica S. Lam"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.14292v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\04a8824c-cab0-5882-b94f-4419835a6417.pdf",
    "bibtex": "@misc{semnani2023wikichatstoppingthehallucinationof,\n    title = {WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia},\n    author = {Sina J. Semnani and Violet Z. Yao and Heidi C. Zhang and Monica S. Lam},\n    year = {2023},\n    eprint = {2305.14292},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.14292},\n}",
    "abstract": "This paper presents the first few-shot LLM-based chatbot that almost never\nhallucinates and has high conversationality and low latency. WikiChat is\ngrounded on the English Wikipedia, the largest curated free-text corpus.\n  WikiChat generates a response from an LLM, retains only the grounded facts,\nand combines them with additional information it retrieves from the corpus to\nform factual and engaging responses. We distill WikiChat based on GPT-4 into a\n7B-parameter LLaMA model with minimal loss of quality, to significantly improve\nits latency, cost and privacy, and facilitate research and deployment.\n  Using a novel hybrid human-and-LLM evaluation methodology, we show that our\nbest system achieves 97.3% factual accuracy in simulated conversations. It\nsignificantly outperforms all retrieval-based and LLM-based baselines, and by\n3.9%, 38.6% and 51.0% on head, tail and recent knowledge compared to GPT-4.\nCompared to previous state-of-the-art retrieval-based chatbots, WikiChat is\nalso significantly more informative and engaging, just like an LLM.\n  WikiChat achieves 97.9% factual accuracy in conversations with human users\nabout recent topics, 55.0% better than GPT-4, while receiving significantly\nhigher user ratings and more favorable comments.",
    "num_pages": 27
}