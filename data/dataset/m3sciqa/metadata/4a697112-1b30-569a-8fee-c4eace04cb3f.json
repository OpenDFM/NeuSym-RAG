{
    "uuid": "4a697112-1b30-569a-8fee-c4eace04cb3f",
    "title": "Grid Long Short-Term Memory",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Nal Kalchbrenner",
        "Ivo Danihelka",
        "Alex Graves"
    ],
    "pdf_url": "http://arxiv.org/pdf/1507.01526v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\4a697112-1b30-569a-8fee-c4eace04cb3f.pdf",
    "bibtex": "@misc{kalchbrenner2016gridlongshorttermmemory,\n    title = {Grid Long Short-Term Memory},\n    author = {Nal Kalchbrenner and Ivo Danihelka and Alex Graves},\n    year = {2016},\n    eprint = {1507.01526},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.NE},\n    url = {http://arxiv.org/abs/1507.01526},\n}",
    "abstract": "This paper introduces Grid Long Short-Term Memory, a network of LSTM cells\narranged in a multidimensional grid that can be applied to vectors, sequences\nor higher dimensional data such as images. The network differs from existing\ndeep LSTM architectures in that the cells are connected between network layers\nas well as along the spatiotemporal dimensions of the data. The network\nprovides a unified way of using LSTM for both deep and sequential computation.\nWe apply the model to algorithmic tasks such as 15-digit integer addition and\nsequence memorization, where it is able to significantly outperform the\nstandard LSTM. We then give results for two empirical tasks. We find that 2D\nGrid LSTM achieves 1.47 bits per character on the Wikipedia character\nprediction benchmark, which is state-of-the-art among neural approaches. In\naddition, we use the Grid LSTM to define a novel two-dimensional translation\nmodel, the Reencoder, and show that it outperforms a phrase-based reference\nsystem on a Chinese-to-English translation task.",
    "num_pages": 15
}