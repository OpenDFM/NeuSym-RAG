{
    "uuid": "befe32c2-c0d6-520c-b7df-ddfcfeb79028",
    "title": "A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Aiwei Liu",
        "Xuming Hu",
        "Lijie Wen",
        "Philip S. Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2303.13547v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\befe32c2-c0d6-520c-b7df-ddfcfeb79028.pdf",
    "bibtex": "@misc{liu2023acomprehensiveevaluationofchatgpts,\n    title = {A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability},\n    author = {Aiwei Liu and Xuming Hu and Lijie Wen and Philip S. Yu},\n    year = {2023},\n    eprint = {2303.13547},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2303.13547},\n}",
    "abstract": "This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL\nability. Given the recent emergence of large-scale conversational language\nmodel ChatGPT and its impressive capabilities in both conversational abilities\nand code generation, we sought to evaluate its Text-to-SQL performance. We\nconducted experiments on 12 benchmark datasets with different languages,\nsettings, or scenarios, and the results demonstrate that ChatGPT has strong\ntext-to-SQL abilities. Although there is still a gap from the current\nstate-of-the-art (SOTA) model performance, considering that the experiment was\nconducted in a zero-shot scenario, ChatGPT's performance is still impressive.\nNotably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms\nthe SOTA model that requires fine-tuning on the Spider dataset by 4.1\\%,\ndemonstrating its potential for use in practical applications. To support\nfurther research in related fields, we have made the data generated by ChatGPT\npublicly available at https://github.com/THU-BPM/chatgpt-sql.",
    "num_pages": 7
}