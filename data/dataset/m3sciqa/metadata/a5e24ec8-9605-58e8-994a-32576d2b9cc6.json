{
    "uuid": "a5e24ec8-9605-58e8-994a-32576d2b9cc6",
    "title": "Teaching Machines to Read and Comprehend",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2015,
    "authors": [
        "Karl Moritz Hermann",
        "Tomáš Kočiský",
        "Edward Grefenstette",
        "Lasse Espeholt",
        "Will Kay",
        "Mustafa Suleyman",
        "Phil Blunsom"
    ],
    "pdf_url": "http://arxiv.org/pdf/1506.03340v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2015\\a5e24ec8-9605-58e8-994a-32576d2b9cc6.pdf",
    "bibtex": "@misc{hermann2015teachingmachinestoreadand,\n    title = {Teaching Machines to Read and Comprehend},\n    author = {Karl Moritz Hermann and Tomáš Kočiský and Edward Grefenstette and Lasse Espeholt and Will Kay and Mustafa Suleyman and Phil Blunsom},\n    year = {2015},\n    eprint = {1506.03340},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1506.03340},\n}",
    "abstract": "Teaching machines to read natural language documents remains an elusive\nchallenge. Machine reading systems can be tested on their ability to answer\nquestions posed on the contents of documents that they have seen, but until now\nlarge scale training and test datasets have been missing for this type of\nevaluation. In this work we define a new methodology that resolves this\nbottleneck and provides large scale supervised reading comprehension data. This\nallows us to develop a class of attention based deep neural networks that learn\nto read real documents and answer complex questions with minimal prior\nknowledge of language structure.",
    "num_pages": 14
}