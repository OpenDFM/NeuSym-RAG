{
    "uuid": "e5280e86-0b93-5183-b502-7316897c4e02",
    "title": "SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Ramesh Nallapati",
        "Feifei Zhai",
        "Bowen Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/1611.04230v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\e5280e86-0b93-5183-b502-7316897c4e02.pdf",
    "bibtex": "@misc{nallapati2016summarunnerarecurrentneuralnetwork,\n    title = {SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents},\n    author = {Ramesh Nallapati and Feifei Zhai and Bowen Zhou},\n    year = {2016},\n    eprint = {1611.04230},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1611.04230},\n}",
    "abstract": "We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence model\nfor extractive summarization of documents and show that it achieves performance\nbetter than or comparable to state-of-the-art. Our model has the additional\nadvantage of being very interpretable, since it allows visualization of its\npredictions broken up by abstract features such as information content,\nsalience and novelty. Another novel contribution of our work is abstractive\ntraining of our extractive model that can train on human generated reference\nsummaries alone, eliminating the need for sentence-level extractive labels.",
    "num_pages": 7
}