{
    "uuid": "2996caf3-f7a5-515a-ba60-091b02f7c9e5",
    "title": "FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Guillaume Jaume",
        "Hazim Kemal Ekenel",
        "Jean-Philippe Thiran"
    ],
    "pdf_url": "http://arxiv.org/pdf/1905.13538v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\2996caf3-f7a5-515a-ba60-091b02f7c9e5.pdf",
    "bibtex": "@misc{jaume2019funsdadatasetforform,\n    title = {FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents},\n    author = {Guillaume Jaume and Hazim Kemal Ekenel and Jean-Philippe Thiran},\n    year = {2019},\n    eprint = {1905.13538},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.IR},\n    url = {http://arxiv.org/abs/1905.13538},\n}",
    "abstract": "We present a new dataset for form understanding in noisy scanned documents\n(FUNSD) that aims at extracting and structuring the textual content of forms.\nThe dataset comprises 199 real, fully annotated, scanned forms. The documents\nare noisy and vary widely in appearance, making form understanding (FoUn) a\nchallenging task. The proposed dataset can be used for various tasks, including\ntext detection, optical character recognition, spatial layout analysis, and\nentity labeling/linking. To the best of our knowledge, this is the first\npublicly available dataset with comprehensive annotations to address FoUn task.\nWe also present a set of baselines and introduce metrics to evaluate\nperformance on the FUNSD dataset, which can be downloaded at\nhttps://guillaumejaume.github.io/FUNSD/.",
    "num_pages": 6
}