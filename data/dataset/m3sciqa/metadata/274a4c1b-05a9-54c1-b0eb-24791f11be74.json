{
    "uuid": "274a4c1b-05a9-54c1-b0eb-24791f11be74",
    "title": "Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Yangming Li",
        "Lemao Liu",
        "Shuming Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2012.05426v5",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\274a4c1b-05a9-54c1-b0eb-24791f11be74.pdf",
    "bibtex": "@misc{li2021empiricalanalysisofunlabeledentity,\n    title = {Empirical Analysis of Unlabeled Entity Problem in Named Entity Recognition},\n    author = {Yangming Li and Lemao Liu and Shuming Shi},\n    year = {2021},\n    eprint = {2012.05426},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2012.05426},\n}",
    "abstract": "In many scenarios, named entity recognition (NER) models severely suffer from\nunlabeled entity problem, where the entities of a sentence may not be fully\nannotated. Through empirical studies performed on synthetic datasets, we find\ntwo causes of performance degradation. One is the reduction of annotated\nentities and the other is treating unlabeled entities as negative instances.\nThe first cause has less impact than the second one and can be mitigated by\nadopting pretraining language models. The second cause seriously misguides a\nmodel in training and greatly affects its performances. Based on the above\nobservations, we propose a general approach, which can almost eliminate the\nmisguidance brought by unlabeled entities. The key idea is to use negative\nsampling that, to a large extent, avoids training NER models with unlabeled\nentities. Experiments on synthetic datasets and real-world datasets show that\nour model is robust to unlabeled entity problem and surpasses prior baselines.\nOn well-annotated datasets, our model is competitive with the state-of-the-art\nmethod.",
    "num_pages": 12
}