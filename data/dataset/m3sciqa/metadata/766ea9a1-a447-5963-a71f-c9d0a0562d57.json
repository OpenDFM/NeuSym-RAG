{
    "uuid": "766ea9a1-a447-5963-a71f-c9d0a0562d57",
    "title": "A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Bing Su",
        "Dazhao Du",
        "Zhao Yang",
        "Yujie Zhou",
        "Jiangmeng Li",
        "Anyi Rao",
        "Hao Sun",
        "Zhiwu Lu",
        "Ji-Rong Wen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2209.05481v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\766ea9a1-a447-5963-a71f-c9d0a0562d57.pdf",
    "bibtex": "@misc{su2022amolecularmultimodalfoundationmodel,\n    title = {A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language},\n    author = {Bing Su and Dazhao Du and Zhao Yang and Yujie Zhou and Jiangmeng Li and Anyi Rao and Hao Sun and Zhiwu Lu and Ji-Rong Wen},\n    year = {2022},\n    eprint = {2209.05481},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2209.05481},\n}",
    "abstract": "Although artificial intelligence (AI) has made significant progress in\nunderstanding molecules in a wide range of fields, existing models generally\nacquire the single cognitive ability from the single molecular modality. Since\nthe hierarchy of molecular knowledge is profound, even humans learn from\ndifferent modalities including both intuitive diagrams and professional texts\nto assist their understanding. Inspired by this, we propose a molecular\nmultimodal foundation model which is pretrained from molecular graphs and their\nsemantically related textual data (crawled from published Scientific Citation\nIndex papers) via contrastive learning. This AI model represents a critical\nattempt that directly bridges molecular graphs and natural language.\nImportantly, through capturing the specific and complementary information of\nthe two modalities, our proposed model can better grasp molecular expertise.\nExperimental results show that our model not only exhibits promising\nperformance in cross-modal tasks such as cross-modal retrieval and molecule\ncaption, but also enhances molecular property prediction and possesses\ncapability to generate meaningful molecular graphs from natural language\ndescriptions. We believe that our model would have a broad impact on\nAI-empowered fields across disciplines such as biology, chemistry, materials,\nenvironment, and medicine, among others.",
    "num_pages": 17
}