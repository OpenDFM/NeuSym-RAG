{
    "uuid": "adfc0ecd-7ed6-5ca8-8c56-f58d16097120",
    "title": "Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Yichi Zhang",
        "Joyce Chai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2106.03427v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\adfc0ecd-7ed6-5ca8-8c56-f58d16097120.pdf",
    "bibtex": "@misc{zhang2021hierarchicaltasklearningfromlanguage,\n    title = {Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring},\n    author = {Yichi Zhang and Joyce Chai},\n    year = {2021},\n    eprint = {2106.03427},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/2106.03427},\n}",
    "abstract": "Despite recent progress, learning new tasks through language instructions\nremains an extremely challenging problem. On the ALFRED benchmark for task\nlearning, the published state-of-the-art system only achieves a task success\nrate of less than 10% in an unseen environment, compared to the human\nperformance of over 90%. To address this issue, this paper takes a closer look\nat task learning. In a departure from a widely applied end-to-end architecture,\nwe decomposed task learning into three sub-problems: sub-goal planning, scene\nnavigation, and object manipulation; and developed a model HiTUT (stands for\nHierarchical Tasks via Unified Transformers) that addresses each sub-problem in\na unified manner to learn a hierarchical task structure. On the ALFRED\nbenchmark, HiTUT has achieved the best performance with a remarkably higher\ngeneralization ability. In the unseen environment, HiTUT achieves over 160%\nperformance gain in success rate compared to the previous state of the art. The\nexplicit representation of task structures also enables an in-depth\nunderstanding of the nature of the problem and the ability of the agent, which\nprovides insight for future benchmark development and evaluation.",
    "num_pages": 12
}