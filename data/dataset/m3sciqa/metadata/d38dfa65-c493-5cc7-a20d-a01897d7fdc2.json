{
    "uuid": "d38dfa65-c493-5cc7-a20d-a01897d7fdc2",
    "title": "MSCTD: A Multimodal Sentiment Chat Translation Dataset",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Yunlong Liang",
        "Fandong Meng",
        "Jinan Xu",
        "Yufeng Chen",
        "Jie Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2202.13645v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\d38dfa65-c493-5cc7-a20d-a01897d7fdc2.pdf",
    "bibtex": "@misc{liang2022msctdamultimodalsentimentchat,\n    title = {MSCTD: A Multimodal Sentiment Chat Translation Dataset},\n    author = {Yunlong Liang and Fandong Meng and Jinan Xu and Yufeng Chen and Jie Zhou},\n    year = {2022},\n    eprint = {2202.13645},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2202.13645},\n}",
    "abstract": "Multimodal machine translation and textual chat translation have received\nconsiderable attention in recent years. Although the conversation in its\nnatural form is usually multimodal, there still lacks work on multimodal\nmachine translation in conversations. In this work, we introduce a new task\nnamed Multimodal Chat Translation (MCT), aiming to generate more accurate\ntranslations with the help of the associated dialogue history and visual\ncontext. To this end, we firstly construct a Multimodal Sentiment Chat\nTranslation Dataset (MSCTD) containing 142,871 English-Chinese utterance pairs\nin 14,762 bilingual dialogues and 30,370 English-German utterance pairs in\n3,079 bilingual dialogues. Each utterance pair, corresponding to the visual\ncontext that reflects the current conversational scene, is annotated with a\nsentiment label. Then, we benchmark the task by establishing multiple baseline\nsystems that incorporate multimodal and sentiment features for MCT. Preliminary\nexperiments on four language directions (English-Chinese and English-German)\nverify the potential of contextual and multimodal information fusion and the\npositive impact of sentiment on the MCT task. Additionally, as a by-product of\nthe MSCTD, it also provides two new benchmarks on multimodal dialogue sentiment\nanalysis. Our work can facilitate research on both multimodal chat translation\nand multimodal dialogue sentiment analysis.",
    "num_pages": 13
}