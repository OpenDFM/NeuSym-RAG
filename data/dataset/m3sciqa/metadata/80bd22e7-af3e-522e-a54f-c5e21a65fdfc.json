{
    "uuid": "80bd22e7-af3e-522e-a54f-c5e21a65fdfc",
    "title": "Decay No More: A Persistent Twitter Dataset for Learning Social Meaning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Chiyu Zhang",
        "Muhammad Abdul-Mageed",
        "El Moatez Billah Nagoudi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2204.04611v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\80bd22e7-af3e-522e-a54f-c5e21a65fdfc.pdf",
    "bibtex": "@misc{zhang2022decaynomoreapersistent,\n    title = {Decay No More: A Persistent Twitter Dataset for Learning Social Meaning},\n    author = {Chiyu Zhang and Muhammad Abdul-Mageed and El Moatez Billah Nagoudi},\n    year = {2022},\n    eprint = {2204.04611},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2204.04611},\n}",
    "abstract": "With the proliferation of social media, many studies resort to social media\nto construct datasets for developing social meaning understanding systems. For\nthe popular case of Twitter, most researchers distribute tweet IDs without the\nactual text contents due to the data distribution policy of the platform. One\nissue is that the posts become increasingly inaccessible over time, which leads\nto unfair comparisons and a temporal bias in social media research. To\nalleviate this challenge of data decay, we leverage a paraphrase model to\npropose a new persistent English Twitter dataset for social meaning (PTSM).\nPTSM consists of $17$ social meaning datasets in $10$ categories of tasks. We\nexperiment with two SOTA pre-trained language models and show that our PTSM can\nsubstitute the actual tweets with paraphrases with marginal performance loss.",
    "num_pages": 6
}