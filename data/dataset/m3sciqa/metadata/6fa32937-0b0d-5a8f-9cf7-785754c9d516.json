{
    "uuid": "6fa32937-0b0d-5a8f-9cf7-785754c9d516",
    "title": "Neural Language Models as Psycholinguistic Subjects: Representations of Syntactic State",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Richard Futrell",
        "Ethan Wilcox",
        "Takashi Morita",
        "Peng Qian",
        "Miguel Ballesteros",
        "Roger Levy"
    ],
    "pdf_url": "http://arxiv.org/pdf/1903.03260v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\6fa32937-0b0d-5a8f-9cf7-785754c9d516.pdf",
    "bibtex": "@misc{futrell2019neurallanguagemodelsaspsycholinguistic,\n    title = {Neural Language Models as Psycholinguistic Subjects: Representations of Syntactic State},\n    author = {Richard Futrell and Ethan Wilcox and Takashi Morita and Peng Qian and Miguel Ballesteros and Roger Levy},\n    year = {2019},\n    eprint = {1903.03260},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1903.03260},\n}",
    "abstract": "We deploy the methods of controlled psycholinguistic experimentation to shed\nlight on the extent to which the behavior of neural network language models\nreflects incremental representations of syntactic state. To do so, we examine\nmodel behavior on artificial sentences containing a variety of syntactically\ncomplex structures. We test four models: two publicly available LSTM sequence\nmodels of English (Jozefowicz et al., 2016; Gulordava et al., 2018) trained on\nlarge datasets; an RNNG (Dyer et al., 2016) trained on a small, parsed dataset;\nand an LSTM trained on the same small corpus as the RNNG. We find evidence that\nthe LSTMs trained on large datasets represent syntactic state over large spans\nof text in a way that is comparable to the RNNG, while the LSTM trained on the\nsmall dataset does not or does so only weakly.",
    "num_pages": 10
}