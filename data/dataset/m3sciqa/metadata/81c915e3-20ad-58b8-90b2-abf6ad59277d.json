{
    "uuid": "81c915e3-20ad-58b8-90b2-abf6ad59277d",
    "title": "Topic-Aware Neural Keyphrase Generation for Social Media Language",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Yue Wang",
        "Jing Li",
        "Hou Pong Chan",
        "Irwin King",
        "Michael R. Lyu",
        "Shuming Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/1906.03889v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\81c915e3-20ad-58b8-90b2-abf6ad59277d.pdf",
    "bibtex": "@misc{wang2019topicawareneuralkeyphrasegenerationfor,\n    title = {Topic-Aware Neural Keyphrase Generation for Social Media Language},\n    author = {Yue Wang and Jing Li and Hou Pong Chan and Irwin King and Michael R. Lyu and Shuming Shi},\n    year = {2019},\n    eprint = {1906.03889},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1906.03889},\n}",
    "abstract": "A huge volume of user-generated content is daily produced on social media. To\nfacilitate automatic language understanding, we study keyphrase prediction,\ndistilling salient information from massive posts. While most existing methods\nextract words from source posts to form keyphrases, we propose a\nsequence-to-sequence (seq2seq) based neural keyphrase generation framework,\nenabling absent keyphrases to be created. Moreover, our model, being\ntopic-aware, allows joint modeling of corpus-level latent topic\nrepresentations, which helps alleviate the data sparsity that widely exhibited\nin social media language. Experiments on three datasets collected from English\nand Chinese social media platforms show that our model significantly\noutperforms both extraction and generation models that do not exploit latent\ntopics. Further discussions show that our model learns meaningful topics, which\ninterprets its superiority in social media keyphrase generation.",
    "num_pages": 11
}