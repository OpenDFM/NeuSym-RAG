{
    "uuid": "66202782-84ce-53c5-886a-7e4db69d264e",
    "title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Pan Lu",
        "Baolin Peng",
        "Hao Cheng",
        "Michel Galley",
        "Kai-Wei Chang",
        "Ying Nian Wu",
        "Song-Chun Zhu",
        "Jianfeng Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2304.09842v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\66202782-84ce-53c5-886a-7e4db69d264e.pdf",
    "bibtex": "@misc{lu2023chameleonplugandplaycompositionalreasoningwith,\n    title = {Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},\n    author = {Pan Lu and Baolin Peng and Hao Cheng and Michel Galley and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Jianfeng Gao},\n    year = {2023},\n    eprint = {2304.09842},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2304.09842},\n}",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in solving\nvarious natural language processing tasks due to emergent reasoning abilities.\nHowever, LLMs have inherent limitations as they are incapable of accessing\nup-to-date information (stored on the Web or in task-specific knowledge bases),\nusing external tools, and performing precise mathematical and logical\nreasoning. In this paper, we present Chameleon, an AI system that mitigates\nthese limitations by augmenting LLMs with plug-and-play modules for\ncompositional reasoning. Chameleon synthesizes programs by composing various\ntools (e.g., LLMs, off-the-shelf vision models, web search engines, Python\nfunctions, and heuristic-based modules) for accomplishing complex reasoning\ntasks. At the heart of Chameleon is an LLM-based planner that assembles a\nsequence of tools to execute to generate the final response. We showcase the\neffectiveness of Chameleon on two multi-modal knowledge-intensive reasoning\ntasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%\noverall accuracy on ScienceQA, improving the best published few-shot result by\n11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,\nlifting the state of the art to 98.78%. Our analysis also shows that the\nGPT-4-powered planner exhibits more consistent and rational tool selection via\ninferring potential constraints from instructions, compared to a\nChatGPT-powered planner. The project is available at\nhttps://chameleon-llm.github.io.",
    "num_pages": 32
}