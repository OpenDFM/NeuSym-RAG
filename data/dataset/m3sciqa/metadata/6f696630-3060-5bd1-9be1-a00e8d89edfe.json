{
    "uuid": "6f696630-3060-5bd1-9be1-a00e8d89edfe",
    "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Eric Mitchell",
        "Yoonho Lee",
        "Alexander Khazatsky",
        "Christopher D. Manning",
        "Chelsea Finn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2301.11305v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\6f696630-3060-5bd1-9be1-a00e8d89edfe.pdf",
    "bibtex": "@misc{mitchell2023detectgptzeroshotmachinegeneratedtextdetection,\n    title = {DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature},\n    author = {Eric Mitchell and Yoonho Lee and Alexander Khazatsky and Christopher D. Manning and Chelsea Finn},\n    year = {2023},\n    eprint = {2301.11305},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2301.11305},\n}",
    "abstract": "The increasing fluency and widespread usage of large language models (LLMs)\nhighlight the desirability of corresponding tools aiding detection of\nLLM-generated text. In this paper, we identify a property of the structure of\nan LLM's probability function that is useful for such detection. Specifically,\nwe demonstrate that text sampled from an LLM tends to occupy negative curvature\nregions of the model's log probability function. Leveraging this observation,\nwe then define a new curvature-based criterion for judging if a passage is\ngenerated from a given LLM. This approach, which we call DetectGPT, does not\nrequire training a separate classifier, collecting a dataset of real or\ngenerated passages, or explicitly watermarking generated text. It uses only log\nprobabilities computed by the model of interest and random perturbations of the\npassage from another generic pre-trained language model (e.g., T5). We find\nDetectGPT is more discriminative than existing zero-shot methods for model\nsample detection, notably improving detection of fake news articles generated\nby 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline\nto 0.95 AUROC for DetectGPT. See https://ericmitchell.ai/detectgpt for code,\ndata, and other project information.",
    "num_pages": 13
}