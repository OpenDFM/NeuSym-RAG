{
    "uuid": "ee84be56-8306-5304-8a3a-3ad106e977f3",
    "title": "Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Wei Han",
        "Hui Chen",
        "Soujanya Poria"
    ],
    "pdf_url": "http://arxiv.org/pdf/2109.00412v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\ee84be56-8306-5304-8a3a-3ad106e977f3.pdf",
    "bibtex": "@misc{han2021improvingmultimodalfusionwithhierarchical,\n    title = {Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis},\n    author = {Wei Han and Hui Chen and Soujanya Poria},\n    year = {2021},\n    eprint = {2109.00412},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2109.00412},\n}",
    "abstract": "In multimodal sentiment analysis (MSA), the performance of a model highly\ndepends on the quality of synthesized embeddings. These embeddings are\ngenerated from the upstream process called multimodal fusion, which aims to\nextract and combine the input unimodal raw data to produce a richer multimodal\nrepresentation. Previous work either back-propagates the task loss or\nmanipulates the geometric property of feature spaces to produce favorable\nfusion results, which neglects the preservation of critical task-related\ninformation that flows from input to the fusion results. In this work, we\npropose a framework named MultiModal InfoMax (MMIM), which hierarchically\nmaximizes the Mutual Information (MI) in unimodal input pairs (inter-modality)\nand between multimodal fusion result and unimodal input in order to maintain\ntask-related information through multimodal fusion. The framework is jointly\ntrained with the main task (MSA) to improve the performance of the downstream\nMSA task. To address the intractable issue of MI bounds, we further formulate a\nset of computationally simple parametric and non-parametric methods to\napproximate their truth value. Experimental results on the two widely used\ndatasets demonstrate the efficacy of our approach. The implementation of this\nwork is publicly available at\nhttps://github.com/declare-lab/Multimodal-Infomax.",
    "num_pages": 13
}