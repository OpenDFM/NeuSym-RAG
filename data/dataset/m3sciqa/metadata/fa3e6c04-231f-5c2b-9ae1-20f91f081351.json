{
    "uuid": "fa3e6c04-231f-5c2b-9ae1-20f91f081351",
    "title": "End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Tuan-Anh Nguyen Dang",
        "Dat-Thanh Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2106.00952v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\fa3e6c04-231f-5c2b-9ae1-20f91f081351.pdf",
    "bibtex": "@misc{dang2021endtoendinformationextractionbycharacterlevel,\n    title = {End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net},\n    author = {Tuan-Anh Nguyen Dang and Dat-Thanh Nguyen},\n    year = {2021},\n    eprint = {2106.00952},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2106.00952},\n}",
    "abstract": "Information extraction from document images has received a lot of attention\nrecently, due to the need for digitizing a large volume of unstructured\ndocuments such as invoices, receipts, bank transfers, etc. In this paper, we\npropose a novel deep learning architecture for end-to-end information\nextraction on the 2D character-grid embedding of the document, namely the\n\\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and\nspatial relations between 2D elements, our model leverages a specialized\nmulti-stage encoder-decoders design, in conjunction with efficient uses of the\nself-attention mechanism and the box convolution. Experimental results on\ndifferent datasets show that our model outperforms the baseline U-Net\narchitecture by a large margin while using 40\\% fewer parameters. Moreover, it\nalso significantly improved the baseline in erroneous OCR and limited training\ndata scenario, thus becomes practical for real-world applications.",
    "num_pages": 13
}