{
    "uuid": "e0fe58d1-5915-5058-a0d9-fead5d6c3cde",
    "title": "CoP: Factual Inconsistency Detection by Controlling the Preference",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Shuaijie She",
        "Xiang Geng",
        "Shujian Huang",
        "Jiajun Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2212.01611v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\e0fe58d1-5915-5058-a0d9-fead5d6c3cde.pdf",
    "bibtex": "@misc{she2023copfactualinconsistencydetectionby,\n    title = {CoP: Factual Inconsistency Detection by Controlling the Preference},\n    author = {Shuaijie She and Xiang Geng and Shujian Huang and Jiajun Chen},\n    year = {2023},\n    eprint = {2212.01611},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2212.01611},\n}",
    "abstract": "Abstractive summarization is the process of generating a summary given a\ndocument as input. Although significant progress has been made, the factual\ninconsistency between the document and the generated summary still limits its\npractical applications. Previous work found that the probabilities assigned by\nthe generation model reflect its preferences for the generated summary,\nincluding the preference for factual consistency, and the preference for the\nlanguage or knowledge prior as well. To separate the preference for factual\nconsistency, we propose an unsupervised framework named CoP by controlling the\npreference of the generation model with the help of prompt. More specifically,\nthe framework performs an extra inference step in which a text prompt is\nintroduced as an additional input. In this way, another preference is described\nby the generation probability of this extra inference process. The difference\nbetween the above two preferences, i.e. the difference between the\nprobabilities, could be used as measurements for detecting factual\ninconsistencies. Interestingly, we found that with the properly designed\nprompt, our framework could evaluate specific preferences and serve as\nmeasurements for fine-grained categories of inconsistency, such as\nentity-related inconsistency, coreference-related inconsistency, etc. Moreover,\nour framework could also be extended to the supervised setting to learn better\nprompt from the labeled data as well. Experiments show that our framework\nachieves new SOTA results on three factual inconsistency detection tasks.",
    "num_pages": 8
}