{
    "uuid": "47cbfa6b-6a2f-521e-a7e2-19a3c3460b47",
    "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2015,
    "authors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/1502.01852v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2015\\47cbfa6b-6a2f-521e-a7e2-19a3c3460b47.pdf",
    "bibtex": "@misc{he2015delvingdeepintorectifierssurpassing,\n    title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},\n    author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},\n    year = {2015},\n    eprint = {1502.01852},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/1502.01852},\n}",
    "abstract": "Rectified activation units (rectifiers) are essential for state-of-the-art\nneural networks. In this work, we study rectifier neural networks for image\nclassification from two aspects. First, we propose a Parametric Rectified\nLinear Unit (PReLU) that generalizes the traditional rectified unit. PReLU\nimproves model fitting with nearly zero extra computational cost and little\noverfitting risk. Second, we derive a robust initialization method that\nparticularly considers the rectifier nonlinearities. This method enables us to\ntrain extremely deep rectified models directly from scratch and to investigate\ndeeper or wider network architectures. Based on our PReLU networks\n(PReLU-nets), we achieve 4.94% top-5 test error on the ImageNet 2012\nclassification dataset. This is a 26% relative improvement over the ILSVRC 2014\nwinner (GoogLeNet, 6.66%). To our knowledge, our result is the first to surpass\nhuman-level performance (5.1%, Russakovsky et al.) on this visual recognition\nchallenge.",
    "num_pages": 11
}