{
    "uuid": "1f5110f9-63db-5e8e-adef-c2f33b58c5ab",
    "title": "DiffusionNER: Boundary Diffusion for Named Entity Recognition",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Yongliang Shen",
        "Kaitao Song",
        "Xu Tan",
        "Dongsheng Li",
        "Weiming Lu",
        "Yueting Zhuang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.13298v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\1f5110f9-63db-5e8e-adef-c2f33b58c5ab.pdf",
    "bibtex": "@misc{shen2023diffusionnerboundarydiffusionfornamed,\n    title = {DiffusionNER: Boundary Diffusion for Named Entity Recognition},\n    author = {Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},\n    year = {2023},\n    eprint = {2305.13298},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.13298},\n}",
    "abstract": "In this paper, we propose DiffusionNER, which formulates the named entity\nrecognition task as a boundary-denoising diffusion process and thus generates\nnamed entities from noisy spans. During training, DiffusionNER gradually adds\nnoises to the golden entity boundaries by a fixed forward diffusion process and\nlearns a reverse diffusion process to recover the entity boundaries. In\ninference, DiffusionNER first randomly samples some noisy spans from a standard\nGaussian distribution and then generates the named entities by denoising them\nwith the learned reverse diffusion process. The proposed boundary-denoising\ndiffusion process allows progressive refinement and dynamic sampling of\nentities, empowering DiffusionNER with efficient and flexible entity generation\ncapability. Experiments on multiple flat and nested NER datasets demonstrate\nthat DiffusionNER achieves comparable or even better performance than previous\nstate-of-the-art models.",
    "num_pages": 14
}