{
    "uuid": "7bc3c9de-c176-55c5-b340-9ef183168f59",
    "title": "Let's Agree to Agree: Neural Networks Share Classification Order on Real Datasets",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Guy Hacohen",
        "Leshem Choshen",
        "Daphna Weinshall"
    ],
    "pdf_url": "http://arxiv.org/pdf/1905.10854v7",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\7bc3c9de-c176-55c5-b340-9ef183168f59.pdf",
    "bibtex": "@misc{hacohen2020letsagreetoagreeneural,\n    title = {Let's Agree to Agree: Neural Networks Share Classification Order on Real Datasets},\n    author = {Guy Hacohen and Leshem Choshen and Daphna Weinshall},\n    year = {2020},\n    eprint = {1905.10854},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1905.10854},\n}",
    "abstract": "We report a series of robust empirical observations, demonstrating that deep\nNeural Networks learn the examples in both the training and test sets in a\nsimilar order. This phenomenon is observed in all the commonly used benchmarks\nwe evaluated, including many image classification benchmarks, and one text\nclassification benchmark. While this phenomenon is strongest for models of the\nsame architecture, it also crosses architectural boundaries -- models of\ndifferent architectures start by learning the same examples, after which the\nmore powerful model may continue to learn additional examples. We further show\nthat this pattern of results reflects the interplay between the way neural\nnetworks learn benchmark datasets. Thus, when fixing the architecture, we show\nsynthetic datasets where this pattern ceases to exist. When fixing the dataset,\nwe show that other learning paradigms may learn the data in a different order.\nWe hypothesize that our results reflect how neural networks discover structure\nin natural datasets.",
    "num_pages": 22
}