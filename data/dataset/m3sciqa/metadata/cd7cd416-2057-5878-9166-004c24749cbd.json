{
    "uuid": "cd7cd416-2057-5878-9166-004c24749cbd",
    "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Xiao Liu",
        "Kaixuan Ji",
        "Yicheng Fu",
        "Weng Lam Tam",
        "Zhengxiao Du",
        "Zhilin Yang",
        "Jie Tang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2110.07602v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\cd7cd416-2057-5878-9166-004c24749cbd.pdf",
    "bibtex": "@misc{liu2022ptuningv2prompttuningcan,\n    title = {P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks},\n    author = {Xiao Liu and Kaixuan Ji and Yicheng Fu and Weng Lam Tam and Zhengxiao Du and Zhilin Yang and Jie Tang},\n    year = {2022},\n    eprint = {2110.07602},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2110.07602},\n}",
    "abstract": "Prompt tuning, which only tunes continuous prompts with a frozen language\nmodel, substantially reduces per-task storage and memory usage at training.\nHowever, in the context of NLU, prior work reveals that prompt tuning does not\nperform well for normal-sized pretrained models. We also find that existing\nmethods of prompt tuning cannot handle hard sequence labeling tasks, indicating\na lack of universality. We present a novel empirical finding that properly\noptimized prompt tuning can be universally effective across a wide range of\nmodel scales and NLU tasks. It matches the performance of finetuning while\nhaving only 0.1%-3% tuned parameters. Our method P-Tuning v2 is an\nimplementation of Deep Prompt Tuning \\cite{li2021prefix,qin2021learning}\noptimized and adapted for NLU. Given the universality and simplicity of\nP-Tuning v2, we believe it can serve as an alternative to finetuning and a\nstrong baseline for future research.Our code and data are released at\nhttps://github.com/THUDM/P-tuning-v2.",
    "num_pages": 8
}