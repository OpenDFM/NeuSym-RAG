{
    "uuid": "ab9c34bc-777c-5ba4-9831-a203fa8bd682",
    "title": "Residual Attention: A Simple but Effective Method for Multi-Label Recognition",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Ke Zhu",
        "Jianxin Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2108.02456v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\ab9c34bc-777c-5ba4-9831-a203fa8bd682.pdf",
    "bibtex": "@misc{zhu2021residualattentionasimplebut,\n    title = {Residual Attention: A Simple but Effective Method for Multi-Label Recognition},\n    author = {Ke Zhu and Jianxin Wu},\n    year = {2021},\n    eprint = {2108.02456},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2108.02456},\n}",
    "abstract": "Multi-label image recognition is a challenging computer vision task of\npractical use. Progresses in this area, however, are often characterized by\ncomplicated methods, heavy computations, and lack of intuitive explanations. To\neffectively capture different spatial regions occupied by objects from\ndifferent categories, we propose an embarrassingly simple module, named\nclass-specific residual attention (CSRA). CSRA generates class-specific\nfeatures for every category by proposing a simple spatial attention score, and\nthen combines it with the class-agnostic average pooling feature. CSRA achieves\nstate-of-the-art results on multilabel recognition, and at the same time is\nmuch simpler than them. Furthermore, with only 4 lines of code, CSRA also leads\nto consistent improvement across many diverse pretrained models and datasets\nwithout any extra training. CSRA is both easy to implement and light in\ncomputations, which also enjoys intuitive explanations and visualizations.",
    "num_pages": 10
}