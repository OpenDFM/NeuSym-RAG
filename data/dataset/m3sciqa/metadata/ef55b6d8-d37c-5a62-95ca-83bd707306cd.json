{
    "uuid": "ef55b6d8-d37c-5a62-95ca-83bd707306cd",
    "title": "Improved Techniques for Training GANs",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Tim Salimans",
        "Ian Goodfellow",
        "Wojciech Zaremba",
        "Vicki Cheung",
        "Alec Radford",
        "Xi Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.03498v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\ef55b6d8-d37c-5a62-95ca-83bd707306cd.pdf",
    "bibtex": "@misc{salimans2016improvedtechniquesfortraininggans,\n    title = {Improved Techniques for Training GANs},\n    author = {Tim Salimans and Ian Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},\n    year = {2016},\n    eprint = {1606.03498},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1606.03498},\n}",
    "abstract": "We present a variety of new architectural features and training procedures\nthat we apply to the generative adversarial networks (GANs) framework. We focus\non two applications of GANs: semi-supervised learning, and the generation of\nimages that humans find visually realistic. Unlike most work on generative\nmodels, our primary goal is not to train a model that assigns high likelihood\nto test data, nor do we require the model to be able to learn well without\nusing any labels. Using our new techniques, we achieve state-of-the-art results\nin semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated\nimages are of high quality as confirmed by a visual Turing test: our model\ngenerates MNIST samples that humans cannot distinguish from real data, and\nCIFAR-10 samples that yield a human error rate of 21.3%. We also present\nImageNet samples with unprecedented resolution and show that our methods enable\nthe model to learn recognizable features of ImageNet classes.",
    "num_pages": 10
}