{
    "uuid": "f5545f86-f052-5ba4-a7ac-60252dd219d1",
    "title": "SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Shamsuddeen Hassan Muhammad",
        "Idris Abdulmumin",
        "Seid Muhie Yimam",
        "David Ifeoluwa Adelani",
        "Ibrahim Sa'id Ahmad",
        "Nedjma Ousidhoum",
        "Abinew Ayele",
        "Saif M. Mohammad",
        "Meriem Beloucif",
        "Sebastian Ruder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2304.06845v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\f5545f86-f052-5ba4-a7ac-60252dd219d1.pdf",
    "bibtex": "@misc{muhammad2023semeval2023task12sentimentanalysis,\n    title = {SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)},\n    author = {Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Seid Muhie Yimam and David Ifeoluwa Adelani and Ibrahim Sa'id Ahmad and Nedjma Ousidhoum and Abinew Ayele and Saif M. Mohammad and Meriem Beloucif and Sebastian Ruder},\n    year = {2023},\n    eprint = {2304.06845},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2304.06845},\n}",
    "abstract": "We present the first Africentric SemEval Shared task, Sentiment Analysis for\nAfrican Languages (AfriSenti-SemEval) - The dataset is available at\nhttps://github.com/afrisenti-semeval/afrisent-semeval-2023. AfriSenti-SemEval\nis a sentiment classification challenge in 14 African languages: Amharic,\nAlgerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican\nPortuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and\nYor\\`ub\\'a (Muhammad et al., 2023), using data labeled with 3 sentiment\nclasses. We present three subtasks: (1) Task A: monolingual classification,\nwhich received 44 submissions; (2) Task B: multilingual classification, which\nreceived 32 submissions; and (3) Task C: zero-shot classification, which\nreceived 34 submissions. The best performance for tasks A and B was achieved by\nNLNDE team with 71.31 and 75.06 weighted F1, respectively. UCAS-IIE-NLP\nachieved the best average score for task C with 58.15 weighted F1. We describe\nthe various approaches adopted by the top 10 systems and their approaches.",
    "num_pages": 19
}