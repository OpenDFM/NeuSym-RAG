{
    "uuid": "750c0d08-363e-59a3-8d37-6c5ad16551d8",
    "title": "SpeechFormer: A Hierarchical Efficient Framework Incorporating the Characteristics of Speech",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Weidong Chen",
        "Xiaofen Xing",
        "Xiangmin Xu",
        "Jianxin Pang",
        "Lan Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2203.03812v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\750c0d08-363e-59a3-8d37-6c5ad16551d8.pdf",
    "bibtex": "@misc{chen2022speechformerahierarchicalefficientframework,\n    title = {SpeechFormer: A Hierarchical Efficient Framework Incorporating the Characteristics of Speech},\n    author = {Weidong Chen and Xiaofen Xing and Xiangmin Xu and Jianxin Pang and Lan Du},\n    year = {2022},\n    eprint = {2203.03812},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.SD},\n    url = {http://arxiv.org/abs/2203.03812},\n}",
    "abstract": "Transformer has obtained promising results on cognitive speech signal\nprocessing field, which is of interest in various applications ranging from\nemotion to neurocognitive disorder analysis. However, most works treat speech\nsignal as a whole, leading to the neglect of the pronunciation structure that\nis unique to speech and reflects the cognitive process. Meanwhile, Transformer\nhas heavy computational burden due to its full attention operation. In this\npaper, a hierarchical efficient framework, called SpeechFormer, which considers\nthe structural characteristics of speech, is proposed and can be served as a\ngeneral-purpose backbone for cognitive speech signal processing. The proposed\nSpeechFormer consists of frame, phoneme, word and utterance stages in\nsuccession, each performing a neighboring attention according to the structural\npattern of speech with high computational efficiency. SpeechFormer is evaluated\non speech emotion recognition (IEMOCAP & MELD) and neurocognitive disorder\ndetection (Pitt & DAIC-WOZ) tasks, and the results show that SpeechFormer\noutperforms the standard Transformer-based framework while greatly reducing the\ncomputational cost. Furthermore, our SpeechFormer achieves comparable results\nto the state-of-the-art approaches.",
    "num_pages": 5
}