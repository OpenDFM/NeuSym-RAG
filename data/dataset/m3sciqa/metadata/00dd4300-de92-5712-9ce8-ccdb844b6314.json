{
    "uuid": "00dd4300-de92-5712-9ce8-ccdb844b6314",
    "title": "Attention-based Neural Text Segmentation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Pinkesh Badjatiya",
        "Litton J Kurisinkel",
        "Manish Gupta",
        "Vasudeva Varma"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.09935v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\00dd4300-de92-5712-9ce8-ccdb844b6314.pdf",
    "bibtex": "@misc{badjatiya2018attentionbasedneuraltextsegmentation,\n    title = {Attention-based Neural Text Segmentation},\n    author = {Pinkesh Badjatiya and Litton J Kurisinkel and Manish Gupta and Vasudeva Varma},\n    year = {2018},\n    eprint = {1808.09935},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1808.09935},\n}",
    "abstract": "Text segmentation plays an important role in various Natural Language\nProcessing (NLP) tasks like summarization, context understanding, document\nindexing and document noise removal. Previous methods for this task require\nmanual feature engineering, huge memory requirements and large execution times.\nTo the best of our knowledge, this paper is the first one to present a novel\nsupervised neural approach for text segmentation. Specifically, we propose an\nattention-based bidirectional LSTM model where sentence embeddings are learned\nusing CNNs and the segments are predicted based on contextual information. This\nmodel can automatically handle variable sized context information. Compared to\nthe existing competitive baselines, the proposed model shows a performance\nimprovement of ~7% in WinDiff score on three benchmark datasets.",
    "num_pages": 13
}