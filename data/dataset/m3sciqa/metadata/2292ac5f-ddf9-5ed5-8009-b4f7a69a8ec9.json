{
    "uuid": "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9",
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Alex Wang",
        "Amanpreet Singh",
        "Julian Michael",
        "Felix Hill",
        "Omer Levy",
        "Samuel R. Bowman"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.07461v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9.pdf",
    "bibtex": "@misc{wang2019glueamultitaskbenchmarkand,\n    title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n    author = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},\n    year = {2019},\n    eprint = {1804.07461},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1804.07461},\n}",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful,\nboth practically and as a scientific object of study, it must be general: it\nmust be able to process language in a way that is not exclusively tailored to\nany one specific task or dataset. In pursuit of this objective, we introduce\nthe General Language Understanding Evaluation benchmark (GLUE), a tool for\nevaluating and analyzing the performance of models across a diverse range of\nexisting NLU tasks. GLUE is model-agnostic, but it incentivizes sharing\nknowledge across tasks because certain tasks have very limited training data.\nWe further provide a hand-crafted diagnostic test suite that enables detailed\nlinguistic analysis of NLU models. We evaluate baselines based on current\nmethods for multi-task and transfer learning and find that they do not\nimmediately give substantial improvements over the aggregate performance of\ntraining a separate model per task, indicating room for improvement in\ndeveloping general and robust NLU systems.",
    "num_pages": 20
}