{
    "uuid": "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1",
    "title": "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Pan Lu",
        "Liang Qiu",
        "Kai-Wei Chang",
        "Ying Nian Wu",
        "Song-Chun Zhu",
        "Tanmay Rajpurohit",
        "Peter Clark",
        "Ashwin Kalyan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2209.14610v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\b32cc591-f1bb-558c-b4e4-d9d6d659c2c1.pdf",
    "bibtex": "@misc{lu2023dynamicpromptlearningviapolicy,\n    title = {Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning},\n    author = {Pan Lu and Liang Qiu and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Tanmay Rajpurohit and Peter Clark and Ashwin Kalyan},\n    year = {2023},\n    eprint = {2209.14610},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2209.14610},\n}",
    "abstract": "Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.",
    "num_pages": 26
}