{
    "uuid": "88affa18-ec3f-5871-857f-7c83b4732075",
    "title": "Neural Question Generation from Text: A Preliminary Study",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Qingyu Zhou",
        "Nan Yang",
        "Furu Wei",
        "Chuanqi Tan",
        "Hangbo Bao",
        "Ming Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.01792v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\88affa18-ec3f-5871-857f-7c83b4732075.pdf",
    "bibtex": "@misc{zhou2017neuralquestiongenerationfromtext,\n    title = {Neural Question Generation from Text: A Preliminary Study},\n    author = {Qingyu Zhou and Nan Yang and Furu Wei and Chuanqi Tan and Hangbo Bao and Ming Zhou},\n    year = {2017},\n    eprint = {1704.01792},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1704.01792},\n}",
    "abstract": "Automatic question generation aims to generate questions from a text passage\nwhere the generated questions can be answered by certain sub-spans of the given\npassage. Traditional methods mainly use rigid heuristic rules to transform a\nsentence into related questions. In this work, we propose to apply the neural\nencoder-decoder model to generate meaningful and diverse questions from natural\nlanguage sentences. The encoder reads the input text and the answer position,\nto produce an answer-aware input representation, which is fed to the decoder to\ngenerate an answer focused question. We conduct a preliminary study on neural\nquestion generation from text with the SQuAD dataset, and the experiment\nresults show that our method can produce fluent and diverse questions.",
    "num_pages": 6
}