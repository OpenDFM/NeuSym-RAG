{
    "uuid": "f539c3b0-32b8-5419-b22e-75fe5729c7c5",
    "title": "Distributional Modeling on a Diet: One-shot Word Learning from Text Only",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Su Wang",
        "Stephen Roller",
        "Katrin Erk"
    ],
    "pdf_url": "http://arxiv.org/pdf/1704.04550v4",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\f539c3b0-32b8-5419-b22e-75fe5729c7c5.pdf",
    "bibtex": "@misc{wang2017distributionalmodelingonadiet,\n    title = {Distributional Modeling on a Diet: One-shot Word Learning from Text Only},\n    author = {Su Wang and Stephen Roller and Katrin Erk},\n    year = {2017},\n    eprint = {1704.04550},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1704.04550},\n}",
    "abstract": "We test whether distributional models can do one-shot learning of\ndefinitional properties from text only. Using Bayesian models, we find that\nfirst learning overarching structure in the known data, regularities in textual\ncontexts and in properties, helps one-shot learning, and that individual\ncontext items can be highly informative. Our experiments show that our model\ncan learn properties from a single exposure when given an informative\nutterance.",
    "num_pages": 10
}