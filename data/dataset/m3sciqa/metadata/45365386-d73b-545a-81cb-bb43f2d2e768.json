{
    "uuid": "45365386-d73b-545a-81cb-bb43f2d2e768",
    "title": "Rethinking Word-Level Auto-Completion in Computer-Aided Translation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Xingyu Chen",
        "Lemao Liu",
        "Guoping Huang",
        "Zhirui Zhang",
        "Mingming Yang",
        "Shuming Shi",
        "Rui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.14523v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\45365386-d73b-545a-81cb-bb43f2d2e768.pdf",
    "bibtex": "@misc{chen2023rethinkingwordlevelautocompletionincomputeraided,\n    title = {Rethinking Word-Level Auto-Completion in Computer-Aided Translation},\n    author = {Xingyu Chen and Lemao Liu and Guoping Huang and Zhirui Zhang and Mingming Yang and Shuming Shi and Rui Wang},\n    year = {2023},\n    eprint = {2310.14523},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.14523},\n}",
    "abstract": "Word-Level Auto-Completion (WLAC) plays a crucial role in Computer-Assisted\nTranslation. It aims at providing word-level auto-completion suggestions for\nhuman translators. While previous studies have primarily focused on designing\ncomplex model architectures, this paper takes a different perspective by\nrethinking the fundamental question: what kind of words are good\nauto-completions? We introduce a measurable criterion to answer this question\nand discover that existing WLAC models often fail to meet this criterion.\nBuilding upon this observation, we propose an effective approach to enhance\nWLAC performance by promoting adherence to the criterion. Notably, the proposed\napproach is general and can be applied to various encoder-based architectures.\nThrough extensive experiments, we demonstrate that our approach outperforms the\ntop-performing system submitted to the WLAC shared tasks in WMT2022, while\nutilizing significantly smaller model sizes.",
    "num_pages": 11
}