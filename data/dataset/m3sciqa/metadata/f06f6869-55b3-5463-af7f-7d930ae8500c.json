{
    "uuid": "f06f6869-55b3-5463-af7f-7d930ae8500c",
    "title": "Improving Language Models via Plug-and-Play Retrieval Feedback",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Wenhao Yu",
        "Zhihan Zhang",
        "Zhenwen Liang",
        "Meng Jiang",
        "Ashish Sabharwal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.14002v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\f06f6869-55b3-5463-af7f-7d930ae8500c.pdf",
    "bibtex": "@misc{yu2023improvinglanguagemodelsviaplugandplay,\n    title = {Improving Language Models via Plug-and-Play Retrieval Feedback},\n    author = {Wenhao Yu and Zhihan Zhang and Zhenwen Liang and Meng Jiang and Ashish Sabharwal},\n    year = {2023},\n    eprint = {2305.14002},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.14002},\n}",
    "abstract": "Large language models (LLMs) exhibit remarkable performance across various\nNLP tasks. However, they often generate incorrect or hallucinated information,\nwhich hinders their practical applicability in real-world scenarios. Human\nfeedback has been shown to effectively enhance the factuality and quality of\ngenerated content, addressing some of these limitations. However, this approach\nis resource-intensive, involving manual input and supervision, which can be\ntime-consuming and expensive. Moreover, it cannot be provided during inference,\nfurther limiting its practical utility in dynamic and interactive applications.\nIn this paper, we introduce ReFeed, a novel pipeline designed to enhance LLMs\nby providing automatic retrieval feedback in a plug-and-play framework without\nthe need for expensive fine-tuning. ReFeed first generates initial outputs,\nthen utilizes a retrieval model to acquire relevant information from large\ndocument collections, and finally incorporates the retrieved information into\nthe in-context demonstration for output refinement, thereby addressing the\nlimitations of LLMs in a more efficient and cost-effective manner. Experiments\non four knowledge-intensive benchmark datasets demonstrate our proposed ReFeed\ncould improve over +6.0% under zero-shot setting and +2.5% under few-shot\nsetting, compared to baselines without using retrieval feedback.",
    "num_pages": 12
}