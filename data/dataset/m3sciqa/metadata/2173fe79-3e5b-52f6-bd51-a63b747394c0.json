{
    "uuid": "2173fe79-3e5b-52f6-bd51-a63b747394c0",
    "title": "A large annotated corpus for learning natural language inference",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2015,
    "authors": [
        "Samuel R. Bowman",
        "Gabor Angeli",
        "Christopher Potts",
        "Christopher D. Manning"
    ],
    "pdf_url": "http://arxiv.org/pdf/1508.05326v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2015\\2173fe79-3e5b-52f6-bd51-a63b747394c0.pdf",
    "bibtex": "@misc{bowman2015alargeannotatedcorpusfor,\n    title = {A large annotated corpus for learning natural language inference},\n    author = {Samuel R. Bowman and Gabor Angeli and Christopher Potts and Christopher D. Manning},\n    year = {2015},\n    eprint = {1508.05326},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1508.05326},\n}",
    "abstract": "Understanding entailment and contradiction is fundamental to understanding\nnatural language, and inference about entailment and contradiction is a\nvaluable testing ground for the development of semantic representations.\nHowever, machine learning research in this area has been dramatically limited\nby the lack of large-scale resources. To address this, we introduce the\nStanford Natural Language Inference corpus, a new, freely available collection\nof labeled sentence pairs, written by humans doing a novel grounded task based\non image captioning. At 570K pairs, it is two orders of magnitude larger than\nall other resources of its type. This increase in scale allows lexicalized\nclassifiers to outperform some sophisticated existing entailment models, and it\nallows a neural network-based model to perform competitively on natural\nlanguage inference benchmarks for the first time.",
    "num_pages": 11
}