{
    "uuid": "a15c6ae3-d802-5225-8256-e4ed086ba7ac",
    "title": "SentEval: An Evaluation Toolkit for Universal Sentence Representations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Alexis Conneau",
        "Douwe Kiela"
    ],
    "pdf_url": "http://arxiv.org/pdf/1803.05449v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\a15c6ae3-d802-5225-8256-e4ed086ba7ac.pdf",
    "bibtex": "@misc{conneau2018sentevalanevaluationtoolkitfor,\n    title = {SentEval: An Evaluation Toolkit for Universal Sentence Representations},\n    author = {Alexis Conneau and Douwe Kiela},\n    year = {2018},\n    eprint = {1803.05449},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1803.05449},\n}",
    "abstract": "We introduce SentEval, a toolkit for evaluating the quality of universal\nsentence representations. SentEval encompasses a variety of tasks, including\nbinary and multi-class classification, natural language inference and sentence\nsimilarity. The set of tasks was selected based on what appears to be the\ncommunity consensus regarding the appropriate evaluations for universal\nsentence representations. The toolkit comes with scripts to download and\npreprocess datasets, and an easy interface to evaluate sentence encoders. The\naim is to provide a fairer, less cumbersome and more centralized way for\nevaluating sentence representations.",
    "num_pages": 6
}