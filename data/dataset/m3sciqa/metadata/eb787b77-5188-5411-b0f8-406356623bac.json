{
    "uuid": "eb787b77-5188-5411-b0f8-406356623bac",
    "title": "PaLM 2 Technical Report",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Rohan Anil",
        "Andrew M. Dai",
        "Orhan Firat",
        "Melvin Johnson",
        "Dmitry Lepikhin",
        "Alexandre Passos",
        "Siamak Shakeri",
        "Emanuel Taropa",
        "Paige Bailey",
        "Zhifeng Chen",
        "Eric Chu",
        "Jonathan H. Clark",
        "Laurent El Shafey",
        "Yanping Huang",
        "Kathy Meier-Hellstern",
        "Gaurav Mishra",
        "Erica Moreira",
        "Mark Omernick",
        "Kevin Robinson",
        "Sebastian Ruder",
        "Yi Tay",
        "Kefan Xiao",
        "Yuanzhong Xu",
        "Yujing Zhang",
        "Gustavo Hernandez Abrego",
        "Junwhan Ahn",
        "Jacob Austin",
        "Paul Barham",
        "Jan Botha",
        "James Bradbury",
        "Siddhartha Brahma",
        "Kevin Brooks",
        "Michele Catasta",
        "Yong Cheng",
        "Colin Cherry",
        "Christopher A. Choquette-Choo",
        "Aakanksha Chowdhery",
        "Clément Crepy",
        "Shachi Dave",
        "Mostafa Dehghani",
        "Sunipa Dev",
        "Jacob Devlin",
        "Mark Díaz",
        "Nan Du",
        "Ethan Dyer",
        "Vlad Feinberg",
        "Fangxiaoyu Feng",
        "Vlad Fienber",
        "Markus Freitag",
        "Xavier Garcia",
        "Sebastian Gehrmann",
        "Lucas Gonzalez",
        "Guy Gur-Ari",
        "Steven Hand",
        "Hadi Hashemi",
        "Le Hou",
        "Joshua Howland",
        "Andrea Hu",
        "Jeffrey Hui",
        "Jeremy Hurwitz",
        "Michael Isard",
        "Abe Ittycheriah",
        "Matthew Jagielski",
        "Wenhao Jia",
        "Kathleen Kenealy",
        "Maxim Krikun",
        "Sneha Kudugunta",
        "Chang Lan",
        "Katherine Lee",
        "Benjamin Lee",
        "Eric Li",
        "Music Li",
        "Wei Li",
        "YaGuang Li",
        "Jian Li",
        "Hyeontaek Lim",
        "Hanzhao Lin",
        "Zhongtao Liu",
        "Frederick Liu",
        "Marcello Maggioni",
        "Aroma Mahendru",
        "Joshua Maynez",
        "Vedant Misra",
        "Maysam Moussalem",
        "Zachary Nado",
        "John Nham",
        "Eric Ni",
        "Andrew Nystrom",
        "Alicia Parrish",
        "Marie Pellat",
        "Martin Polacek",
        "Alex Polozov",
        "Reiner Pope",
        "Siyuan Qiao",
        "Emily Reif",
        "Bryan Richter",
        "Parker Riley",
        "Alex Castro Ros",
        "Aurko Roy",
        "Brennan Saeta",
        "Rajkumar Samuel",
        "Renee Shelby",
        "Ambrose Slone",
        "Daniel Smilkov",
        "David R. So",
        "Daniel Sohn",
        "Simon Tokumine",
        "Dasha Valter",
        "Vijay Vasudevan",
        "Kiran Vodrahalli",
        "Xuezhi Wang",
        "Pidong Wang",
        "Zirui Wang",
        "Tao Wang",
        "John Wieting",
        "Yuhuai Wu",
        "Kelvin Xu",
        "Yunhan Xu",
        "Linting Xue",
        "Pengcheng Yin",
        "Jiahui Yu",
        "Qiao Zhang",
        "Steven Zheng",
        "Ce Zheng",
        "Weikang Zhou",
        "Denny Zhou",
        "Slav Petrov",
        "Yonghui Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.10403v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\eb787b77-5188-5411-b0f8-406356623bac.pdf",
    "bibtex": "@misc{anil2023palm2technicalreport,\n    title = {PaLM 2 Technical Report},\n    author = {Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},\n    year = {2023},\n    eprint = {2305.10403},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.10403},\n}",
    "abstract": "We introduce PaLM 2, a new state-of-the-art language model that has better\nmultilingual and reasoning capabilities and is more compute-efficient than its\npredecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture\nof objectives. Through extensive evaluations on English and multilingual\nlanguage, and reasoning tasks, we demonstrate that PaLM 2 has significantly\nimproved quality on downstream tasks across different model sizes, while\nsimultaneously exhibiting faster and more efficient inference compared to PaLM.\nThis improved efficiency enables broader deployment while also allowing the\nmodel to respond faster, for a more natural pace of interaction. PaLM 2\ndemonstrates robust reasoning capabilities exemplified by large improvements\nover PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable\nperformance on a suite of responsible AI evaluations, and enables\ninference-time control over toxicity without additional overhead or impact on\nother capabilities. Overall, PaLM 2 achieves state-of-the-art performance\nacross a diverse set of tasks and capabilities.\n  When discussing the PaLM 2 family, it is important to distinguish between\npre-trained models (of various sizes), fine-tuned variants of these models, and\nthe user-facing products that use these models. In particular, user-facing\nproducts typically include additional pre- and post-processing steps.\nAdditionally, the underlying models may evolve over time. Therefore, one should\nnot expect the performance of user-facing products to exactly match the results\nreported in this report.",
    "num_pages": 93
}