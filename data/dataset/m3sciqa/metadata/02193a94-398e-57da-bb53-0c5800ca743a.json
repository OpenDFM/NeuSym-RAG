{
    "uuid": "02193a94-398e-57da-bb53-0c5800ca743a",
    "title": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Shima Rahimi Moghaddam",
        "Christopher J. Honey"
    ],
    "pdf_url": "http://arxiv.org/pdf/2304.11490v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\02193a94-398e-57da-bb53-0c5800ca743a.pdf",
    "bibtex": "@misc{moghaddam2023boostingtheoryofmindperformanceinlarge,\n    title = {Boosting Theory-of-Mind Performance in Large Language Models via Prompting},\n    author = {Shima Rahimi Moghaddam and Christopher J. Honey},\n    year = {2023},\n    eprint = {2304.11490},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/2304.11490},\n}",
    "abstract": "Large language models (LLMs) excel in many tasks in 2023, but they still face\nchallenges in complex reasoning. Theory-of-mind (ToM) tasks, which require\nunderstanding agents' beliefs, goals, and mental states, are essential for\ncommon-sense reasoning involving humans, making it crucial to enhance LLM\nperformance in this area. This study measures the ToM performance of GPT-4 and\nthree GPT-3.5 variants (Davinci-2, Davinci-3, GPT-3.5-Turbo), and investigates\nthe effectiveness of in-context learning in improving their ToM comprehension.\nWe evaluated prompts featuring two-shot chain of thought reasoning and\nstep-by-step thinking instructions. We found that LLMs trained with\nReinforcement Learning from Human Feedback (RLHF) (all models excluding\nDavinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed\nbest in zero-shot settings, reaching nearly 80% ToM accuracy, but still fell\nshort of the 87% human accuracy on the test set. However, when supplied with\nprompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM\naccuracy, with GPT-4 reaching 100%. These results demonstrate that appropriate\nprompting enhances LLM ToM reasoning, and they underscore the context-dependent\nnature of LLM cognitive capacities.",
    "num_pages": 27
}