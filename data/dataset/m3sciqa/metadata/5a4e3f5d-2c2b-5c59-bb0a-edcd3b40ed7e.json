{
    "uuid": "5a4e3f5d-2c2b-5c59-bb0a-edcd3b40ed7e",
    "title": "Adaptive Cross-Modal Few-Shot Learning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Chen Xing",
        "Negar Rostamzadeh",
        "Boris N. Oreshkin",
        "Pedro O. Pinheiro"
    ],
    "pdf_url": "http://arxiv.org/pdf/1902.07104v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\5a4e3f5d-2c2b-5c59-bb0a-edcd3b40ed7e.pdf",
    "bibtex": "@misc{xing2020adaptivecrossmodalfewshotlearning,\n    title = {Adaptive Cross-Modal Few-Shot Learning},\n    author = {Chen Xing and Negar Rostamzadeh and Boris N. Oreshkin and Pedro O. Pinheiro},\n    year = {2020},\n    eprint = {1902.07104},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1902.07104},\n}",
    "abstract": "Metric-based meta-learning techniques have successfully been applied to\nfew-shot classification problems. In this paper, we propose to leverage\ncross-modal information to enhance metric-based few-shot learning methods.\nVisual and semantic feature spaces have different structures by definition. For\ncertain concepts, visual features might be richer and more discriminative than\ntext ones. While for others, the inverse might be true. Moreover, when the\nsupport from visual information is limited in image classification, semantic\nrepresentations (learned from unsupervised text corpora) can provide strong\nprior knowledge and context to help learning. Based on these two intuitions, we\npropose a mechanism that can adaptively combine information from both\nmodalities according to new image categories to be learned. Through a series of\nexperiments, we show that by this adaptive combination of the two modalities,\nour model outperforms current uni-modality few-shot learning methods and\nmodality-alignment methods by a large margin on all benchmarks and few-shot\nscenarios tested. Experiments also show that our model can effectively adjust\nits focus on the two modalities. The improvement in performance is particularly\nlarge when the number of shots is very small.",
    "num_pages": 15
}