{
    "uuid": "446b417e-0e23-5098-afe3-0790a06ab23e",
    "title": "LaMDA: Language Models for Dialog Applications",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Romal Thoppilan",
        "Daniel De Freitas",
        "Jamie Hall",
        "Noam Shazeer",
        "Apoorv Kulshreshtha",
        "Heng-Tze Cheng",
        "Alicia Jin",
        "Taylor Bos",
        "Leslie Baker",
        "Yu Du",
        "YaGuang Li",
        "Hongrae Lee",
        "Huaixiu Steven Zheng",
        "Amin Ghafouri",
        "Marcelo Menegali",
        "Yanping Huang",
        "Maxim Krikun",
        "Dmitry Lepikhin",
        "James Qin",
        "Dehao Chen",
        "Yuanzhong Xu",
        "Zhifeng Chen",
        "Adam Roberts",
        "Maarten Bosma",
        "Vincent Zhao",
        "Yanqi Zhou",
        "Chung-Ching Chang",
        "Igor Krivokon",
        "Will Rusch",
        "Marc Pickett",
        "Pranesh Srinivasan",
        "Laichee Man",
        "Kathleen Meier-Hellstern",
        "Meredith Ringel Morris",
        "Tulsee Doshi",
        "Renelito Delos Santos",
        "Toju Duke",
        "Johnny Soraker",
        "Ben Zevenbergen",
        "Vinodkumar Prabhakaran",
        "Mark Diaz",
        "Ben Hutchinson",
        "Kristen Olson",
        "Alejandra Molina",
        "Erin Hoffman-John",
        "Josh Lee",
        "Lora Aroyo",
        "Ravi Rajakumar",
        "Alena Butryna",
        "Matthew Lamm",
        "Viktoriya Kuzmina",
        "Joe Fenton",
        "Aaron Cohen",
        "Rachel Bernstein",
        "Ray Kurzweil",
        "Blaise Aguera-Arcas",
        "Claire Cui",
        "Marian Croak",
        "Ed Chi",
        "Quoc Le"
    ],
    "pdf_url": "http://arxiv.org/pdf/2201.08239v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\446b417e-0e23-5098-afe3-0790a06ab23e.pdf",
    "bibtex": "@misc{thoppilan2022lamdalanguagemodelsfordialog,\n    title = {LaMDA: Language Models for Dialog Applications},\n    author = {Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},\n    year = {2022},\n    eprint = {2201.08239},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2201.08239},\n}",
    "abstract": "We present LaMDA: Language Models for Dialog Applications. LaMDA is a family\nof Transformer-based neural language models specialized for dialog, which have\nup to 137B parameters and are pre-trained on 1.56T words of public dialog data\nand web text. While model scaling alone can improve quality, it shows less\nimprovements on safety and factual grounding. We demonstrate that fine-tuning\nwith annotated data and enabling the model to consult external knowledge\nsources can lead to significant improvements towards the two key challenges of\nsafety and factual grounding. The first challenge, safety, involves ensuring\nthat the model's responses are consistent with a set of human values, such as\npreventing harmful suggestions and unfair bias. We quantify safety using a\nmetric based on an illustrative set of human values, and we find that filtering\ncandidate responses using a LaMDA classifier fine-tuned with a small amount of\ncrowdworker-annotated data offers a promising approach to improving model\nsafety. The second challenge, factual grounding, involves enabling the model to\nconsult external knowledge sources, such as an information retrieval system, a\nlanguage translator, and a calculator. We quantify factuality using a\ngroundedness metric, and we find that our approach enables the model to\ngenerate responses grounded in known sources, rather than responses that merely\nsound plausible. Finally, we explore the use of LaMDA in the domains of\neducation and content recommendations, and analyze their helpfulness and role\nconsistency.",
    "num_pages": 47
}