{
    "uuid": "e938b553-f1b6-5eaa-9abb-efe79edf89e5",
    "title": "IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Bryan Wilie",
        "Karissa Vincentio",
        "Genta Indra Winata",
        "Samuel Cahyawijaya",
        "Xiaohong Li",
        "Zhi Yuan Lim",
        "Sidik Soleman",
        "Rahmad Mahendra",
        "Pascale Fung",
        "Syafri Bahar",
        "Ayu Purwarianti"
    ],
    "pdf_url": "http://arxiv.org/pdf/2009.05387v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\e938b553-f1b6-5eaa-9abb-efe79edf89e5.pdf",
    "bibtex": "@misc{wilie2020indonlubenchmarkandresourcesfor,\n    title = {IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n    author = {Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and Xiaohong Li and Zhi Yuan Lim and Sidik Soleman and Rahmad Mahendra and Pascale Fung and Syafri Bahar and Ayu Purwarianti},\n    year = {2020},\n    eprint = {2009.05387},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2009.05387},\n}",
    "abstract": "Although Indonesian is known to be the fourth most frequently used language\nover the internet, the research progress on this language in the natural\nlanguage processing (NLP) is slow-moving due to a lack of available resources.\nIn response, we introduce the first-ever vast resource for the training,\nevaluating, and benchmarking on Indonesian natural language understanding\n(IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence\nclassification to pair-sentences sequence labeling with different levels of\ncomplexity. The datasets for the tasks lie in different domains and styles to\nensure task diversity. We also provide a set of Indonesian pre-trained models\n(IndoBERT) trained from a large and clean Indonesian dataset Indo4B collected\nfrom publicly available sources such as social media texts, blogs, news, and\nwebsites. We release baseline models for all twelve tasks, as well as the\nframework for benchmark evaluation, and thus it enables everyone to benchmark\ntheir system performances.",
    "num_pages": 15
}