{
    "uuid": "3eb58497-86ef-5979-ab34-37ded2b70778",
    "title": "Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Shereen Oraby",
        "Lena Reed",
        "Shubhangi Tandon",
        "T. S. Sharath",
        "Stephanie Lukin",
        "Marilyn Walker"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.08352v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\3eb58497-86ef-5979-ab34-37ded2b70778.pdf",
    "bibtex": "@misc{oraby2018controllingpersonalitybasedstylisticvariationwith,\n    title = {Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators},\n    author = {Shereen Oraby and Lena Reed and Shubhangi Tandon and T. S. Sharath and Stephanie Lukin and Marilyn Walker},\n    year = {2018},\n    eprint = {1805.08352},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1805.08352},\n}",
    "abstract": "Natural language generators for task-oriented dialogue must effectively\nrealize system dialogue actions and their associated semantics. In many\napplications, it is also desirable for generators to control the style of an\nutterance. To date, work on task-oriented neural generation has primarily\nfocused on semantic fidelity rather than achieving stylistic goals, while work\non style has been done in contexts where it is difficult to measure content\npreservation. Here we present three different sequence-to-sequence models and\ncarefully test how well they disentangle content and style. We use a\nstatistical generator, Personage, to synthesize a new corpus of over 88,000\nrestaurant domain utterances whose style varies according to models of\npersonality, giving us total control over both the semantic content and the\nstylistic variation in the training data. We then vary the amount of explicit\nstylistic supervision given to the three models. We show that our most explicit\nmodel can simultaneously achieve high fidelity to both semantic and stylistic\ngoals: this model adds a context vector of 36 stylistic parameters as input to\nthe hidden state of the encoder at each time step, showing the benefits of\nexplicit stylistic supervision, even when the amount of training data is large.",
    "num_pages": 11
}