{
    "uuid": "54169656-141d-58b2-afd6-5f26cb2889ed",
    "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Iulian Vlad Serban",
        "Alessandro Sordoni",
        "Ryan Lowe",
        "Laurent Charlin",
        "Joelle Pineau",
        "Aaron Courville",
        "Yoshua Bengio"
    ],
    "pdf_url": "http://arxiv.org/pdf/1605.06069v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\54169656-141d-58b2-afd6-5f26cb2889ed.pdf",
    "bibtex": "@misc{serban2016ahierarchicallatentvariableencoderdecoder,\n    title = {A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues},\n    author = {Iulian Vlad Serban and Alessandro Sordoni and Ryan Lowe and Laurent Charlin and Joelle Pineau and Aaron Courville and Yoshua Bengio},\n    year = {2016},\n    eprint = {1605.06069},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1605.06069},\n}",
    "abstract": "Sequential data often possesses a hierarchical structure with complex\ndependencies between subsequences, such as found between the utterances in a\ndialogue. In an effort to model this kind of generative process, we propose a\nneural network-based generative architecture, with latent stochastic variables\nthat span a variable number of time steps. We apply the proposed model to the\ntask of dialogue response generation and compare it with recent neural network\narchitectures. We evaluate the model performance through automatic evaluation\nmetrics and by carrying out a human evaluation. The experiments demonstrate\nthat our model improves upon recently proposed models and that the latent\nvariables facilitate the generation of long outputs and maintain the context.",
    "num_pages": 15
}