{
    "uuid": "404bcd7c-20d3-5290-aad4-e056e19d16c1",
    "title": "Propose-and-Refine: A Two-Stage Set Prediction Network for Nested Named Entity Recognition",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Shuhui Wu",
        "Yongliang Shen",
        "Zeqi Tan",
        "Weiming Lu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2204.12732v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\404bcd7c-20d3-5290-aad4-e056e19d16c1.pdf",
    "bibtex": "@misc{wu2022proposeandrefineatwostagesetprediction,\n    title = {Propose-and-Refine: A Two-Stage Set Prediction Network for Nested Named Entity Recognition},\n    author = {Shuhui Wu and Yongliang Shen and Zeqi Tan and Weiming Lu},\n    year = {2022},\n    eprint = {2204.12732},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2204.12732},\n}",
    "abstract": "Nested named entity recognition (nested NER) is a fundamental task in natural\nlanguage processing. Various span-based methods have been proposed to detect\nnested entities with span representations. However, span-based methods do not\nconsider the relationship between a span and other entities or phrases, which\nis helpful in the NER task. Besides, span-based methods have trouble predicting\nlong entities due to limited span enumeration length. To mitigate these issues,\nwe present the Propose-and-Refine Network (PnRNet), a two-stage set prediction\nnetwork for nested NER. In the propose stage, we use a span-based predictor to\ngenerate some coarse entity predictions as entity proposals. In the refine\nstage, proposals interact with each other, and richer contextual information is\nincorporated into the proposal representations. The refined proposal\nrepresentations are used to re-predict entity boundaries and classes. In this\nway, errors in coarse proposals can be eliminated, and the boundary prediction\nis no longer constrained by the span enumeration length limitation.\nAdditionally, we build multi-scale sentence representations, which better model\nthe hierarchical structure of sentences and provide richer contextual\ninformation than token-level representations. Experiments show that PnRNet\nachieves state-of-the-art performance on four nested NER datasets and one flat\nNER dataset.",
    "num_pages": 9
}