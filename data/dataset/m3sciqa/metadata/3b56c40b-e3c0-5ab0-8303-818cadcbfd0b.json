{
    "uuid": "3b56c40b-e3c0-5ab0-8303-818cadcbfd0b",
    "title": "Translating Natural Language to Planning Goals with Large-Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Yaqi Xie",
        "Chen Yu",
        "Tongyao Zhu",
        "Jinbin Bai",
        "Ze Gong",
        "Harold Soh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2302.05128v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\3b56c40b-e3c0-5ab0-8303-818cadcbfd0b.pdf",
    "bibtex": "@misc{xie2023translatingnaturallanguagetoplanning,\n    title = {Translating Natural Language to Planning Goals with Large-Language Models},\n    author = {Yaqi Xie and Chen Yu and Tongyao Zhu and Jinbin Bai and Ze Gong and Harold Soh},\n    year = {2023},\n    eprint = {2302.05128},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2302.05128},\n}",
    "abstract": "Recent large language models (LLMs) have demonstrated remarkable performance\non a variety of natural language processing (NLP) tasks, leading to intense\nexcitement about their applicability across various domains. Unfortunately,\nrecent work has also shown that LLMs are unable to perform accurate reasoning\nnor solve planning problems, which may limit their usefulness for\nrobotics-related tasks. In this work, our central question is whether LLMs are\nable to translate goals specified in natural language to a structured planning\nlanguage. If so, LLM can act as a natural interface between the planner and\nhuman users; the translated goal can be handed to domain-independent AI\nplanners that are very effective at planning. Our empirical results on GPT 3.5\nvariants show that LLMs are much better suited towards translation rather than\nplanning. We find that LLMs are able to leverage commonsense knowledge and\nreasoning to furnish missing details from under-specified goals (as is often\nthe case in natural language). However, our experiments also reveal that LLMs\ncan fail to generate goals in tasks that involve numerical or physical (e.g.,\nspatial) reasoning, and that LLMs are sensitive to the prompts used. As such,\nthese models are promising for translation to structured planning languages,\nbut care should be taken in their use.",
    "num_pages": 15
}