{
    "uuid": "e62ca3c9-15fe-5a2f-8f57-5914991cbae4",
    "title": "Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Aida Mostafazadeh Davani",
        "Mark Díaz",
        "Vinodkumar Prabhakaran"
    ],
    "pdf_url": "http://arxiv.org/pdf/2110.05719v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\e62ca3c9-15fe-5a2f-8f57-5914991cbae4.pdf",
    "bibtex": "@misc{davani2021dealingwithdisagreementslookingbeyond,\n    title = {Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations},\n    author = {Aida Mostafazadeh Davani and Mark Díaz and Vinodkumar Prabhakaran},\n    year = {2021},\n    eprint = {2110.05719},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2110.05719},\n}",
    "abstract": "Majority voting and averaging are common approaches employed to resolve\nannotator disagreements and derive single ground truth labels from multiple\nannotations. However, annotators may systematically disagree with one another,\noften reflecting their individual biases and values, especially in the case of\nsubjective tasks such as detecting affect, aggression, and hate speech.\nAnnotator disagreements may capture important nuances in such tasks that are\noften ignored while aggregating annotations to a single ground truth. In order\nto address this, we investigate the efficacy of multi-annotator models. In\nparticular, our multi-task based approach treats predicting each annotators'\njudgements as separate subtasks, while sharing a common learned representation\nof the task. We show that this approach yields same or better performance than\naggregating labels in the data prior to training across seven different binary\nclassification tasks. Our approach also provides a way to estimate uncertainty\nin predictions, which we demonstrate better correlate with annotation\ndisagreements than traditional methods. Being able to model uncertainty is\nespecially useful in deployment scenarios where knowing when not to make a\nprediction is important.",
    "num_pages": 18
}