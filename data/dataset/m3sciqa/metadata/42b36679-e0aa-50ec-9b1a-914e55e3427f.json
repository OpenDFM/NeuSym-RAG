{
    "uuid": "42b36679-e0aa-50ec-9b1a-914e55e3427f",
    "title": "Differentially Private Federated Knowledge Graphs Embedding",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Hao Peng",
        "Haoran Li",
        "Yangqiu Song",
        "Vincent Zheng",
        "Jianxin Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2105.07615v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\42b36679-e0aa-50ec-9b1a-914e55e3427f.pdf",
    "bibtex": "@misc{peng2021differentiallyprivatefederatedknowledgegraphs,\n    title = {Differentially Private Federated Knowledge Graphs Embedding},\n    author = {Hao Peng and Haoran Li and Yangqiu Song and Vincent Zheng and Jianxin Li},\n    year = {2021},\n    eprint = {2105.07615},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2105.07615},\n}",
    "abstract": "Knowledge graph embedding plays an important role in knowledge\nrepresentation, reasoning, and data mining applications. However, for multiple\ncross-domain knowledge graphs, state-of-the-art embedding models cannot make\nfull use of the data from different knowledge domains while preserving the\nprivacy of exchanged data. In addition, the centralized embedding model may not\nscale to the extensive real-world knowledge graphs. Therefore, we propose a\nnovel decentralized scalable learning framework, \\emph{Federated Knowledge\nGraphs Embedding} (FKGE), where embeddings from different knowledge graphs can\nbe learnt in an asynchronous and peer-to-peer manner while being\nprivacy-preserving. FKGE exploits adversarial generation between pairs of\nknowledge graphs to translate identical entities and relations of different\ndomains into near embedding spaces. In order to protect the privacy of the\ntraining data, FKGE further implements a privacy-preserving neural network\nstructure to guarantee no raw data leakage. We conduct extensive experiments to\nevaluate FKGE on 11 knowledge graphs, demonstrating a significant and\nconsistent improvement in model quality with at most 17.85\\% and 7.90\\%\nincreases in performance on triple classification and link prediction tasks.",
    "num_pages": 10
}