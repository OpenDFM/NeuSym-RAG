{
    "uuid": "c170861e-b3c6-5f40-bad9-e98ba1f9c2d8",
    "title": "SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Miao Peng",
        "Ben Liu",
        "Qianqian Xie",
        "Wenjie Xu",
        "Hua Wang",
        "Min Peng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2210.04870v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\c170861e-b3c6-5f40-bad9-e98ba1f9c2d8.pdf",
    "bibtex": "@misc{peng2024smileschemaaugmentedmultilevelcontrastivelearning,\n    title = {SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction},\n    author = {Miao Peng and Ben Liu and Qianqian Xie and Wenjie Xu and Hua Wang and Min Peng},\n    year = {2024},\n    eprint = {2210.04870},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2210.04870},\n}",
    "abstract": "Link prediction is the task of inferring missing links between entities in\nknowledge graphs. Embedding-based methods have shown effectiveness in\naddressing this problem by modeling relational patterns in triples. However,\nthe link prediction task often requires contextual information in entity\nneighborhoods, while most existing embedding-based methods fail to capture it.\nAdditionally, little attention is paid to the diversity of entity\nrepresentations in different contexts, which often leads to false prediction\nresults. In this situation, we consider that the schema of knowledge graph\ncontains the specific contextual information, and it is beneficial for\npreserving the consistency of entities across contexts. In this paper, we\npropose a novel Schema-augmented Multi-level contrastive LEarning framework\n(SMiLE) to conduct knowledge graph link prediction. Specifically, we first\nexploit network schema as the prior constraint to sample negatives and\npre-train our model by employing a multi-level contrastive learning method to\nyield both prior schema and contextual information. Then we fine-tune our model\nunder the supervision of individual triples to learn subtler representations\nfor link prediction. Extensive experimental results on four knowledge graph\ndatasets with thorough analysis of each component demonstrate the effectiveness\nof our proposed framework against state-of-the-art baselines. The\nimplementation of SMiLE is available at https://github.com/GKNL/SMiLE.",
    "num_pages": 13
}