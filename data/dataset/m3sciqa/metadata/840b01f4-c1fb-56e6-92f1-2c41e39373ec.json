{
    "uuid": "840b01f4-c1fb-56e6-92f1-2c41e39373ec",
    "title": "ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Haoqin Tu",
        "Bowen Yang",
        "Xianfeng Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2306.16649v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\840b01f4-c1fb-56e6-92f1-2c41e39373ec.pdf",
    "bibtex": "@misc{tu2023zerogenzeroshotmultimodalcontrollabletext,\n    title = {ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple Oracles},\n    author = {Haoqin Tu and Bowen Yang and Xianfeng Zhao},\n    year = {2023},\n    eprint = {2306.16649},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2306.16649},\n}",
    "abstract": "Automatically generating textual content with desired attributes is an\nambitious task that people have pursued long. Existing works have made a series\nof progress in incorporating unimodal controls into language models (LMs),\nwhereas how to generate controllable sentences with multimodal signals and high\nefficiency remains an open question. To tackle the puzzle, we propose a new\nparadigm of zero-shot controllable text generation with multimodal signals\n(\\textsc{ZeroGen}). Specifically, \\textsc{ZeroGen} leverages controls of text\nand image successively from token-level to sentence-level and maps them into a\nunified probability space at decoding, which customizes the LM outputs by\nweighted addition without extra training. To achieve better inter-modal\ntrade-offs, we further introduce an effective dynamic weighting mechanism to\nregulate all control weights. Moreover, we conduct substantial experiments to\nprobe the relationship of being in-depth or in-width between signals from\ndistinct modalities. Encouraging empirical results on three downstream tasks\nshow that \\textsc{ZeroGen} not only outperforms its counterparts on captioning\ntasks by a large margin but also shows great potential in multimodal news\ngeneration with a higher degree of control. Our code will be released at\nhttps://github.com/ImKeTT/ZeroGen.",
    "num_pages": 17
}