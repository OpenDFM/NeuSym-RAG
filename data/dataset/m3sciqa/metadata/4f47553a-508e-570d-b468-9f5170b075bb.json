{
    "uuid": "4f47553a-508e-570d-b468-9f5170b075bb",
    "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Zexuan Zhong",
        "Zhengxuan Wu",
        "Christopher D. Manning",
        "Christopher Potts",
        "Danqi Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.14795v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\4f47553a-508e-570d-b468-9f5170b075bb.pdf",
    "bibtex": "@misc{zhong2024mquakeassessingknowledgeeditingin,\n    title = {MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions},\n    author = {Zexuan Zhong and Zhengxuan Wu and Christopher D. Manning and Christopher Potts and Danqi Chen},\n    year = {2024},\n    eprint = {2305.14795},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.14795},\n}",
    "abstract": "The information stored in large language models (LLMs) falls out of date\nquickly, and retraining from scratch is often not an option. This has recently\ngiven rise to a range of techniques for injecting new facts through updating\nmodel weights. Current evaluation paradigms are extremely limited, mainly\nvalidating the recall of edited facts, but changing one fact should cause\nrippling changes to the model's related beliefs. If we edit the UK Prime\nMinister to now be Rishi Sunak, then we should get a different answer to Who is\nmarried to the British Prime Minister? In this work, we present a benchmark,\nMQuAKE (Multi-hop Question Answering for Knowledge Editing), comprising\nmulti-hop questions that assess whether edited models correctly answer\nquestions where the answer should change as an entailed consequence of edited\nfacts. While we find that current knowledge-editing approaches can recall\nedited facts accurately, they fail catastrophically on the constructed\nmulti-hop questions. We thus propose a simple memory-based approach, MeLLo,\nwhich stores all edited facts externally while prompting the language model\niteratively to generate answers that are consistent with the edited facts.\nWhile MQuAKE remains challenging, we show that MeLLo scales well with LLMs\n(e.g., OpenAI GPT-3.5-turbo) and outperforms previous model editors by a large\nmargin.",
    "num_pages": 17
}