{
    "uuid": "5e1b0738-5c04-5daf-af64-4361b08a26be",
    "title": "Memory-assisted prompt editing to improve GPT-3 after deployment",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Aman Madaan",
        "Niket Tandon",
        "Peter Clark",
        "Yiming Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2201.06009v7",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\5e1b0738-5c04-5daf-af64-4361b08a26be.pdf",
    "bibtex": "@misc{madaan2023memoryassistedprompteditingtoimprove,\n    title = {Memory-assisted prompt editing to improve GPT-3 after deployment},\n    author = {Aman Madaan and Niket Tandon and Peter Clark and Yiming Yang},\n    year = {2023},\n    eprint = {2201.06009},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2201.06009},\n}",
    "abstract": "Large LMs such as GPT-3 are powerful, but can commit mistakes that are\nobvious to humans. For example, GPT-3 would mistakenly interpret \"What word is\nsimilar to good?\" to mean a homophone, while the user intended a synonym. Our\ngoal is to effectively correct such errors via user interactions with the\nsystem but without retraining, which will be prohibitively costly. We pair\nGPT-3 with a growing memory of recorded cases where the model misunderstood the\nuser's intents, along with user feedback for clarification. Such a memory\nallows our system to produce enhanced prompts for any new query based on the\nuser feedback for error correction on similar cases in the past. On four tasks\n(two lexical tasks, two advanced ethical reasoning tasks), we show how a\n(simulated) user can interactively teach a deployed GPT-3, substantially\nincreasing its accuracy over the queries with different kinds of\nmisunderstandings by the GPT-3. Our approach is a step towards the low-cost\nutility enhancement for very large pre-trained LMs. Code, data, and\ninstructions to implement MEMPROMPT for a new task at\nhttps://www.memprompt.com/.",
    "num_pages": 30
}