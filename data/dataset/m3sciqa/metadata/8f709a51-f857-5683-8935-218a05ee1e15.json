{
    "uuid": "8f709a51-f857-5683-8935-218a05ee1e15",
    "title": "WinoDict: Probing language models for in-context word acquisition",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Julian Martin Eisenschlos",
        "Jeremy R. Cole",
        "Fangyu Liu",
        "William W. Cohen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2209.12153v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\8f709a51-f857-5683-8935-218a05ee1e15.pdf",
    "bibtex": "@misc{eisenschlos2022winodictprobinglanguagemodelsfor,\n    title = {WinoDict: Probing language models for in-context word acquisition},\n    author = {Julian Martin Eisenschlos and Jeremy R. Cole and Fangyu Liu and William W. Cohen},\n    year = {2022},\n    eprint = {2209.12153},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2209.12153},\n}",
    "abstract": "We introduce a new in-context learning paradigm to measure Large Language\nModels' (LLMs) ability to learn novel words during inference. In particular, we\nrewrite Winograd-style co-reference resolution problems by replacing the key\nconcept word with a synthetic but plausible word that the model must understand\nto complete the task. Solving this task requires the model to make use of the\ndictionary definition of the new word given in the prompt. This benchmark\naddresses word acquisition, one important aspect of the diachronic degradation\nknown to afflict LLMs. As LLMs are frozen in time at the moment they are\ntrained, they are normally unable to reflect the way language changes over\ntime. We show that the accuracy of LLMs compared to the original Winograd tasks\ndecreases radically in our benchmark, thus identifying a limitation of current\nmodels and providing a benchmark to measure future improvements in LLMs ability\nto do in-context learning.",
    "num_pages": 9
}