{
    "uuid": "d6b76a71-f118-56d3-84ed-a3401238f2a3",
    "title": "Efficient Wait-k Models for Simultaneous Machine Translation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Maha Elbayad",
        "Laurent Besacier",
        "Jakob Verbeek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2005.08595v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\d6b76a71-f118-56d3-84ed-a3401238f2a3.pdf",
    "bibtex": "@misc{elbayad2020efficientwaitkmodelsforsimultaneous,\n    title = {Efficient Wait-k Models for Simultaneous Machine Translation},\n    author = {Maha Elbayad and Laurent Besacier and Jakob Verbeek},\n    year = {2020},\n    eprint = {2005.08595},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2005.08595},\n}",
    "abstract": "Simultaneous machine translation consists in starting output generation\nbefore the entire input sequence is available. Wait-k decoders offer a simple\nbut efficient approach for this problem. They first read k source tokens, after\nwhich they alternate between producing a target token and reading another\nsource token. We investigate the behavior of wait-k decoding in low resource\nsettings for spoken corpora using IWSLT datasets. We improve training of these\nmodels using unidirectional encoders, and training across multiple values of k.\nExperiments with Transformer and 2D-convolutional architectures show that our\nwait-k models generalize well across a wide range of latency levels. We also\nshow that the 2D-convolution architecture is competitive with Transformers for\nsimultaneous translation of spoken language.",
    "num_pages": 5
}