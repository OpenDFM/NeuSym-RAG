{
    "uuid": "2f6551e2-3835-5c86-9a91-da8b6c8bd429",
    "title": "Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Chenfei Wu",
        "Shengming Yin",
        "Weizhen Qi",
        "Xiaodong Wang",
        "Zecheng Tang",
        "Nan Duan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2303.04671v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\2f6551e2-3835-5c86-9a91-da8b6c8bd429.pdf",
    "bibtex": "@misc{wu2023visualchatgpttalkingdrawingand,\n    title = {Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models},\n    author = {Chenfei Wu and Shengming Yin and Weizhen Qi and Xiaodong Wang and Zecheng Tang and Nan Duan},\n    year = {2023},\n    eprint = {2303.04671},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2303.04671},\n}",
    "abstract": "ChatGPT is attracting a cross-field interest as it provides a language\ninterface with remarkable conversational competency and reasoning capabilities\nacross many domains. However, since ChatGPT is trained with languages, it is\ncurrently not capable of processing or generating images from the visual world.\nAt the same time, Visual Foundation Models, such as Visual Transformers or\nStable Diffusion, although showing great visual understanding and generation\ncapabilities, they are only experts on specific tasks with one-round fixed\ninputs and outputs. To this end, We build a system called \\textbf{Visual\nChatGPT}, incorporating different Visual Foundation Models, to enable the user\nto interact with ChatGPT by 1) sending and receiving not only languages but\nalso images 2) providing complex visual questions or visual editing\ninstructions that require the collaboration of multiple AI models with\nmulti-steps. 3) providing feedback and asking for corrected results. We design\na series of prompts to inject the visual model information into ChatGPT,\nconsidering models of multiple inputs/outputs and models that require visual\nfeedback. Experiments show that Visual ChatGPT opens the door to investigating\nthe visual roles of ChatGPT with the help of Visual Foundation Models. Our\nsystem is publicly available at\n\\url{https://github.com/microsoft/visual-chatgpt}.",
    "num_pages": 17
}