{
    "uuid": "0337fff3-2745-5430-b1ca-9d43c836a09c",
    "title": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Gautier Izacard",
        "Patrick Lewis",
        "Maria Lomeli",
        "Lucas Hosseini",
        "Fabio Petroni",
        "Timo Schick",
        "Jane Dwivedi-Yu",
        "Armand Joulin",
        "Sebastian Riedel",
        "Edouard Grave"
    ],
    "pdf_url": "http://arxiv.org/pdf/2208.03299v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\0337fff3-2745-5430-b1ca-9d43c836a09c.pdf",
    "bibtex": "@misc{izacard2022atlasfewshotlearningwithretrieval,\n    title = {Atlas: Few-shot Learning with Retrieval Augmented Language Models},\n    author = {Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},\n    year = {2022},\n    eprint = {2208.03299},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2208.03299},\n}",
    "abstract": "Large language models have shown impressive few-shot results on a wide range\nof tasks. However, when knowledge is key for such results, as is the case for\ntasks such as question answering and fact checking, massive parameter counts to\nstore knowledge seem to be needed. Retrieval augmented models are known to\nexcel at knowledge intensive tasks without the need for as many parameters, but\nit is unclear whether they work in few-shot settings. In this work we present\nAtlas, a carefully designed and pre-trained retrieval augmented language model\nable to learn knowledge intensive tasks with very few training examples. We\nperform evaluations on a wide range of tasks, including MMLU, KILT and\nNaturalQuestions, and study the impact of the content of the document index,\nshowing that it can easily be updated. Notably, Atlas reaches over 42% accuracy\non Natural Questions using only 64 examples, outperforming a 540B parameters\nmodel by 3% despite having 50x fewer parameters.",
    "num_pages": 33
}