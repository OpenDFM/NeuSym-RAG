{
    "uuid": "e606240b-8963-5ee5-b4f2-fb4949398e3a",
    "title": "BLEURT: Learning Robust Metrics for Text Generation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Thibault Sellam",
        "Dipanjan Das",
        "Ankur P. Parikh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.04696v5",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\e606240b-8963-5ee5-b4f2-fb4949398e3a.pdf",
    "bibtex": "@misc{sellam2020bleurtlearningrobustmetricsfor,\n    title = {BLEURT: Learning Robust Metrics for Text Generation},\n    author = {Thibault Sellam and Dipanjan Das and Ankur P. Parikh},\n    year = {2020},\n    eprint = {2004.04696},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2004.04696},\n}",
    "abstract": "Text generation has made significant advances in the last few years. Yet,\nevaluation metrics have lagged behind, as the most popular choices (e.g., BLEU\nand ROUGE) may correlate poorly with human judgments. We propose BLEURT, a\nlearned evaluation metric based on BERT that can model human judgments with a\nfew thousand possibly biased training examples. A key aspect of our approach is\na novel pre-training scheme that uses millions of synthetic examples to help\nthe model generalize. BLEURT provides state-of-the-art results on the last\nthree years of the WMT Metrics shared task and the WebNLG Competition dataset.\nIn contrast to a vanilla BERT-based approach, it yields superior results even\nwhen the training data is scarce and out-of-distribution.",
    "num_pages": 12
}