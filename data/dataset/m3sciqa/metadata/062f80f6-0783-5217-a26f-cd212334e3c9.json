{
    "uuid": "062f80f6-0783-5217-a26f-cd212334e3c9",
    "title": "Rethinking Graph Convolutional Networks in Knowledge Graph Completion",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Zhanqiu Zhang",
        "Jie Wang",
        "Jieping Ye",
        "Feng Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2202.05679v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\062f80f6-0783-5217-a26f-cd212334e3c9.pdf",
    "bibtex": "@misc{zhang2022rethinkinggraphconvolutionalnetworksin,\n    title = {Rethinking Graph Convolutional Networks in Knowledge Graph Completion},\n    author = {Zhanqiu Zhang and Jie Wang and Jieping Ye and Feng Wu},\n    year = {2022},\n    eprint = {2202.05679},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/2202.05679},\n}",
    "abstract": "Graph convolutional networks (GCNs) -- which are effective in modeling graph\nstructures -- have been increasingly popular in knowledge graph completion\n(KGC). GCN-based KGC models first use GCNs to generate expressive entity\nrepresentations and then use knowledge graph embedding (KGE) models to capture\nthe interactions among entities and relations. However, many GCN-based KGC\nmodels fail to outperform state-of-the-art KGE models though introducing\nadditional computational complexity. This phenomenon motivates us to explore\nthe real effect of GCNs in KGC. Therefore, in this paper, we build upon\nrepresentative GCN-based KGC models and introduce variants to find which factor\nof GCNs is critical in KGC. Surprisingly, we observe from experiments that the\ngraph structure modeling in GCNs does not have a significant impact on the\nperformance of KGC models, which is in contrast to the common belief. Instead,\nthe transformations for entity representations are responsible for the\nperformance improvements. Based on the observation, we propose a simple yet\neffective framework named LTE-KGE, which equips existing KGE models with\nlinearly transformed entity embeddings. Experiments demonstrate that LTE-KGE\nmodels lead to similar performance improvements with GCN-based KGC methods,\nwhile being more computationally efficient. These results suggest that existing\nGCNs are unnecessary for KGC, and novel GCN-based KGC models should count on\nmore ablation studies to validate their effectiveness. The code of all the\nexperiments is available on GitHub at https://github.com/MIRALab-USTC/GCN4KGC.",
    "num_pages": 10
}