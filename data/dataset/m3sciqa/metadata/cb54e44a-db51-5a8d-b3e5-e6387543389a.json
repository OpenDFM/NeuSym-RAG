{
    "uuid": "cb54e44a-db51-5a8d-b3e5-e6387543389a",
    "title": "Faith and Fate: Limits of Transformers on Compositionality",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Nouha Dziri",
        "Ximing Lu",
        "Melanie Sclar",
        "Xiang Lorraine Li",
        "Liwei Jiang",
        "Bill Yuchen Lin",
        "Peter West",
        "Chandra Bhagavatula",
        "Ronan Le Bras",
        "Jena D. Hwang",
        "Soumya Sanyal",
        "Sean Welleck",
        "Xiang Ren",
        "Allyson Ettinger",
        "Zaid Harchaoui",
        "Yejin Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.18654v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\cb54e44a-db51-5a8d-b3e5-e6387543389a.pdf",
    "bibtex": "@misc{dziri2023faithandfatelimitsof,\n    title = {Faith and Fate: Limits of Transformers on Compositionality},\n    author = {Nouha Dziri and Ximing Lu and Melanie Sclar and Xiang Lorraine Li and Liwei Jiang and Bill Yuchen Lin and Peter West and Chandra Bhagavatula and Ronan Le Bras and Jena D. Hwang and Soumya Sanyal and Sean Welleck and Xiang Ren and Allyson Ettinger and Zaid Harchaoui and Yejin Choi},\n    year = {2023},\n    eprint = {2305.18654},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.18654},\n}",
    "abstract": "Transformer large language models (LLMs) have sparked admiration for their\nexceptional performance on tasks that demand intricate multi-step reasoning.\nYet, these models simultaneously show failures on surprisingly trivial\nproblems. This begs the question: Are these errors incidental, or do they\nsignal more substantial limitations? In an attempt to demystify transformer\nLLMs, we investigate the limits of these models across three representative\ncompositional tasks -- multi-digit multiplication, logic grid puzzles, and a\nclassic dynamic programming problem. These tasks require breaking problems down\ninto sub-steps and synthesizing these steps into a precise answer. We formulate\ncompositional tasks as computation graphs to systematically quantify the level\nof complexity, and break down reasoning steps into intermediate sub-procedures.\nOur empirical findings suggest that transformer LLMs solve compositional tasks\nby reducing multi-step compositional reasoning into linearized subgraph\nmatching, without necessarily developing systematic problem-solving skills. To\nround off our empirical study, we provide theoretical arguments on abstract\nmulti-step reasoning problems that highlight how autoregressive generations'\nperformance can rapidly decay with\\,increased\\,task\\,complexity.",
    "num_pages": 40
}