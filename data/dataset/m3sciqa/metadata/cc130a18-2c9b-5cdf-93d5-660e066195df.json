{
    "uuid": "cc130a18-2c9b-5cdf-93d5-660e066195df",
    "title": "Automatic Chain of Thought Prompting in Large Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Zhuosheng Zhang",
        "Aston Zhang",
        "Mu Li",
        "Alex Smola"
    ],
    "pdf_url": "http://arxiv.org/pdf/2210.03493v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\cc130a18-2c9b-5cdf-93d5-660e066195df.pdf",
    "bibtex": "@misc{zhang2022automaticchainofthoughtprompting,\n    title = {Automatic Chain of Thought Prompting in Large Language Models},\n    author = {Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola},\n    year = {2022},\n    eprint = {2210.03493},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2210.03493},\n}",
    "abstract": "Large language models (LLMs) can perform complex reasoning by generating\nintermediate reasoning steps. Providing these steps for prompting\ndemonstrations is called chain-of-thought (CoT) prompting. CoT prompting has\ntwo major paradigms. One leverages a simple prompt like \"Let's think step by\nstep\" to facilitate step-by-step thinking before answering a question. The\nother uses a few manual demonstrations one by one, each composed of a question\nand a reasoning chain that leads to an answer. The superior performance of the\nsecond paradigm hinges on the hand-crafting of task-specific demonstrations one\nby one. We show that such manual efforts may be eliminated by leveraging LLMs\nwith the \"Let's think step by step\" prompt to generate reasoning chains for\ndemonstrations one by one, i.e., let's think not just step by step, but also\none by one. However, these generated chains often come with mistakes. To\nmitigate the effect of such mistakes, we find that diversity matters for\nautomatically constructing demonstrations. We propose an automatic CoT\nprompting method: Auto-CoT. It samples questions with diversity and generates\nreasoning chains to construct demonstrations. On ten public benchmark reasoning\ntasks with GPT-3, Auto-CoT consistently matches or exceeds the performance of\nthe CoT paradigm that requires manual designs of demonstrations. Code is\navailable at https://github.com/amazon-research/auto-cot",
    "num_pages": 25
}