{
    "uuid": "eee65441-957d-5caa-a5e1-e063d3b1526f",
    "title": "Prototypical Networks for Few-shot Learning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Jake Snell",
        "Kevin Swersky",
        "Richard S. Zemel"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.05175v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\eee65441-957d-5caa-a5e1-e063d3b1526f.pdf",
    "bibtex": "@misc{snell2017prototypicalnetworksforfewshotlearning,\n    title = {Prototypical Networks for Few-shot Learning},\n    author = {Jake Snell and Kevin Swersky and Richard S. Zemel},\n    year = {2017},\n    eprint = {1703.05175},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1703.05175},\n}",
    "abstract": "We propose prototypical networks for the problem of few-shot classification,\nwhere a classifier must generalize to new classes not seen in the training set,\ngiven only a small number of examples of each new class. Prototypical networks\nlearn a metric space in which classification can be performed by computing\ndistances to prototype representations of each class. Compared to recent\napproaches for few-shot learning, they reflect a simpler inductive bias that is\nbeneficial in this limited-data regime, and achieve excellent results. We\nprovide an analysis showing that some simple design decisions can yield\nsubstantial improvements over recent approaches involving complicated\narchitectural choices and meta-learning. We further extend prototypical\nnetworks to zero-shot learning and achieve state-of-the-art results on the\nCU-Birds dataset.",
    "num_pages": 13
}