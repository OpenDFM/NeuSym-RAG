{
    "uuid": "1e7d9f86-3567-55b8-be98-064a3d297af1",
    "title": "Dense Passage Retrieval for Open-Domain Question Answering",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Vladimir Karpukhin",
        "Barlas Oğuz",
        "Sewon Min",
        "Patrick Lewis",
        "Ledell Wu",
        "Sergey Edunov",
        "Danqi Chen",
        "Wen-tau Yih"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.04906v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\1e7d9f86-3567-55b8-be98-064a3d297af1.pdf",
    "bibtex": "@misc{karpukhin2020densepassageretrievalforopendomain,\n    title = {Dense Passage Retrieval for Open-Domain Question Answering},\n    author = {Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},\n    year = {2020},\n    eprint = {2004.04906},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2004.04906},\n}",
    "abstract": "Open-domain question answering relies on efficient passage retrieval to\nselect candidate contexts, where traditional sparse vector space models, such\nas TF-IDF or BM25, are the de facto method. In this work, we show that\nretrieval can be practically implemented using dense representations alone,\nwhere embeddings are learned from a small number of questions and passages by a\nsimple dual-encoder framework. When evaluated on a wide range of open-domain QA\ndatasets, our dense retriever outperforms a strong Lucene-BM25 system largely\nby 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our\nend-to-end QA system establish new state-of-the-art on multiple open-domain QA\nbenchmarks.",
    "num_pages": 13
}