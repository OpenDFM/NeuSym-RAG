{
    "uuid": "9b027a68-0c67-587b-b01e-1abb132d9f19",
    "title": "CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Yunshan Ma",
        "Yingzhi He",
        "An Zhang",
        "Xiang Wang",
        "Tat-Seng Chua"
    ],
    "pdf_url": "http://arxiv.org/pdf/2206.00242v5",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\9b027a68-0c67-587b-b01e-1abb132d9f19.pdf",
    "bibtex": "@misc{ma2023crosscbrcrossviewcontrastivelearningfor,\n    title = {CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation},\n    author = {Yunshan Ma and Yingzhi He and An Zhang and Xiang Wang and Tat-Seng Chua},\n    year = {2023},\n    eprint = {2206.00242},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.IR},\n    url = {http://arxiv.org/abs/2206.00242},\n}",
    "abstract": "Bundle recommendation aims to recommend a bundle of related items to users,\nwhich can satisfy the users' various needs with one-stop convenience. Recent\nmethods usually take advantage of both user-bundle and user-item interactions\ninformation to obtain informative representations for users and bundles,\ncorresponding to bundle view and item view, respectively. However, they either\nuse a unified view without differentiation or loosely combine the predictions\nof two separate views, while the crucial cooperative association between the\ntwo views' representations is overlooked. In this work, we propose to model the\ncooperative association between the two different views through cross-view\ncontrastive learning. By encouraging the alignment of the two separately\nlearned views, each view can distill complementary information from the other\nview, achieving mutual enhancement. Moreover, by enlarging the dispersion of\ndifferent users/bundles, the self-discrimination of representations is\nenhanced. Extensive experiments on three public datasets demonstrate that our\nmethod outperforms SOTA baselines by a large margin. Meanwhile, our method\nrequires minimal parameters of three set of embeddings (user, bundle, and item)\nand the computational costs are largely reduced due to more concise graph\nstructure and graph learning module. In addition, various ablation and model\nstudies demystify the working mechanism and justify our hypothesis. Codes and\ndatasets are available at https://github.com/mysbupt/CrossCBR.",
    "num_pages": 9
}