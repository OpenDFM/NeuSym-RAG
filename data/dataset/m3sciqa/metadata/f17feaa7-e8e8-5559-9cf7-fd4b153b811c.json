{
    "uuid": "f17feaa7-e8e8-5559-9cf7-fd4b153b811c",
    "title": "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Jiahui Yu",
        "Yuanzhong Xu",
        "Jing Yu Koh",
        "Thang Luong",
        "Gunjan Baid",
        "Zirui Wang",
        "Vijay Vasudevan",
        "Alexander Ku",
        "Yinfei Yang",
        "Burcu Karagol Ayan",
        "Ben Hutchinson",
        "Wei Han",
        "Zarana Parekh",
        "Xin Li",
        "Han Zhang",
        "Jason Baldridge",
        "Yonghui Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2206.10789v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\f17feaa7-e8e8-5559-9cf7-fd4b153b811c.pdf",
    "bibtex": "@misc{yu2022scalingautoregressivemodelsforcontentrich,\n    title = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},\n    author = {Jiahui Yu and Yuanzhong Xu and Jing Yu Koh and Thang Luong and Gunjan Baid and Zirui Wang and Vijay Vasudevan and Alexander Ku and Yinfei Yang and Burcu Karagol Ayan and Ben Hutchinson and Wei Han and Zarana Parekh and Xin Li and Han Zhang and Jason Baldridge and Yonghui Wu},\n    year = {2022},\n    eprint = {2206.10789},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2206.10789},\n}",
    "abstract": "We present the Pathways Autoregressive Text-to-Image (Parti) model, which\ngenerates high-fidelity photorealistic images and supports content-rich\nsynthesis involving complex compositions and world knowledge. Parti treats\ntext-to-image generation as a sequence-to-sequence modeling problem, akin to\nmachine translation, with sequences of image tokens as the target outputs\nrather than text tokens in another language. This strategy can naturally tap\ninto the rich body of prior work on large language models, which have seen\ncontinued advances in capabilities and performance through scaling data and\nmodel sizes. Our approach is simple: First, Parti uses a Transformer-based\nimage tokenizer, ViT-VQGAN, to encode images as sequences of discrete tokens.\nSecond, we achieve consistent quality improvements by scaling the\nencoder-decoder Transformer model up to 20B parameters, with a new\nstate-of-the-art zero-shot FID score of 7.23 and finetuned FID score of 3.22 on\nMS-COCO. Our detailed analysis on Localized Narratives as well as PartiPrompts\n(P2), a new holistic benchmark of over 1600 English prompts, demonstrate the\neffectiveness of Parti across a wide variety of categories and difficulty\naspects. We also explore and highlight limitations of our models in order to\ndefine and exemplify key areas of focus for further improvements. See\nhttps://parti.research.google/ for high-resolution images.",
    "num_pages": 49
}