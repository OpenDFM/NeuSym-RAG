{
    "uuid": "859e8f4c-ae74-5f55-949b-a4122ccc3c14",
    "title": "Memory-Based Model Editing at Scale",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Eric Mitchell",
        "Charles Lin",
        "Antoine Bosselut",
        "Christopher D. Manning",
        "Chelsea Finn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2206.06520v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\859e8f4c-ae74-5f55-949b-a4122ccc3c14.pdf",
    "bibtex": "@misc{mitchell2022memorybasedmodeleditingatscale,\n    title = {Memory-Based Model Editing at Scale},\n    author = {Eric Mitchell and Charles Lin and Antoine Bosselut and Christopher D. Manning and Chelsea Finn},\n    year = {2022},\n    eprint = {2206.06520},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/2206.06520},\n}",
    "abstract": "Even the largest neural networks make errors, and once-correct predictions\ncan become invalid as the world changes. Model editors make local updates to\nthe behavior of base (pre-trained) models to inject updated knowledge or\ncorrect undesirable behaviors. Existing model editors have shown promise, but\nalso suffer from insufficient expressiveness: they struggle to accurately model\nan edit's intended scope (examples affected by the edit), leading to inaccurate\npredictions for test inputs loosely related to the edit, and they often fail\naltogether after many edits. As a higher-capacity alternative, we propose\nSemi-Parametric Editing with a Retrieval-Augmented Counterfactual Model\n(SERAC), which stores edits in an explicit memory and learns to reason over\nthem to modulate the base model's predictions as needed. To enable more\nrigorous evaluation of model editors, we introduce three challenging language\nmodel editing problems based on question answering, fact-checking, and dialogue\ngeneration. We find that only SERAC achieves high performance on all three\nproblems, consistently outperforming existing approaches to model editing by a\nsignificant margin. Code, data, and additional project information will be made\navailable at https://sites.google.com/view/serac-editing.",
    "num_pages": 15
}