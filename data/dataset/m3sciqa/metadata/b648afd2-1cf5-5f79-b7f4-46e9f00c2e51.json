{
    "uuid": "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51",
    "title": "Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Shucheng Li",
        "Lingfei Wu",
        "Shiwei Feng",
        "Fangli Xu",
        "Fengyuan Xu",
        "Sheng Zhong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.13781v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\b648afd2-1cf5-5f79-b7f4-46e9f00c2e51.pdf",
    "bibtex": "@misc{li2020graphtotreeneuralnetworksforlearning,\n    title = {Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem},\n    author = {Shucheng Li and Lingfei Wu and Shiwei Feng and Fangli Xu and Fengyuan Xu and Sheng Zhong},\n    year = {2020},\n    eprint = {2004.13781},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2004.13781},\n}",
    "abstract": "The celebrated Seq2Seq technique and its numerous variants achieve excellent\nperformance on many tasks such as neural machine translation, semantic parsing,\nand math word problem solving. However, these models either only consider input\nobjects as sequences while ignoring the important structural information for\nencoding, or they simply treat output objects as sequence outputs instead of\nstructural objects for decoding. In this paper, we present a novel\nGraph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder\nand a hierarchical tree decoder, that encodes an augmented graph-structured\ninput and decodes a tree-structured output. In particular, we investigated our\nmodel for solving two problems, neural semantic parsing and math word problem.\nOur extensive experiments demonstrate that our Graph2Tree model outperforms or\nmatches the performance of other state-of-the-art models on these tasks.",
    "num_pages": 12
}