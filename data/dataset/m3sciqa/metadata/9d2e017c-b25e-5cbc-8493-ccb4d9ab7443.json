{
    "uuid": "9d2e017c-b25e-5cbc-8493-ccb4d9ab7443",
    "title": "Is Everything in Order? A Simple Way to Order Sentences",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Somnath Basu Roy Chowdhury",
        "Faeze Brahman",
        "Snigdha Chaturvedi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2104.07064v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\9d2e017c-b25e-5cbc-8493-ccb4d9ab7443.pdf",
    "bibtex": "@misc{chowdhury2021iseverythinginordera,\n    title = {Is Everything in Order? A Simple Way to Order Sentences},\n    author = {Somnath Basu Roy Chowdhury and Faeze Brahman and Snigdha Chaturvedi},\n    year = {2021},\n    eprint = {2104.07064},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2104.07064},\n}",
    "abstract": "The task of organizing a shuffled set of sentences into a coherent text has\nbeen used to evaluate a machine's understanding of causal and temporal\nrelations. We formulate the sentence ordering task as a conditional\ntext-to-marker generation problem. We present Reorder-BART (Re-BART) that\nleverages a pre-trained Transformer-based model to identify a coherent order\nfor a given set of shuffled sentences. The model takes a set of shuffled\nsentences with sentence-specific markers as input and generates a sequence of\nposition markers of the sentences in the ordered text. Re-BART achieves the\nstate-of-the-art performance across 7 datasets in Perfect Match Ratio (PMR) and\nKendall's tau ($\\tau$). We perform evaluations in a zero-shot setting,\nshowcasing that our model is able to generalize well across other datasets. We\nadditionally perform several experiments to understand the functioning and\nlimitations of our framework.",
    "num_pages": 11
}