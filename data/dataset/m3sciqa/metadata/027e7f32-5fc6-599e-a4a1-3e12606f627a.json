{
    "uuid": "027e7f32-5fc6-599e-a4a1-3e12606f627a",
    "title": "Challenges in Generalization in Open Domain Question Answering",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Linqing Liu",
        "Patrick Lewis",
        "Sebastian Riedel",
        "Pontus Stenetorp"
    ],
    "pdf_url": "http://arxiv.org/pdf/2109.01156v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\027e7f32-5fc6-599e-a4a1-3e12606f627a.pdf",
    "bibtex": "@misc{liu2022challengesingeneralizationinopen,\n    title = {Challenges in Generalization in Open Domain Question Answering},\n    author = {Linqing Liu and Patrick Lewis and Sebastian Riedel and Pontus Stenetorp},\n    year = {2022},\n    eprint = {2109.01156},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2109.01156},\n}",
    "abstract": "Recent work on Open Domain Question Answering has shown that there is a large\ndiscrepancy in model performance between novel test questions and those that\nlargely overlap with training questions. However, it is unclear which aspects\nof novel questions make them challenging. Drawing upon studies on systematic\ngeneralization, we introduce and annotate questions according to three\ncategories that measure different levels and kinds of generalization: training\nset overlap, compositional generalization (comp-gen), and novel-entity\ngeneralization (novel-entity). When evaluating six popular parametric and\nnon-parametric models, we find that for the established Natural Questions and\nTriviaQA datasets, even the strongest model performance for\ncomp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the\nfull test set -- indicating the challenge posed by these types of questions.\nFurthermore, we show that whilst non-parametric models can handle questions\ncontaining novel entities relatively well, they struggle with those requiring\ncompositional generalization. Lastly, we find that key question difficulty\nfactors are: cascading errors from the retrieval component, frequency of\nquestion pattern, and frequency of the entity.",
    "num_pages": 16
}