{
    "uuid": "d88358e9-efe9-5844-8bfa-b1d3ed22ce82",
    "title": "On the Opportunities and Risks of Foundation Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Rishi Bommasani",
        "Drew A. Hudson",
        "Ehsan Adeli",
        "Russ Altman",
        "Simran Arora",
        "Sydney von Arx",
        "Michael S. Bernstein",
        "Jeannette Bohg",
        "Antoine Bosselut",
        "Emma Brunskill",
        "Erik Brynjolfsson",
        "Shyamal Buch",
        "Dallas Card",
        "Rodrigo Castellon",
        "Niladri Chatterji",
        "Annie Chen",
        "Kathleen Creel",
        "Jared Quincy Davis",
        "Dora Demszky",
        "Chris Donahue",
        "Moussa Doumbouya",
        "Esin Durmus",
        "Stefano Ermon",
        "John Etchemendy",
        "Kawin Ethayarajh",
        "Li Fei-Fei",
        "Chelsea Finn",
        "Trevor Gale",
        "Lauren Gillespie",
        "Karan Goel",
        "Noah Goodman",
        "Shelby Grossman",
        "Neel Guha",
        "Tatsunori Hashimoto",
        "Peter Henderson",
        "John Hewitt",
        "Daniel E. Ho",
        "Jenny Hong",
        "Kyle Hsu",
        "Jing Huang",
        "Thomas Icard",
        "Saahil Jain",
        "Dan Jurafsky",
        "Pratyusha Kalluri",
        "Siddharth Karamcheti",
        "Geoff Keeling",
        "Fereshte Khani",
        "Omar Khattab",
        "Pang Wei Koh",
        "Mark Krass",
        "Ranjay Krishna",
        "Rohith Kuditipudi",
        "Ananya Kumar",
        "Faisal Ladhak",
        "Mina Lee",
        "Tony Lee",
        "Jure Leskovec",
        "Isabelle Levent",
        "Xiang Lisa Li",
        "Xuechen Li",
        "Tengyu Ma",
        "Ali Malik",
        "Christopher D. Manning",
        "Suvir Mirchandani",
        "Eric Mitchell",
        "Zanele Munyikwa",
        "Suraj Nair",
        "Avanika Narayan",
        "Deepak Narayanan",
        "Ben Newman",
        "Allen Nie",
        "Juan Carlos Niebles",
        "Hamed Nilforoshan",
        "Julian Nyarko",
        "Giray Ogut",
        "Laurel Orr",
        "Isabel Papadimitriou",
        "Joon Sung Park",
        "Chris Piech",
        "Eva Portelance",
        "Christopher Potts",
        "Aditi Raghunathan",
        "Rob Reich",
        "Hongyu Ren",
        "Frieda Rong",
        "Yusuf Roohani",
        "Camilo Ruiz",
        "Jack Ryan",
        "Christopher Ré",
        "Dorsa Sadigh",
        "Shiori Sagawa",
        "Keshav Santhanam",
        "Andy Shih",
        "Krishnan Srinivasan",
        "Alex Tamkin",
        "Rohan Taori",
        "Armin W. Thomas",
        "Florian Tramèr",
        "Rose E. Wang",
        "William Wang",
        "Bohan Wu",
        "Jiajun Wu",
        "Yuhuai Wu",
        "Sang Michael Xie",
        "Michihiro Yasunaga",
        "Jiaxuan You",
        "Matei Zaharia",
        "Michael Zhang",
        "Tianyi Zhang",
        "Xikun Zhang",
        "Yuhui Zhang",
        "Lucia Zheng",
        "Kaitlyn Zhou",
        "Percy Liang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2108.07258v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\d88358e9-efe9-5844-8bfa-b1d3ed22ce82.pdf",
    "bibtex": "@misc{bommasani2022ontheopportunitiesandrisks,\n    title = {On the Opportunities and Risks of Foundation Models},\n    author = {Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},\n    year = {2022},\n    eprint = {2108.07258},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2108.07258},\n}",
    "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT,\nDALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a\nwide range of downstream tasks. We call these models foundation models to\nunderscore their critically central yet incomplete character. This report\nprovides a thorough account of the opportunities and risks of foundation\nmodels, ranging from their capabilities (e.g., language, vision, robotics,\nreasoning, human interaction) and technical principles(e.g., model\narchitectures, training procedures, data, systems, security, evaluation,\ntheory) to their applications (e.g., law, healthcare, education) and societal\nimpact (e.g., inequity, misuse, economic and environmental impact, legal and\nethical considerations). Though foundation models are based on standard deep\nlearning and transfer learning, their scale results in new emergent\ncapabilities,and their effectiveness across so many tasks incentivizes\nhomogenization. Homogenization provides powerful leverage but demands caution,\nas the defects of the foundation model are inherited by all the adapted models\ndownstream. Despite the impending widespread deployment of foundation models,\nwe currently lack a clear understanding of how they work, when they fail, and\nwhat they are even capable of due to their emergent properties. To tackle these\nquestions, we believe much of the critical research on foundation models will\nrequire deep interdisciplinary collaboration commensurate with their\nfundamentally sociotechnical nature.",
    "num_pages": 214
}