{
    "uuid": "d8294ff2-583e-51c8-800f-d71a9308007f",
    "title": "Multi-VQG: Generating Engaging Questions for Multiple Images",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Min-Hsuan Yeh",
        "Vicent Chen",
        "Ting-Hao 'Kenneth' Haung",
        "Lun-Wei Ku"
    ],
    "pdf_url": "http://arxiv.org/pdf/2211.07441v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\d8294ff2-583e-51c8-800f-d71a9308007f.pdf",
    "bibtex": "@misc{yeh2022multivqggeneratingengagingquestionsfor,\n    title = {Multi-VQG: Generating Engaging Questions for Multiple Images},\n    author = {Min-Hsuan Yeh and Vicent Chen and Ting-Hao 'Kenneth' Haung and Lun-Wei Ku},\n    year = {2022},\n    eprint = {2211.07441},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2211.07441},\n}",
    "abstract": "Generating engaging content has drawn much recent attention in the NLP\ncommunity. Asking questions is a natural way to respond to photos and promote\nawareness. However, most answers to questions in traditional question-answering\n(QA) datasets are factoids, which reduce individuals' willingness to answer.\nFurthermore, traditional visual question generation (VQG) confines the source\ndata for question generation to single images, resulting in a limited ability\nto comprehend time-series information of the underlying event. In this paper,\nwe propose generating engaging questions from multiple images. We present MVQG,\na new dataset, and establish a series of baselines, including both end-to-end\nand dual-stage architectures. Results show that building stories behind the\nimage sequence enables models to generate engaging questions, which confirms\nour assumption that people typically construct a picture of the event in their\nminds before asking questions. These results open up an exciting challenge for\nvisual-and-language models to implicitly construct a story behind a series of\nphotos to allow for creativity and experience sharing and hence draw attention\nto downstream applications.",
    "num_pages": 14
}