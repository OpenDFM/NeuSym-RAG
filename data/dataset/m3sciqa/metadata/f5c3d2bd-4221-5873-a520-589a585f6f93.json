{
    "uuid": "f5c3d2bd-4221-5873-a520-589a585f6f93",
    "title": "A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Griffin Adams",
        "Jason Zucker",
        "Noémie Elhadad"
    ],
    "pdf_url": "http://arxiv.org/pdf/2303.03948v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\f5c3d2bd-4221-5873-a520-589a585f6f93.pdf",
    "bibtex": "@misc{adams2023ametaevaluationoffaithfulnessmetrics,\n    title = {A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization},\n    author = {Griffin Adams and Jason Zucker and Noémie Elhadad},\n    year = {2023},\n    eprint = {2303.03948},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2303.03948},\n}",
    "abstract": "Long-form clinical summarization of hospital admissions has real-world\nsignificance because of its potential to help both clinicians and patients. The\nfaithfulness of summaries is critical to their safe usage in clinical settings.\nTo better understand the limitations of abstractive systems, as well as the\nsuitability of existing evaluation metrics, we benchmark faithfulness metrics\nagainst fine-grained human annotations for model-generated summaries of a\npatient's Brief Hospital Course. We create a corpus of patient hospital\nadmissions and summaries for a cohort of HIV patients, each with complex\nmedical histories. Annotators are presented with summaries and source notes,\nand asked to categorize manually highlighted summary elements (clinical\nentities like conditions and medications as well as actions like \"following\nup\") into one of three categories: ``Incorrect,'' ``Missing,'' and ``Not in\nNotes.'' We meta-evaluate a broad set of proposed faithfulness metrics and,\nacross metrics, explore the importance of domain adaptation (e.g. the impact of\nin-domain pre-training and metric fine-tuning), the use of source-summary\nalignments, and the effects of distilling a single metric from an ensemble of\npre-existing metrics. Off-the-shelf metrics with no exposure to clinical text\ncorrelate well yet overly rely on summary extractiveness. As a practical guide\nto long-form clinical narrative summarization, we find that most metrics\ncorrelate best to human judgments when provided with one summary sentence at a\ntime and a minimal set of relevant source context.",
    "num_pages": 23
}