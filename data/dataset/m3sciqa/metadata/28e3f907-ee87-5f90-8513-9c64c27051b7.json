{
    "uuid": "28e3f907-ee87-5f90-8513-9c64c27051b7",
    "title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Ilias Chalkidis",
        "Abhik Jana",
        "Dirk Hartung",
        "Michael Bommarito",
        "Ion Androutsopoulos",
        "Daniel Martin Katz",
        "Nikolaos Aletras"
    ],
    "pdf_url": "http://arxiv.org/pdf/2110.00976v4",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\28e3f907-ee87-5f90-8513-9c64c27051b7.pdf",
    "bibtex": "@misc{chalkidis2022lexglueabenchmarkdatasetfor,\n    title = {LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},\n    author = {Ilias Chalkidis and Abhik Jana and Dirk Hartung and Michael Bommarito and Ion Androutsopoulos and Daniel Martin Katz and Nikolaos Aletras},\n    year = {2022},\n    eprint = {2110.00976},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2110.00976},\n}",
    "abstract": "Laws and their interpretations, legal arguments and agreements\\ are typically\nexpressed in writing, leading to the production of vast corpora of legal text.\nTheir analysis, which is at the center of legal practice, becomes increasingly\nelaborate as these collections grow in size. Natural language understanding\n(NLU) technologies can be a valuable tool to support legal practitioners in\nthese endeavors. Their usefulness, however, largely depends on whether current\nstate-of-the-art models can generalize across various tasks in the legal\ndomain. To answer this currently open question, we introduce the Legal General\nLanguage Understanding Evaluation (LexGLUE) benchmark, a collection of datasets\nfor evaluating model performance across a diverse set of legal NLU tasks in a\nstandardized way. We also provide an evaluation and analysis of several generic\nand legal-oriented models demonstrating that the latter consistently offer\nperformance improvements across multiple tasks.",
    "num_pages": 22
}