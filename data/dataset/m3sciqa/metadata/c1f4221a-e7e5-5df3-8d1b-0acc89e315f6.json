{
    "uuid": "c1f4221a-e7e5-5df3-8d1b-0acc89e315f6",
    "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Gautier Izacard",
        "Edouard Grave"
    ],
    "pdf_url": "http://arxiv.org/pdf/2007.01282v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\c1f4221a-e7e5-5df3-8d1b-0acc89e315f6.pdf",
    "bibtex": "@misc{izacard2021leveragingpassageretrievalwithgenerative,\n    title = {Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering},\n    author = {Gautier Izacard and Edouard Grave},\n    year = {2021},\n    eprint = {2007.01282},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2007.01282},\n}",
    "abstract": "Generative models for open domain question answering have proven to be\ncompetitive, without resorting to external knowledge. While promising, this\napproach requires to use models with billions of parameters, which are\nexpensive to train and query. In this paper, we investigate how much these\nmodels can benefit from retrieving text passages, potentially containing\nevidence. We obtain state-of-the-art results on the Natural Questions and\nTriviaQA open benchmarks. Interestingly, we observe that the performance of\nthis method significantly improves when increasing the number of retrieved\npassages. This is evidence that generative models are good at aggregating and\ncombining evidence from multiple passages.",
    "num_pages": 6
}