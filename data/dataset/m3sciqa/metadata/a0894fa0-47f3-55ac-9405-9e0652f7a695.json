{
    "uuid": "a0894fa0-47f3-55ac-9405-9e0652f7a695",
    "title": "Few-shot Learning for Named Entity Recognition in Medical Text",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Maximilian Hofer",
        "Andrey Kormilitzin",
        "Paul Goldberg",
        "Alejo Nevado-Holgado"
    ],
    "pdf_url": "http://arxiv.org/pdf/1811.05468v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\a0894fa0-47f3-55ac-9405-9e0652f7a695.pdf",
    "bibtex": "@misc{hofer2018fewshotlearningfornamedentity,\n    title = {Few-shot Learning for Named Entity Recognition in Medical Text},\n    author = {Maximilian Hofer and Andrey Kormilitzin and Paul Goldberg and Alejo Nevado-Holgado},\n    year = {2018},\n    eprint = {1811.05468},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1811.05468},\n}",
    "abstract": "Deep neural network models have recently achieved state-of-the-art\nperformance gains in a variety of natural language processing (NLP) tasks\n(Young, Hazarika, Poria, & Cambria, 2017). However, these gains rely on the\navailability of large amounts of annotated examples, without which\nstate-of-the-art performance is rarely achievable. This is especially\ninconvenient for the many NLP fields where annotated examples are scarce, such\nas medical text. To improve NLP models in this situation, we evaluate five\nimprovements on named entity recognition (NER) tasks when only ten annotated\nexamples are available: (1) layer-wise initialization with pre-trained weights,\n(2) hyperparameter tuning, (3) combining pre-training data, (4) custom word\nembeddings, and (5) optimizing out-of-vocabulary (OOV) words. Experimental\nresults show that the F1 score of 69.3% achievable by state-of-the-art models\ncan be improved to 78.87%.",
    "num_pages": 10
}