{
    "uuid": "f3728bd2-f6be-585c-8ced-36649229dde9",
    "title": "Ruddit: Norms of Offensiveness for English Reddit Comments",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Rishav Hada",
        "Sohi Sudhir",
        "Pushkar Mishra",
        "Helen Yannakoudakis",
        "Saif M. Mohammad",
        "Ekaterina Shutova"
    ],
    "pdf_url": "http://arxiv.org/pdf/2106.05664v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\f3728bd2-f6be-585c-8ced-36649229dde9.pdf",
    "bibtex": "@misc{hada2022rudditnormsofoffensivenessfor,\n    title = {Ruddit: Norms of Offensiveness for English Reddit Comments},\n    author = {Rishav Hada and Sohi Sudhir and Pushkar Mishra and Helen Yannakoudakis and Saif M. Mohammad and Ekaterina Shutova},\n    year = {2022},\n    eprint = {2106.05664},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2106.05664},\n}",
    "abstract": "On social media platforms, hateful and offensive language negatively impact\nthe mental well-being of users and the participation of people from diverse\nbackgrounds. Automatic methods to detect offensive language have largely relied\non datasets with categorical labels. However, comments can vary in their degree\nof offensiveness. We create the first dataset of English language Reddit\ncomments that has fine-grained, real-valued scores between -1 (maximally\nsupportive) and 1 (maximally offensive). The dataset was annotated using\nBest--Worst Scaling, a form of comparative annotation that has been shown to\nalleviate known biases of using rating scales. We show that the method produces\nhighly reliable offensiveness scores. Finally, we evaluate the ability of\nwidely-used neural models to predict offensiveness scores on this new dataset.",
    "num_pages": 18
}