{
    "uuid": "114ffdfa-8150-5705-8818-1052107f5cff",
    "title": "Perceiver: General Perception with Iterative Attention",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Andrew Jaegle",
        "Felix Gimeno",
        "Andrew Brock",
        "Andrew Zisserman",
        "Oriol Vinyals",
        "Joao Carreira"
    ],
    "pdf_url": "http://arxiv.org/pdf/2103.03206v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\114ffdfa-8150-5705-8818-1052107f5cff.pdf",
    "bibtex": "@misc{jaegle2021perceivergeneralperceptionwithiterative,\n    title = {Perceiver: General Perception with Iterative Attention},\n    author = {Andrew Jaegle and Felix Gimeno and Andrew Brock and Andrew Zisserman and Oriol Vinyals and Joao Carreira},\n    year = {2021},\n    eprint = {2103.03206},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2103.03206},\n}",
    "abstract": "Biological systems perceive the world by simultaneously processing\nhigh-dimensional inputs from modalities as diverse as vision, audition, touch,\nproprioception, etc. The perception models used in deep learning on the other\nhand are designed for individual modalities, often relying on domain-specific\nassumptions such as the local grid structures exploited by virtually all\nexisting vision models. These priors introduce helpful inductive biases, but\nalso lock models to individual modalities. In this paper we introduce the\nPerceiver - a model that builds upon Transformers and hence makes few\narchitectural assumptions about the relationship between its inputs, but that\nalso scales to hundreds of thousands of inputs, like ConvNets. The model\nleverages an asymmetric attention mechanism to iteratively distill inputs into\na tight latent bottleneck, allowing it to scale to handle very large inputs. We\nshow that this architecture is competitive with or outperforms strong,\nspecialized models on classification tasks across various modalities: images,\npoint clouds, audio, video, and video+audio. The Perceiver obtains performance\ncomparable to ResNet-50 and ViT on ImageNet without 2D convolutions by directly\nattending to 50,000 pixels. It is also competitive in all modalities in\nAudioSet.",
    "num_pages": 43
}