{
    "uuid": "bfc4e2c5-a593-5974-bd48-8220a9ee00b7",
    "title": "Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment Intensity Annotation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Svetlana Kiritchenko",
        "Saif M. Mohammad"
    ],
    "pdf_url": "http://arxiv.org/pdf/1712.01765v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\bfc4e2c5-a593-5974-bd48-8220a9ee00b7.pdf",
    "bibtex": "@misc{kiritchenko2017bestworstscalingmorereliablethan,\n    title = {Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment Intensity Annotation},\n    author = {Svetlana Kiritchenko and Saif M. Mohammad},\n    year = {2017},\n    eprint = {1712.01765},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1712.01765},\n}",
    "abstract": "Rating scales are a widely used method for data annotation; however, they\npresent several challenges, such as difficulty in maintaining inter- and\nintra-annotator consistency. Best-worst scaling (BWS) is an alternative method\nof annotation that is claimed to produce high-quality annotations while keeping\nthe required number of annotations similar to that of rating scales. However,\nthe veracity of this claim has never been systematically established. Here for\nthe first time, we set up an experiment that directly compares the rating scale\nmethod with BWS. We show that with the same total number of annotations, BWS\nproduces significantly more reliable results than the rating scale.",
    "num_pages": 6
}