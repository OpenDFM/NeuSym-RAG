{
    "uuid": "d4f2933e-e3ec-5035-bb6c-90041be7751c",
    "title": "Show and Tell: A Neural Image Caption Generator",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2015,
    "authors": [
        "Oriol Vinyals",
        "Alexander Toshev",
        "Samy Bengio",
        "Dumitru Erhan"
    ],
    "pdf_url": "http://arxiv.org/pdf/1411.4555v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2015\\d4f2933e-e3ec-5035-bb6c-90041be7751c.pdf",
    "bibtex": "@misc{vinyals2015showandtellaneural,\n    title = {Show and Tell: A Neural Image Caption Generator},\n    author = {Oriol Vinyals and Alexander Toshev and Samy Bengio and Dumitru Erhan},\n    year = {2015},\n    eprint = {1411.4555},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/1411.4555},\n}",
    "abstract": "Automatically describing the content of an image is a fundamental problem in\nartificial intelligence that connects computer vision and natural language\nprocessing. In this paper, we present a generative model based on a deep\nrecurrent architecture that combines recent advances in computer vision and\nmachine translation and that can be used to generate natural sentences\ndescribing an image. The model is trained to maximize the likelihood of the\ntarget description sentence given the training image. Experiments on several\ndatasets show the accuracy of the model and the fluency of the language it\nlearns solely from image descriptions. Our model is often quite accurate, which\nwe verify both qualitatively and quantitatively. For instance, while the\ncurrent state-of-the-art BLEU-1 score (the higher the better) on the Pascal\ndataset is 25, our approach yields 59, to be compared to human performance\naround 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66,\nand on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we\nachieve a BLEU-4 of 27.7, which is the current state-of-the-art.",
    "num_pages": 9
}