{
    "uuid": "a76b882d-198d-56d9-9ced-191f44ac95e8",
    "title": "R$^3$Net:Relation-embedded Representation Reconstruction Network for Change Captioning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Yunbin Tu",
        "Liang Li",
        "Chenggang Yan",
        "Shengxiang Gao",
        "Zhengtao Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2110.10328v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\a76b882d-198d-56d9-9ced-191f44ac95e8.pdf",
    "bibtex": "@misc{tu2021r3netrelationembeddedrepresentationreconstructionnetworkfor,\n    title = {R$^3$Net:Relation-embedded Representation Reconstruction Network for Change Captioning},\n    author = {Yunbin Tu and Liang Li and Chenggang Yan and Shengxiang Gao and Zhengtao Yu},\n    year = {2021},\n    eprint = {2110.10328},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2110.10328},\n}",
    "abstract": "Change captioning is to use a natural language sentence to describe the\nfine-grained disagreement between two similar images. Viewpoint change is the\nmost typical distractor in this task, because it changes the scale and location\nof the objects and overwhelms the representation of real change. In this paper,\nwe propose a Relation-embedded Representation Reconstruction Network (R$^3$Net)\nto explicitly distinguish the real change from the large amount of clutter and\nirrelevant changes. Specifically, a relation-embedded module is first devised\nto explore potential changed objects in the large amount of clutter. Then,\nbased on the semantic similarities of corresponding locations in the two\nimages, a representation reconstruction module (RRM) is designed to learn the\nreconstruction representation and further model the difference representation.\nBesides, we introduce a syntactic skeleton predictor (SSP) to enhance the\nsemantic interaction between change localization and caption generation.\nExtensive experiments show that the proposed method achieves the\nstate-of-the-art results on two public datasets.",
    "num_pages": 11
}