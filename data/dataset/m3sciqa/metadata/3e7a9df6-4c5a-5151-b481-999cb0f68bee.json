{
    "uuid": "3e7a9df6-4c5a-5151-b481-999cb0f68bee",
    "title": "RARR: Researching and Revising What Language Models Say, Using Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Luyu Gao",
        "Zhuyun Dai",
        "Panupong Pasupat",
        "Anthony Chen",
        "Arun Tejasvi Chaganty",
        "Yicheng Fan",
        "Vincent Y. Zhao",
        "Ni Lao",
        "Hongrae Lee",
        "Da-Cheng Juan",
        "Kelvin Guu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2210.08726v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\3e7a9df6-4c5a-5151-b481-999cb0f68bee.pdf",
    "bibtex": "@misc{gao2023rarrresearchingandrevisingwhat,\n    title = {RARR: Researching and Revising What Language Models Say, Using Language Models},\n    author = {Luyu Gao and Zhuyun Dai and Panupong Pasupat and Anthony Chen and Arun Tejasvi Chaganty and Yicheng Fan and Vincent Y. Zhao and Ni Lao and Hongrae Lee and Da-Cheng Juan and Kelvin Guu},\n    year = {2023},\n    eprint = {2210.08726},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2210.08726},\n}",
    "abstract": "Language models (LMs) now excel at many tasks such as few-shot learning,\nquestion answering, reasoning, and dialog. However, they sometimes generate\nunsupported or misleading content. A user cannot easily determine whether their\noutputs are trustworthy or not, because most LMs do not have any built-in\nmechanism for attribution to external evidence. To enable attribution while\nstill preserving all the powerful advantages of recent generation models, we\npropose RARR (Retrofit Attribution using Research and Revision), a system that\n1) automatically finds attribution for the output of any text generation model\nand 2) post-edits the output to fix unsupported content while preserving the\noriginal output as much as possible. When applied to the output of several\nstate-of-the-art LMs on a diverse set of generation tasks, we find that RARR\nsignificantly improves attribution while otherwise preserving the original\ninput to a much greater degree than previously explored edit models.\nFurthermore, the implementation of RARR requires only a handful of training\nexamples, a large language model, and standard web search.",
    "num_pages": 30
}