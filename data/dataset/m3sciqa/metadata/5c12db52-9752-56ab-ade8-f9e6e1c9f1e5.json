{
    "uuid": "5c12db52-9752-56ab-ade8-f9e6e1c9f1e5",
    "title": "From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Shanshan Xu",
        "T. Y. S. S Santosh",
        "Oana Ichim",
        "Isabella Risini",
        "Barbara Plank",
        "Matthias Grabmair"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.11878v5",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\5c12db52-9752-56ab-ade8-f9e6e1c9f1e5.pdf",
    "bibtex": "@misc{xu2024fromdissonancetoinsightsdissecting,\n    title = {From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification},\n    author = {Shanshan Xu and T. Y. S. S Santosh and Oana Ichim and Isabella Risini and Barbara Plank and Matthias Grabmair},\n    year = {2024},\n    eprint = {2310.11878},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.11878},\n}",
    "abstract": "In legal NLP, Case Outcome Classification (COC) must not only be accurate but\nalso trustworthy and explainable. Existing work in explainable COC has been\nlimited to annotations by a single expert. However, it is well-known that\nlawyers may disagree in their assessment of case facts. We hence collect a\nnovel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two\nexperts in the domain of international human rights law, for whom we observe\nweak agreement. We study their disagreements and build a two-level\ntask-independent taxonomy, supplemented with COC-specific subcategories. To our\nknowledge, this is the first work in the legal NLP that focuses on human label\nvariation. We quantitatively assess different taxonomy categories and find that\ndisagreements mainly stem from underspecification of the legal context, which\nposes challenges given the typically limited granularity and noise in COC\nmetadata. We further assess the explainablility of SOTA COC models on RAVE and\nobserve limited agreement between models and experts. Overall, our case study\nreveals hitherto underappreciated complexities in creating benchmark datasets\nin legal NLP that revolve around identifying aspects of a case's facts\nsupposedly relevant to its outcome.",
    "num_pages": 19
}