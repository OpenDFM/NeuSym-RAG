{
    "uuid": "5161fb60-4394-5446-9e6e-ce1f1e9e393a",
    "title": "MoleculeNet: A Benchmark for Molecular Machine Learning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Zhenqin Wu",
        "Bharath Ramsundar",
        "Evan N. Feinberg",
        "Joseph Gomes",
        "Caleb Geniesse",
        "Aneesh S. Pappu",
        "Karl Leswing",
        "Vijay Pande"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.00564v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\5161fb60-4394-5446-9e6e-ce1f1e9e393a.pdf",
    "bibtex": "@misc{wu2018moleculenetabenchmarkformolecular,\n    title = {MoleculeNet: A Benchmark for Molecular Machine Learning},\n    author = {Zhenqin Wu and Bharath Ramsundar and Evan N. Feinberg and Joseph Gomes and Caleb Geniesse and Aneesh S. Pappu and Karl Leswing and Vijay Pande},\n    year = {2018},\n    eprint = {1703.00564},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1703.00564},\n}",
    "abstract": "Molecular machine learning has been maturing rapidly over the last few years.\nImproved methods and the presence of larger datasets have enabled machine\nlearning algorithms to make increasingly accurate predictions about molecular\nproperties. However, algorithmic progress has been limited due to the lack of a\nstandard benchmark to compare the efficacy of proposed methods; most new\nalgorithms are benchmarked on different datasets making it challenging to gauge\nthe quality of proposed methods. This work introduces MoleculeNet, a large\nscale benchmark for molecular machine learning. MoleculeNet curates multiple\npublic datasets, establishes metrics for evaluation, and offers high quality\nopen-source implementations of multiple previously proposed molecular\nfeaturization and learning algorithms (released as part of the DeepChem open\nsource library). MoleculeNet benchmarks demonstrate that learnable\nrepresentations are powerful tools for molecular machine learning and broadly\noffer the best performance. However, this result comes with caveats. Learnable\nrepresentations still struggle to deal with complex tasks under data scarcity\nand highly imbalanced classification. For quantum mechanical and biophysical\ndatasets, the use of physics-aware featurizations can be more important than\nchoice of particular learning algorithm.",
    "num_pages": 65
}