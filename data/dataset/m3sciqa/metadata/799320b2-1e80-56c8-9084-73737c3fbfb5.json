{
    "uuid": "799320b2-1e80-56c8-9084-73737c3fbfb5",
    "title": "A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Junjie Ye",
        "Xuanting Chen",
        "Nuo Xu",
        "Can Zu",
        "Zekai Shao",
        "Shichun Liu",
        "Yuhan Cui",
        "Zeyang Zhou",
        "Chao Gong",
        "Yang Shen",
        "Jie Zhou",
        "Siming Chen",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2303.10420v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\799320b2-1e80-56c8-9084-73737c3fbfb5.pdf",
    "bibtex": "@misc{ye2023acomprehensivecapabilityanalysisof,\n    title = {A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models},\n    author = {Junjie Ye and Xuanting Chen and Nuo Xu and Can Zu and Zekai Shao and Shichun Liu and Yuhan Cui and Zeyang Zhou and Chao Gong and Yang Shen and Jie Zhou and Siming Chen and Tao Gui and Qi Zhang and Xuanjing Huang},\n    year = {2023},\n    eprint = {2303.10420},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2303.10420},\n}",
    "abstract": "GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on,\nhave gained considerable attention due to their exceptional natural language\nprocessing capabilities. However, despite the abundance of research on the\ndifference in capabilities between GPT series models and fine-tuned models,\nthere has been limited attention given to the evolution of GPT series models'\ncapabilities over time. To conduct a comprehensive analysis of the capabilities\nof GPT series models, we select six representative models, comprising two GPT-3\nseries models (i.e., davinci and text-davinci-001) and four GPT-3.5 series\nmodels (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and\ngpt-3.5-turbo). We evaluate their performance on nine natural language\nunderstanding (NLU) tasks using 21 datasets. In particular, we compare the\nperformance and robustness of different models for each task under zero-shot\nand few-shot scenarios. Our extensive experiments reveal that the overall\nability of GPT series models on NLU tasks does not increase gradually as the\nmodels evolve, especially with the introduction of the RLHF training strategy.\nWhile this strategy enhances the models' ability to generate human-like\nresponses, it also compromises their ability to solve some tasks. Furthermore,\nour findings indicate that there is still room for improvement in areas such as\nmodel robustness.",
    "num_pages": 47
}