{
    "uuid": "206d89fa-26e9-5109-8b5b-e1fa826a311e",
    "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga",
        "Alban Desmaison",
        "Andreas Köpf",
        "Edward Yang",
        "Zach DeVito",
        "Martin Raison",
        "Alykhan Tejani",
        "Sasank Chilamkurthy",
        "Benoit Steiner",
        "Lu Fang",
        "Junjie Bai",
        "Soumith Chintala"
    ],
    "pdf_url": "http://arxiv.org/pdf/1912.01703v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\206d89fa-26e9-5109-8b5b-e1fa826a311e.pdf",
    "bibtex": "@misc{paszke2019pytorchanimperativestylehighperformance,\n    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},\n    author = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},\n    year = {2019},\n    eprint = {1912.01703},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1912.01703},\n}",
    "abstract": "Deep learning frameworks have often focused on either usability or speed, but\nnot both. PyTorch is a machine learning library that shows that these two goals\nare in fact compatible: it provides an imperative and Pythonic programming\nstyle that supports code as a model, makes debugging easy and is consistent\nwith other popular scientific computing libraries, while remaining efficient\nand supporting hardware accelerators such as GPUs.\n  In this paper, we detail the principles that drove the implementation of\nPyTorch and how they are reflected in its architecture. We emphasize that every\naspect of PyTorch is a regular Python program under the full control of its\nuser. We also explain how the careful and pragmatic implementation of the key\ncomponents of its runtime enables them to work together to achieve compelling\nperformance.\n  We demonstrate the efficiency of individual subsystems, as well as the\noverall speed of PyTorch on several common benchmarks.",
    "num_pages": 12
}