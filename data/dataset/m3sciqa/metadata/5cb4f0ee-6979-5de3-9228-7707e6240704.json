{
    "uuid": "5cb4f0ee-6979-5de3-9228-7707e6240704",
    "title": "Diversity Enhanced Narrative Question Generation for Storybooks",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Hokeun Yoon",
        "JinYeong Bak"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.16446v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\5cb4f0ee-6979-5de3-9228-7707e6240704.pdf",
    "bibtex": "@misc{yoon2023diversityenhancednarrativequestiongeneration,\n    title = {Diversity Enhanced Narrative Question Generation for Storybooks},\n    author = {Hokeun Yoon and JinYeong Bak},\n    year = {2023},\n    eprint = {2310.16446},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.16446},\n}",
    "abstract": "Question generation (QG) from a given context can enhance comprehension,\nengagement, assessment, and overall efficacy in learning or conversational\nenvironments. Despite recent advancements in QG, the challenge of enhancing or\nmeasuring the diversity of generated questions often remains unaddressed. In\nthis paper, we introduce a multi-question generation model (mQG), which is\ncapable of generating multiple, diverse, and answerable questions by focusing\non context and questions. To validate the answerability of the generated\nquestions, we employ a SQuAD2.0 fine-tuned question answering model,\nclassifying the questions as answerable or not. We train and evaluate mQG on\nthe FairytaleQA dataset, a well-structured QA dataset based on storybooks, with\nnarrative questions. We further apply a zero-shot adaptation on the TellMeWhy\nand SQuAD1.1 datasets. mQG shows promising results across various evaluation\nmetrics, among strong baselines.",
    "num_pages": 18
}