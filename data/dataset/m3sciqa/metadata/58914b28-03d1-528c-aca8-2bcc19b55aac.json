{
    "uuid": "58914b28-03d1-528c-aca8-2bcc19b55aac",
    "title": "Learning to Ask: Neural Question Generation for Reading Comprehension",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Xinya Du",
        "Junru Shao",
        "Claire Cardie"
    ],
    "pdf_url": "http://arxiv.org/pdf/1705.00106v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\58914b28-03d1-528c-aca8-2bcc19b55aac.pdf",
    "bibtex": "@misc{du2017learningtoaskneuralquestion,\n    title = {Learning to Ask: Neural Question Generation for Reading Comprehension},\n    author = {Xinya Du and Junru Shao and Claire Cardie},\n    year = {2017},\n    eprint = {1705.00106},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1705.00106},\n}",
    "abstract": "We study automatic question generation for sentences from text passages in\nreading comprehension. We introduce an attention-based sequence learning model\nfor the task and investigate the effect of encoding sentence- vs.\nparagraph-level information. In contrast to all previous work, our model does\nnot rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead\ntrainable end-to-end via sequence-to-sequence learning. Automatic evaluation\nresults show that our system significantly outperforms the state-of-the-art\nrule-based system. In human evaluations, questions generated by our system are\nalso rated as being more natural (i.e., grammaticality, fluency) and as more\ndifficult to answer (in terms of syntactic and lexical divergence from the\noriginal text and reasoning needed to answer).",
    "num_pages": 11
}