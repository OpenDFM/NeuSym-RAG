{
    "uuid": "d7894a4b-2b2f-5355-8193-5c68ffd30928",
    "title": "Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Desmond Elliott",
        "Stella Frank",
        "Loïc Barrault",
        "Fethi Bougares",
        "Lucia Specia"
    ],
    "pdf_url": "http://arxiv.org/pdf/1710.07177v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\d7894a4b-2b2f-5355-8193-5c68ffd30928.pdf",
    "bibtex": "@misc{elliott2017findingsofthesecondshared,\n    title = {Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description},\n    author = {Desmond Elliott and Stella Frank and Loïc Barrault and Fethi Bougares and Lucia Specia},\n    year = {2017},\n    eprint = {1710.07177},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1710.07177},\n}",
    "abstract": "We present the results from the second shared task on multimodal machine\ntranslation and multilingual image description. Nine teams submitted 19 systems\nto two tasks. The multimodal translation task, in which the source sentence is\nsupplemented by an image, was extended with a new language (French) and two new\ntest sets. The multilingual image description task was changed such that at\ntest time, only the image is given. Compared to last year, multimodal systems\nimproved, but text-only systems remain competitive.",
    "num_pages": 20
}