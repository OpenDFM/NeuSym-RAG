{
    "uuid": "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d",
    "title": "Complex Embeddings for Simple Link Prediction",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Théo Trouillon",
        "Johannes Welbl",
        "Sebastian Riedel",
        "Éric Gaussier",
        "Guillaume Bouchard"
    ],
    "pdf_url": "http://arxiv.org/pdf/1606.06357v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\a5a36de6-f56b-586f-ab8f-83c1bfa31d0d.pdf",
    "bibtex": "@misc{trouillon2016complexembeddingsforsimplelink,\n    title = {Complex Embeddings for Simple Link Prediction},\n    author = {Théo Trouillon and Johannes Welbl and Sebastian Riedel and Éric Gaussier and Guillaume Bouchard},\n    year = {2016},\n    eprint = {1606.06357},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/1606.06357},\n}",
    "abstract": "In statistical relational learning, the link prediction problem is key to\nautomatically understand the structure of large knowledge bases. As in previous\nstudies, we propose to solve this problem through latent factorization.\nHowever, here we make use of complex valued embeddings. The composition of\ncomplex embeddings can handle a large variety of binary relations, among them\nsymmetric and antisymmetric relations. Compared to state-of-the-art models such\nas Neural Tensor Network and Holographic Embeddings, our approach based on\ncomplex embeddings is arguably simpler, as it only uses the Hermitian dot\nproduct, the complex counterpart of the standard dot product between real\nvectors. Our approach is scalable to large datasets as it remains linear in\nboth space and time, while consistently outperforming alternative approaches on\nstandard link prediction benchmarks.",
    "num_pages": 12
}