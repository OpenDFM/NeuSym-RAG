{
    "uuid": "809c6f68-1e37-541f-afd3-2a72fd4a06c4",
    "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Bjarke Felbo",
        "Alan Mislove",
        "Anders Søgaard",
        "Iyad Rahwan",
        "Sune Lehmann"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.00524v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\809c6f68-1e37-541f-afd3-2a72fd4a06c4.pdf",
    "bibtex": "@misc{felbo2017usingmillionsofemojioccurrences,\n    title = {Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm},\n    author = {Bjarke Felbo and Alan Mislove and Anders Søgaard and Iyad Rahwan and Sune Lehmann},\n    year = {2017},\n    eprint = {1708.00524},\n    archivePrefix = {arXiv},\n    primaryClass = {stat.ML},\n    url = {http://arxiv.org/abs/1708.00524},\n}",
    "abstract": "NLP tasks are often limited by scarcity of manually annotated data. In social\nmedia sentiment analysis and related tasks, researchers have therefore used\nbinarized emoticons and specific hashtags as forms of distant supervision. Our\npaper shows that by extending the distant supervision to a more diverse set of\nnoisy labels, the models can learn richer representations. Through emoji\nprediction on a dataset of 1246 million tweets containing one of 64 common\nemojis we obtain state-of-the-art performance on 8 benchmark datasets within\nsentiment, emotion and sarcasm detection using a single pretrained model. Our\nanalyses confirm that the diversity of our emotional labels yield a performance\nimprovement over previous distant supervision approaches.",
    "num_pages": 13
}