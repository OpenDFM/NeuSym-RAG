{
    "uuid": "437d1762-d8da-56a8-80e2-f6b5e823ad60",
    "title": "Transformer-based Entity Typing in Knowledge Graphs",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Zhiwei Hu",
        "Víctor Gutiérrez-Basulto",
        "Zhiliang Xiang",
        "Ru Li",
        "Jeff Z. Pan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2210.11151v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\437d1762-d8da-56a8-80e2-f6b5e823ad60.pdf",
    "bibtex": "@misc{hu2022transformerbasedentitytypinginknowledge,\n    title = {Transformer-based Entity Typing in Knowledge Graphs},\n    author = {Zhiwei Hu and Víctor Gutiérrez-Basulto and Zhiliang Xiang and Ru Li and Jeff Z. Pan},\n    year = {2022},\n    eprint = {2210.11151},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/2210.11151},\n}",
    "abstract": "We investigate the knowledge graph entity typing task which aims at inferring\nplausible entity types. In this paper, we propose a novel Transformer-based\nEntity Typing (TET) approach, effectively encoding the content of neighbors of\nan entity. More precisely, TET is composed of three different mechanisms: a\nlocal transformer allowing to infer missing types of an entity by independently\nencoding the information provided by each of its neighbors; a global\ntransformer aggregating the information of all neighbors of an entity into a\nsingle long sequence to reason about more complex entity types; and a context\ntransformer integrating neighbors content based on their contribution to the\ntype inference through information exchange between neighbor pairs.\nFurthermore, TET uses information about class membership of types to\nsemantically strengthen the representation of an entity. Experiments on two\nreal-world datasets demonstrate the superior performance of TET compared to the\nstate-of-the-art.",
    "num_pages": 14
}