{
    "uuid": "3a69cec2-a986-57db-8ea0-bfb4e9e3b548",
    "title": "Towards an Automated SOAP Note: Classifying Utterances from Medical Conversations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Benjamin Schloss",
        "Sandeep Konam"
    ],
    "pdf_url": "http://arxiv.org/pdf/2007.08749v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\3a69cec2-a986-57db-8ea0-bfb4e9e3b548.pdf",
    "bibtex": "@misc{schloss2020towardsanautomatedsoapnote,\n    title = {Towards an Automated SOAP Note: Classifying Utterances from Medical Conversations},\n    author = {Benjamin Schloss and Sandeep Konam},\n    year = {2020},\n    eprint = {2007.08749},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2007.08749},\n}",
    "abstract": "Summaries generated from medical conversations can improve recall and\nunderstanding of care plans for patients and reduce documentation burden for\ndoctors. Recent advancements in automatic speech recognition (ASR) and natural\nlanguage understanding (NLU) offer potential solutions to generate these\nsummaries automatically, but rigorous quantitative baselines for benchmarking\nresearch in this domain are lacking. In this paper, we bridge this gap for two\ntasks: classifying utterances from medical conversations according to (i) the\nSOAP section and (ii) the speaker role. Both are fundamental building blocks\nalong the path towards an end-to-end, automated SOAP note for medical\nconversations. We provide details on a dataset that contains human and ASR\ntranscriptions of medical conversations and corresponding machine learning\noptimized SOAP notes. We then present a systematic analysis in which we adapt\nan existing deep learning architecture to the two aforementioned tasks. The\nresults suggest that modelling context in a hierarchical manner, which captures\nboth word and utterance level context, yields substantial improvements on both\nclassification tasks. Additionally, we develop and analyze a modular method for\nadapting our model to ASR output.",
    "num_pages": 21
}