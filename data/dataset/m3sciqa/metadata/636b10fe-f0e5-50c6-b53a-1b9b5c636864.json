{
    "uuid": "636b10fe-f0e5-50c6-b53a-1b9b5c636864",
    "title": "Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Wang-Cheng Kang",
        "Jianmo Ni",
        "Nikhil Mehta",
        "Maheswaran Sathiamoorthy",
        "Lichan Hong",
        "Ed Chi",
        "Derek Zhiyuan Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.06474v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\636b10fe-f0e5-50c6-b53a-1b9b5c636864.pdf",
    "bibtex": "@misc{kang2023dollmsunderstanduserpreferences,\n    title = {Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction},\n    author = {Wang-Cheng Kang and Jianmo Ni and Nikhil Mehta and Maheswaran Sathiamoorthy and Lichan Hong and Ed Chi and Derek Zhiyuan Cheng},\n    year = {2023},\n    eprint = {2305.06474},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.IR},\n    url = {http://arxiv.org/abs/2305.06474},\n}",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities in\ngeneralizing to new tasks in a zero-shot or few-shot manner. However, the\nextent to which LLMs can comprehend user preferences based on their previous\nbehavior remains an emerging and still unclear research question.\nTraditionally, Collaborative Filtering (CF) has been the most effective method\nfor these tasks, predominantly relying on the extensive volume of rating data.\nIn contrast, LLMs typically demand considerably less data while maintaining an\nexhaustive world knowledge about each item, such as movies or products. In this\npaper, we conduct a thorough examination of both CF and LLMs within the classic\ntask of user rating prediction, which involves predicting a user's rating for a\ncandidate item based on their past ratings. We investigate various LLMs in\ndifferent sizes, ranging from 250M to 540B parameters and evaluate their\nperformance in zero-shot, few-shot, and fine-tuning scenarios. We conduct\ncomprehensive analysis to compare between LLMs and strong CF methods, and find\nthat zero-shot LLMs lag behind traditional recommender models that have the\naccess to user interaction data, indicating the importance of user interaction\ndata. However, through fine-tuning, LLMs achieve comparable or even better\nperformance with only a small fraction of the training data, demonstrating\ntheir potential through data efficiency.",
    "num_pages": 11
}