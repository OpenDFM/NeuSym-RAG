{
    "uuid": "903c5f8d-dc70-5a8f-9660-d960ffecd438",
    "title": "OneStop QAMaker: Extract Question-Answer Pairs from Text in a One-Stop Approach",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Shaobo Cui",
        "Xintong Bao",
        "Xinxing Zu",
        "Yangyang Guo",
        "Zhongzhou Zhao",
        "Ji Zhang",
        "Haiqing Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2102.12128v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\903c5f8d-dc70-5a8f-9660-d960ffecd438.pdf",
    "bibtex": "@misc{cui2021onestopqamakerextractquestionanswerpairs,\n    title = {OneStop QAMaker: Extract Question-Answer Pairs from Text in a One-Stop Approach},\n    author = {Shaobo Cui and Xintong Bao and Xinxing Zu and Yangyang Guo and Zhongzhou Zhao and Ji Zhang and Haiqing Chen},\n    year = {2021},\n    eprint = {2102.12128},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2102.12128},\n}",
    "abstract": "Large-scale question-answer (QA) pairs are critical for advancing research\nareas like machine reading comprehension and question answering. To construct\nQA pairs from documents requires determining how to ask a question and what is\nthe corresponding answer. Existing methods for QA pair generation usually\nfollow a pipeline approach. Namely, they first choose the most likely candidate\nanswer span and then generate the answer-specific question. This pipeline\napproach, however, is undesired in mining the most appropriate QA pairs from\ndocuments since it ignores the connection between question generation and\nanswer extraction, which may lead to incompatible QA pair generation, i.e., the\nselected answer span is inappropriate for question generation. However, for\nhuman annotators, we take the whole QA pair into account and consider the\ncompatibility between question and answer. Inspired by such motivation, instead\nof the conventional pipeline approach, we propose a model named OneStop\ngenerate QA pairs from documents in a one-stop approach. Specifically,\nquestions and their corresponding answer span is extracted simultaneously and\nthe process of question generation and answer extraction mutually affect each\nother. Additionally, OneStop is much more efficient to be trained and deployed\nin industrial scenarios since it involves only one model to solve the complex\nQA generation task. We conduct comprehensive experiments on three large-scale\nmachine reading comprehension datasets: SQuAD, NewsQA, and DuReader. The\nexperimental results demonstrate that our OneStop model outperforms the\nbaselines significantly regarding the quality of generated questions, quality\nof generated question-answer pairs, and model efficiency.",
    "num_pages": 8
}