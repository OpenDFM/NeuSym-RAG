{
    "uuid": "2b337d45-3a71-59e6-9706-d9ea917c8a9d",
    "title": "Open Question Answering over Tables and Text",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Wenhu Chen",
        "Ming-Wei Chang",
        "Eva Schlinger",
        "William Wang",
        "William W. Cohen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2010.10439v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\2b337d45-3a71-59e6-9706-d9ea917c8a9d.pdf",
    "bibtex": "@misc{chen2021openquestionansweringovertables,\n    title = {Open Question Answering over Tables and Text},\n    author = {Wenhu Chen and Ming-Wei Chang and Eva Schlinger and William Wang and William W. Cohen},\n    year = {2021},\n    eprint = {2010.10439},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2010.10439},\n}",
    "abstract": "In open question answering (QA), the answer to a question is produced by\nretrieving and then analyzing documents that might contain answers to the\nquestion. Most open QA systems have considered only retrieving information from\nunstructured text. Here we consider for the first time open QA over both\ntabular and textual data and present a new large-scale dataset Open\nTable-and-Text Question Answering (OTT-QA) to evaluate performance on this\ntask. Most questions in OTT-QA require multi-hop inference across tabular data\nand unstructured text, and the evidence required to answer a question can be\ndistributed in different ways over these two types of input, making evidence\nretrieval challenging -- our baseline model using an iterative retriever and\nBERT-based reader achieves an exact match score less than 10%. We then propose\ntwo novel techniques to address the challenge of retrieving and aggregating\nevidence for OTT-QA. The first technique is to use \"early fusion\" to group\nmultiple highly relevant tabular and textual units into a fused block, which\nprovides more context for the retriever to search for. The second technique is\nto use a cross-block reader to model the cross-dependency between multiple\nretrieved evidence with global-local sparse attention. Combining these two\ntechniques improves the score significantly, to above 27%.",
    "num_pages": 19
}