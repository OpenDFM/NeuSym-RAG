{
    "uuid": "1ee90f2d-74b4-5c24-ade4-7608f608d42b",
    "title": "On Relations Between the Relative entropy and $χ^2$-Divergence, Generalizations and Applications",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Tomohiro Nishiyama",
        "Igal Sason"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.11197v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\1ee90f2d-74b4-5c24-ade4-7608f608d42b.pdf",
    "bibtex": "@misc{nishiyama2020onrelationsbetweentherelative,\n    title = {On Relations Between the Relative entropy and $χ^2$-Divergence, Generalizations and Applications},\n    author = {Tomohiro Nishiyama and Igal Sason},\n    year = {2020},\n    eprint = {2004.11197},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.IT},\n    url = {http://arxiv.org/abs/2004.11197},\n}",
    "abstract": "The relative entropy and chi-squared divergence are fundamental divergence\nmeasures in information theory and statistics. This paper is focused on a study\nof integral relations between the two divergences, the implications of these\nrelations, their information-theoretic applications, and some generalizations\npertaining to the rich class of $f$-divergences. Applications that are studied\nin this paper refer to lossless compression, the method of types and large\ndeviations, strong~data-processing inequalities, bounds on contraction\ncoefficients and maximal correlation, and the convergence rate to stationarity\nof a type of discrete-time Markov chains.",
    "num_pages": 37
}