{
    "uuid": "afd759ef-87a1-55e5-a5c5-b0102325830d",
    "title": "''Fifty Shades of Bias'': Normative Ratings of Gender Bias in GPT Generated English Text",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Rishav Hada",
        "Agrima Seth",
        "Harshita Diddee",
        "Kalika Bali"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.17428v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\afd759ef-87a1-55e5-a5c5-b0102325830d.pdf",
    "bibtex": "@misc{hada2023fiftyshadesofbiasnormative,\n    title = {''Fifty Shades of Bias'': Normative Ratings of Gender Bias in GPT Generated English Text},\n    author = {Rishav Hada and Agrima Seth and Harshita Diddee and Kalika Bali},\n    year = {2023},\n    eprint = {2310.17428},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.17428},\n}",
    "abstract": "Language serves as a powerful tool for the manifestation of societal belief\nsystems. In doing so, it also perpetuates the prevalent biases in our society.\nGender bias is one of the most pervasive biases in our society and is seen in\nonline and offline discourses. With LLMs increasingly gaining human-like\nfluency in text generation, gaining a nuanced understanding of the biases these\nsystems can generate is imperative. Prior work often treats gender bias as a\nbinary classification task. However, acknowledging that bias must be perceived\nat a relative scale; we investigate the generation and consequent receptivity\nof manual annotators to bias of varying degrees. Specifically, we create the\nfirst dataset of GPT-generated English text with normative ratings of gender\nbias. Ratings were obtained using Best--Worst Scaling -- an efficient\ncomparative annotation framework. Next, we systematically analyze the variation\nof themes of gender biases in the observed ranking and show that\nidentity-attack is most closely related to gender bias. Finally, we show the\nperformance of existing automated models trained on related concepts on our\ndataset.",
    "num_pages": 15
}