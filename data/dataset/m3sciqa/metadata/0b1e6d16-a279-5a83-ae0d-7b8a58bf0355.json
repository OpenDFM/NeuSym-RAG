{
    "uuid": "0b1e6d16-a279-5a83-ae0d-7b8a58bf0355",
    "title": "Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Zhiwei Hu",
        "Víctor Gutiérrez-Basulto",
        "Zhiliang Xiang",
        "Ru Li",
        "Jeff Z. Pan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.12008v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\0b1e6d16-a279-5a83-ae0d-7b8a58bf0355.pdf",
    "bibtex": "@misc{hu2023multiviewcontrastivelearningforentity,\n    title = {Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs},\n    author = {Zhiwei Hu and Víctor Gutiérrez-Basulto and Zhiliang Xiang and Ru Li and Jeff Z. Pan},\n    year = {2023},\n    eprint = {2310.12008},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.12008},\n}",
    "abstract": "Knowledge graph entity typing (KGET) aims at inferring plausible types of\nentities in knowledge graphs. Existing approaches to KGET focus on how to\nbetter encode the knowledge provided by the neighbors and types of an entity\ninto its representation. However, they ignore the semantic knowledge provided\nby the way in which types can be clustered together. In this paper, we propose\na novel method called Multi-view Contrastive Learning for knowledge graph\nEntity Typing (MCLET), which effectively encodes the coarse-grained knowledge\nprovided by clusters into entity and type embeddings. MCLET is composed of\nthree modules: i) Multi-view Generation and Encoder module, which encodes\nstructured information from entity-type, entity-cluster and cluster-type views;\nii) Cross-view Contrastive Learning module, which encourages different views to\ncollaboratively improve view-specific representations of entities and types;\niii) Entity Typing Prediction module, which integrates multi-head attention and\na Mixture-of-Experts strategy to infer missing entity types. Extensive\nexperiments show the strong performance of MCLET compared to the\nstate-of-the-art",
    "num_pages": 14
}