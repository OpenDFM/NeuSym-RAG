{
    "uuid": "e40adcf7-c7a6-56d8-8280-d58c5290e392",
    "title": "One Vector is Not Enough: Entity-Augmented Distributional Semantics for Discourse Relations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2014,
    "authors": [
        "Yangfeng Ji",
        "Jacob Eisenstein"
    ],
    "pdf_url": "http://arxiv.org/pdf/1411.6699v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2014\\e40adcf7-c7a6-56d8-8280-d58c5290e392.pdf",
    "bibtex": "@misc{ji2014onevectorisnotenough,\n    title = {One Vector is Not Enough: Entity-Augmented Distributional Semantics for Discourse Relations},\n    author = {Yangfeng Ji and Jacob Eisenstein},\n    year = {2014},\n    eprint = {1411.6699},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1411.6699},\n}",
    "abstract": "Discourse relations bind smaller linguistic units into coherent texts.\nHowever, automatically identifying discourse relations is difficult, because it\nrequires understanding the semantics of the linked arguments. A more subtle\nchallenge is that it is not enough to represent the meaning of each argument of\na discourse relation, because the relation may depend on links between\nlower-level components, such as entity mentions. Our solution computes\ndistributional meaning representations by composition up the syntactic parse\ntree. A key difference from previous work on compositional distributional\nsemantics is that we also compute representations for entity mentions, using a\nnovel downward compositional pass. Discourse relations are predicted from the\ndistributional representations of the arguments, and also of their coreferent\nentity mentions. The resulting system obtains substantial improvements over the\nprevious state-of-the-art in predicting implicit discourse relations in the\nPenn Discourse Treebank.",
    "num_pages": 13
}