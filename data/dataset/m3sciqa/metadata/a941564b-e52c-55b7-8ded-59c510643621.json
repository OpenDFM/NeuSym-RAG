{
    "uuid": "a941564b-e52c-55b7-8ded-59c510643621",
    "title": "Image Captioning: Transforming Objects into Words",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Simao Herdade",
        "Armin Kappeler",
        "Kofi Boakye",
        "Joao Soares"
    ],
    "pdf_url": "http://arxiv.org/pdf/1906.05963v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\a941564b-e52c-55b7-8ded-59c510643621.pdf",
    "bibtex": "@misc{herdade2020imagecaptioningtransformingobjectsinto,\n    title = {Image Captioning: Transforming Objects into Words},\n    author = {Simao Herdade and Armin Kappeler and Kofi Boakye and Joao Soares},\n    year = {2020},\n    eprint = {1906.05963},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/1906.05963},\n}",
    "abstract": "Image captioning models typically follow an encoder-decoder architecture\nwhich uses abstract image feature vectors as input to the encoder. One of the\nmost successful algorithms uses feature vectors extracted from the region\nproposals obtained from an object detector. In this work we introduce the\nObject Relation Transformer, that builds upon this approach by explicitly\nincorporating information about the spatial relationship between input detected\nobjects through geometric attention. Quantitative and qualitative results\ndemonstrate the importance of such geometric attention for image captioning,\nleading to improvements on all common captioning metrics on the MS-COCO\ndataset.",
    "num_pages": 11
}