{
    "uuid": "d1251ff0-e100-545c-8a1c-664b75854f3c",
    "title": "Improving Summarization with Human Edits",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2025,
    "authors": [
        "Zonghai Yao",
        "Benjamin J Schloss",
        "Sai P. Selvaraj"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.05857v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2025\\d1251ff0-e100-545c-8a1c-664b75854f3c.pdf",
    "bibtex": "@misc{yao2025improvingsummarizationwithhumanedits,\n    title = {Improving Summarization with Human Edits},\n    author = {Zonghai Yao and Benjamin J Schloss and Sai P. Selvaraj},\n    year = {2025},\n    eprint = {2310.05857},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.05857},\n}",
    "abstract": "Recent work has shown the promise of learning with human feedback paradigms\nto produce human-determined high-quality text. Existing works use human\nfeedback to train large language models (LLMs) in general domain abstractive\nsummarization and have obtained summary quality exceeding traditional\nlikelihood training. In this paper, we focus on a less explored form of human\nfeedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training\n(SALT), a novel technique to use both the human-edited and model-generated data\ntogether in the training loop. In addition, we demonstrate simulating Human\nEdits with ground truth summaries coming from existing training data --\nImitation edits, along with the model-generated summaries obtained after the\ntraining, to reduce the need for expensive human-edit data. In our experiments,\nwe extend human feedback exploration from general domain summarization to\nmedical domain summarization. Our results demonstrate the effectiveness of SALT\nin improving the summary quality with Human and Imitation Edits. Through\nadditional experiments, we show that SALT outperforms the conventional RLHF\nmethod (designed for human preferences) -- DPO, when applied to human-edit\ndata. We hope the evidence in our paper prompts researchers to explore,\ncollect, and better use different human feedback approaches scalably.",
    "num_pages": 18
}