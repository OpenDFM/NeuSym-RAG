{
    "uuid": "473d3226-31b0-5da8-87e5-745966b86051",
    "title": "It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Youssef Mohamed",
        "Faizan Farooq Khan",
        "Kilichbek Haydarov",
        "Mohamed Elhoseiny"
    ],
    "pdf_url": "http://arxiv.org/pdf/2204.07660v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\473d3226-31b0-5da8-87e5-745966b86051.pdf",
    "bibtex": "@misc{mohamed2022itisokaytonot,\n    title = {It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection},\n    author = {Youssef Mohamed and Faizan Farooq Khan and Kilichbek Haydarov and Mohamed Elhoseiny},\n    year = {2022},\n    eprint = {2204.07660},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2204.07660},\n}",
    "abstract": "Datasets that capture the connection between vision, language, and affection\nare limited, causing a lack of understanding of the emotional aspect of human\nintelligence. As a step in this direction, the ArtEmis dataset was recently\nintroduced as a large-scale dataset of emotional reactions to images along with\nlanguage explanations of these chosen emotions. We observed a significant\nemotional bias towards instance-rich emotions, making trained neural speakers\nless accurate in describing under-represented emotions. We show that collecting\nnew data, in the same way, is not effective in mitigating this emotional bias.\nTo remedy this problem, we propose a contrastive data collection approach to\nbalance ArtEmis with a new complementary dataset such that a pair of similar\nimages have contrasting emotions (one positive and one negative). We collected\n260,533 instances using the proposed method, we combine them with ArtEmis,\ncreating a second iteration of the dataset. The new combined dataset, dubbed\nArtEmis v2.0, has a balanced distribution of emotions with explanations\nrevealing more fine details in the associated painting. Our experiments show\nthat neural speakers trained on the new dataset improve CIDEr and METEOR\nevaluation metrics by 20% and 7%, respectively, compared to the biased dataset.\nFinally, we also show that the performance per emotion of neural speakers is\nimproved across all the emotion categories, significantly on under-represented\nemotions. The collected dataset and code are available at\nhttps://artemisdataset-v2.org.",
    "num_pages": 10
}