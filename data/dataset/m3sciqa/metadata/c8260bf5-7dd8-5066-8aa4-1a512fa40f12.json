{
    "uuid": "c8260bf5-7dd8-5066-8aa4-1a512fa40f12",
    "title": "A Survey of Current Datasets for Vision and Language Research",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2015,
    "authors": [
        "Francis Ferraro",
        "Nasrin Mostafazadeh",
        "Ting-Hao",
        "Huang",
        "Lucy Vanderwende",
        "Jacob Devlin",
        "Michel Galley",
        "Margaret Mitchell"
    ],
    "pdf_url": "http://arxiv.org/pdf/1506.06833v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2015\\c8260bf5-7dd8-5066-8aa4-1a512fa40f12.pdf",
    "bibtex": "@misc{ferraro2015asurveyofcurrentdatasets,\n    title = {A Survey of Current Datasets for Vision and Language Research},\n    author = {Francis Ferraro and Nasrin Mostafazadeh and Ting-Hao and Huang and Lucy Vanderwende and Jacob Devlin and Michel Galley and Margaret Mitchell},\n    year = {2015},\n    eprint = {1506.06833},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1506.06833},\n}",
    "abstract": "Integrating vision and language has long been a dream in work on artificial\nintelligence (AI). In the past two years, we have witnessed an explosion of\nwork that brings together vision and language from images to videos and beyond.\nThe available corpora have played a crucial role in advancing this area of\nresearch. In this paper, we propose a set of quality metrics for evaluating and\nanalyzing the vision & language datasets and categorize them accordingly. Our\nanalyses show that the most recent datasets have been using more complex\nlanguage and more abstract concepts, however, there are different strengths and\nweaknesses in each.",
    "num_pages": 7
}