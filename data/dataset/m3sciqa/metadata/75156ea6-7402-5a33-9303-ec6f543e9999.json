{
    "uuid": "75156ea6-7402-5a33-9303-ec6f543e9999",
    "title": "BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Qizhi Pei",
        "Wei Zhang",
        "Jinhua Zhu",
        "Kehan Wu",
        "Kaiyuan Gao",
        "Lijun Wu",
        "Yingce Xia",
        "Rui Yan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.07276v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\75156ea6-7402-5a33-9303-ec6f543e9999.pdf",
    "bibtex": "@misc{pei2024biot5enrichingcrossmodalintegrationin,\n    title = {BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations},\n    author = {Qizhi Pei and Wei Zhang and Jinhua Zhu and Kehan Wu and Kaiyuan Gao and Lijun Wu and Yingce Xia and Rui Yan},\n    year = {2024},\n    eprint = {2310.07276},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.07276},\n}",
    "abstract": "Recent advancements in biological research leverage the integration of\nmolecules, proteins, and natural language to enhance drug discovery. However,\ncurrent models exhibit several limitations, such as the generation of invalid\nmolecular SMILES, underutilization of contextual information, and equal\ntreatment of structured and unstructured knowledge. To address these issues, we\npropose $\\mathbf{BioT5}$, a comprehensive pre-training framework that enriches\ncross-modal integration in biology with chemical knowledge and natural language\nassociations. $\\mathbf{BioT5}$ utilizes SELFIES for $100%$ robust molecular\nrepresentations and extracts knowledge from the surrounding context of\nbio-entities in unstructured biological literature. Furthermore,\n$\\mathbf{BioT5}$ distinguishes between structured and unstructured knowledge,\nleading to more effective utilization of information. After fine-tuning, BioT5\nshows superior performance across a wide range of tasks, demonstrating its\nstrong capability of capturing underlying relations and properties of\nbio-entities. Our code is available at\n$\\href{https://github.com/QizhiPei/BioT5}{Github}$.",
    "num_pages": 22
}