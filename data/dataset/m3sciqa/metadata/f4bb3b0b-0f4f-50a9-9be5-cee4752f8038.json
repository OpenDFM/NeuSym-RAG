{
    "uuid": "f4bb3b0b-0f4f-50a9-9be5-cee4752f8038",
    "title": "Aligning Visual Prototypes with BERT Embeddings for Few-Shot Learning",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Kun Yan",
        "Zied Bouraoui",
        "Ping Wang",
        "Shoaib Jameel",
        "Steven Schockaert"
    ],
    "pdf_url": "http://arxiv.org/pdf/2105.10195v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\f4bb3b0b-0f4f-50a9-9be5-cee4752f8038.pdf",
    "bibtex": "@misc{yan2021aligningvisualprototypeswithbert,\n    title = {Aligning Visual Prototypes with BERT Embeddings for Few-Shot Learning},\n    author = {Kun Yan and Zied Bouraoui and Ping Wang and Shoaib Jameel and Steven Schockaert},\n    year = {2021},\n    eprint = {2105.10195},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2105.10195},\n}",
    "abstract": "Few-shot learning (FSL) is the task of learning to recognize previously\nunseen categories of images from a small number of training examples. This is a\nchallenging task, as the available examples may not be enough to unambiguously\ndetermine which visual features are most characteristic of the considered\ncategories. To alleviate this issue, we propose a method that additionally\ntakes into account the names of the image classes. While the use of class names\nhas already been explored in previous work, our approach differs in two key\naspects. First, while previous work has aimed to directly predict visual\nprototypes from word embeddings, we found that better results can be obtained\nby treating visual and text-based prototypes separately. Second, we propose a\nsimple strategy for learning class name embeddings using the BERT language\nmodel, which we found to substantially outperform the GloVe vectors that were\nused in previous work. We furthermore propose a strategy for dealing with the\nhigh dimensionality of these vectors, inspired by models for aligning\ncross-lingual word embeddings. We provide experiments on miniImageNet, CUB and\ntieredImageNet, showing that our approach consistently improves the\nstate-of-the-art in metric-based FSL.",
    "num_pages": 10
}