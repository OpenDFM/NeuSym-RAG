{
    "uuid": "7c70448c-cb61-54ea-a9d9-d7ecc5477ba2",
    "title": "A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Yongliang Shen",
        "Xinyin Ma",
        "Yechun Tang",
        "Weiming Lu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2101.10213v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\7c70448c-cb61-54ea-a9d9-d7ecc5477ba2.pdf",
    "bibtex": "@misc{shen2021atriggersensememoryflowframework,\n    title = {A Trigger-Sense Memory Flow Framework for Joint Entity and Relation Extraction},\n    author = {Yongliang Shen and Xinyin Ma and Yechun Tang and Weiming Lu},\n    year = {2021},\n    eprint = {2101.10213},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2101.10213},\n}",
    "abstract": "Joint entity and relation extraction framework constructs a unified model to\nperform entity recognition and relation extraction simultaneously, which can\nexploit the dependency between the two tasks to mitigate the error propagation\nproblem suffered by the pipeline model. Current efforts on joint entity and\nrelation extraction focus on enhancing the interaction between entity\nrecognition and relation extraction through parameter sharing, joint decoding,\nor other ad-hoc tricks (e.g., modeled as a semi-Markov decision process, cast\nas a multi-round reading comprehension task). However, there are still two\nissues on the table. First, the interaction utilized by most methods is still\nweak and uni-directional, which is unable to model the mutual dependency\nbetween the two tasks. Second, relation triggers are ignored by most methods,\nwhich can help explain why humans would extract a relation in the sentence.\nThey're essential for relation extraction but overlooked. To this end, we\npresent a Trigger-Sense Memory Flow Framework (TriMF) for joint entity and\nrelation extraction. We build a memory module to remember category\nrepresentations learned in entity recognition and relation extraction tasks.\nAnd based on it, we design a multi-level memory flow attention mechanism to\nenhance the bi-directional interaction between entity recognition and relation\nextraction. Moreover, without any human annotations, our model can enhance\nrelation trigger information in a sentence through a trigger sensor module,\nwhich improves the model performance and makes model predictions with better\ninterpretation. Experiment results show that our proposed framework achieves\nstate-of-the-art results by improves the relation F1 to 52.44% (+3.2%) on\nSciERC, 66.49% (+4.9%) on ACE05, 72.35% (+0.6%) on CoNLL04 and 80.66% (+2.3%)\non ADE.",
    "num_pages": 12
}