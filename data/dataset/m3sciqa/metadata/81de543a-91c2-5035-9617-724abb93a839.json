{
    "uuid": "81de543a-91c2-5035-9617-724abb93a839",
    "title": "Modeling Multi-turn Conversation with Deep Utterance Aggregation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Zhuosheng Zhang",
        "Jiangtong Li",
        "Pengfei Zhu",
        "Hai Zhao",
        "Gongshen Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/1806.09102v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\81de543a-91c2-5035-9617-724abb93a839.pdf",
    "bibtex": "@misc{zhang2018modelingmultiturnconversationwithdeep,\n    title = {Modeling Multi-turn Conversation with Deep Utterance Aggregation},\n    author = {Zhuosheng Zhang and Jiangtong Li and Pengfei Zhu and Hai Zhao and Gongshen Liu},\n    year = {2018},\n    eprint = {1806.09102},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1806.09102},\n}",
    "abstract": "Multi-turn conversation understanding is a major challenge for building\nintelligent dialogue systems. This work focuses on retrieval-based response\nmatching for multi-turn conversation whose related work simply concatenates the\nconversation utterances, ignoring the interactions among previous utterances\nfor context modeling. In this paper, we formulate previous utterances into\ncontext using a proposed deep utterance aggregation model to form a\nfine-grained context representation. In detail, a self-matching attention is\nfirst introduced to route the vital information in each utterance. Then the\nmodel matches a response with each refined utterance and the final matching\nscore is obtained after attentive turns aggregation. Experimental results show\nour model outperforms the state-of-the-art methods on three multi-turn\nconversation benchmarks, including a newly introduced e-commerce dialogue\ncorpus.",
    "num_pages": 13
}