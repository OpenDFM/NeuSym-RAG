{
    "uuid": "739a3a50-92df-500d-822f-5a16e07b9da2",
    "title": "Information Association for Language Model Updating by Mitigating LM-Logical Discrepancy",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Pengfei Yu",
        "Heng Ji"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.18582v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\739a3a50-92df-500d-822f-5a16e07b9da2.pdf",
    "bibtex": "@misc{yu2024informationassociationforlanguagemodel,\n    title = {Information Association for Language Model Updating by Mitigating LM-Logical Discrepancy},\n    author = {Pengfei Yu and Heng Ji},\n    year = {2024},\n    eprint = {2305.18582},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.18582},\n}",
    "abstract": "Large Language Models~(LLMs) struggle with providing current information due\nto the outdated pre-training data. Existing methods for updating LLMs, such as\nknowledge editing and continual fine-tuning, have significant drawbacks in\ngeneralizability of new information and the requirements on structured updating\ncorpus. We identify the core challenge behind these drawbacks: the LM-logical\ndiscrepancy featuring the difference between language modeling probabilities\nand logical probabilities. To evaluate and address the core challenge, we\npropose a new task formulation of the information updating task that only\nrequires the provision of an unstructured updating corpus and evaluates the\nperformance of information updating on the generalizability to question-answer\npairs pertaining to the updating information. We further propose a novel and\neffective pipeline approach for the task, highlighting a self-prompting-based\nquestion-answer generation process and a associative distillation methods to\nbridge the LM-logical discrepancy. We develop two datasets for evaluation, one\nsourced from news articles published in March and April 2023, and the other\nfrom the Natural Questions benchmark. Experimental results demonstrate the\nsuperiority of our approach, significantly increasing the factual consistency\nscore (on a scale from 0 to 1) by up to 0.16. Furthermore, our method\neffectively mitigates forgetting utilizing a compact replay buffer with only\n2.3% of the training tokens.",
    "num_pages": 13
}