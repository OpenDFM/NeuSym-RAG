{
    "uuid": "07f09067-3b43-5c96-941d-de3a582e8770",
    "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Dzmitry Bahdanau",
        "Kyunghyun Cho",
        "Yoshua Bengio"
    ],
    "pdf_url": "http://arxiv.org/pdf/1409.0473v7",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\07f09067-3b43-5c96-941d-de3a582e8770.pdf",
    "bibtex": "@misc{bahdanau2016neuralmachinetranslationbyjointly,\n    title = {Neural Machine Translation by Jointly Learning to Align and Translate},\n    author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},\n    year = {2016},\n    eprint = {1409.0473},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1409.0473},\n}",
    "abstract": "Neural machine translation is a recently proposed approach to machine\ntranslation. Unlike the traditional statistical machine translation, the neural\nmachine translation aims at building a single neural network that can be\njointly tuned to maximize the translation performance. The models proposed\nrecently for neural machine translation often belong to a family of\nencoder-decoders and consists of an encoder that encodes a source sentence into\na fixed-length vector from which a decoder generates a translation. In this\npaper, we conjecture that the use of a fixed-length vector is a bottleneck in\nimproving the performance of this basic encoder-decoder architecture, and\npropose to extend this by allowing a model to automatically (soft-)search for\nparts of a source sentence that are relevant to predicting a target word,\nwithout having to form these parts as a hard segment explicitly. With this new\napproach, we achieve a translation performance comparable to the existing\nstate-of-the-art phrase-based system on the task of English-to-French\ntranslation. Furthermore, qualitative analysis reveals that the\n(soft-)alignments found by the model agree well with our intuition.",
    "num_pages": 15
}