{
    "uuid": "72fa6e51-23f1-5048-9e33-69914369efcf",
    "title": "ToTTo: A Controlled Table-To-Text Generation Dataset",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Ankur P. Parikh",
        "Xuezhi Wang",
        "Sebastian Gehrmann",
        "Manaal Faruqui",
        "Bhuwan Dhingra",
        "Diyi Yang",
        "Dipanjan Das"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.14373v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\72fa6e51-23f1-5048-9e33-69914369efcf.pdf",
    "bibtex": "@misc{parikh2020tottoacontrolledtabletotextgeneration,\n    title = {ToTTo: A Controlled Table-To-Text Generation Dataset},\n    author = {Ankur P. Parikh and Xuezhi Wang and Sebastian Gehrmann and Manaal Faruqui and Bhuwan Dhingra and Diyi Yang and Dipanjan Das},\n    year = {2020},\n    eprint = {2004.14373},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2004.14373},\n}",
    "abstract": "We present ToTTo, an open-domain English table-to-text dataset with over\n120,000 training examples that proposes a controlled generation task: given a\nWikipedia table and a set of highlighted table cells, produce a one-sentence\ndescription. To obtain generated targets that are natural but also faithful to\nthe source table, we introduce a dataset construction process where annotators\ndirectly revise existing candidate sentences from Wikipedia. We present\nsystematic analyses of our dataset and annotation process as well as results\nachieved by several state-of-the-art baselines. While usually fluent, existing\nmethods often hallucinate phrases that are not supported by the table,\nsuggesting that this dataset can serve as a useful research benchmark for\nhigh-precision conditional text generation.",
    "num_pages": 14
}