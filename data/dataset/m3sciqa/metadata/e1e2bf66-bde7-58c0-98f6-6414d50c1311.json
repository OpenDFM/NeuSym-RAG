{
    "uuid": "e1e2bf66-bde7-58c0-98f6-6414d50c1311",
    "title": "ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Zhengxuan Wu",
        "Christopher D. Manning",
        "Christopher Potts"
    ],
    "pdf_url": "http://arxiv.org/pdf/2303.13716v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\e1e2bf66-bde7-58c0-98f6-6414d50c1311.pdf",
    "bibtex": "@misc{wu2024recogshowincidentaldetailsof,\n    title = {ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation},\n    author = {Zhengxuan Wu and Christopher D. Manning and Christopher Potts},\n    year = {2024},\n    eprint = {2303.13716},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2303.13716},\n}",
    "abstract": "Compositional generalization benchmarks for semantic parsing seek to assess\nwhether models can accurately compute meanings for novel sentences, but\noperationalize this in terms of logical form (LF) prediction. This raises the\nconcern that semantically irrelevant details of the chosen LFs could shape\nmodel performance. We argue that this concern is realized for the COGS\nbenchmark. COGS poses generalization splits that appear impossible for\npresent-day models, which could be taken as an indictment of those models.\nHowever, we show that the negative results trace to incidental features of COGS\nLFs. Converting these LFs to semantically equivalent ones and factoring out\ncapabilities unrelated to semantic interpretation, we find that even baseline\nmodels get traction. A recent variable-free translation of COGS LFs suggests\nsimilar conclusions, but we observe this format is not semantically equivalent;\nit is incapable of accurately representing some COGS meanings. These findings\ninform our proposal for ReCOGS, a modified version of COGS that comes closer to\nassessing the target semantic capabilities while remaining very challenging.\nOverall, our results reaffirm the importance of compositional generalization\nand careful benchmark task design.",
    "num_pages": 14
}