{
    "uuid": "af38cdbf-e96a-5596-aa16-a4d08afba02f",
    "title": "Do Large Language Models Know What They Don't Know?",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Zhangyue Yin",
        "Qiushi Sun",
        "Qipeng Guo",
        "Jiawen Wu",
        "Xipeng Qiu",
        "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.18153v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\af38cdbf-e96a-5596-aa16-a4d08afba02f.pdf",
    "bibtex": "@misc{yin2023dolargelanguagemodelsknow,\n    title = {Do Large Language Models Know What They Don't Know?},\n    author = {Zhangyue Yin and Qiushi Sun and Qipeng Guo and Jiawen Wu and Xipeng Qiu and Xuanjing Huang},\n    year = {2023},\n    eprint = {2305.18153},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.18153},\n}",
    "abstract": "Large language models (LLMs) have a wealth of knowledge that allows them to\nexcel in various Natural Language Processing (NLP) tasks. Current research\nfocuses on enhancing their performance within their existing knowledge. Despite\ntheir vast knowledge, LLMs are still limited by the amount of information they\ncan accommodate and comprehend. Therefore, the ability to understand their own\nlimitations on the unknows, referred to as self-knowledge, is of paramount\nimportance. This study aims to evaluate LLMs' self-knowledge by assessing their\nability to identify unanswerable or unknowable questions. We introduce an\nautomated methodology to detect uncertainty in the responses of these models,\nproviding a novel measure of their self-knowledge. We further introduce a\nunique dataset, SelfAware, consisting of unanswerable questions from five\ndiverse categories and their answerable counterparts. Our extensive analysis,\ninvolving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an\nintrinsic capacity for self-knowledge within these models. Moreover, we\ndemonstrate that in-context learning and instruction tuning can further enhance\nthis self-knowledge. Despite this promising insight, our findings also\nhighlight a considerable gap between the capabilities of these models and human\nproficiency in recognizing the limits of their knowledge.",
    "num_pages": 10
}