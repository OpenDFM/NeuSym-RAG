{
    "uuid": "b528f9d7-6504-56be-abbf-1a1b714760aa",
    "title": "Keyword-Guided Neural Conversational Model",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Peixiang Zhong",
        "Yong Liu",
        "Hao Wang",
        "Chunyan Miao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2012.08383v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\b528f9d7-6504-56be-abbf-1a1b714760aa.pdf",
    "bibtex": "@misc{zhong2021keywordguidedneuralconversationalmodel,\n    title = {Keyword-Guided Neural Conversational Model},\n    author = {Peixiang Zhong and Yong Liu and Hao Wang and Chunyan Miao},\n    year = {2021},\n    eprint = {2012.08383},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2012.08383},\n}",
    "abstract": "We study the problem of imposing conversational goals/keywords on open-domain\nconversational agents, where the agent is required to lead the conversation to\na target keyword smoothly and fast. Solving this problem enables the\napplication of conversational agents in many real-world scenarios, e.g.,\nrecommendation and psychotherapy. The dominant paradigm for tackling this\nproblem is to 1) train a next-turn keyword classifier, and 2) train a\nkeyword-augmented response retrieval model. However, existing approaches in\nthis paradigm have two limitations: 1) the training and evaluation datasets for\nnext-turn keyword classification are directly extracted from conversations\nwithout human annotations, thus, they are noisy and have low correlation with\nhuman judgements, and 2) during keyword transition, the agents solely rely on\nthe similarities between word embeddings to move closer to the target keyword,\nwhich may not reflect how humans converse. In this paper, we assume that human\nconversations are grounded on commonsense and propose a keyword-guided neural\nconversational model that can leverage external commonsense knowledge graphs\n(CKG) for both keyword transition and response retrieval. Automatic evaluations\nsuggest that commonsense improves the performance of both next-turn keyword\nprediction and keyword-augmented response retrieval. In addition, both\nself-play and human evaluations show that our model produces responses with\nsmoother keyword transition and reaches the target keyword faster than\ncompetitive baselines.",
    "num_pages": 9
}