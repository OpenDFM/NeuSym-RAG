{
    "uuid": "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c",
    "title": "Enhancing Knowledge Graph Construction Using Large Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Milena Trajanoska",
        "Riste Stojanov",
        "Dimitar Trajanov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.04676v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c.pdf",
    "bibtex": "@misc{trajanoska2023enhancingknowledgegraphconstructionusing,\n    title = {Enhancing Knowledge Graph Construction Using Large Language Models},\n    author = {Milena Trajanoska and Riste Stojanov and Dimitar Trajanov},\n    year = {2023},\n    eprint = {2305.04676},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.04676},\n}",
    "abstract": "The growing trend of Large Language Models (LLM) development has attracted\nsignificant attention, with models for various applications emerging\nconsistently. However, the combined application of Large Language Models with\nsemantic technologies for reasoning and inference is still a challenging task.\nThis paper analyzes how the current advances in foundational LLM, like ChatGPT,\ncan be compared with the specialized pretrained models, like REBEL, for joint\nentity and relation extraction. To evaluate this approach, we conducted several\nexperiments using sustainability-related text as our use case. We created\npipelines for the automatic creation of Knowledge Graphs from raw texts, and\nour findings indicate that using advanced LLM models can improve the accuracy\nof the process of creating these graphs from unstructured text. Furthermore, we\nexplored the potential of automatic ontology creation using foundation LLM\nmodels, which resulted in even more relevant and accurate knowledge graphs.",
    "num_pages": 6
}