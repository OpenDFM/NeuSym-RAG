{
    "uuid": "251aa23c-e271-5ac1-8f70-da7ebf449029",
    "title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Max Grusky",
        "Mor Naaman",
        "Yoav Artzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/1804.11283v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\251aa23c-e271-5ac1-8f70-da7ebf449029.pdf",
    "bibtex": "@misc{grusky2020newsroomadatasetof13,\n    title = {Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies},\n    author = {Max Grusky and Mor Naaman and Yoav Artzi},\n    year = {2020},\n    eprint = {1804.11283},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1804.11283},\n}",
    "abstract": "We present NEWSROOM, a summarization dataset of 1.3 million articles and\nsummaries written by authors and editors in newsrooms of 38 major news\npublications. Extracted from search and social media metadata between 1998 and\n2017, these high-quality summaries demonstrate high diversity of summarization\nstyles. In particular, the summaries combine abstractive and extractive\nstrategies, borrowing words and phrases from articles at varying rates. We\nanalyze the extraction strategies used in NEWSROOM summaries against other\ndatasets to quantify the diversity and difficulty of our new data, and train\nexisting methods on the data to evaluate its utility and challenges.",
    "num_pages": 12
}