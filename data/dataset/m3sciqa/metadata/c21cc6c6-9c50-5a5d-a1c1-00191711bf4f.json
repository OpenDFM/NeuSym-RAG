{
    "uuid": "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f",
    "title": "Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Zhengbao Jiang",
        "Luyu Gao",
        "Jun Araki",
        "Haibo Ding",
        "Zhiruo Wang",
        "Jamie Callan",
        "Graham Neubig"
    ],
    "pdf_url": "http://arxiv.org/pdf/2212.02027v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\c21cc6c6-9c50-5a5d-a1c1-00191711bf4f.pdf",
    "bibtex": "@misc{jiang2022retrievalasattentionendtoendlearning,\n    title = {Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer},\n    author = {Zhengbao Jiang and Luyu Gao and Jun Araki and Haibo Ding and Zhiruo Wang and Jamie Callan and Graham Neubig},\n    year = {2022},\n    eprint = {2212.02027},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2212.02027},\n}",
    "abstract": "Systems for knowledge-intensive tasks such as open-domain question answering\n(QA) usually consist of two stages: efficient retrieval of relevant documents\nfrom a large corpus and detailed reading of the selected documents to generate\nanswers. Retrievers and readers are usually modeled separately, which\nnecessitates a cumbersome implementation and is hard to train and adapt in an\nend-to-end fashion. In this paper, we revisit this design and eschew the\nseparate architecture and training in favor of a single Transformer that\nperforms Retrieval as Attention (ReAtt), and end-to-end training solely based\non supervision from the end QA task. We demonstrate for the first time that a\nsingle model trained end-to-end can achieve both competitive retrieval and QA\nperformance, matching or slightly outperforming state-of-the-art separately\ntrained retrievers and readers. Moreover, end-to-end adaptation significantly\nboosts its performance on out-of-domain datasets in both supervised and\nunsupervised settings, making our model a simple and adaptable solution for\nknowledge-intensive tasks. Code and models are available at\nhttps://github.com/jzbjyb/ReAtt.",
    "num_pages": 14
}