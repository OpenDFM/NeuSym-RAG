{
    "uuid": "77e2ee1d-55c3-5573-8031-cfce43812fbd",
    "title": "Question Answering as Programming for Solving Time-Sensitive Questions",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Xinyu Zhu",
        "Cheng Yang",
        "Bei Chen",
        "Siheng Li",
        "Jian-Guang Lou",
        "Yujiu Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.14221v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\77e2ee1d-55c3-5573-8031-cfce43812fbd.pdf",
    "bibtex": "@misc{zhu2023questionansweringasprogrammingfor,\n    title = {Question Answering as Programming for Solving Time-Sensitive Questions},\n    author = {Xinyu Zhu and Cheng Yang and Bei Chen and Siheng Li and Jian-Guang Lou and Yujiu Yang},\n    year = {2023},\n    eprint = {2305.14221},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.14221},\n}",
    "abstract": "Question answering plays a pivotal role in human daily life because it\ninvolves our acquisition of knowledge about the world. However, due to the\ndynamic and ever-changing nature of real-world facts, the answer can be\ncompletely different when the time constraint in the question changes.\nRecently, Large Language Models (LLMs) have shown remarkable intelligence in\nquestion answering, while our experiments reveal that the aforementioned\nproblems still pose a significant challenge to existing LLMs. This can be\nattributed to the LLMs' inability to perform rigorous reasoning based on\nsurface-level text semantics. To overcome this limitation, rather than\nrequiring LLMs to directly answer the question, we propose a novel approach\nwhere we reframe the $\\textbf{Q}$uestion $\\textbf{A}$nswering task\n$\\textbf{a}$s $\\textbf{P}$rogramming ($\\textbf{QAaP}$). Concretely, by\nleveraging modern LLMs' superior capability in understanding both natural\nlanguage and programming language, we endeavor to harness LLMs to represent\ndiversely expressed text as well-structured code and select the best matching\nanswer from multiple candidates through programming. We evaluate our QAaP\nframework on several time-sensitive question answering datasets and achieve\ndecent improvement, up to $14.5$% over strong baselines. Our codes and data are\navailable at https://github.com/TianHongZXY/qaap",
    "num_pages": 16
}