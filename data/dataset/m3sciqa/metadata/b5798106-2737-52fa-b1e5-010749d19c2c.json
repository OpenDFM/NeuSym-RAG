{
    "uuid": "b5798106-2737-52fa-b1e5-010749d19c2c",
    "title": "Learning from Task Descriptions",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Orion Weller",
        "Nicholas Lourie",
        "Matt Gardner",
        "Matthew E. Peters"
    ],
    "pdf_url": "http://arxiv.org/pdf/2011.08115v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\b5798106-2737-52fa-b1e5-010749d19c2c.pdf",
    "bibtex": "@misc{weller2020learningfromtaskdescriptions,\n    title = {Learning from Task Descriptions},\n    author = {Orion Weller and Nicholas Lourie and Matt Gardner and Matthew E. Peters},\n    year = {2020},\n    eprint = {2011.08115},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2011.08115},\n}",
    "abstract": "Typically, machine learning systems solve new tasks by training on thousands\nof examples. In contrast, humans can solve new tasks by reading some\ninstructions, with perhaps an example or two. To take a step toward closing\nthis gap, we introduce a framework for developing NLP systems that solve new\ntasks after reading their descriptions, synthesizing prior work in this area.\nWe instantiate this framework with a new English language dataset, ZEST,\nstructured for task-oriented evaluation on unseen tasks. Formulating task\ndescriptions as questions, we ensure each is general enough to apply to many\npossible inputs, thus comprehensively evaluating a model's ability to solve\neach task. Moreover, the dataset's structure tests specific types of systematic\ngeneralization. We find that the state-of-the-art T5 model achieves a score of\n12% on ZEST, leaving a significant challenge for NLP researchers.",
    "num_pages": 14
}