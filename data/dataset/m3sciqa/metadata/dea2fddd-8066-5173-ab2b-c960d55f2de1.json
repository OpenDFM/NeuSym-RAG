{
    "uuid": "dea2fddd-8066-5173-ab2b-c960d55f2de1",
    "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Yixin Nie",
        "Adina Williams",
        "Emily Dinan",
        "Mohit Bansal",
        "Jason Weston",
        "Douwe Kiela"
    ],
    "pdf_url": "http://arxiv.org/pdf/1910.14599v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\dea2fddd-8066-5173-ab2b-c960d55f2de1.pdf",
    "bibtex": "@misc{nie2020adversarialnlianewbenchmark,\n    title = {Adversarial NLI: A New Benchmark for Natural Language Understanding},\n    author = {Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and Jason Weston and Douwe Kiela},\n    year = {2020},\n    eprint = {1910.14599},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1910.14599},\n}",
    "abstract": "We introduce a new large-scale NLI benchmark dataset, collected via an\niterative, adversarial human-and-model-in-the-loop procedure. We show that\ntraining models on this new dataset leads to state-of-the-art performance on a\nvariety of popular NLI benchmarks, while posing a more difficult challenge with\nits new test set. Our analysis sheds light on the shortcomings of current\nstate-of-the-art models, and shows that non-expert annotators are successful at\nfinding their weaknesses. The data collection method can be applied in a\nnever-ending learning scenario, becoming a moving target for NLU, rather than a\nstatic benchmark that will quickly saturate.",
    "num_pages": 17
}