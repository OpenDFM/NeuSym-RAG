{
    "uuid": "00ae9127-82dd-5bbd-9d0f-c2a7a58d65fa",
    "title": "PHD: Pixel-Based Language Modeling of Historical Documents",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Nadav Borenstein",
        "Phillip Rust",
        "Desmond Elliott",
        "Isabelle Augenstein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.18343v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\00ae9127-82dd-5bbd-9d0f-c2a7a58d65fa.pdf",
    "bibtex": "@misc{borenstein2023phdpixelbasedlanguagemodelingof,\n    title = {PHD: Pixel-Based Language Modeling of Historical Documents},\n    author = {Nadav Borenstein and Phillip Rust and Desmond Elliott and Isabelle Augenstein},\n    year = {2023},\n    eprint = {2310.18343},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.18343},\n}",
    "abstract": "The digitisation of historical documents has provided historians with\nunprecedented research opportunities. Yet, the conventional approach to\nanalysing historical documents involves converting them from images to text\nusing OCR, a process that overlooks the potential benefits of treating them as\nimages and introduces high levels of noise. To bridge this gap, we take\nadvantage of recent advancements in pixel-based language models trained to\nreconstruct masked patches of pixels instead of predicting token distributions.\nDue to the scarcity of real historical scans, we propose a novel method for\ngenerating synthetic scans to resemble real historical documents. We then\npre-train our model, PHD, on a combination of synthetic scans and real\nhistorical newspapers from the 1700-1900 period. Through our experiments, we\ndemonstrate that PHD exhibits high proficiency in reconstructing masked image\npatches and provide evidence of our model's noteworthy language understanding\ncapabilities. Notably, we successfully apply our model to a historical QA task,\nhighlighting its usefulness in this domain.",
    "num_pages": 21
}