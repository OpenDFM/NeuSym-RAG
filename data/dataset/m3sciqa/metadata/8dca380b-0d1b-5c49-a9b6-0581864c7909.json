{
    "uuid": "8dca380b-0d1b-5c49-a9b6-0581864c7909",
    "title": "Knowledge-Augmented Language Model Verification",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Jinheon Baek",
        "Soyeong Jeong",
        "Minki Kang",
        "Jong C. Park",
        "Sung Ju Hwang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2310.12836v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\8dca380b-0d1b-5c49-a9b6-0581864c7909.pdf",
    "bibtex": "@misc{baek2023knowledgeaugmentedlanguagemodelverification,\n    title = {Knowledge-Augmented Language Model Verification},\n    author = {Jinheon Baek and Soyeong Jeong and Minki Kang and Jong C. Park and Sung Ju Hwang},\n    year = {2023},\n    eprint = {2310.12836},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2310.12836},\n}",
    "abstract": "Recent Language Models (LMs) have shown impressive capabilities in generating\ntexts with the knowledge internalized in parameters. Yet, LMs often generate\nthe factually incorrect responses to the given queries, since their knowledge\nmay be inaccurate, incomplete, and outdated. To address this problem, previous\nworks propose to augment LMs with the knowledge retrieved from an external\nknowledge source. However, such approaches often show suboptimal text\ngeneration performance due to two reasons: 1) the model may fail to retrieve\nthe knowledge relevant to the given query, or 2) the model may not faithfully\nreflect the retrieved knowledge in the generated text. To overcome these, we\npropose to verify the output and the knowledge of the knowledge-augmented LMs\nwith a separate verifier, which is a small LM that is trained to detect those\ntwo types of errors through instruction-finetuning. Then, when the verifier\nrecognizes an error, we can rectify it by either retrieving new knowledge or\ngenerating new text. Further, we use an ensemble of the outputs from different\ninstructions with a single verifier to enhance the reliability of the\nverification processes. We validate the effectiveness of the proposed\nverification steps on multiple question answering benchmarks, whose results\nshow that the proposed verifier effectively identifies retrieval and generation\nerrors, allowing LMs to provide more factually correct outputs. Our code is\navailable at https://github.com/JinheonBaek/KALMV.",
    "num_pages": 17
}