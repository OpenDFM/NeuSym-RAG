{
    "uuid": "c1db49ca-79d7-5a72-9405-3964e2de0c5c",
    "title": "Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2018,
    "authors": [
        "Logan Lebanoff",
        "Kaiqiang Song",
        "Fei Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/1808.06218v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2018\\c1db49ca-79d7-5a72-9405-3964e2de0c5c.pdf",
    "bibtex": "@misc{lebanoff2018adaptingtheneuralencoderdecoderframework,\n    title = {Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization},\n    author = {Logan Lebanoff and Kaiqiang Song and Fei Liu},\n    year = {2018},\n    eprint = {1808.06218},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1808.06218},\n}",
    "abstract": "Generating a text abstract from a set of documents remains a challenging\ntask. The neural encoder-decoder framework has recently been exploited to\nsummarize single documents, but its success can in part be attributed to the\navailability of large parallel data automatically acquired from the Web. In\ncontrast, parallel data for multi-document summarization are scarce and costly\nto obtain. There is a pressing need to adapt an encoder-decoder model trained\non single-document summarization data to work with multiple-document input. In\nthis paper, we present an initial investigation into a novel adaptation method.\nIt exploits the maximal marginal relevance method to select representative\nsentences from multi-document input, and leverages an abstractive\nencoder-decoder model to fuse disparate sentences to an abstractive summary.\nThe adaptation method is robust and itself requires no training data. Our\nsystem compares favorably to state-of-the-art extractive and abstractive\napproaches judged by automatic metrics and human assessors.",
    "num_pages": 11
}