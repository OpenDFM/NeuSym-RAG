{
    "uuid": "1cbc9c7a-e562-5d6a-af83-4f9a1520dce2",
    "title": "Structural generalization is hard for sequence-to-sequence models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Yuekun Yao",
        "Alexander Koller"
    ],
    "pdf_url": "http://arxiv.org/pdf/2210.13050v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\1cbc9c7a-e562-5d6a-af83-4f9a1520dce2.pdf",
    "bibtex": "@misc{yao2022structuralgeneralizationishardfor,\n    title = {Structural generalization is hard for sequence-to-sequence models},\n    author = {Yuekun Yao and Alexander Koller},\n    year = {2022},\n    eprint = {2210.13050},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2210.13050},\n}",
    "abstract": "Sequence-to-sequence (seq2seq) models have been successful across many NLP\ntasks, including ones that require predicting linguistic structure. However,\nrecent work on compositional generalization has shown that seq2seq models\nachieve very low accuracy in generalizing to linguistic structures that were\nnot seen in training. We present new evidence that this is a general limitation\nof seq2seq models that is present not just in semantic parsing, but also in\nsyntactic parsing and in text-to-text tasks, and that this limitation can often\nbe overcome by neurosymbolic models that have linguistic knowledge built in. We\nfurther report on some experiments that give initial answers on the reasons for\nthese limitations.",
    "num_pages": 15
}