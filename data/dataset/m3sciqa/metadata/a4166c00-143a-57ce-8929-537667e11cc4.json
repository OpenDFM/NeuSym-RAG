{
    "uuid": "a4166c00-143a-57ce-8929-537667e11cc4",
    "title": "CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Ge Zhang",
        "Yizhi Li",
        "Yaoyao Wu",
        "Linyuan Zhang",
        "Chenghua Lin",
        "Jiayi Geng",
        "Shi Wang",
        "Jie Fu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2301.00395v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\a4166c00-143a-57ce-8929-537667e11cc4.pdf",
    "bibtex": "@misc{zhang2023corgipmachinesecorpusfor,\n    title = {CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation},\n    author = {Ge Zhang and Yizhi Li and Yaoyao Wu and Linyuan Zhang and Chenghua Lin and Jiayi Geng and Shi Wang and Jie Fu},\n    year = {2023},\n    eprint = {2301.00395},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2301.00395},\n}",
    "abstract": "As natural language processing (NLP) for gender bias becomes a significant\ninterdisciplinary topic, the prevalent data-driven techniques such as\nlarge-scale language models suffer from data inadequacy and biased corpus,\nespecially for languages with insufficient resources such as Chinese. To this\nend, we propose a Chinese cOrpus foR Gender bIas Probing and Mitigation\nCORGI-PM, which contains 32.9k sentences with high-quality labels derived by\nfollowing an annotation scheme specifically developed for gender bias in the\nChinese context. Moreover, we address three challenges for automatic textual\ngender bias mitigation, which requires the models to detect, classify, and\nmitigate textual gender bias. We also conduct experiments with state-of-the-art\nlanguage models to provide baselines. To our best knowledge, CORGI-PM is the\nfirst sentence-level Chinese corpus for gender bias probing and mitigation.",
    "num_pages": 10
}