{
    "uuid": "d38add76-d914-522b-9c38-1adf92508b32",
    "title": "Compositional Generalization via Neural-Symbolic Stack Machines",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Xinyun Chen",
        "Chen Liang",
        "Adams Wei Yu",
        "Dawn Song",
        "Denny Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2008.06662v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\d38add76-d914-522b-9c38-1adf92508b32.pdf",
    "bibtex": "@misc{chen2020compositionalgeneralizationvianeuralsymbolicstack,\n    title = {Compositional Generalization via Neural-Symbolic Stack Machines},\n    author = {Xinyun Chen and Chen Liang and Adams Wei Yu and Dawn Song and Denny Zhou},\n    year = {2020},\n    eprint = {2008.06662},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2008.06662},\n}",
    "abstract": "Despite achieving tremendous success, existing deep learning models have\nexposed limitations in compositional generalization, the capability to learn\ncompositional rules and apply them to unseen cases in a systematic manner. To\ntackle this issue, we propose the Neural-Symbolic Stack Machine (NeSS). It\ncontains a neural network to generate traces, which are then executed by a\nsymbolic stack machine enhanced with sequence manipulation operations. NeSS\ncombines the expressive power of neural sequence models with the recursion\nsupported by the symbolic stack machine. Without training supervision on\nexecution traces, NeSS achieves 100% generalization performance in four\ndomains: the SCAN benchmark of language-driven navigation tasks, the task of\nfew-shot learning of compositional instructions, the compositional machine\ntranslation benchmark, and context-free grammar parsing tasks.",
    "num_pages": 19
}