{
    "uuid": "e4c15aff-f4fb-5699-ba7b-270af46c07ab",
    "title": "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Zhibin Gou",
        "Zhihong Shao",
        "Yeyun Gong",
        "Yelong Shen",
        "Yujiu Yang",
        "Nan Duan",
        "Weizhu Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.11738v4",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\e4c15aff-f4fb-5699-ba7b-270af46c07ab.pdf",
    "bibtex": "@misc{gou2024criticlargelanguagemodelscan,\n    title = {CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing},\n    author = {Zhibin Gou and Zhihong Shao and Yeyun Gong and Yelong Shen and Yujiu Yang and Nan Duan and Weizhu Chen},\n    year = {2024},\n    eprint = {2305.11738},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.11738},\n}",
    "abstract": "Recent developments in large language models (LLMs) have been impressive.\nHowever, these models sometimes show inconsistencies and problematic behavior,\nsuch as hallucinating facts, generating flawed code, or creating offensive and\ntoxic content. Unlike these models, humans typically utilize external tools to\ncross-check and refine their initial content, like using a search engine for\nfact-checking, or a code interpreter for debugging. Inspired by this\nobservation, we introduce a framework called CRITIC that allows LLMs, which are\nessentially \"black boxes\" to validate and progressively amend their own outputs\nin a manner similar to human interaction with tools. More specifically,\nstarting with an initial output, CRITIC interacts with appropriate tools to\nevaluate certain aspects of the text, and then revises the output based on the\nfeedback obtained during this validation process. Comprehensive evaluations\ninvolving free-form question answering, mathematical program synthesis, and\ntoxicity reduction demonstrate that CRITIC consistently enhances the\nperformance of LLMs. Meanwhile, our research highlights the crucial importance\nof external feedback in promoting the ongoing self-improvement of LLMs.",
    "num_pages": 78
}