{
    "uuid": "c4751155-479d-5cde-94e7-b27416febf8a",
    "title": "A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Valts Blukis",
        "Chris Paxton",
        "Dieter Fox",
        "Animesh Garg",
        "Yoav Artzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2107.05612v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\c4751155-479d-5cde-94e7-b27416febf8a.pdf",
    "bibtex": "@misc{blukis2021apersistentspatialsemanticrepresentation,\n    title = {A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution},\n    author = {Valts Blukis and Chris Paxton and Dieter Fox and Animesh Garg and Yoav Artzi},\n    year = {2021},\n    eprint = {2107.05612},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.RO},\n    url = {http://arxiv.org/abs/2107.05612},\n}",
    "abstract": "Natural language provides an accessible and expressive interface to specify\nlong-term tasks for robotic agents. However, non-experts are likely to specify\nsuch tasks with high-level instructions, which abstract over specific robot\nactions through several layers of abstraction. We propose that key to bridging\nthis gap between language and robot actions over long execution horizons are\npersistent representations. We propose a persistent spatial semantic\nrepresentation method, and show how it enables building an agent that performs\nhierarchical reasoning to effectively execute long-term tasks. We evaluate our\napproach on the ALFRED benchmark and achieve state-of-the-art results, despite\ncompletely avoiding the commonly used step-by-step instructions.",
    "num_pages": 22
}