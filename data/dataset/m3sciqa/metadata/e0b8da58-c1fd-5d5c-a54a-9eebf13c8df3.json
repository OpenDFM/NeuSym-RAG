{
    "uuid": "e0b8da58-c1fd-5d5c-a54a-9eebf13c8df3",
    "title": "Deep Learning on a Data Diet: Finding Important Examples Early in Training",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Mansheej Paul",
        "Surya Ganguli",
        "Gintare Karolina Dziugaite"
    ],
    "pdf_url": "http://arxiv.org/pdf/2107.07075v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\e0b8da58-c1fd-5d5c-a54a-9eebf13c8df3.pdf",
    "bibtex": "@misc{paul2023deeplearningonadata,\n    title = {Deep Learning on a Data Diet: Finding Important Examples Early in Training},\n    author = {Mansheej Paul and Surya Ganguli and Gintare Karolina Dziugaite},\n    year = {2023},\n    eprint = {2107.07075},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/2107.07075},\n}",
    "abstract": "Recent success in deep learning has partially been driven by training\nincreasingly overparametrized networks on ever larger datasets. It is therefore\nnatural to ask: how much of the data is superfluous, which examples are\nimportant for generalization, and how do we find them? In this work, we make\nthe striking observation that, in standard vision datasets, simple scores\naveraged over several weight initializations can be used to identify important\nexamples very early in training. We propose two such scores -- the Gradient\nNormed (GraNd) and the Error L2-Norm (EL2N) scores -- and demonstrate their\nefficacy on a range of architectures and datasets by pruning significant\nfractions of training data without sacrificing test accuracy. In fact, using\nEL2N scores calculated a few epochs into training, we can prune half of the\nCIFAR10 training set while slightly improving test accuracy. Furthermore, for a\ngiven dataset, EL2N scores from one architecture or hyperparameter\nconfiguration generalize to other configurations. Compared to recent work that\nprunes data by discarding examples that are rarely forgotten over the course of\ntraining, our scores use only local information early in training. We also use\nour scores to detect noisy examples and study training dynamics through the\nlens of important examples -- we investigate how the data distribution shapes\nthe loss surface and identify subspaces of the model's data representation that\nare relatively stable over training.",
    "num_pages": 21
}