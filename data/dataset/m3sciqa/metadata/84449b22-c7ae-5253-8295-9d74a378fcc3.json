{
    "uuid": "84449b22-c7ae-5253-8295-9d74a378fcc3",
    "title": "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Harsh Trivedi",
        "Niranjan Balasubramanian",
        "Tushar Khot",
        "Ashish Sabharwal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2212.10509v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\84449b22-c7ae-5253-8295-9d74a378fcc3.pdf",
    "bibtex": "@misc{trivedi2023interleavingretrievalwithchainofthoughtreasoning,\n    title = {Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions},\n    author = {Harsh Trivedi and Niranjan Balasubramanian and Tushar Khot and Ashish Sabharwal},\n    year = {2023},\n    eprint = {2212.10509},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2212.10509},\n}",
    "abstract": "Prompting-based large language models (LLMs) are surprisingly powerful at\ngenerating natural language reasoning steps or Chains-of-Thoughts (CoT) for\nmulti-step question answering (QA). They struggle, however, when the necessary\nknowledge is either unavailable to the LLM or not up-to-date within its\nparameters. While using the question to retrieve relevant text from an external\nknowledge source helps LLMs, we observe that this one-step retrieve-and-read\napproach is insufficient for multi-step QA. Here, \\textit{what to retrieve}\ndepends on \\textit{what has already been derived}, which in turn may depend on\n\\textit{what was previously retrieved}. To address this, we propose IRCoT, a\nnew approach for multi-step QA that interleaves retrieval with steps\n(sentences) in a CoT, guiding the retrieval with CoT and in turn using\nretrieved results to improve CoT. Using IRCoT with GPT3 substantially improves\nretrieval (up to 21 points) as well as downstream QA (up to 15 points) on four\ndatasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar\nsubstantial gains in out-of-distribution (OOD) settings as well as with much\nsmaller models such as Flan-T5-large without additional training. IRCoT reduces\nmodel hallucination, resulting in factually more accurate CoT reasoning. Code,\ndata, and prompts are available at \\url{https://github.com/stonybrooknlp/ircot}",
    "num_pages": 22
}