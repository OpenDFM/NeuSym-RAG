{
    "uuid": "945d086d-178d-52d6-aeb4-3988380b6b68",
    "title": "Context Variance Evaluation of Pretrained Language Models for Prompt-based Biomedical Knowledge Probing",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Zonghai Yao",
        "Yi Cao",
        "Zhichao Yang",
        "Hong Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2211.10265v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\945d086d-178d-52d6-aeb4-3988380b6b68.pdf",
    "bibtex": "@misc{yao2023contextvarianceevaluationofpretrained,\n    title = {Context Variance Evaluation of Pretrained Language Models for Prompt-based Biomedical Knowledge Probing},\n    author = {Zonghai Yao and Yi Cao and Zhichao Yang and Hong Yu},\n    year = {2023},\n    eprint = {2211.10265},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2211.10265},\n}",
    "abstract": "Pretrained language models (PLMs) have motivated research on what kinds of\nknowledge these models learn. Fill-in-the-blanks problem (e.g., cloze tests) is\na natural approach for gauging such knowledge. BioLAMA generates prompts for\nbiomedical factual knowledge triples and uses the Top-k accuracy metric to\nevaluate different PLMs' knowledge. However, existing research has shown that\nsuch prompt-based knowledge probing methods can only probe a lower bound of\nknowledge. Many factors like prompt-based probing biases make the LAMA\nbenchmark unreliable and unstable. This problem is more prominent in BioLAMA.\nThe severe long-tailed distribution in vocabulary and large-N-M relation make\nthe performance gap between LAMA and BioLAMA remain notable. To address these,\nwe introduce context variance into the prompt generation and propose a new\nrank-change-based evaluation metric. Different from the previous known-unknown\nevaluation criteria, we propose the concept of \"Misunderstand\" in LAMA for the\nfirst time. Through experiments on 12 PLMs, our context variance prompts and\nUnderstand-Confuse-Misunderstand (UCM) metric makes BioLAMA more friendly to\nlarge-N-M relations and rare relations. We also conducted a set of control\nexperiments to disentangle \"understand\" from just \"read and copy\".",
    "num_pages": 10
}