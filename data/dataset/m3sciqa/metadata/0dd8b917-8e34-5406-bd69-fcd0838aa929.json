{
    "uuid": "0dd8b917-8e34-5406-bd69-fcd0838aa929",
    "title": "TuckER: Tensor Factorization for Knowledge Graph Completion",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Ivana Balažević",
        "Carl Allen",
        "Timothy M. Hospedales"
    ],
    "pdf_url": "http://arxiv.org/pdf/1901.09590v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\0dd8b917-8e34-5406-bd69-fcd0838aa929.pdf",
    "bibtex": "@misc{balaevi2019tuckertensorfactorizationforknowledge,\n    title = {TuckER: Tensor Factorization for Knowledge Graph Completion},\n    author = {Ivana Balažević and Carl Allen and Timothy M. Hospedales},\n    year = {2019},\n    eprint = {1901.09590},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1901.09590},\n}",
    "abstract": "Knowledge graphs are structured representations of real world facts. However,\nthey typically contain only a small subset of all possible facts. Link\nprediction is a task of inferring missing facts based on existing ones. We\npropose TuckER, a relatively straightforward but powerful linear model based on\nTucker decomposition of the binary tensor representation of knowledge graph\ntriples. TuckER outperforms previous state-of-the-art models across standard\nlink prediction datasets, acting as a strong baseline for more elaborate\nmodels. We show that TuckER is a fully expressive model, derive sufficient\nbounds on its embedding dimensionalities and demonstrate that several\npreviously introduced linear models can be viewed as special cases of TuckER.",
    "num_pages": 11
}