{
    "uuid": "2697ec60-b994-5ce0-9c67-06ecde1dc5de",
    "title": "Rethinking Negative Sampling for Handling Missing Entity Annotations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Yangming Li",
        "Lemao Liu",
        "Shuming Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2108.11607v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\2697ec60-b994-5ce0-9c67-06ecde1dc5de.pdf",
    "bibtex": "@misc{li2022rethinkingnegativesamplingforhandling,\n    title = {Rethinking Negative Sampling for Handling Missing Entity Annotations},\n    author = {Yangming Li and Lemao Liu and Shuming Shi},\n    year = {2022},\n    eprint = {2108.11607},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2108.11607},\n}",
    "abstract": "Negative sampling is highly effective in handling missing annotations for\nnamed entity recognition (NER). One of our contributions is an analysis on how\nit makes sense through introducing two insightful concepts: missampling and\nuncertainty. Empirical studies show low missampling rate and high uncertainty\nare both essential for achieving promising performances with negative sampling.\nBased on the sparsity of named entities, we also theoretically derive a lower\nbound for the probability of zero missampling rate, which is only relevant to\nsentence length. The other contribution is an adaptive and weighted sampling\ndistribution that further improves negative sampling via our former analysis.\nExperiments on synthetic datasets and well-annotated datasets (e.g.,\nCoNLL-2003) show that our proposed approach benefits negative sampling in terms\nof F1 score and loss convergence. Besides, models with improved negative\nsampling have achieved new state-of-the-art results on real-world datasets\n(e.g., EC).",
    "num_pages": 10
}