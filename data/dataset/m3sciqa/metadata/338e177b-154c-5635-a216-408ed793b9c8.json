{
    "uuid": "338e177b-154c-5635-a216-408ed793b9c8",
    "title": "Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Jing Zhang",
        "Xiaokang Zhang",
        "Jifan Yu",
        "Jian Tang",
        "Jie Tang",
        "Cuiping Li",
        "Hong Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2202.13296v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\338e177b-154c-5635-a216-408ed793b9c8.pdf",
    "bibtex": "@misc{zhang2022subgraphretrievalenhancedmodelfor,\n    title = {Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering},\n    author = {Jing Zhang and Xiaokang Zhang and Jifan Yu and Jian Tang and Jie Tang and Cuiping Li and Hong Chen},\n    year = {2022},\n    eprint = {2202.13296},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2202.13296},\n}",
    "abstract": "Recent works on knowledge base question answering (KBQA) retrieve subgraphs\nfor easier reasoning. A desired subgraph is crucial as a small one may exclude\nthe answer but a large one might introduce more noises. However, the existing\nretrieval is either heuristic or interwoven with the reasoning, causing\nreasoning on the partial subgraphs, which increases the reasoning bias when the\nintermediate supervision is missing. This paper proposes a trainable subgraph\nretriever (SR) decoupled from the subsequent reasoning process, which enables a\nplug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive\nexperiments demonstrate SR achieves significantly better retrieval and QA\nperformance than existing retrieval methods. Via weakly supervised pre-training\nas well as the end-to-end fine-tuning, SRl achieves new state-of-the-art\nperformance when combined with NSM, a subgraph-oriented reasoner, for\nembedding-based KBQA methods.",
    "num_pages": 12
}