{
    "uuid": "81f14584-369f-51cd-b3ad-c34dcf1b45a1",
    "title": "Recurrent Neural Network Grammars",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2016,
    "authors": [
        "Chris Dyer",
        "Adhiguna Kuncoro",
        "Miguel Ballesteros",
        "Noah A. Smith"
    ],
    "pdf_url": "http://arxiv.org/pdf/1602.07776v4",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2016\\81f14584-369f-51cd-b3ad-c34dcf1b45a1.pdf",
    "bibtex": "@misc{dyer2016recurrentneuralnetworkgrammars,\n    title = {Recurrent Neural Network Grammars},\n    author = {Chris Dyer and Adhiguna Kuncoro and Miguel Ballesteros and Noah A. Smith},\n    year = {2016},\n    eprint = {1602.07776},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1602.07776},\n}",
    "abstract": "We introduce recurrent neural network grammars, probabilistic models of\nsentences with explicit phrase structure. We explain efficient inference\nprocedures that allow application to both parsing and language modeling.\nExperiments show that they provide better parsing in English than any single\npreviously published supervised generative model and better language modeling\nthan state-of-the-art sequential RNNs in English and Chinese.",
    "num_pages": 13
}