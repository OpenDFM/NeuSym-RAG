{
    "uuid": "90d02a2b-330f-5255-a4bd-e341c87e0631",
    "title": "Survey of Hallucination in Natural Language Generation",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Ziwei Ji",
        "Nayeon Lee",
        "Rita Frieske",
        "Tiezheng Yu",
        "Dan Su",
        "Yan Xu",
        "Etsuko Ishii",
        "Yejin Bang",
        "Delong Chen",
        "Wenliang Dai",
        "Ho Shu Chan",
        "Andrea Madotto",
        "Pascale Fung"
    ],
    "pdf_url": "http://arxiv.org/pdf/2202.03629v7",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\90d02a2b-330f-5255-a4bd-e341c87e0631.pdf",
    "bibtex": "@misc{ji2024surveyofhallucinationinnatural,\n    title = {Survey of Hallucination in Natural Language Generation},\n    author = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Yejin Bang and Delong Chen and Wenliang Dai and Ho Shu Chan and Andrea Madotto and Pascale Fung},\n    year = {2024},\n    eprint = {2202.03629},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2202.03629},\n}",
    "abstract": "Natural Language Generation (NLG) has improved exponentially in recent years\nthanks to the development of sequence-to-sequence deep learning technologies\nsuch as Transformer-based language models. This advancement has led to more\nfluent and coherent NLG, leading to improved development in downstream tasks\nsuch as abstractive summarization, dialogue generation and data-to-text\ngeneration. However, it is also apparent that deep learning based generation is\nprone to hallucinate unintended text, which degrades the system performance and\nfails to meet user expectations in many real-world scenarios. To address this\nissue, many studies have been presented in measuring and mitigating\nhallucinated texts, but these have never been reviewed in a comprehensive\nmanner before. In this survey, we thus provide a broad overview of the research\nprogress and challenges in the hallucination problem in NLG. The survey is\norganized into two parts: (1) a general overview of metrics, mitigation\nmethods, and future directions; (2) an overview of task-specific research\nprogress on hallucinations in the following downstream tasks, namely\nabstractive summarization, dialogue generation, generative question answering,\ndata-to-text generation, machine translation, and visual-language generation;\nand (3) hallucinations in large language models (LLMs). This survey serves to\nfacilitate collaborative efforts among researchers in tackling the challenge of\nhallucinated texts in NLG.",
    "num_pages": 59
}