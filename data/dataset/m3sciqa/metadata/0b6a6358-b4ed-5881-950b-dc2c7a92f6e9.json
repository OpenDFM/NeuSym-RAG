{
    "uuid": "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9",
    "title": "Evaluating the Ripple Effects of Knowledge Editing in Language Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Roi Cohen",
        "Eden Biran",
        "Ori Yoran",
        "Amir Globerson",
        "Mor Geva"
    ],
    "pdf_url": "http://arxiv.org/pdf/2307.12976v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\0b6a6358-b4ed-5881-950b-dc2c7a92f6e9.pdf",
    "bibtex": "@misc{cohen2023evaluatingtherippleeffectsof,\n    title = {Evaluating the Ripple Effects of Knowledge Editing in Language Models},\n    author = {Roi Cohen and Eden Biran and Ori Yoran and Amir Globerson and Mor Geva},\n    year = {2023},\n    eprint = {2307.12976},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2307.12976},\n}",
    "abstract": "Modern language models capture a large body of factual knowledge. However,\nsome facts can be incorrectly induced or become obsolete over time, resulting\nin factually incorrect generations. This has led to the development of various\nediting methods that allow updating facts encoded by the model. Evaluation of\nthese methods has primarily focused on testing whether an individual fact has\nbeen successfully injected, and if similar predictions for other subjects have\nnot changed. Here we argue that such evaluation is limited, since injecting one\nfact (e.g. ``Jack Depp is the son of Johnny Depp'') introduces a ``ripple\neffect'' in the form of additional facts that the model needs to update\n(e.g.``Jack Depp is the sibling of Lily-Rose Depp''). To address this issue, we\npropose a novel set of evaluation criteria that consider the implications of an\nedit on related facts. Using these criteria, we then construct RippleEdits, a\ndiagnostic benchmark of 5K factual edits, capturing a variety of types of\nripple effects. We evaluate prominent editing methods on RippleEdits, showing\nthat current methods fail to introduce consistent changes in the model's\nknowledge. In addition, we find that a simple in-context editing baseline\nobtains the best scores on our benchmark, suggesting a promising research\ndirection for model editing.",
    "num_pages": 15
}