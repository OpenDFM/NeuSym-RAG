{
    "uuid": "dbe6cf51-ba01-5f0d-83b3-e29f71bafbf1",
    "title": "Axiomatic Attribution for Deep Networks",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2017,
    "authors": [
        "Mukund Sundararajan",
        "Ankur Taly",
        "Qiqi Yan"
    ],
    "pdf_url": "http://arxiv.org/pdf/1703.01365v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2017\\dbe6cf51-ba01-5f0d-83b3-e29f71bafbf1.pdf",
    "bibtex": "@misc{sundararajan2017axiomaticattributionfordeepnetworks,\n    title = {Axiomatic Attribution for Deep Networks},\n    author = {Mukund Sundararajan and Ankur Taly and Qiqi Yan},\n    year = {2017},\n    eprint = {1703.01365},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG},\n    url = {http://arxiv.org/abs/1703.01365},\n}",
    "abstract": "We study the problem of attributing the prediction of a deep network to its\ninput features, a problem previously studied by several other works. We\nidentify two fundamental axioms---Sensitivity and Implementation Invariance\nthat attribution methods ought to satisfy. We show that they are not satisfied\nby most known attribution methods, which we consider to be a fundamental\nweakness of those methods. We use the axioms to guide the design of a new\nattribution method called Integrated Gradients. Our method requires no\nmodification to the original network and is extremely simple to implement; it\njust needs a few calls to the standard gradient operator. We apply this method\nto a couple of image models, a couple of text models and a chemistry model,\ndemonstrating its ability to debug networks, to extract rules from a network,\nand to enable users to engage with models better.",
    "num_pages": 11
}