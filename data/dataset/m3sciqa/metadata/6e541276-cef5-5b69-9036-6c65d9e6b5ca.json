{
    "uuid": "6e541276-cef5-5b69-9036-6c65d9e6b5ca",
    "title": "Surface Form Competition: Why the Highest Probability Answer Isn't Always Right",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Ari Holtzman",
        "Peter West",
        "Vered Shwartz",
        "Yejin Choi",
        "Luke Zettlemoyer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2104.08315v9",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\6e541276-cef5-5b69-9036-6c65d9e6b5ca.pdf",
    "bibtex": "@misc{holtzman2022surfaceformcompetitionwhythe,\n    title = {Surface Form Competition: Why the Highest Probability Answer Isn't Always Right},\n    author = {Ari Holtzman and Peter West and Vered Shwartz and Yejin Choi and Luke Zettlemoyer},\n    year = {2022},\n    eprint = {2104.08315},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2104.08315},\n}",
    "abstract": "Large language models have shown promising results in zero-shot settings\n(Brown et al.,2020; Radford et al., 2019). For example, they can perform\nmultiple choice tasks simply by conditioning on a question and selecting the\nanswer with the highest probability.\n  However, ranking by string probability can be problematic due to surface form\ncompetition-wherein different surface forms compete for probability mass, even\nif they represent the same underlying concept, e.g. \"computer\" and \"PC.\" Since\nprobability mass is finite, this lowers the probability of the correct answer,\ndue to competition from other strings that are valid answers (but not one of\nthe multiple choice options).\n  We introduce Domain Conditional Pointwise Mutual Information, an alternative\nscoring function that directly compensates for surface form competition by\nsimply reweighing each option according to a term that is proportional to its a\npriori likelihood within the context of the specific zero-shot task. It\nachieves consistent gains in zero-shot performance over both calibrated (Zhao\net al., 2021) and uncalibrated scoring functions on all GPT-2 and GPT-3 models\nover a variety of multiple choice datasets.",
    "num_pages": 14
}