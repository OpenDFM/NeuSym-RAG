{
    "uuid": "f7306500-2b64-5ee2-9f7e-f4beb3b0ebcf",
    "title": "Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Kalpesh Krishna",
        "Yixiao Song",
        "Marzena Karpinska",
        "John Wieting",
        "Mohit Iyyer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2303.13408v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\f7306500-2b64-5ee2-9f7e-f4beb3b0ebcf.pdf",
    "bibtex": "@misc{krishna2023paraphrasingevadesdetectorsofaigenerated,\n    title = {Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense},\n    author = {Kalpesh Krishna and Yixiao Song and Marzena Karpinska and John Wieting and Mohit Iyyer},\n    year = {2023},\n    eprint = {2303.13408},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2303.13408},\n}",
    "abstract": "The rise in malicious usage of large language models, such as fake content\ncreation and academic plagiarism, has motivated the development of approaches\nthat identify AI-generated text, including those based on watermarking or\noutlier detection. However, the robustness of these detection algorithms to\nparaphrases of AI-generated text remains unclear. To stress test these\ndetectors, we build a 11B parameter paraphrase generation model (DIPPER) that\ncan paraphrase paragraphs, condition on surrounding context, and control\nlexical diversity and content reordering. Using DIPPER to paraphrase text\ngenerated by three large language models (including GPT3.5-davinci-003)\nsuccessfully evades several detectors, including watermarking, GPTZero,\nDetectGPT, and OpenAI's text classifier. For example, DIPPER drops detection\naccuracy of DetectGPT from 70.3% to 4.6% (at a constant false positive rate of\n1%), without appreciably modifying the input semantics.\n  To increase the robustness of AI-generated text detection to paraphrase\nattacks, we introduce a simple defense that relies on retrieving\nsemantically-similar generations and must be maintained by a language model API\nprovider. Given a candidate text, our algorithm searches a database of\nsequences previously generated by the API, looking for sequences that match the\ncandidate text within a certain threshold. We empirically verify our defense\nusing a database of 15M generations from a fine-tuned T5-XXL model and find\nthat it can detect 80% to 97% of paraphrased generations across different\nsettings while only classifying 1% of human-written sequences as AI-generated.\nWe open-source our models, code and data.",
    "num_pages": 32
}