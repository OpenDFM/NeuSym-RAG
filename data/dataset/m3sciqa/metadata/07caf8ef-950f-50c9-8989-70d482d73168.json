{
    "uuid": "07caf8ef-950f-50c9-8989-70d482d73168",
    "title": "Defending Against Neural Fake News",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Rowan Zellers",
        "Ari Holtzman",
        "Hannah Rashkin",
        "Yonatan Bisk",
        "Ali Farhadi",
        "Franziska Roesner",
        "Yejin Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/1905.12616v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\07caf8ef-950f-50c9-8989-70d482d73168.pdf",
    "bibtex": "@misc{zellers2020defendingagainstneuralfakenews,\n    title = {Defending Against Neural Fake News},\n    author = {Rowan Zellers and Ari Holtzman and Hannah Rashkin and Yonatan Bisk and Ali Farhadi and Franziska Roesner and Yejin Choi},\n    year = {2020},\n    eprint = {1905.12616},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1905.12616},\n}",
    "abstract": "Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.",
    "num_pages": 21
}