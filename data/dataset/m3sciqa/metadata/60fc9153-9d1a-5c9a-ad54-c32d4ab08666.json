{
    "uuid": "60fc9153-9d1a-5c9a-ad54-c32d4ab08666",
    "title": "Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented Dialogues and Annotations",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Tiziano Labruna",
        "Sofia Brenna",
        "Andrea Zaninello",
        "Bernardo Magnini"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.14556v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\60fc9153-9d1a-5c9a-ad54-c32d4ab08666.pdf",
    "bibtex": "@misc{labruna2023unravelingchatgptacriticalanalysis,\n    title = {Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented Dialogues and Annotations},\n    author = {Tiziano Labruna and Sofia Brenna and Andrea Zaninello and Bernardo Magnini},\n    year = {2023},\n    eprint = {2305.14556},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2305.14556},\n}",
    "abstract": "Large pre-trained language models have exhibited unprecedented capabilities\nin producing high-quality text via prompting techniques. This fact introduces\nnew possibilities for data collection and annotation, particularly in\nsituations where such data is scarce, complex to gather, expensive, or even\nsensitive. In this paper, we explore the potential of these models to generate\nand annotate goal-oriented dialogues, and conduct an in-depth analysis to\nevaluate their quality. Our experiments employ ChatGPT, and encompass three\ncategories of goal-oriented dialogues (task-oriented, collaborative, and\nexplanatory), two generation modes (interactive and one-shot), and two\nlanguages (English and Italian). Based on extensive human-based evaluations, we\ndemonstrate that the quality of generated dialogues and annotations is on par\nwith those generated by humans.",
    "num_pages": 14
}