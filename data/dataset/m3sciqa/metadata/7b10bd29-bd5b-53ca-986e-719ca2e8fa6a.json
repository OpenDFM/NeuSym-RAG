{
    "uuid": "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a",
    "title": "GoEmotions: A Dataset of Fine-Grained Emotions",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Dorottya Demszky",
        "Dana Movshovitz-Attias",
        "Jeongwoo Ko",
        "Alan Cowen",
        "Gaurav Nemade",
        "Sujith Ravi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2005.00547v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\7b10bd29-bd5b-53ca-986e-719ca2e8fa6a.pdf",
    "bibtex": "@misc{demszky2020goemotionsadatasetoffinegrained,\n    title = {GoEmotions: A Dataset of Fine-Grained Emotions},\n    author = {Dorottya Demszky and Dana Movshovitz-Attias and Jeongwoo Ko and Alan Cowen and Gaurav Nemade and Sujith Ravi},\n    year = {2020},\n    eprint = {2005.00547},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2005.00547},\n}",
    "abstract": "Understanding emotion expressed in language has a wide range of applications,\nfrom building empathetic chatbots to detecting harmful online behavior.\nAdvancement in this area can be improved using large-scale datasets with a\nfine-grained typology, adaptable to multiple downstream tasks. We introduce\nGoEmotions, the largest manually annotated dataset of 58k English Reddit\ncomments, labeled for 27 emotion categories or Neutral. We demonstrate the high\nquality of the annotations via Principal Preserved Component Analysis. We\nconduct transfer learning experiments with existing emotion benchmarks to show\nthat our dataset generalizes well to other domains and different emotion\ntaxonomies. Our BERT-based model achieves an average F1-score of .46 across our\nproposed taxonomy, leaving much room for improvement.",
    "num_pages": 15
}