{
    "uuid": "49b4cdbd-7730-5f6c-9be1-e404ddf81009",
    "title": "ICDAR 2023 Competition on Structured Text Extraction from Visually-Rich Document Images",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Wenwen Yu",
        "Chengquan Zhang",
        "Haoyu Cao",
        "Wei Hua",
        "Bohan Li",
        "Huang Chen",
        "Mingyu Liu",
        "Mingrui Chen",
        "Jianfeng Kuang",
        "Mengjun Cheng",
        "Yuning Du",
        "Shikun Feng",
        "Xiaoguang Hu",
        "Pengyuan Lyu",
        "Kun Yao",
        "Yuechen Yu",
        "Yuliang Liu",
        "Wanxiang Che",
        "Errui Ding",
        "Cheng-Lin Liu",
        "Jiebo Luo",
        "Shuicheng Yan",
        "Min Zhang",
        "Dimosthenis Karatzas",
        "Xing Sun",
        "Jingdong Wang",
        "Xiang Bai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2306.03287v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\49b4cdbd-7730-5f6c-9be1-e404ddf81009.pdf",
    "bibtex": "@misc{yu2023icdar2023competitiononstructured,\n    title = {ICDAR 2023 Competition on Structured Text Extraction from Visually-Rich Document Images},\n    author = {Wenwen Yu and Chengquan Zhang and Haoyu Cao and Wei Hua and Bohan Li and Huang Chen and Mingyu Liu and Mingrui Chen and Jianfeng Kuang and Mengjun Cheng and Yuning Du and Shikun Feng and Xiaoguang Hu and Pengyuan Lyu and Kun Yao and Yuechen Yu and Yuliang Liu and Wanxiang Che and Errui Ding and Cheng-Lin Liu and Jiebo Luo and Shuicheng Yan and Min Zhang and Dimosthenis Karatzas and Xing Sun and Jingdong Wang and Xiang Bai},\n    year = {2023},\n    eprint = {2306.03287},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2306.03287},\n}",
    "abstract": "Structured text extraction is one of the most valuable and challenging\napplication directions in the field of Document AI. However, the scenarios of\npast benchmarks are limited, and the corresponding evaluation protocols usually\nfocus on the submodules of the structured text extraction scheme. In order to\neliminate these problems, we organized the ICDAR 2023 competition on Structured\ntext extraction from Visually-Rich Document images (SVRD). We set up two tracks\nfor SVRD including Track 1: HUST-CELL and Track 2: Baidu-FEST, where HUST-CELL\naims to evaluate the end-to-end performance of Complex Entity Linking and\nLabeling, and Baidu-FEST focuses on evaluating the performance and\ngeneralization of Zero-shot / Few-shot Structured Text extraction from an\nend-to-end perspective. Compared to the current document benchmarks, our two\ntracks of competition benchmark enriches the scenarios greatly and contains\nmore than 50 types of visually-rich document images (mainly from the actual\nenterprise applications). The competition opened on 30th December, 2022 and\nclosed on 24th March, 2023. There are 35 participants and 91 valid submissions\nreceived for Track 1, and 15 participants and 26 valid submissions received for\nTrack 2. In this report we will presents the motivation, competition datasets,\ntask definition, evaluation protocol, and submission summaries. According to\nthe performance of the submissions, we believe there is still a large gap on\nthe expected information extraction performance for complex and zero-shot\nscenarios. It is hoped that this competition will attract many researchers in\nthe field of CV and NLP, and bring some new thoughts to the field of Document\nAI.",
    "num_pages": 17
}