{
    "uuid": "3c47cf47-b671-55d5-a396-e294638f7023",
    "title": "SWING: Balancing Coverage and Faithfulness for Dialogue Summarization",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Kung-Hsiang Huang",
        "Siffi Singh",
        "Xiaofei Ma",
        "Wei Xiao",
        "Feng Nan",
        "Nicholas Dingwall",
        "William Yang Wang",
        "Kathleen McKeown"
    ],
    "pdf_url": "http://arxiv.org/pdf/2301.10483v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\3c47cf47-b671-55d5-a396-e294638f7023.pdf",
    "bibtex": "@misc{huang2023swingbalancingcoverageandfaithfulness,\n    title = {SWING: Balancing Coverage and Faithfulness for Dialogue Summarization},\n    author = {Kung-Hsiang Huang and Siffi Singh and Xiaofei Ma and Wei Xiao and Feng Nan and Nicholas Dingwall and William Yang Wang and Kathleen McKeown},\n    year = {2023},\n    eprint = {2301.10483},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2301.10483},\n}",
    "abstract": "Missing information is a common issue of dialogue summarization where some\ninformation in the reference summaries is not covered in the generated\nsummaries. To address this issue, we propose to utilize natural language\ninference (NLI) models to improve coverage while avoiding introducing factual\ninconsistencies. Specifically, we use NLI to compute fine-grained training\nsignals to encourage the model to generate content in the reference summaries\nthat have not been covered, as well as to distinguish between factually\nconsistent and inconsistent generated sentences. Experiments on the DialogSum\nand SAMSum datasets confirm the effectiveness of the proposed approach in\nbalancing coverage and faithfulness, validated with automatic metrics and human\nevaluations. Additionally, we compute the correlation between commonly used\nautomatic metrics with human judgments in terms of three different dimensions\nregarding coverage and factual consistency to provide insight into the most\nsuitable metric for evaluating dialogue summaries.",
    "num_pages": 14
}