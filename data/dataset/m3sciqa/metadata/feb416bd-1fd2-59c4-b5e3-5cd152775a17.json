{
    "uuid": "feb416bd-1fd2-59c4-b5e3-5cd152775a17",
    "title": "Dissociating language and thought in large language models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2024,
    "authors": [
        "Kyle Mahowald",
        "Anna A. Ivanova",
        "Idan A. Blank",
        "Nancy Kanwisher",
        "Joshua B. Tenenbaum",
        "Evelina Fedorenko"
    ],
    "pdf_url": "http://arxiv.org/pdf/2301.06627v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2024\\feb416bd-1fd2-59c4-b5e3-5cd152775a17.pdf",
    "bibtex": "@misc{mahowald2024dissociatinglanguageandthoughtin,\n    title = {Dissociating language and thought in large language models},\n    author = {Kyle Mahowald and Anna A. Ivanova and Idan A. Blank and Nancy Kanwisher and Joshua B. Tenenbaum and Evelina Fedorenko},\n    year = {2024},\n    eprint = {2301.06627},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2301.06627},\n}",
    "abstract": "Large Language Models (LLMs) have come closest among all models to date to\nmastering human language, yet opinions about their linguistic and cognitive\ncapabilities remain split. Here, we evaluate LLMs using a distinction between\nformal linguistic competence -- knowledge of linguistic rules and patterns --\nand functional linguistic competence -- understanding and using language in the\nworld. We ground this distinction in human neuroscience, which has shown that\nformal and functional competence rely on different neural mechanisms. Although\nLLMs are surprisingly good at formal competence, their performance on\nfunctional competence tasks remains spotty and often requires specialized\nfine-tuning and/or coupling with external modules. We posit that models that\nuse language in human-like ways would need to master both of these competence\ntypes, which, in turn, could require the emergence of mechanisms specialized\nfor formal linguistic competence, distinct from functional competence.",
    "num_pages": 30
}