{
    "uuid": "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7",
    "title": "Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Hao Tan",
        "Licheng Yu",
        "Mohit Bansal"
    ],
    "pdf_url": "http://arxiv.org/pdf/1904.04195v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7.pdf",
    "bibtex": "@misc{tan2019learningtonavigateunseenenvironments,\n    title = {Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout},\n    author = {Hao Tan and Licheng Yu and Mohit Bansal},\n    year = {2019},\n    eprint = {1904.04195},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1904.04195},\n}",
    "abstract": "A grand goal in AI is to build a robot that can accurately navigate based on\nnatural language instructions, which requires the agent to perceive the scene,\nunderstand and ground language, and act in the real-world environment. One key\nchallenge here is to learn to navigate in new environments that are unseen\nduring training. Most of the existing approaches perform dramatically worse in\nunseen environments as compared to seen ones. In this paper, we present a\ngeneralizable navigational agent. Our agent is trained in two stages. The first\nstage is training via mixed imitation and reinforcement learning, combining the\nbenefits from both off-policy and on-policy optimization. The second stage is\nfine-tuning via newly-introduced 'unseen' triplets (environment, path,\ninstruction). To generate these unseen triplets, we propose a simple but\neffective 'environmental dropout' method to mimic unseen environments, which\novercomes the problem of limited seen environment variability. Next, we apply\nsemi-supervised learning (via back-translation) on these dropped-out\nenvironments to generate new paths and instructions. Empirically, we show that\nour agent is substantially better at generalizability when fine-tuned with\nthese triplets, outperforming the state-of-art approaches by a large margin on\nthe private unseen test set of the Room-to-Room task, and achieving the top\nrank on the leaderboard.",
    "num_pages": 12
}