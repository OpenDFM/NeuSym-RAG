{
    "uuid": "34ea827e-75b7-5db5-8f5f-635ac55b4a5e",
    "title": "DiT: Self-supervised Pre-training for Document Image Transformer",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Junlong Li",
        "Yiheng Xu",
        "Tengchao Lv",
        "Lei Cui",
        "Cha Zhang",
        "Furu Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2203.02378v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\34ea827e-75b7-5db5-8f5f-635ac55b4a5e.pdf",
    "bibtex": "@misc{li2022ditselfsupervisedpretrainingfordocument,\n    title = {DiT: Self-supervised Pre-training for Document Image Transformer},\n    author = {Junlong Li and Yiheng Xu and Tengchao Lv and Lei Cui and Cha Zhang and Furu Wei},\n    year = {2022},\n    eprint = {2203.02378},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2203.02378},\n}",
    "abstract": "Image Transformer has recently achieved significant progress for natural\nimage understanding, either using supervised (ViT, DeiT, etc.) or\nself-supervised (BEiT, MAE, etc.) pre-training techniques. In this paper, we\npropose \\textbf{DiT}, a self-supervised pre-trained \\textbf{D}ocument\n\\textbf{I}mage \\textbf{T}ransformer model using large-scale unlabeled text\nimages for Document AI tasks, which is essential since no supervised\ncounterparts ever exist due to the lack of human-labeled document images. We\nleverage DiT as the backbone network in a variety of vision-based Document AI\ntasks, including document image classification, document layout analysis, table\ndetection as well as text detection for OCR. Experiment results have\nillustrated that the self-supervised pre-trained DiT model achieves new\nstate-of-the-art results on these downstream tasks, e.g. document image\nclassification (91.11 $\\rightarrow$ 92.69), document layout analysis (91.0\n$\\rightarrow$ 94.9), table detection (94.23 $\\rightarrow$ 96.55) and text\ndetection for OCR (93.07 $\\rightarrow$ 94.29). The code and pre-trained models\nare publicly available at \\url{https://aka.ms/msdit}.",
    "num_pages": 10
}