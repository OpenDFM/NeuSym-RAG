{
    "uuid": "10394dc5-9259-54c9-8868-bf2692924ffa",
    "title": "Neural Network Acceptability Judgments",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2019,
    "authors": [
        "Alex Warstadt",
        "Amanpreet Singh",
        "Samuel R. Bowman"
    ],
    "pdf_url": "http://arxiv.org/pdf/1805.12471v3",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2019\\10394dc5-9259-54c9-8868-bf2692924ffa.pdf",
    "bibtex": "@misc{warstadt2019neuralnetworkacceptabilityjudgments,\n    title = {Neural Network Acceptability Judgments},\n    author = {Alex Warstadt and Amanpreet Singh and Samuel R. Bowman},\n    year = {2019},\n    eprint = {1805.12471},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1805.12471},\n}",
    "abstract": "This paper investigates the ability of artificial neural networks to judge\nthe grammatical acceptability of a sentence, with the goal of testing their\nlinguistic competence. We introduce the Corpus of Linguistic Acceptability\n(CoLA), a set of 10,657 English sentences labeled as grammatical or\nungrammatical from published linguistics literature. As baselines, we train\nseveral recurrent neural network models on acceptability classification, and\nfind that our models outperform unsupervised models by Lau et al (2016) on\nCoLA. Error-analysis on specific grammatical phenomena reveals that both Lau et\nal.'s models and ours learn systematic generalizations like subject-verb-object\norder. However, all models we test perform far below human level on a wide\nrange of grammatical constructions.",
    "num_pages": 17
}