{
    "uuid": "88ac1798-77b6-575e-bb56-686a270f2b90",
    "title": "LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training for Document Understanding",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Yi Tu",
        "Ya Guo",
        "Huan Chen",
        "Jinyang Tang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2305.18721v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\88ac1798-77b6-575e-bb56-686a270f2b90.pdf",
    "bibtex": "@misc{tu2023layoutmaskenhancetextlayoutinteractionin,\n    title = {LayoutMask: Enhance Text-Layout Interaction in Multi-modal Pre-training for Document Understanding},\n    author = {Yi Tu and Ya Guo and Huan Chen and Jinyang Tang},\n    year = {2023},\n    eprint = {2305.18721},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV},\n    url = {http://arxiv.org/abs/2305.18721},\n}",
    "abstract": "Visually-rich Document Understanding (VrDU) has attracted much research\nattention over the past years. Pre-trained models on a large number of document\nimages with transformer-based backbones have led to significant performance\ngains in this field. The major challenge is how to fusion the different\nmodalities (text, layout, and image) of the documents in a unified model with\ndifferent pre-training tasks. This paper focuses on improving text-layout\ninteractions and proposes a novel multi-modal pre-training model, LayoutMask.\nLayoutMask uses local 1D position, instead of global 1D position, as layout\ninput and has two pre-training objectives: (1) Masked Language Modeling:\npredicting masked tokens with two novel masking strategies; (2) Masked Position\nModeling: predicting masked 2D positions to improve layout representation\nlearning. LayoutMask can enhance the interactions between text and layout\nmodalities in a unified model and produce adaptive and robust multi-modal\nrepresentations for downstream tasks. Experimental results show that our\nproposed method can achieve state-of-the-art results on a wide variety of VrDU\nproblems, including form understanding, receipt understanding, and document\nimage classification.",
    "num_pages": 11
}