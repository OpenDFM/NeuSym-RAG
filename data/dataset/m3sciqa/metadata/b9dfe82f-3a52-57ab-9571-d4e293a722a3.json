{
    "uuid": "b9dfe82f-3a52-57ab-9571-d4e293a722a3",
    "title": "The Curious Case of Neural Text Degeneration",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2020,
    "authors": [
        "Ari Holtzman",
        "Jan Buys",
        "Li Du",
        "Maxwell Forbes",
        "Yejin Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/1904.09751v2",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2020\\b9dfe82f-3a52-57ab-9571-d4e293a722a3.pdf",
    "bibtex": "@misc{holtzman2020thecuriouscaseofneural,\n    title = {The Curious Case of Neural Text Degeneration},\n    author = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},\n    year = {2020},\n    eprint = {1904.09751},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1904.09751},\n}",
    "abstract": "Despite considerable advancements with deep neural language models, the\nenigma of neural text degeneration persists when these models are tested as\ntext generators. The counter-intuitive empirical observation is that even\nthough the use of likelihood as training objective leads to high quality models\nfor a broad range of language understanding tasks, using likelihood as a\ndecoding objective leads to text that is bland and strangely repetitive.\n  In this paper, we reveal surprising distributional differences between human\ntext and machine text. In addition, we find that decoding strategies alone can\ndramatically effect the quality of machine text, even when generated from\nexactly the same neural language model. Our findings motivate Nucleus Sampling,\na simple but effective method to draw the best out of neural generation. By\nsampling text from the dynamic nucleus of the probability distribution, which\nallows for diversity while effectively truncating the less reliable tail of the\ndistribution, the resulting text better demonstrates the quality of human text,\nyielding enhanced diversity without sacrificing fluency and coherence.",
    "num_pages": 16
}