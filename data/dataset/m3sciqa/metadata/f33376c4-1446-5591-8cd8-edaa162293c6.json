{
    "uuid": "f33376c4-1446-5591-8cd8-edaa162293c6",
    "title": "M-SENA: An Integrated Platform for Multimodal Sentiment Analysis",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2022,
    "authors": [
        "Huisheng Mao",
        "Ziqi Yuan",
        "Hua Xu",
        "Wenmeng Yu",
        "Yihe Liu",
        "Kai Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2203.12441v1",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2022\\f33376c4-1446-5591-8cd8-edaa162293c6.pdf",
    "bibtex": "@misc{mao2022msenaanintegratedplatformfor,\n    title = {M-SENA: An Integrated Platform for Multimodal Sentiment Analysis},\n    author = {Huisheng Mao and Ziqi Yuan and Hua Xu and Wenmeng Yu and Yihe Liu and Kai Gao},\n    year = {2022},\n    eprint = {2203.12441},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.AI},\n    url = {http://arxiv.org/abs/2203.12441},\n}",
    "abstract": "M-SENA is an open-sourced platform for Multimodal Sentiment Analysis. It aims\nto facilitate advanced research by providing flexible toolkits, reliable\nbenchmarks, and intuitive demonstrations. The platform features a fully modular\nvideo sentiment analysis framework consisting of data management, feature\nextraction, model training, and result analysis modules. In this paper, we\nfirst illustrate the overall architecture of the M-SENA platform and then\nintroduce features of the core modules. Reliable baseline results of different\nmodality features and MSA benchmarks are also reported. Moreover, we use model\nevaluation and analysis tools provided by M-SENA to present intermediate\nrepresentation visualization, on-the-fly instance test, and generalization\nability test results. The source code of the platform is publicly available at\nhttps://github.com/thuiar/M-SENA.",
    "num_pages": 11
}