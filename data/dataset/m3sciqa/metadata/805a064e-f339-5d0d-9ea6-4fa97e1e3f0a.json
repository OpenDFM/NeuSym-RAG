{
    "uuid": "805a064e-f339-5d0d-9ea6-4fa97e1e3f0a",
    "title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue Response Models",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2021,
    "authors": [
        "Tianxing He",
        "Jun Liu",
        "Kyunghyun Cho",
        "Myle Ott",
        "Bing Liu",
        "James Glass",
        "Fuchun Peng"
    ],
    "pdf_url": "http://arxiv.org/pdf/1910.07117v5",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2021\\805a064e-f339-5d0d-9ea6-4fa97e1e3f0a.pdf",
    "bibtex": "@misc{he2021analyzingtheforgettingproblemin,\n    title = {Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue Response Models},\n    author = {Tianxing He and Jun Liu and Kyunghyun Cho and Myle Ott and Bing Liu and James Glass and Fuchun Peng},\n    year = {2021},\n    eprint = {1910.07117},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/1910.07117},\n}",
    "abstract": "In this work, we study how the finetuning stage in the pretrain-finetune\nframework changes the behavior of a pretrained neural language generator. We\nfocus on the transformer encoder-decoder model for the open-domain dialogue\nresponse generation task. Our major finding is that after standard finetuning,\nthe model forgets some of the important language generation skills acquired\nduring large-scale pretraining. We demonstrate the forgetting phenomenon\nthrough a set of detailed behavior analysis from the perspectives of knowledge\ntransfer, context sensitivity, and function space projection. As a preliminary\nattempt to alleviate the forgetting problem, we propose an intuitive finetuning\nstrategy named \"mix-review\". We find that mix-review effectively regularizes\nthe finetuning process, and the forgetting problem is alleviated to some\nextent. Finally, we discuss interesting behavior of the resulting dialogue\nmodel and its implications.",
    "num_pages": 13
}