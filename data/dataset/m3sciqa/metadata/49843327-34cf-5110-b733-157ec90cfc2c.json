{
    "uuid": "49843327-34cf-5110-b733-157ec90cfc2c",
    "title": "Toward Subgraph-Guided Knowledge Graph Question Generation with Graph Neural Networks",
    "conference": "arxiv",
    "conference_full": "ArXiv",
    "volume": null,
    "year": 2023,
    "authors": [
        "Yu Chen",
        "Lingfei Wu",
        "Mohammed J. Zaki"
    ],
    "pdf_url": "http://arxiv.org/pdf/2004.06015v4",
    "pdf_path": "data\\dataset\\m3sciqa\\papers\\arxiv2023\\49843327-34cf-5110-b733-157ec90cfc2c.pdf",
    "bibtex": "@misc{chen2023towardsubgraphguidedknowledgegraphquestion,\n    title = {Toward Subgraph-Guided Knowledge Graph Question Generation with Graph Neural Networks},\n    author = {Yu Chen and Lingfei Wu and Mohammed J. Zaki},\n    year = {2023},\n    eprint = {2004.06015},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL},\n    url = {http://arxiv.org/abs/2004.06015},\n}",
    "abstract": "Knowledge graph (KG) question generation (QG) aims to generate natural\nlanguage questions from KGs and target answers. Previous works mostly focus on\na simple setting which is to generate questions from a single KG triple. In\nthis work, we focus on a more realistic setting where we aim to generate\nquestions from a KG subgraph and target answers. In addition, most of previous\nworks built on either RNN-based or Transformer based models to encode a\nlinearized KG sugraph, which totally discards the explicit structure\ninformation of a KG subgraph. To address this issue, we propose to apply a\nbidirectional Graph2Seq model to encode the KG subgraph. Furthermore, we\nenhance our RNN decoder with node-level copying mechanism to allow directly\ncopying node attributes from the KG subgraph to the output question. Both\nautomatic and human evaluation results demonstrate that our model achieves new\nstate-of-the-art scores, outperforming existing methods by a significant margin\non two QG benchmarks. Experimental results also show that our QG model can\nconsistently benefit the Question Answering (QA) task as a mean of data\naugmentation.",
    "num_pages": 12
}