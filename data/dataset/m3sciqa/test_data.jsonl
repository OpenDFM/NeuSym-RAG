{"uuid": "00198f82-cadc-53ab-8106-cccca57cb249", "question": "Consider the paper that introduces the model that corresponds to the first row of the table. What specific methodological approach does the paper propose to address the challenge of generating high-cognitive-demand educational questions from children's storybooks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5cb4f0ee-6979-5de3-9228-7707e6240704"], "reference_pdf": ["78b201f5-8cc7-5580-a1e9-3e61fd50a3b0", "412f0d4e-18e1-50b9-9029-b2f3dc0f7eff", "a239e827-0d3f-5f3a-9757-0b218e376c95", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "c48ce7f0-0f60-568a-a32a-61dac182a786", "6f6a00e8-6bd2-5287-ab63-6b0b5f3e422d", "6440959d-ac81-5a2c-ae6e-9082bf5ee380", "28a47974-2035-5575-9a75-7df451faf18d", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "f6e91a91-0b1e-5280-8522-a20492033f16", "822d7c33-cc29-503d-96f9-a82f49f90f06", "977a0308-a19f-537c-940c-4064e7796e83", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "e756a768-abbe-52e1-8416-6c24deaa43ff", "f96ef4a4-88c2-52dd-bcad-82b7d77045f0", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the first row of the table. What specific methodological approach does the paper propose to address the challenge of generating high-cognitive-demand educational questions from children's storybooks?", "reference_answer": "The paper proposes a novel framework that combines question type prediction and event-centric summarization to generate educational questions for storybooks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16446/tell_me_why_table.png"]}
{"uuid": "00cce473-8fd6-5052-9e27-a63049a7641a", "question": "Consider the paper that introduces the model that shows the best overall performance in the 'Foreign' scenario. What specific condition under the DA-WR algorithm ensures the convergence of the cumulative distribution function resulting from the data augmentation process to the target distribution?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that shows the best overall performance in the 'Foreign' scenario. What specific condition under the DA-WR algorithm ensures the convergence of the cumulative distribution function resulting from the data augmentation process to the target distribution?", "reference_answer": "The specific condition under the DA-WR algorithm that ensures the convergence of the cumulative distribution function resulting from the data augmentation process to the target distribution is the satisfaction of conditions {\\bf (C)-(C'')}."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/average_relative_performance.png"]}
{"uuid": "017758fd-7ec0-52d9-b652-787c26325aab", "question": "Consider the paper that introduces the method that demonstrates the lowest score in the CSQA2.0 dev/dev* task. What specific methodological approach does the paper employ to align the model proposed in the paper with human intentions, particularly in terms of handling sensitive content?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5bf1e056-9343-55e5-967a-c63726575c9e"], "reference_pdf": ["6a643dcf-5695-5089-ab9c-7d1dd3c04ff4", "e8f47ab4-abbd-5553-b031-4d0d76afab3e", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "345aaf21-19b7-552f-9991-4549ea1995aa", "dccb63d4-f203-5a8b-8f8a-10fb38fda9b4", "80e783a2-8364-5565-8600-93cc7a0b066a", "c7304df5-0d4d-594e-9f83-cb5d9a19b350", "7072220d-1680-5120-b061-9c5d175922e2", "23b2039f-1245-5334-8452-b245c78e29cf", "c1f4221a-e7e5-5df3-8d1b-0acc89e315f6", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "1e7d9f86-3567-55b8-be98-064a3d297af1", "67479dd9-47ba-5b58-bf3d-3ee378a5030f", "3967df69-753f-527b-9c82-35378bcaa943", "2bc7f244-8607-5501-a3c5-916c66efc615", "f8406901-eed8-5981-94c2-92d667fedd98", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "fd9457ae-5f08-5f7f-aed1-f46fa2f20c2d", "7dfb54d5-b8dc-52b1-a79d-a286df0819cd"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that demonstrates the lowest score in the CSQA2.0 dev/dev* task. What specific methodological approach does the paper employ to align the model proposed in the paper with human intentions, particularly in terms of handling sensitive content?", "reference_answer": "Reinforcement learning from human feedback (RLHF)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.18397/result_table.png"]}
{"uuid": "01d272cf-d929-5170-a218-2cc0c45b15a7", "question": "Consider the paper that introduces the dataset that has 1 SM task and 14 languages. What was the highest zero-shot cross-lingual transfer performance F1 score achieved for the target language Tigrinya, and from which source language was it transferred?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that has 1 SM task and 14 languages. What was the highest zero-shot cross-lingual transfer performance F1 score achieved for the target language Tigrinya, and from which source language was it transferred?", "reference_answer": "68.6, Hausa"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "03e0dae7-c172-548a-9f62-d11b778b0c9e", "question": "Consider the paper that introduces the method whose results are displayed in a lighter grey color in the table. What specific improvement in CIDEr score does the model proposed in the paper contribute to image captioning through the text infilling pretraining task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method whose results are displayed in a lighter grey color in the table. What specific improvement in CIDEr score does the model proposed in the paper contribute to image captioning through the text infilling pretraining task?", "reference_answer": "+0.8"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "04a88c6d-0596-52cb-8843-f82b36e6ed62", "question": "Consider the paper that introduces the model that scores an 84.2 in the 'T10' column. What is the observed accuracy drop percentage for the model proposed in the paper on the FewRel dataset for relations with maximum similarity in the range [0.85, 1.00)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores an 84.2 in the 'T10' column. What is the observed accuracy drop percentage for the model proposed in the paper on the FewRel dataset for relations with maximum similarity in the range [0.85, 1.00)?", "reference_answer": "9.7"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "04f0af22-b379-5a24-a0b9-fd1eff1a4a71", "question": "Consider the paper that introduces the model that corresponds to the green dashed line. What specific architectural change was made to the Transformer's layer normalization in this model compared to its originally proposed form?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["b868c871-5514-505d-8587-367e156e1e28"], "reference_pdf": ["aeb9b828-4aff-5f24-a169-6fe27f0e1e2c", "675768f2-88cd-54a4-b359-f29fe975fcef", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "ad72f105-7a2a-5959-8f49-342eb4469f36", "9f2e58b0-9d4e-56b0-a504-e5f77a2f1476", "d8388017-45ea-5dfa-9238-3d88f2c1ce6a", "f7306500-2b64-5ee2-9f7e-f4beb3b0ebcf", "799320b2-1e80-56c8-9084-73737c3fbfb5", "7415a335-10d7-55f3-af82-07c08f608ecd", "a24d04a0-5d7b-518f-97d3-5202a6f549a4", "947f07f1-5d2a-554e-a441-9838afd4a779", "34417770-67d7-5cab-b9d4-76999c97bc02", "6f696630-3060-5bd1-9be1-a00e8d89edfe", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "ad6fa17b-383b-53da-8737-9038180d5159", "0801ed2c-711f-5ffe-94d6-c264e679e00e", "7908763f-3a9d-5ce5-af59-f68888750583", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "40862fb4-44fd-5785-91f9-e24afaa2923d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "80772a52-97c8-5bf8-9893-0de1cc8c02f4", "07caf8ef-950f-50c9-8989-70d482d73168", "3f2695ed-eeac-5dcc-9200-fa2eaa0f02ad", "2173fe79-3e5b-52f6-bd51-a63b747394c0", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the green dashed line. What specific architectural change was made to the Transformer's layer normalization in this model compared to its originally proposed form?", "reference_answer": "a simplified version of layer normalization where the activations are only rescaled and no additive bias is applied."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05030/diversity_score.png"]}
{"uuid": "05539d2c-e1ee-54a5-b17f-2838ed253dbe", "question": "Consider the paper that introduces the method which has approximately 30 perplexity and the highest average max toxicity. What is the model's success rate (SR) percentage for the Guide Context strategy with a lambda value of 20?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has approximately 30 perplexity and the highest average max toxicity. What is the model's success rate (SR) percentage for the Guide Context strategy with a lambda value of 20?", "reference_answer": "95.1%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "05d5ef36-284e-5872-9db7-3d0199d8bf63", "question": "Consider the paper that introduces the model that has the highest performance on the En-Fr task in the MSCOCO dataset. How does its performance with hallucinated visual tokens compare to using ground-truth visual representations on the Multi30K dataset for the EN→DE task using the Transformer-Tiny model?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["c653b597-b831-535e-bdb1-af03d3f3f1e7"], "reference_pdf": ["dd2f2eae-81f5-5525-971f-5540dde42f6c", "fffd1c97-f03e-5210-8dce-f0eb709b9199", "f1ea3e20-3942-5edd-9c70-f73b10f2da1e", "40d27262-e113-523f-9533-3ee949bdfb05", "c89e402d-2dd4-57dc-883b-be5c04e54b3a", "ad354a8b-1b60-517d-a7fa-d22b435b7f8f", "5052872f-0692-5df0-b02c-ce0f895d539b", "f17feaa7-e8e8-5559-9cf7-fd4b153b811c", "a0c50dc5-15b6-5924-bb70-08d2617f583f", "7821eda8-5710-57df-96c4-89cf30bf7a77", "884e57aa-78e0-5621-958c-8681a2d6f61f", "3b8af772-96a1-578e-a3de-272d2cb9ad7f", "5b08577d-f73f-56d5-be75-931a10239a0d", "f0266918-92ed-5f40-8bd8-499d2979a4e4", "d38dfa65-c493-5cc7-a20d-a01897d7fdc2", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "88185cdb-ff85-5600-bbcb-5bb65ecd6665", "5671a75b-4bcf-5446-82c0-481b1cd418f2", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "e26e48f8-0721-56f6-89dd-9e96448a75c5", "67c0b261-9f6d-50ac-b824-816f48441fa8", "ef1fd71c-6764-5364-8f8f-18d147a69e6d", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "9d24c743-9966-5400-a5f9-6825eca1d557", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "4b2861dc-27c5-57f4-8e01-b018654b3e25", "d7894a4b-2b2f-5355-8193-5c68ffd30928", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "0e854ebb-88e7-55c4-952b-818ce54bc014", "d9b0f39f-60aa-53f3-8382-532440370fdf", "ac65b094-5a2c-5ab7-8497-a3cd526fa8ca", "dfac74e2-051a-5a1f-98fc-d5497a48f44b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest performance on the En-Fr task in the MSCOCO dataset. How does its performance with hallucinated visual tokens compare to using ground-truth visual representations on the Multi30K dataset for the EN→DE task using the Transformer-Tiny model?", "reference_answer": "VALHALLA with hallucinated visual tokens achieves an average BLEU score of 35.4 on the EN$\\rightarrow$DE task using the Transformer-Tiny model, compared to using ground-truth visual representations which also results in an average BLEU score of 35.4."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13361/result_table.png"]}
{"uuid": "05e412d1-1cc9-52e8-a3a2-39f4ee8f73eb", "question": "Consider the paper that introduces the model depicted in the figure that exhibits the highest fluctuation. How does the model's sequential training approach, as proposed in the paper, specifically address the negative transfer problem observed in certain evaluation dimensions?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["872650ac-af1b-5ead-bff8-975b0ce8d32d"], "reference_pdf": ["cd28f82e-0927-58c3-b17d-bfd6b5888b79", "3c47cf47-b671-55d5-a396-e294638f7023", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "450c1e1c-8f69-5d85-9a26-df3a876f65e1", "fe26770b-ff50-56e9-8546-8310b7215de7", "43042c01-285d-53a4-8e75-a14921ddd5b7", "060cedb0-10c7-53d3-a4f3-4610a1cb854f", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "deef91b8-6c7c-5fbc-b196-a248c88cb07b", "e3b247ba-4ea5-5d11-9653-e6df72b1c84d", "8bd7983c-5a5b-50cb-99ab-62297274885c", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "6106e3f0-e82c-5ded-a9c2-0d8444beb47b", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "917794fc-6091-585f-9aca-18d5d7fe492b", "98f94381-9ab9-5337-a63e-99c8ad892b6f", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "dea2fddd-8066-5173-ab2b-c960d55f2de1", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "85ba33aa-25d1-526b-a87d-42cfd55a08c9", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "eb251b7d-833d-54cd-9374-0481e7af7292", "c50df058-1617-58f1-9b89-c397fcdceb6f", "f3354010-9feb-5b44-afec-0f6be57ca4d6", "03280b0e-c24d-50a6-a988-b6ca1b7d3519", "ab8d017f-8645-5337-aa84-f52783391b99", "67f97fa1-4d75-5346-8e7f-4701de843e11"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model depicted in the figure that exhibits the highest fluctuation. How does the model's sequential training approach, as proposed in the paper, specifically address the negative transfer problem observed in certain evaluation dimensions?", "reference_answer": "The sequential training approach of UniEval specifically addresses the negative transfer problem observed in certain evaluation dimensions by employing a method from continual learning: whenever a new dimension is introduced, a small portion of data from all previous dimensions is added to replay. This strategy allows for easy extension of the evaluator to new dimensions without training from scratch and enables explicit learning of dimensions related to basic linguistic features before moving on to dimensions that require a better understanding of the text."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13189/calibration_figure.png"]}
{"uuid": "0674722b-d4a6-5e2c-bcd5-dcc70d6e92c9", "question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. In its methodology of quantifying temporal degradation (TD), what mathematical modification is applied to the difference in performance between aligned and misaligned models to ensure that, as performance deteriorates, the calculated value increases regardless of the direction of time between the training and evaluation timestamps?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. In its methodology of quantifying temporal degradation (TD), what mathematical modification is applied to the difference in performance between aligned and misaligned models to ensure that, as performance deteriorates, the calculated value increases regardless of the direction of time between the training and evaluation timestamps?", "reference_answer": "-\\left(S_{t' \\shortto t} - S_{t \\shortto t} \\right) \\times \\text{sign}(t' - t)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "07671c3e-1eb5-55eb-b15e-8e54b0a5ea3e", "question": "Consider the paper that introduces the method at the rightmost part of the figure. What specific computational advantage does the model proposed in the paper offer over a unidirectional classifier in terms of the number of forward passes required for computing $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method at the rightmost part of the figure. What specific computational advantage does the model proposed in the paper offer over a unidirectional classifier in terms of the number of forward passes required for computing $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$?", "reference_answer": "GeDi's online classification trick can compute $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$ on the order of 10k fold less computation as compared with a unidirectional classifier."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "08bbcb26-6113-55eb-b3dc-2bd23d936062", "question": "Consider the paper that introduces the method in the table that is listed right above One-Round Distillation and right below Specialization. What is the accuracy improvement for the MAWPS dataset when using an external calculator for the model proposed in the paper compared to its baseline accuracy?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the table that is listed right above One-Round Distillation and right below Specialization. What is the accuracy improvement for the MAWPS dataset when using an external calculator for the model proposed in the paper compared to its baseline accuracy?", "reference_answer": "34.07%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "0a0d2d89-18ff-56af-b21a-0f5d2a031a03", "question": "Consider the paper that introduces the Seq2Seq/Tree model that has a Test Accuracy of 79.6. What specific method does the model's solution discrimination module use to encode the equation representation of a solution?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the Seq2Seq/Tree model that has a Test Accuracy of 79.6. What specific method does the model's solution discrimination module use to encode the equation representation of a solution?", "reference_answer": "gate-recurrent-unit (GRU)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "0a859d9f-76e6-5153-b4f9-d5c9b951e952", "question": "Consider the paper that introduces the method that has an F1 score of 75. What specific advantage does the incorporation of Part-Intensity Fields (PIF) and Part-Association Fields (PAF) modules provide to the model proposed in the paper in terms of entity linking?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an F1 score of 75. What specific advantage does the incorporation of Part-Intensity Fields (PIF) and Part-Association Fields (PAF) modules provide to the model proposed in the paper in terms of entity linking?", "reference_answer": "The PIF-PAF modules enable the MSAU-PAF model to efficiently and robustly predict the confidence association between two entities with composite field structure in densely and occluded documents."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "0a905537-c645-5616-ae3a-0d47ace4034c", "question": "Consider the paper that introduces the method that corresponds to the second highest Acc-5 score on MOSI. Based on the ablation study results, what combination of tasks achieved the highest F1-Score for the model proposed in the paper in 'negative/positive' right calculation method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the second highest Acc-5 score on MOSI. Based on the ablation study results, what combination of tasks achieved the highest F1-Score for the model proposed in the paper in 'negative/positive' right calculation method?", "reference_answer": "M, T, V"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "0a984119-b4e9-58a6-b4e9-b2a48128f8c8", "question": "Consider the paper that introduces the method that corresponds to a higher F1 score than that of LDSGM but a lower F1 score than 65.76 for PDTB-Top. What is the primary reason for its better performance compared to the PIDRP method across all four top-level senses of the PDTB?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to a higher F1 score than that of LDSGM but a lower F1 score than 65.76 for PDTB-Top. What is the primary reason for its better performance compared to the PIDRP method across all four top-level senses of the PDTB?", "reference_answer": "The main reason for the poor performance of the PIDRP method compared to the PCP method across all four top-level senses of the PDTB is that connective prediction is closer to the natural language patterns when the model is in the pre-training stage than direct implicit discourse relation prediction."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "0ad707b0-56f8-5245-9dd6-163ae9e43702", "question": "Consider the paper that introduces the model that is seventh in the table. What is the primary reason the PIDRP method performs worse than the PCP method, across all four top-level senses of the PDTB, especially on the Temporal sense?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that is seventh in the table. What is the primary reason the PIDRP method performs worse than the PCP method, across all four top-level senses of the PDTB, especially on the Temporal sense?", "reference_answer": "The primary reason the PIDRP method performs worse than the PCP method across all four top-level senses of the PDTB, especially on the Temporal sense, is that connective prediction is closer to the natural language patterns when the model is in the pre-training stage than direct implicit discourse relation prediction."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "0b86b6c4-217c-5ee7-86f8-a9e7997a3294", "question": "Consider the paper that introduces the model shown on the penultimate line of the table. What is the exact improvement in ROC-AUC score for the ClinTox dataset achieved by the model proposed in the paper over GEM?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["75156ea6-7402-5a33-9303-ec6f543e9999"], "reference_pdf": ["7aa1a28a-1256-5732-9581-f2538bfcaf8e", "adf24566-930f-5a42-8118-6aeb65e4f6f4", "825de5ef-3ab4-5629-9fc4-4b0805f419b8", "a1002509-bd90-5cde-9fd2-7b6216144d71", "653e5d86-f991-5533-bd83-a5d95f760b18", "aa22dd10-f8dc-5b74-893f-4f3b21431f24", "766ea9a1-a447-5963-a71f-c9d0a0562d57", "7ea7979f-d2cf-58e4-b00e-2b4027aaf436", "a2401db7-a8bd-588a-856c-4d9ad4f85409", "3a2ae924-5f60-5905-abab-631f660f7bb6", "54fbf9e2-28d0-54ce-ba51-27f90b206c6e", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "3b7baa1d-606b-5481-9c27-fec60e4c7533", "6d068e18-8fb7-5dff-b0bf-b95297a79dc5", "7908763f-3a9d-5ce5-af59-f68888750583", "4ef708b0-51b3-5527-91fc-a55d70b49671", "e2b71dfc-0678-5451-82f6-42650b5ca0dc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "05397506-c619-548a-9f1f-18f85acc151e", "cf69528e-9892-5b27-ab66-0b66a1304268", "a2677b99-9e0d-5c14-8e19-f1c7d5cfa93f", "7908763f-3a9d-5ce5-af59-f68888750583", "7d25556e-bc5e-58ba-b1d8-294c67ed7d98", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6fd2a9e7-7fea-5866-b0c4-120b7cc5baae", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "d97c36ef-e3d9-5f53-a6ff-00d5ee2f2777", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "d4f91c73-f4cf-5209-bec5-6ff66eb29d19", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "5161fb60-4394-5446-9e6e-ce1f1e9e393a", "1777f12e-991e-52d4-8b6b-03807d589e87", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "964db907-da57-5f8b-b1ef-1054c077ca89", "4a697112-1b30-569a-8fee-c4eace04cb3f", "33130f85-57c8-54d5-b050-075bb1ccab97"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown on the penultimate line of the table. What is the exact improvement in ROC-AUC score for the ClinTox dataset achieved by the model proposed in the paper over GEM?", "reference_answer": "5.2"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07276/performance_table.png"]}
{"uuid": "0bc119df-5981-5d94-979b-5e3dda14495c", "question": "Consider the paper that introduces the dataset which has a training set size of 8,844. What specific linguistic phenomenon can cause annotators to re-read multiple times due to issues such as lack of punctuation, diacritics, and ambiguous text meaning, particularly when the text could be interpreted as inappropriate in multiple ways?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has a training set size of 8,844. What specific linguistic phenomenon can cause annotators to re-read multiple times due to issues such as lack of punctuation, diacritics, and ambiguous text meaning, particularly when the text could be interpreted as inappropriate in multiple ways?", "reference_answer": "Non-diacritical marks comments"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "0cc9d595-9d7a-54e8-ba65-1fd8eb8a05a4", "question": "Consider the paper that introduces the dataset which has the largest number of instances in the ABS category. What threshold value was set for the 'Group' domain during the aspect discovery stage?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the largest number of instances in the ABS category. What threshold value was set for the 'Group' domain during the aspect discovery stage?", "reference_answer": "0.5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "0d18332d-ab23-5a75-9b34-12d69b1a2349", "question": "Consider the paper that introduces the benchmark that corresponds to the light green color in the figure. What specific criteria were used to exclude tasks from the subset due to their reliance on specialized knowledge or being outside the scope of the work?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark that corresponds to the light green color in the figure. What specific criteria were used to exclude tasks from the subset due to their reliance on specialized knowledge or being outside the scope of the work?", "reference_answer": "Not solvable by authors within 60 minutes, requires specialized knowledge, or not even worth attempting with chain-of-thought."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "0f833148-d53e-5d3d-9584-9e292ceab369", "question": "Consider the paper that introduces the method that consistently achieves a higher MRR score than NodePiece. What is the relative increase in MRR achieved by the model proposed in the paper compared to RotatE on the FB15k-237 dataset using a similar parameter budget?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that consistently achieves a higher MRR score than NodePiece. What is the relative increase in MRR achieved by the model proposed in the paper compared to RotatE on the FB15k-237 dataset using a similar parameter budget?", "reference_answer": "4.7%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_comparison_figure.png"]}
{"uuid": "0f96c3df-b5b2-5f05-8d42-7c696d288538", "question": "Consider the paper that introduces the first method shown in Implicit --> Continual Learning --> Continual Knowledge Editing category. What is the specific combination of methods within that method that yielded state-of-the-art performance in OECT scores based on the integration of regularization and replay methods?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in Implicit --> Continual Learning --> Continual Knowledge Editing category. What is the specific combination of methods within that method that yielded state-of-the-art performance in OECT scores based on the integration of regularization and replay methods?", "reference_answer": "MIR with OnlineL2Reg"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "0fcab05d-7aa7-5d2a-a23b-5cca31da4ea8", "question": "Consider the paper that introduces the method that has a lower F1 score than LayoutXLM and a higher F1 score than SPADE. What specific methodological adjustment does the model proposed in the paper make to the GraphSAGE aggregation strategy to accommodate the unique challenges of document graph structures?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than LayoutXLM and a higher F1 score than SPADE. What specific methodological adjustment does the model proposed in the paper make to the GraphSAGE aggregation strategy to accommodate the unique challenges of document graph structures?", "reference_answer": "The Doc2Graph model adjusts the GraphSAGE aggregation strategy by redefining the neighborhood aggregation to consider only a subset of neighbors $\\Upsilon(i) = \\{j \\in N(i): |i - j| < threshold\\}$, where $|i - j|$ is the Euclidean distance between nodes $i$ and $j$, normalized between 0 and 1, and stored on their connecting edge. This adjustment, along with a constant scale factor $c$, aims to maintain the locality property during the message passing algorithm, accommodating the unique challenges of document graph structures."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "106d8add-f173-54c8-9149-cff2efb09819", "question": "Consider the paper that introduces the model that corresponds to an F1 score of 65.76 on PDTB-Top. How does the model proposed in the paper's utilization of the local hierarchy-aware contrastive loss $\\mathcal{L}_{L}$ compare to its hard-label version $\\mathcal{L}_{L'}$ in terms of performance impact?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to an F1 score of 65.76 on PDTB-Top. How does the model proposed in the paper's utilization of the local hierarchy-aware contrastive loss $\\mathcal{L}_{L}$ compare to its hard-label version $\\mathcal{L}_{L'}$ in terms of performance impact?", "reference_answer": "The performance drops notably when replacing $\\mathcal{L}_{L}$ with $\\mathcal{L}_{L'}$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "10a264ed-69d8-56a6-884a-943b41d0b0ae", "question": "Consider the paper that introduces the method that is in the second row of the table. In the context of the paper's methodological approach, why might the use of Locally Linear Embedding (LLE) for regularizing the space of label prototypes be considered less appropriate compared to the clustering-based strategy represented by ConCN clusters?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["09e64ec3-5f93-5ee7-a81a-5bc1dd99f004"], "reference_pdf": ["0ed7c020-1b01-5cb4-a990-280fdfcfd830", "f393f359-5002-5544-88cf-484f811f9de0", "df4d0a6f-162d-5a17-a7e2-c949dcb008fe", "8c672eae-46ec-5a53-ac32-3c72cc49ded9", "fb059017-6ff5-5b9f-9a51-d6ab436eed1e", "5ee7745a-e70f-5bec-b49d-1d0fabdf453d", "cc1ac0c9-340a-5ae3-8410-c000b2696eb8", "69ac39b0-3765-5232-93b7-01b3ef16b580", "f4bb3b0b-0f4f-50a9-9be5-cee4752f8038", "73dc0489-e9e0-52b0-bdf4-5f39ae3b0693", "243c5488-19f9-5ddf-82ce-2c13c5b6c76f", "436473bc-4190-5d91-9004-71ef63cee599", "d112b9d1-d4d4-5a03-b2f9-9107954158b4", "be79a7b9-9e94-52e9-9d4d-2784cfc33987", "006134c0-3d8a-522f-98bc-3d15db04df18", "2f3a116d-c852-5487-bbf0-587ee8db7379", "79c58b97-75e2-590f-ab73-90c71c7af2a6", "cf51bf0c-3d81-5337-a640-b6c88e5ee0c1", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "65b54391-8920-574c-adb0-f323aa10cbb1", "76b6a5b6-5439-591e-bf61-ca971f3ad23e", "5a4e3f5d-2c2b-5c59-bb0a-edcd3b40ed7e", "8903812c-bb72-5ff3-8faf-3787d56c1ceb", "0ed7c020-1b01-5cb4-a990-280fdfcfd830", "26e45afd-1c91-5f0f-bb47-33707acec072", "5a922b70-446f-5cac-a455-3d725f110ca0", "0f9c5f89-7c6f-5bd2-bd90-727a9980a494", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the second row of the table. In the context of the paper's methodological approach, why might the use of Locally Linear Embedding (LLE) for regularizing the space of label prototypes be considered less appropriate compared to the clustering-based strategy represented by ConCN clusters?", "reference_answer": "The use of Locally Linear Embedding (LLE) for regularizing the space of label prototypes might be considered less appropriate compared to the proposed clustering-based strategy because LLE imposes the condition that prototypes with similar labels should themselves also be similar, which is not always appropriate given the nature of ultra-fine entity typing where labels can denote mutually exclusive categories despite being semantically similar."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14793/comparison_table.png"]}
{"uuid": "10c5feaa-a3c8-5b23-a7da-1caff05f8dbf", "question": "Consider the paper that introduces the dataset which has a training set size of 8,844. What specific error type in the error analysis indicates a failure due to the model proposed in the paper's inability to understand comments with indirect and disrespectful references?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has a training set size of 8,844. What specific error type in the error analysis indicates a failure due to the model proposed in the paper's inability to understand comments with indirect and disrespectful references?", "reference_answer": "Allusion: The comment refers to another person or subject in an indirect and disrespectful way."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "111dbe62-b1f1-5cc7-ba70-5665b9739aa3", "question": "Consider the paper that introduces the benchmark represented by the triangle marker in the figure. What is the average human-rater performance for the 'Temporal Sequences' task in the suite it belongs to?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark represented by the triangle marker in the figure. What is the average human-rater performance for the 'Temporal Sequences' task in the suite it belongs to?", "reference_answer": "90.8%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "12f2a56b-d021-577b-a966-c1cb0738c0c2", "question": "Consider the paper that introduces the model shown in the figure that corresponds to the green line. What is the Pearson's correlation coefficient between word overlap and the model performance of DPT for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the figure that corresponds to the green line. What is the Pearson's correlation coefficient between word overlap and the model performance of DPT for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/accuracy_figure.png"]}
{"uuid": "135c2ecd-268b-5610-8816-1f677e1b9137", "question": "Consider the paper that introduces the method that results in a score of 22.4 in the GSM8K dataset. What specific performance tradeoff is observed when selecting the best model, as proposed by the paper, based on the GSM8K validation set versus the M-A-S validation performance?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that results in a score of 22.4 in the GSM8K dataset. What specific performance tradeoff is observed when selecting the best model, as proposed by the paper, based on the GSM8K validation set versus the M-A-S validation performance?", "reference_answer": "The specific performance tradeoff observed when selecting the best model based on the GSM8K validation set versus the M-A-S validation performance is that choosing the best model based on the GSM8K validation set does not necessarily lead to the best validation performance on the M-A-S OOD setting. However, choosing the best model based on the M-A-S validation performance leads to a smaller performance drop in GSM8K."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "13cea4ce-4595-5c9d-b1a0-5336bfdbb581", "question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. What is the Pearson's correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. What is the Pearson's correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "13dab863-45df-5122-9163-a9d4411b397e", "question": "Consider the paper that introduces the method that has the highest score in the WQ-R task. How does the paraphrasing-based approach differ from the model proposed in the paper in handling instances with simple expressions, according to the limitations section?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the highest score in the WQ-R task. How does the paraphrasing-based approach differ from the model proposed in the paper in handling instances with simple expressions, according to the limitations section?", "reference_answer": "The paraphrasing-based approach focuses on words, while the proposed method focuses more on the structure of the sentences."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "14974ca3-bf36-53c5-b80f-cb28b808303a", "question": "Consider the paper that introduces the supervised method that results in the lowest score in 10-shot prompting. What specific performance improvement does the model proposed in the paper provide using dynamic masking over static masking for the MNLI-m task according to the paper's findings?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["debf097e-fb5e-52e6-ba62-bf1714b5ccec"], "reference_pdf": ["9441027e-e7d4-59d3-8377-3e68c3f8d6d5", "8860e51f-7c25-5d5c-b0ba-b3726371476c", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "dca70611-4c00-5e95-960e-f6c42eabfd2e", "47d497a4-55b6-5cc1-8d54-2ba8244156c6", "2925c847-385a-5175-a215-e2e46465d755", "bc1c15b7-674b-5686-b3e5-59a4745eefd7", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "8f9d03a3-9cf4-5e26-a59f-6abb1b6eb278", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "a0894fa0-47f3-55ac-9405-9e0652f7a695", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the supervised method that results in the lowest score in 10-shot prompting. What specific performance improvement does the model proposed in the paper provide using dynamic masking over static masking for the MNLI-m task according to the paper's findings?", "reference_answer": "0.3%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11715/few-shot_NER_table.png"]}
{"uuid": "14e3e263-2e51-54b6-a1f3-6015198d9cc0", "question": "Consider the paper that introduces the method which has an F1 score of 75. How does the inclusion of Coordinate Convolution (CoordConv) specifically impact the F1 scores for both Entity Labeling and Entity Linking tasks in the model proposed in the paper, according to the ablation study results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has an F1 score of 75. How does the inclusion of Coordinate Convolution (CoordConv) specifically impact the F1 scores for both Entity Labeling and Entity Linking tasks in the model proposed in the paper, according to the ablation study results?", "reference_answer": "The inclusion of Coordinate Convolution (CoordConv) specifically impacts the F1 scores for both Entity Labeling and Entity Linking tasks in the MSAU-PAF model by increasing the F1 score by 0.02 in both tasks, according to the ablation study results."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "16e0f2cb-b348-52e3-900b-bf83d4099471", "question": "Consider the paper that introduces the large language model that achieves a lower HVI score than OPT but a higher HVI score than Alpaca. What specific methodological difference in the evaluation setup for the model's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9b154fc7-cac7-5a8f-89ac-1ea50638b087"], "reference_pdf": ["87b70047-b849-5220-a3df-28e992c41bf2", "d4de27d2-08b9-57ae-b0a7-a4b9b26047bf", "507be7a7-d7c2-5c15-8ffe-9e6bfe40e5b0", "54eb4a06-225f-5814-ae97-c54611c3f95c", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "4d2120b1-212d-52ad-a0e5-c56245349f00", "34417770-67d7-5cab-b9d4-76999c97bc02", "a0863db0-4018-56ff-81bf-bdb1ff2ed4b7", "e59b32f7-7a87-5940-b581-3e110d2fd77d", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "884e57aa-78e0-5621-958c-8681a2d6f61f", "98b88819-fa1f-503b-9e15-3b078e676975", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "3caa80e4-e308-5fd8-b45f-6b55c8a7a835", "ad6fa17b-383b-53da-8737-9038180d5159", "a1302ac9-0f53-556b-96cd-38977a533888", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "7908763f-3a9d-5ce5-af59-f68888750583", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "dd073182-00f0-5a9f-800b-7779293ab2ae", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "17623cac-c243-591b-b7bc-d261f6ebd607"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the large language model that achieves a lower HVI score than OPT but a higher HVI score than Alpaca. What specific methodological difference in the evaluation setup for the model's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "reference_answer": "The use of sampling a letter choice at temperature 0 using the already-sampled explanation for certain exams, rather than extracting the model's letter choice directly from the explanation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.04988/HVI_figure.png"]}
{"uuid": "1772be24-0614-534c-8129-416c7953964d", "question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "17872591-c032-5684-b518-5a0f859caeeb", "question": "Consider the paper that introduces the method that corresponds to a score of 25.9 in the Seen, Val, SR dataset. How does the performance of the model proposed in the paper's factorized approach compare to Shridhar et al.'s single-branch model in terms of task success rates across the 7 high-level categories in the ALFRED benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to a score of 25.9 in the Seen, Val, SR dataset. How does the performance of the model proposed in the paper's factorized approach compare to Shridhar et al.'s single-branch model in terms of task success rates across the 7 high-level categories in the ALFRED benchmark?", "reference_answer": "MOCA outperforms Shridhar et al.'s model in all 7 high-level categories of the ALFRED benchmark, showing significant improvements in both seen and unseen environments."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "178e58c3-f5dc-51ae-8cb4-f25d5783bdd6", "question": "Consider the paper that introduces the method that has the lowest MAE in the CH-SIMS task. Which method, demonstrating the lowest MAE in the CH-SIMS task, achieves what specific improvement in accuracy percentage over the state-of-the-art for 5-class sentiment classification according to the performance of the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the lowest MAE in the CH-SIMS task. Which method, demonstrating the lowest MAE in the CH-SIMS task, achieves what specific improvement in accuracy percentage over the state-of-the-art for 5-class sentiment classification according to the performance of the model proposed in the paper?", "reference_answer": "6.7"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/result_table.png"]}
{"uuid": "179cffa6-2934-5336-b4af-4e06d7e19ed2", "question": "Consider the paper that introduces the method which is in the second row of the table. What is the percentage drop in $F_1$ score observed upon the removal of data augmentation during training on the \\cord\\ dataset according to the ablation study proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is in the second row of the table. What is the percentage drop in $F_1$ score observed upon the removal of data augmentation during training on the \\cord\\ dataset according to the ablation study proposed in the paper?", "reference_answer": "2.6%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "17e603be-c4ff-5425-b2a4-e52fc043fb1d", "question": "Consider the paper that introduces the model shown in the table that has an overall score of less than 3.80. What specific adaptation in the text embeddings allows it to build correspondence among query text, label text, and objects in grounding tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87061b7c-1d22-547a-8872-d4aeab4af856"], "reference_pdf": ["494cb703-b95f-5e14-a0e7-a3fd11506fc1", "6f3f28fe-d2d7-586a-88ad-9221a4b30d73", "34417770-67d7-5cab-b9d4-76999c97bc02", "d8294ff2-583e-51c8-800f-d71a9308007f", "2ca6dd33-bf5b-50cf-b091-3282a484d4a8", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "04eb3bcf-5a3a-574f-84e5-2bf5ad50cde4", "3eebefdb-5ed6-51bf-92c6-b28841844f45", "4d93d596-b0bd-54c6-bd9e-041037077bc7", "ffa6aa03-6f5b-56a1-9120-8d8c625c0880", "e201f724-c783-5300-baeb-1379ae22f643", "7aacee49-58db-593f-9a47-44846ba2ed23", "7908763f-3a9d-5ce5-af59-f68888750583", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "ec5a0dc4-0a52-55b2-a4a2-54e1006e50b9", "8d432bf0-21eb-51f9-b126-078fe08a3012", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "3e2528f0-84e9-5fa9-a440-22ae6fcc2500", "c8260bf5-7dd8-5066-8aa4-1a512fa40f12", "1b61dc63-60bb-51d1-9935-260cf324487f", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the table that has an overall score of less than 3.80. What specific adaptation in the text embeddings allows it to build correspondence among query text, label text, and objects in grounding tasks?", "reference_answer": "Embedding sharing"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15129/human_eval_table.png"]}
{"uuid": "180f5654-cc09-53bc-9db0-df6bf1b5b6f2", "question": "Consider the paper that introduces the transformer-based method that achieves the highest MRR score on the FB15kET dataset. What specific aspect of the model proposed in the paper allows for the differentiated integration of neighbor content while preserving the graph structure?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0b1e6d16-a279-5a83-ae0d-7b8a58bf0355"], "reference_pdf": ["ab8da4b2-8830-5dc2-b901-ca484702bbbe", "8f3a0cf7-ba90-5e39-8e9a-2ebf3b91b288", "437d1762-d8da-56a8-80e2-f6b5e823ad60", "c170861e-b3c6-5f40-bad9-e98ba1f9c2d8", "cc219d54-6f1e-524d-9a4a-dc4d0a5a4eec", "9b027a68-0c67-587b-b01e-1abb132d9f19", "1f670f2d-99fb-58c5-aef3-901c956d9929", "d0b35b26-2b4c-5209-bb22-d8a44032dd05", "3801abe7-8272-532f-bf4e-a10ce43700db", "fbea0c82-5838-5d56-a4c7-3d9737ea7c08", "ab9c34bc-777c-5ba4-9831-a203fa8bd682", "128f2558-545f-58e7-ad6f-50141b4b068f", "35cfee52-9b21-542e-a4a5-dc403ccd4fba", "a208b8d1-6ff3-588a-9334-4195ba7e524c", "b99fd553-6018-563d-820f-d97c0bbe1ea0", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "4675e5b7-915c-5c6f-afeb-c6d437bb8164", "46202f6e-dfd7-5efd-816d-f285579141d0", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "1777f12e-991e-52d4-8b6b-03807d589e87", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the transformer-based method that achieves the highest MRR score on the FB15kET dataset. What specific aspect of the model proposed in the paper allows for the differentiated integration of neighbor content while preserving the graph structure?", "reference_answer": "The context transformer integrates neighbours content in a differentiated way through information exchange between neighbour pairs, while preserving the graph structure."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12008/comparison_table.png"]}
{"uuid": "182a324e-565c-5d66-bc80-7e1703e7d9c6", "question": "Consider the paper that introduces the model represented with a dot marker. What specific methodological adjustment did the authors make to the initialization scheme of the DialoGPT Large model to account for its model depth?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented with a dot marker. What specific methodological adjustment did the authors make to the initialization scheme of the DialoGPT Large model to account for its model depth?", "reference_answer": "They modified the initialization scheme to account for model depth."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "1918aa21-4c9e-5f5c-aacf-77c156afdba5", "question": "Consider the paper that introduces the dataset which has 1 language but 13 SM tasks. What is the exact match score between the labels and predictions for Flan-T5 on the SentiEval benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has 1 language but 13 SM tasks. What is the exact match score between the labels and predictions for Flan-T5 on the SentiEval benchmark?", "reference_answer": "29.07"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "19281c8c-a4c9-526f-816a-11c6d1c54f09", "question": "Consider the paper that introduces the method that demonstrates the second lowest Acc-7 score on MOSI. Which model has a lower computational complexity compared to the Tensor Fusion Network (TFN) model, in terms of the number of parameters when $M=3$, $d_1 = 32$, $d_2 = 32$, $d_3 = 64$, $r = 4$, and $d_y = 1$?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that demonstrates the second lowest Acc-7 score on MOSI. Which model has a lower computational complexity compared to the Tensor Fusion Network (TFN) model, in terms of the number of parameters when $M=3$, $d_1 = 32$, $d_2 = 32$, $d_3 = 64$, $r = 4$, and $d_y = 1$?", "reference_answer": "The \\ourl\\ model contains about 1.1e6 parameters while TFN contains about 12.5e6 parameters."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "197526e6-c9ec-5584-ba17-0011a99bef68", "question": "Consider the paper that introduces the method that exhibits the highest score in the Seen, Val, SR dataset. What specific architectural feature allows the model proposed in the paper, EmBERT, to handle long-horizon planning effectively?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the highest score in the Seen, Val, SR dataset. What specific architectural feature allows the model proposed in the paper, EmBERT, to handle long-horizon planning effectively?", "reference_answer": "Segment-Level Recurrent Action Decoder where involves 1. Object-centric navigation 2. Decoupled Multimodal Transformers"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "1a3388f6-9e4d-54eb-b30f-8a54daceeecc", "question": "Consider the paper that introduces the method that has an F1 score of 54.83. What specific strategy does the model proposed in the paper employ to unify multilingual multimodal inputs efficiently?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an F1 score of 54.83. What specific strategy does the model proposed in the paper employ to unify multilingual multimodal inputs efficiently?", "reference_answer": "LayoutXLM employs a strategy of obtaining character-level bounding boxes after tokenization using SentencePiece with a unigram language model, and then calculating the bounding box of each token by merging the bounding boxes of all characters it contains. This approach efficiently unifies the multilingual multimodal inputs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "1b177372-b3df-5757-aac7-615ab62284e5", "question": "Consider the paper that introduces the method that corresponds to the penultimate row of the table. How does the performance of the model proposed in the paper, named ViTCAP, with concepts extracted from captions compare to using concepts derived from an object detector in terms of CIDEr scores on the COCO-caption Karpathy split?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e30a2f94-a104-572f-b30f-3ae7ff87f6e7"], "reference_pdf": ["d3c84791-eee6-5f1b-8500-1c0a84375f47", "f8d549ad-783d-591b-9ed4-4be9b95e7d9a", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "6c4dc282-e455-530e-9a34-4900a85e2964", "0a4a6ae4-afd1-5807-8417-fcd4b4809799", "1ad58efb-6d3b-5d50-b516-a01ae90f0787", "ee1dfb4c-7988-5a4c-bb1c-a26a7a03b8bf", "7aa9fab2-572b-5e8c-a92a-7b09e4f4c306", "4d3092f6-d683-5121-b9a5-7fca4ff91894", "a76b882d-198d-56d9-9ced-191f44ac95e8", "c6401b44-ad7a-5948-88ad-b180075d7dbe", "60b654b7-5847-56a5-8aaf-2e22fb679dc2", "0466db28-e878-5df8-8ebf-4a9aa8eb7b8e", "fc840122-59b3-5e1d-8c9b-4469f9395fda", "79c9710e-50b0-5c46-8210-1c5539a5328d", "cffe9204-ae34-53b2-adfc-ba74227619b8", "29322424-fba7-5659-a1df-8acb9f557bd8", "4974e1c8-fbd5-5689-ab45-78f2829161d3", "f4f54d07-2fac-59ba-ad99-7e60fba39833", "7ccc7830-102e-567f-9853-bed1eec59176", "f5b9aa98-8d6c-59b7-8883-d1339aeddd97", "949e1567-7aad-545b-b6ec-f5bad4d8bb4e", "6f26f6da-6cc3-5aa4-9f91-ca29b2d64729", "5baa788b-6e39-5587-8800-43f1801adef3", "69728e8c-59e5-5c53-a3cc-f245d1f7af59", "01d0de9d-f910-5674-841b-39ed4688eed7", "a941564b-e52c-55b7-8ded-59c510643621", "f3fe57c2-c6c8-5707-afaf-8f889823dffc", "facc9abe-bac6-5c51-8c10-0d2c28e15868", "cd71e042-6d38-56be-b014-7b9e02e8733e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "70aa012e-fef9-59af-8957-7d698937f537", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "2e3cfef4-fac0-5942-9361-f1321fc394b3", "2b8f1988-37a8-5fc1-b6c3-40b70dd2867f", "d4f2933e-e3ec-5035-bb6c-90041be7751c", "d95266e3-9e89-592a-b1fe-b55d3279249d", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "01d0de9d-f910-5674-841b-39ed4688eed7"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the penultimate row of the table. How does the performance of the model proposed in the paper, named ViTCAP, with concepts extracted from captions compare to using concepts derived from an object detector in terms of CIDEr scores on the COCO-caption Karpathy split?", "reference_answer": "Using concepts extracted from captions leads to better performance (121.8 CIDEr) compared to using concepts derived from an object detector (117.4 CIDEr for BUTD and 119.7 CIDEr for VinVL)."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.08223/result_table.png"]}
{"uuid": "1b19c8c1-36c9-5131-9a04-887c9a90729b", "question": "Consider the paper that introduces the method that shows the lowest overall performance. What specific feature of the ALFRED dataset's expert demonstrations makes re-planning during a DAgger-style student-forcing paradigm non-trivial for the model proposed in the paper, and can lead to the inability to complete a task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that shows the lowest overall performance. What specific feature of the ALFRED dataset's expert demonstrations makes re-planning during a DAgger-style student-forcing paradigm non-trivial for the model proposed in the paper, and can lead to the inability to complete a task?", "reference_answer": "The inability to undo certain actions"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "1b1a16f4-f066-54a3-9c2c-36d3dc0cf535", "question": "Consider the paper that introduces the benchmark that has the highest 'Generation Token Length' in the figure. What is the primary reason for the underestimation of language model capabilities in the BIG-Bench paper according to the findings related to the model proposed in the paper and answer-only prompting?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark that has the highest 'Generation Token Length' in the figure. What is the primary reason for the underestimation of language model capabilities in the BIG-Bench paper according to the findings related to the model proposed in the paper and answer-only prompting?", "reference_answer": "The underestimation is primarily due to the lack of inclusion of instructions and answer options in the prompt."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "1c4fc694-fb6d-5f07-9a82-d7e9f97d5234", "question": "Consider the paper that introduces the method in the table that corresponds to a ROUGE L score equal to 41.39. How does the application of normalizing flow in the model proposed in the paper specifically contribute to the improvement of abstractive text summarization performance?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52dd679b-8475-5f7a-b960-da2093d8dbe3"], "reference_pdf": ["2b4f3800-c515-559d-aa36-85d34f6fd899", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "f8566398-9ed0-577d-9f9c-78c1b182920b", "872f2c5a-cf6e-5b97-9db7-5202225e6ffb", "7305a38b-a07e-5e95-8462-d583bc1e90c8", "b513d596-2606-5a5f-9891-664942fb1488", "6617e100-5326-5f77-89fc-58086d9008bc", "0fd254fb-0bb3-596a-9199-4463e1bed74d", "6dc11137-351a-5db7-a5dd-3bed39195d89", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "5ba21c89-fb4e-5966-a738-55d18340ed19", "b5dfa69f-e462-54ae-afc6-069808c1b469", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "5b08f953-b4e3-5d1d-9a7f-4c3728a4b0b4", "c76b968a-995a-5109-a4eb-f329fa710f26", "3e23a677-9f88-5a36-a751-7eaaca56c05f", "f5a196f6-0141-5856-880a-c064fd0a7ae4", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "75f411aa-b7b8-53e9-a462-676a7c43af57", "d77ebf73-718c-584e-83ef-4b263f378f1c", "d086f9d2-e87c-5292-925f-26f489250673", "a2349860-0574-558e-8142-b5eeb03efb7c", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "1939c6ce-d2d4-5c9f-999c-4d416f0f2ff7", "bbe57e9c-d84e-5bea-b912-640a33ee042c", "8de91fd4-65e1-519f-b17c-1f889ead8ea7", "a6cf032e-ddb4-561d-bd17-941b9bd28a0e", "58b68b03-a6a4-5977-a584-6f7b13dab877", "0fd254fb-0bb3-596a-9199-4463e1bed74d", "9610c218-3fc1-50c1-9412-849cb6c143c0", "d1586d70-b85f-506c-bf13-16816c8debdc", "13f37e61-5d92-5688-94e4-81c5c80ee126", "25dfb38b-fc5c-50f0-aa8a-59e9fd41943f", "ced47103-b45c-5707-818d-d3151961186c", "6cc62946-4f47-57f5-b109-b923f5840e29", "5d668c9c-fe3c-544d-8aa7-a2a4d7ecb90c", "f894b5e9-2253-54a3-affc-218df494d358", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "99dd3a08-02e8-501f-9353-8153b5764ad3", "fc11469f-1375-57f9-802c-06094e17834e", "397588f0-a421-5b51-8535-5cc1694e2921", "ebaab94f-c9fb-5186-951c-d7259a580fde", "28ad8a82-46ea-55d5-9c2d-4faaf0e88ab0", "1e17d663-53fb-59ea-b642-18a00e2ce376", "3327fb1f-7d25-5b78-9328-a1a471faecd3", "c090d857-0bb9-5075-9ec6-07b11d317089", "0fd254fb-0bb3-596a-9199-4463e1bed74d", "54169656-141d-58b2-afd6-5f26cb2889ed", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "c18fb95e-8ca9-5822-bd59-666d91a6554d", "a5e24ec8-9605-58e8-994a-32576d2b9cc6", "348ad27b-a8bd-57b1-b591-b5bcebd5a3c0", "ae10df12-cb06-58ac-a746-6f941ee929e3", "193f0d17-74ac-53cd-b79e-680fa62356c7", "87aa5397-d9a3-535a-9804-e1b84488bf43", "4a324a22-6bd2-5602-84bc-07231c819440", "9660596b-5980-5a5a-9310-06f00c53405a", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "df53ebe7-ed7e-56b5-9a14-1c0b4dbe2f7d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the table that corresponds to a ROUGE L score equal to 41.39. How does the application of normalizing flow in the model proposed in the paper specifically contribute to the improvement of abstractive text summarization performance?", "reference_answer": "The application of normalizing flow in the neural topic model specifically contributes to the improvement of abstractive text summarization performance by enabling a better approximation of the true posterior distribution of global semantics. This enriched representation of global semantics allows the summarization model to have a deeper understanding of the overall document content, which in turn helps in generating summaries that are more aligned with the key points and nuances of the original text. Additionally, the integration of a contextualized gating mechanism ensures that the influence of global semantics on the summarization process is optimally balanced, preventing the potential overwhelming of contextualized representations and maintaining the quality of the generated summaries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00588/comparison_table.png"]}
{"uuid": "1e6d60ff-b7f3-54c4-99e6-8788f4556d1a", "question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. Based on the ablation study findings, what is the accuracy of the model proposed in the paper when fine-tuned on 20% of the GSM8K dataset data and utilizing an external calculator?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. Based on the ablation study findings, what is the accuracy of the model proposed in the paper when fine-tuned on 20% of the GSM8K dataset data and utilizing an external calculator?", "reference_answer": "20.47%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "1f5a6a24-ee02-5f82-9c76-043571fbed64", "question": "Consider the paper that introduces the model that corresponds to the brown bars in the figure. What specific method does the paper propose to address the limitations of large language models (LLMs) in maintaining multi-turn consistency in dialogues?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the brown bars in the figure. What specific method does the paper propose to address the limitations of large language models (LLMs) in maintaining multi-turn consistency in dialogues?", "reference_answer": "Ghost Attention (GAtt)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/prompt_setting_figure.png"]}
{"uuid": "1f5e5e94-1751-5e27-9600-521cbcf72b29", "question": "Consider the paper that introduces the dataset in the table that has the fewest number of turns. What specific advantage does the curriculum learning strategy offer for the model's performance on low-resource languages according to the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b7315180-e811-5a4a-882f-d4a8e0ffe866"], "reference_pdf": ["25905c58-6108-5577-b948-fbaa6aa23e6e", "7d06b7cd-d351-5e13-a0d1-d72ac792b3e7", "b846c66a-a177-5119-af8d-ec4757d6a06c", "2ee103a7-04e2-53fe-83fe-da3bee6579f6", "42c5c7c9-6099-53c2-8868-147e11467288", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "f92811a6-b9ce-519e-9346-f3b892d7f535", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "70d90498-b24e-5af4-84e5-c40377652bce", "01c9329e-9789-52dc-9eed-c99a8ef88a5c"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has the fewest number of turns. What specific advantage does the curriculum learning strategy offer for the model's performance on low-resource languages according to the paper?", "reference_answer": "The curriculum learning strategy enables the transfer of general knowledge from English to other languages, leading to significant improvements in overall performance on low-resource languages."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2402.04588/comparison_table.png"]}
{"uuid": "1f7c6d01-44d5-575b-af37-7a023fea506b", "question": "Consider the paper that introduces the benchmark that results in the highest execution accuracy for this method. What specific mathematical operations are included in the Numeric Reasoning Knowledge category of external knowledge evidence?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["ba614015-ae38-5939-8106-728d33b07d78"], "reference_pdf": ["b16e8b8f-0d45-58db-b7ec-72837add121d", "befe32c2-c0d6-520c-b7df-ddfcfeb79028", "a0ce147c-98bf-52ba-8365-84983999c80a", "6103a65c-dea4-59ae-bcc4-5f7420478289", "a87515b4-ac31-5ecb-a261-cc3c8d5f4c8b", "0b9362a1-e422-5331-a3ec-a8abc9c8c249", "8ff266a0-ac5b-543b-b908-bdea848acd2d", "79c6d4f0-99c6-5051-bc74-19bc136089f4", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "73172932-ae8b-5d7d-bee0-6bc34aea20e7", "d135e939-c86d-56a7-8840-c346de4706f9", "1d0dae01-2fe3-5971-86b2-965007cceb0c", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "45fbbb5f-4e5d-52b2-8956-84eedc7cba9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark that results in the highest execution accuracy for this method. What specific mathematical operations are included in the Numeric Reasoning Knowledge category of external knowledge evidence?", "reference_answer": "MINUS, ADDITION, DIVISION, MULTIPLY"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18538/result_table.png"]}
{"uuid": "1fc376a8-4c7c-5b8d-9c46-30908005bd01", "question": "Consider the paper that introduces the method which is shown in the table above the 'Magister et al' row but below the 'UL2' row. How does the performance of a GPT-2 Large model fine-tuned with ground truth step-by-step annotation compare to one fine-tuned with the model proposed in the paper-generated Chain of Thought (CoT) on the GSM8K dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is shown in the table above the 'Magister et al' row but below the 'UL2' row. How does the performance of a GPT-2 Large model fine-tuned with ground truth step-by-step annotation compare to one fine-tuned with the model proposed in the paper-generated Chain of Thought (CoT) on the GSM8K dataset?", "reference_answer": "The GPT-2 Large model fine-tuned with ground truth step-by-step annotation outperforms the one fine-tuned with LLM-generated Chain of Thought (CoT) on the GSM8K dataset."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "208d8321-da17-5b6b-ab53-680481efccd6", "question": "Consider the paper that introduces the dataset which has the largest number of instances, QASUM. What specific threshold value was chosen for the matching score to include an abstract sentence in an aspect-based summary in the model proposed in the paper, and how was this value determined?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the largest number of instances, QASUM. What specific threshold value was chosen for the matching score to include an abstract sentence in an aspect-based summary in the model proposed in the paper, and how was this value determined?", "reference_answer": "0.5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "20a6fb40-b3f5-50ae-8e66-423b7196ec27", "question": "Consider the paper that introduces the method in the figure that demonstrates the highest Toxicity Probability Score when the number of samples equals 1M. What is the inference time for feature extraction using the model proposed in the paper compared to VinVL and M2 Transformer?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9906dc9c-eae7-5352-82ca-533b23d498a1"], "reference_pdf": ["f2c45532-0d1d-52f3-8293-a28562dca0c2", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "a9e9314b-4cc2-58e5-bbbd-e0908b71d865", "120aa43e-5a6b-5fc6-9e11-fecd0d3ca36e", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "411227b7-53f4-546d-9c14-70bf07f74473", "1b95bbb6-5c74-52f2-8c79-8fa03ff4879c", "cbb30373-01f6-5707-81b7-fd36a3e42c87", "d4223ac7-9d75-531d-9113-b52397da2e1e", "aa4f0205-fd37-5154-9b71-ce252dccab5c", "4a87a9d9-1977-5796-b15b-18eeb2537ea3", "884e57aa-78e0-5621-958c-8681a2d6f61f", "b95e3586-0087-5079-8c32-66506a0ba806", "c3e48be8-b991-5cfe-bd59-05d2496a094d", "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1", "e4ad4c66-c12f-5367-a923-7342a3a48ac0", "19b4c2c4-42f6-595f-8a56-13b3d241ee6d", "d62a70d3-39eb-57b2-854c-06ae086c4b84", "eb335bea-aa4d-5fb1-9e60-189c2f979d4f", "45decdf4-f524-52d5-8385-3da8d839888b", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "a039db49-aed3-57e6-8720-913aaac61942", "51e5bebd-9870-5529-875f-710339447ecb", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "95c63efc-ff02-585d-bcdf-75e933c5816a", "9baa42c9-b79b-5654-85d3-860ee3241d5e", "c466be66-c99c-5dcd-90a5-5b86d4a6638a", "a229d47a-0069-5d45-8bac-7e5eb2e8b8d1", "0b363526-f924-5baa-be50-c665bd10cb5b", "fa4b52f4-0a73-5305-bf28-adee87c842ec", "72e031f9-130a-5dd0-9f2c-bb29e197a8c2", "14028d43-a37a-52d4-8869-f174ff05ca4c", "d88358e9-efe9-5844-8bfa-b1d3ed22ce82", "45b99aad-66f7-5bc9-a6ef-cc7eb8d66567", "ded8818d-5039-5cc2-b3c7-9f4908153210", "4b918831-da2b-5123-8351-ffdf3abde7c2", "04873797-c04f-5d4b-bab4-fcace1b87c1b", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "5da677b6-dec7-57c9-afb4-5c1af7801b8c", "82a80b14-aa33-57ed-b666-c182235bc860", "5a09a7b9-bceb-58cc-a560-2845b8774e26", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "5fabde11-10a7-5fc8-a1b5-57a6237b5535", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e41d952a-d067-52a4-9fea-12aa78420924", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "b82c062d-e25e-560b-9fe8-47a56901fc74", "1ee90f2d-74b4-5c24-ade4-7608f608d42b", "a02bef04-a577-5433-8a32-7d3786ccfd02", "345e1ebc-c05b-59ea-9619-557ba7bc6e3c", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "0178ef4d-109b-512b-8194-c5debb2014b1", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd4cf2bd-a308-5ae4-8718-2eb04418d7e5", "5c347f12-43c5-57a5-832b-bcf310dfad98", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "ef55b6d8-d37c-5a62-95ca-83bd707306cd", "c5227d39-0b3c-5458-a976-982cdd8d4015", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "1c5aa016-c6ba-5928-87b6-b71a0c952504", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure that demonstrates the highest Toxicity Probability Score when the number of samples equals 1M. What is the inference time for feature extraction using the model proposed in the paper compared to VinVL and M2 Transformer?", "reference_answer": "31 ms"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.11523/figure.png"]}
{"uuid": "21142e2a-4f1d-5332-a7c4-4e94ca1f7526", "question": "Consider the paper that introduces the method that demonstrates the lowest EA score on the FinQA task. What specific feature of the BERT model's output is utilized in the model's policy network for dynamic prompting via policy gradient in PromptPG?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that demonstrates the lowest EA score on the FinQA task. What specific feature of the BERT model's output is utilized in the model's policy network for dynamic prompting via policy gradient in PromptPG?", "reference_answer": "\\texttt{[CLS]} token representation"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "21c1f2ad-266e-5e5b-ac44-9c0841ee8d10", "question": "Consider the paper that introduces the method that achieves a score of 31.8 in the Seen, Test, SR dataset. How does its performance with OSCAR initialization and without predicting the parent object or visual region classification compare on the Seen and Unseen validation folds for the Task and GC metrics?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a score of 31.8 in the Seen, Test, SR dataset. How does its performance with OSCAR initialization and without predicting the parent object or visual region classification compare on the Seen and Unseen validation folds for the Task and GC metrics?", "reference_answer": "Seen Task: 37.44%, Seen GC: 44.62%, Unseen Task: 5.73%, Unseen GC: 15.91%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "22ac810b-99da-528f-9e64-4740fbc6d004", "question": "Consider the paper that introduces the model in the table that has 12M updated parameters. What is its core innovation in the context of unifying retrieval and reasoning for multi-hop KGQA tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the table that has 12M updated parameters. What is its core innovation in the context of unifying retrieval and reasoning for multi-hop KGQA tasks?", "reference_answer": "The core innovation of UniKGQA in the context of unifying retrieval and reasoning for multi-hop KGQA tasks is the unification of retrieval and reasoning in both model architecture and parameter learning."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_table.png"]}
{"uuid": "2337a7ef-0c0e-5999-beba-23f1c65da9c8", "question": "Consider the paper that introduces the method that has a lower Hits@1 score than ReasoningLM but a higher Hits@1 score than NSM across all fine-tuning samples. What is the core innovation of the model proposed in the paper in the context of unifying retrieval and reasoning for multi-hop KGQA tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower Hits@1 score than ReasoningLM but a higher Hits@1 score than NSM across all fine-tuning samples. What is the core innovation of the model proposed in the paper in the context of unifying retrieval and reasoning for multi-hop KGQA tasks?", "reference_answer": "The core innovation of UniKGQA in the context of unifying retrieval and reasoning for multi-hop KGQA tasks is the unification of retrieval and reasoning in both model architecture and parameter learning."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "233c728d-3716-56a8-84d5-16b09bb3959f", "question": "Consider the paper that introduces the method which is represented by the lavender color. What specific computational advantage does the model proposed in the paper offer over a unidirectional classifier in terms of the number of forward passes required for computing $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is represented by the lavender color. What specific computational advantage does the model proposed in the paper offer over a unidirectional classifier in terms of the number of forward passes required for computing $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$?", "reference_answer": "GeDi's online classification trick can compute $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$ on the order of 10k fold less computation as compared with a unidirectional classifier."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "2340f757-82fa-54cb-99f2-1e5db7cb9e3d", "question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What specific pre-training task is designed for both retrieval and reasoning models in the model proposed in the paper to ensure their unification in parameter learning?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What specific pre-training task is designed for both retrieval and reasoning models in the model proposed in the paper to ensure their unification in parameter learning?", "reference_answer": "question-relation matching"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "2398a934-d6d3-5b6d-a422-2573cbfc7f92", "question": "Consider the paper that introduces the method that has a perplexity of 60. What is the primary goal of discriminatively training conditional language models (CC-LMs) with its training approach?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a perplexity of 60. What is the primary goal of discriminatively training conditional language models (CC-LMs) with its training approach?", "reference_answer": "The primary goal of discriminatively training CC-LMs with GeDi training is to make them better discriminators for GeDi-guided generation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "2410d944-fa55-5f41-995c-f21dc93dab5d", "question": "Consider the paper that introduces the model that scores higher than ACA but lower than RationaleCL in the 'T5' column. What hyperparameter values were used for the FewRel dataset in its experiments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores higher than ACA but lower than RationaleCL in the 'T5' column. What hyperparameter values were used for the FewRel dataset in its experiments?", "reference_answer": "$\\alpha=0.5$, $\\beta=0.5$, $\\tau_1=0.1$, $\\mu=0.5$, $\\omega=0.1$, $\\tau_2=0.5$, $\\gamma=1.25$, $\\lambda_1=0.5$, $\\lambda_2=1.1$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "241d9830-8725-5876-94bb-811071bc3bf4", "question": "Consider the paper that introduces the model that has the highest performance on the En-De task in the Test2016 dataset in Previous Image-must Systems. What is the average BLEU score improvement of this model over the text-only baseline on the EN$\\rightarrow$DE task for the Transformer-Tiny model on the Multi30K dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["c653b597-b831-535e-bdb1-af03d3f3f1e7"], "reference_pdf": ["dd2f2eae-81f5-5525-971f-5540dde42f6c", "fffd1c97-f03e-5210-8dce-f0eb709b9199", "f1ea3e20-3942-5edd-9c70-f73b10f2da1e", "40d27262-e113-523f-9533-3ee949bdfb05", "c89e402d-2dd4-57dc-883b-be5c04e54b3a", "ad354a8b-1b60-517d-a7fa-d22b435b7f8f", "5052872f-0692-5df0-b02c-ce0f895d539b", "f17feaa7-e8e8-5559-9cf7-fd4b153b811c", "a0c50dc5-15b6-5924-bb70-08d2617f583f", "7821eda8-5710-57df-96c4-89cf30bf7a77", "884e57aa-78e0-5621-958c-8681a2d6f61f", "3b8af772-96a1-578e-a3de-272d2cb9ad7f", "5b08577d-f73f-56d5-be75-931a10239a0d", "f0266918-92ed-5f40-8bd8-499d2979a4e4", "d38dfa65-c493-5cc7-a20d-a01897d7fdc2", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "88185cdb-ff85-5600-bbcb-5bb65ecd6665", "5671a75b-4bcf-5446-82c0-481b1cd418f2", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "e26e48f8-0721-56f6-89dd-9e96448a75c5", "67c0b261-9f6d-50ac-b824-816f48441fa8", "ef1fd71c-6764-5364-8f8f-18d147a69e6d", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "9d24c743-9966-5400-a5f9-6825eca1d557", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "4b2861dc-27c5-57f4-8e01-b018654b3e25", "d7894a4b-2b2f-5355-8193-5c68ffd30928", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "0e854ebb-88e7-55c4-952b-818ce54bc014", "d9b0f39f-60aa-53f3-8382-532440370fdf", "ac65b094-5a2c-5ab7-8497-a3cd526fa8ca", "dfac74e2-051a-5a1f-98fc-d5497a48f44b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest performance on the En-De task in the Test2016 dataset in Previous Image-must Systems. What is the average BLEU score improvement of this model over the text-only baseline on the EN$\\rightarrow$DE task for the Transformer-Tiny model on the Multi30K dataset?", "reference_answer": "2.1"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13361/result_table.png"]}
{"uuid": "2514eb44-a7a2-5108-ab63-68900bcc801f", "question": "Consider the paper that introduces the method which is listed in the table below the VL-BART method and above the OFA-base method. What is the role of the $\\tiny{<}obj\\tiny{>}$ token in the output sequence design of the UniTAB model?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is listed in the table below the VL-BART method and above the OFA-base method. What is the role of the $\\tiny{<}obj\\tiny{>}$ token in the output sequence design of the UniTAB model?", "reference_answer": "Indicates word-box alignments and simplifies sequence prediction by providing hints of text-box code-switching."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "251aee5b-8fc0-5d4f-9c19-c024b4e4fe42", "question": "Consider the paper that introduces the model represented by a blue line in the figure. Based on the human evaluation results, which variant was statistically indistinguishable from human responses in terms of relevance?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented by a blue line in the figure. Based on the human evaluation results, which variant was statistically indistinguishable from human responses in terms of relevance?", "reference_answer": "DialoGPT (345M, w/ MMI)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "25b49266-6343-5ba2-a237-80af8ed6c27e", "question": "Consider the paper that introduces the model that has the highest accuracy in the COGS-all dataset. What specific architectural change was made to the Transformer's layer normalization in the model proposed in the paper compared to its originally proposed form?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["6b729c10-15e8-5eaa-8b40-8c8eafbd3ddb"], "reference_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b", "e1e2bf66-bde7-58c0-98f6-6414d50c1311", "34417770-67d7-5cab-b9d4-76999c97bc02", "776bb6da-c5c2-5c73-b8ac-f038fc55bb6a", "9c9e036b-576a-5a70-923f-4d33da527760", "1cbc9c7a-e562-5d6a-af83-4f9a1520dce2", "ce99c350-ea64-53eb-b705-c33884619d64", "53504791-99de-5143-a351-a080bdcc3bc8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "696b4e72-71ad-5357-b60a-7cd5121619dc", "a4c0cf83-a1d0-57b1-84d9-9b7d365f5ad9", "9775a2f4-5880-5569-8cff-46fce5420bf0", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "2eaf2338-0cce-5f50-8917-338a927b7e1a", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "42fd3669-c60f-5d28-b51d-4523bebf0734", "24c55b93-968f-5a40-8520-acfd6229bde6", "ea02c473-42cb-5fbe-9287-aea0fa4a842e", "e5036d4f-b1eb-5a28-b5e0-4887f14183d2", "837e7fdc-f434-546f-9a83-81afc1529b90", "ff84e2fe-51c3-5208-8002-402a7d477b19", "94993d82-6d3b-5b04-b25f-13e33faf6822", "4fe1db4a-687c-55c3-b8c1-3c6ca2a8b302", "0ce323c7-bde8-560b-98c9-6c2c9b5cdf08", "47cbfa6b-6a2f-521e-a7e2-19a3c3460b47", "42fd3669-c60f-5d28-b51d-4523bebf0734"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest accuracy in the COGS-all dataset. What specific architectural change was made to the Transformer's layer normalization in the model proposed in the paper compared to its originally proposed form?", "reference_answer": "a simplified version of layer normalization where the activations are only rescaled and no additive bias is applied."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15040/accuracy_figure.png"]}
{"uuid": "25bb6403-be20-58a7-be90-a99babac1661", "question": "Consider the paper that introduces the method which is in the second row of the table. What specific algorithmic enhancement does the model proposed in the paper, identified as SPADE, apply to handle the issue of tail-sharing edges in the spatial dependency graphs, and what is its impact on the F1 score for the \\cord\\ dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is in the second row of the table. What specific algorithmic enhancement does the model proposed in the paper, identified as SPADE, apply to handle the issue of tail-sharing edges in the spatial dependency graphs, and what is its impact on the F1 score for the \\cord\\ dataset?", "reference_answer": "SPADE applies a tail collision avoidance algorithm to handle the issue of tail-sharing edges in the spatial dependency graphs. This algorithm iteratively trims the tail-sharing edges, keeping only the one with the highest linking probability, and generates new edges until the process becomes self-consistent. This enhancement leads to an increase in the F1 score by +1.0% for the \\cord\\ dataset with oracle (ground truth OCR results), and by +0.8% without the oracle."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "25f1d4b6-a835-5e17-8484-8c9ecb2e54fd", "question": "Consider the paper that introduces the method which is shown in the fourth row of the table. What is the impact of using a death mask with agent-specific global state (AS) on the performance of MAPPO in the SMAC domain?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["db2cacba-a6d6-5de3-8b45-95a4a07883c3"], "reference_pdf": ["8de6d12b-9dcd-5a37-aaf6-c9295ce1e8a9", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "74746a87-dab3-59c9-be08-3ecfcf6438eb", "3141fa52-db69-539c-8979-fbae34e9747a", "02193a94-398e-57da-bb53-0c5800ca743a", "fbe2cad7-8871-57e9-99a5-041bd72a96d1", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "3b56c40b-e3c0-5ab0-8303-818cadcbfd0b", "95286e49-8ec0-51d4-b4af-8a0cb4b59b63", "feb416bd-1fd2-59c4-b5e3-5cd152775a17", "56bb5074-0a00-578b-ad44-e24096458b1e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "a84ef890-5c36-506a-b8ea-79837d85ae3b", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "446b417e-0e23-5098-afe3-0790a06ab23e", "25b64ade-68d0-5d1f-a552-4169ec42054f", "d22f49c8-5ad1-5151-adaa-41d9c94fdbc0", "118cac21-d91b-55b6-bfce-0742348b4c2d", "79a7862f-22dd-56b1-affd-42f774cf64fb", "172b7dad-d436-5ced-9eb4-0f5702d227b2", "dd21cb7c-5752-5764-b486-bbf8f2e53f84", "177b1aea-89bc-52c2-bf91-6f27f1964f71", "34ef8fe5-e5a0-5401-8a39-e8944a3ea356"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is shown in the fourth row of the table. What is the impact of using a death mask with agent-specific global state (AS) on the performance of MAPPO in the SMAC domain?", "reference_answer": "Using a death mask with agent-specific global state (AS) significantly improves MAPPO's performance in the SMAC domain."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10701/result_table.png"]}
{"uuid": "26b97f3a-5473-5466-a110-d9506fe06067", "question": "Consider the paper that introduces the method at the rightmost part of the figure. What is the minimum number of tokens in the set \\(\\gV_m\\) that maintains at least \\(\\rho\\) in cumulative probability mass in \\(P_w(x_t|x_{<t},c)\\) during the generation guided by this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method at the rightmost part of the figure. What is the minimum number of tokens in the set \\(\\gV_m\\) that maintains at least \\(\\rho\\) in cumulative probability mass in \\(P_w(x_t|x_{<t},c)\\) during the generation guided by this method?", "reference_answer": "n=m"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "26de5a9c-6b68-59e4-8c43-0fb7a4505437", "question": "Consider the paper that introduces the method that achieves an F1 score with a mean of 58.86 in the TAT-QA task. What specific aspect of the policy gradient strategy allows the model proposed in the paper to outperform heuristic-based example selection strategies in the context of few-shot GPT-3?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an F1 score with a mean of 58.86 in the TAT-QA task. What specific aspect of the policy gradient strategy allows the model proposed in the paper to outperform heuristic-based example selection strategies in the context of few-shot GPT-3?", "reference_answer": "The specific aspect of the policy gradient strategy that allows PromptPG to outperform heuristic-based example selection strategies in the context of few-shot GPT-3 is its ability to learn to select in-context examples from a small amount of training data dynamically, thereby constructing the optimal prompt for the test example. This approach significantly reduces the prediction variance compared to random selection and improves the selection of in-context examples over existing strategies."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "26f10cdb-9cb4-5a71-9969-435da3877ca7", "question": "Consider the paper that introduces the method that exhibits a score of 34.9 in the Acc-7 metric on MOSI. What specific improvement in accuracy percentage does the model proposed in the paper achieve over the state-of-the-art for 5-class sentiment classification?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits a score of 34.9 in the Acc-7 metric on MOSI. What specific improvement in accuracy percentage does the model proposed in the paper achieve over the state-of-the-art for 5-class sentiment classification?", "reference_answer": "6.7"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "278083ad-d374-5248-874d-3af8c2b8ad56", "question": "Consider the paper that introduces the method that has a lower F1 score than TPP and a higher F1 score than BROS. What specific performance gain does the integration of both CoordConv and Corner Pooling modules contribute to the Entity Linking task in the model proposed in the paper, according to the ablation study?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than TPP and a higher F1 score than BROS. What specific performance gain does the integration of both CoordConv and Corner Pooling modules contribute to the Entity Linking task in the model proposed in the paper, according to the ablation study?", "reference_answer": "0.03"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "2849db52-cab9-5e35-923e-70f88f077a0d", "question": "Consider the paper that introduces the method that demonstrates the second highest score in the TweetEval Irony dataset for both zero-shot and few-shot prompting. What specific adaptation in the text embeddings allows the model, proposed by the paper, to build correspondence among query text, label text, and objects in grounding tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["2479f89b-b7c0-534f-b51d-d24093d3a1f9"], "reference_pdf": ["7aacee49-58db-593f-9a47-44846ba2ed23", "881f50d7-f0cf-59e7-8351-429ea3655e0b", "57c06ca1-608a-5816-86dd-0f35be577ce0", "1165b8f0-4261-5c50-9583-bfc199324e61", "1c848190-6829-5b07-a439-3452fd19617b", "ea8d0d91-a08c-547f-aa61-fc136ce41e58", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "003269db-f43b-57bc-a219-825c655fab01", "16e73621-a0c1-5f1d-ae72-fa60befecf05", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "b31b84cd-d7c7-50d1-9dc2-cb340ea4d218", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "a76fdb50-d95e-5db2-83a6-ece16257796b", "e0523cf0-8310-565e-9d91-c539c15adcb7", "be395337-c3e2-5e16-b2ef-1ed22e6736dd", "729f79df-1057-5418-89cd-592408770592", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "1e0413f9-466d-57a0-be12-cbfb9da4056a", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "8f02441e-aa43-5abf-bd9b-cfd760b7cc20", "e5c8fae9-734a-54d1-bde4-03ec07d10c86", "b5798106-2737-52fa-b1e5-010749d19c2c", "6677d3c0-7aea-5795-a934-d93933e25157", "02cf0294-1961-54c5-a745-0d99126e65d3", "c76b968a-995a-5109-a4eb-f329fa710f26", "de0470bf-d650-5f5c-9fb8-926b7ed2c806", "65c601c1-c571-5d9e-aa32-e37fcc3e0097", "445e9197-1321-57c3-93bf-7084e795848d", "da29dae2-1a88-5793-8149-81c0b63122ca", "02193a94-398e-57da-bb53-0c5800ca743a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that demonstrates the second highest score in the TweetEval Irony dataset for both zero-shot and few-shot prompting. What specific adaptation in the text embeddings allows the model, proposed by the paper, to build correspondence among query text, label text, and objects in grounding tasks?", "reference_answer": "Embedding sharing"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15746/comparison_2_table.png"]}
{"uuid": "28f1b31f-b91e-5237-8491-f00056ac39a0", "question": "Consider the paper that introduces the method that has the lowest MAE in the CH-SIMS task. What specific regularization techniques were applied to the $\\mathcal{U}_v$, $\\mathcal{U}_a$, and $\\mathcal{U}_s$ subnetworks in the model proposed in the paper, and what were their parameter values?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the lowest MAE in the CH-SIMS task. What specific regularization techniques were applied to the $\\mathcal{U}_v$, $\\mathcal{U}_a$, and $\\mathcal{U}_s$ subnetworks in the model proposed in the paper, and what were their parameter values?", "reference_answer": "Dropout with p=0.15 and L2 norm with coefficient 0.01."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/result_table.png"]}
{"uuid": "2a1ef5cc-1395-54ec-bb12-893f0d7a98fa", "question": "Consider the paper that introduces the method that has an accuracy of 78.1% on the VQA-v2 task. How does the model's performance on the RefCOCO+ testA set compare to the previous state-of-the-art model UNICORN in terms of improvement points?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an accuracy of 78.1% on the VQA-v2 task. How does the model's performance on the RefCOCO+ testA set compare to the previous state-of-the-art model UNICORN in terms of improvement points?", "reference_answer": "6.65"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "2b05b7ba-a5a1-5071-a84a-240ac3a10e86", "question": "Consider the paper that introduces the model that achieves a higher TP score than GIT but a lower TP score than LLaVA. What specific architectural feature of the model proposed in the paper allows it to avoid the computational steps of class-aware NMS and RoI Align during feature extraction?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["9906dc9c-eae7-5352-82ca-533b23d498a1"], "reference_pdf": ["f2c45532-0d1d-52f3-8293-a28562dca0c2", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "a9e9314b-4cc2-58e5-bbbd-e0908b71d865", "120aa43e-5a6b-5fc6-9e11-fecd0d3ca36e", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "411227b7-53f4-546d-9c14-70bf07f74473", "1b95bbb6-5c74-52f2-8c79-8fa03ff4879c", "cbb30373-01f6-5707-81b7-fd36a3e42c87", "d4223ac7-9d75-531d-9113-b52397da2e1e", "aa4f0205-fd37-5154-9b71-ce252dccab5c", "4a87a9d9-1977-5796-b15b-18eeb2537ea3", "884e57aa-78e0-5621-958c-8681a2d6f61f", "b95e3586-0087-5079-8c32-66506a0ba806", "c3e48be8-b991-5cfe-bd59-05d2496a094d", "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1", "e4ad4c66-c12f-5367-a923-7342a3a48ac0", "19b4c2c4-42f6-595f-8a56-13b3d241ee6d", "d62a70d3-39eb-57b2-854c-06ae086c4b84", "eb335bea-aa4d-5fb1-9e60-189c2f979d4f", "45decdf4-f524-52d5-8385-3da8d839888b", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "a039db49-aed3-57e6-8720-913aaac61942", "51e5bebd-9870-5529-875f-710339447ecb", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "95c63efc-ff02-585d-bcdf-75e933c5816a", "9baa42c9-b79b-5654-85d3-860ee3241d5e", "c466be66-c99c-5dcd-90a5-5b86d4a6638a", "a229d47a-0069-5d45-8bac-7e5eb2e8b8d1", "0b363526-f924-5baa-be50-c665bd10cb5b", "fa4b52f4-0a73-5305-bf28-adee87c842ec", "72e031f9-130a-5dd0-9f2c-bb29e197a8c2", "14028d43-a37a-52d4-8869-f174ff05ca4c", "d88358e9-efe9-5844-8bfa-b1d3ed22ce82", "45b99aad-66f7-5bc9-a6ef-cc7eb8d66567", "ded8818d-5039-5cc2-b3c7-9f4908153210", "4b918831-da2b-5123-8351-ffdf3abde7c2", "04873797-c04f-5d4b-bab4-fcace1b87c1b", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "5da677b6-dec7-57c9-afb4-5c1af7801b8c", "82a80b14-aa33-57ed-b666-c182235bc860", "5a09a7b9-bceb-58cc-a560-2845b8774e26", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "5fabde11-10a7-5fc8-a1b5-57a6237b5535", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e41d952a-d067-52a4-9fea-12aa78420924", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "b82c062d-e25e-560b-9fe8-47a56901fc74", "1ee90f2d-74b4-5c24-ade4-7608f608d42b", "a02bef04-a577-5433-8a32-7d3786ccfd02", "345e1ebc-c05b-59ea-9619-557ba7bc6e3c", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "0178ef4d-109b-512b-8194-c5debb2014b1", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd4cf2bd-a308-5ae4-8718-2eb04418d7e5", "5c347f12-43c5-57a5-832b-bcf310dfad98", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "ef55b6d8-d37c-5a62-95ca-83bd707306cd", "c5227d39-0b3c-5458-a976-982cdd8d4015", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "1c5aa016-c6ba-5928-87b6-b71a0c952504", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a higher TP score than GIT but a lower TP score than LLaVA. What specific architectural feature of the model proposed in the paper allows it to avoid the computational steps of class-aware NMS and RoI Align during feature extraction?", "reference_answer": "Deformable DETR-based detector"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.11523/comparison_table.png"]}
{"uuid": "2b1b8514-f720-5f51-a3ee-8afb0dece146", "question": "Consider the paper that analyzes the dataset located in the top left of the figure. What specific linguistic phenomenon mentioned in the paper, requiring familiarity with social media to interpret correctly, is expressed in Chinese?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that analyzes the dataset located in the top left of the figure. What specific linguistic phenomenon mentioned in the paper, requiring familiarity with social media to interpret correctly, is expressed in Chinese?", "reference_answer": "您说的都对"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "2b27f55d-f012-5f01-90dd-ec0cc7ad9462", "question": "Consider the paper that introduces the Seq2Exp model marked with the Club citation symbol. What is the maximum Memory Departing Distance (M-MDD) value for which the model proposed in the paper with Memory Register (MR) outperforms the same model without MR on the MathQA dataset according to Figure \\ref{fig:Cache-MCDP-MathQA}?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the Seq2Exp model marked with the Club citation symbol. What is the maximum Memory Departing Distance (M-MDD) value for which the model proposed in the paper with Memory Register (MR) outperforms the same model without MR on the MathQA dataset according to Figure \\ref{fig:Cache-MCDP-MathQA}?", "reference_answer": "5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "2bb432e6-923a-5b54-9f7b-6cb0d313081c", "question": "Consider the paper that introduces the supervised method that achieves the highest score in 100-shot prompting. What specific performance improvement does the model proposed in the paper achieve on the RACE dataset compared to XLNet, and what does this imply about its ability to handle tasks requiring reasoning over longer contexts?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["debf097e-fb5e-52e6-ba62-bf1714b5ccec"], "reference_pdf": ["9441027e-e7d4-59d3-8377-3e68c3f8d6d5", "8860e51f-7c25-5d5c-b0ba-b3726371476c", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "dca70611-4c00-5e95-960e-f6c42eabfd2e", "47d497a4-55b6-5cc1-8d54-2ba8244156c6", "2925c847-385a-5175-a215-e2e46465d755", "bc1c15b7-674b-5686-b3e5-59a4745eefd7", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "8f9d03a3-9cf4-5e26-a59f-6abb1b6eb278", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "a0894fa0-47f3-55ac-9405-9e0652f7a695", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the supervised method that achieves the highest score in 100-shot prompting. What specific performance improvement does the model proposed in the paper achieve on the RACE dataset compared to XLNet, and what does this imply about its ability to handle tasks requiring reasoning over longer contexts?", "reference_answer": "RoBERTa achieves an accuracy of 83.2% on the RACE dataset compared to XLNet's 81.7%, implying it has a better ability to handle tasks requiring reasoning over longer contexts."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11715/few-shot_NER_table.png"]}
{"uuid": "2c2836c5-68c1-5441-bdaa-8c1818c5d2aa", "question": "Consider the paper that introduces the dataset with the largest number of dialogues. What specific methodological approach does the generation-based model, proposed by the paper, employ to mimic human knowledge selection in dialogue response generation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset with the largest number of dialogues. What specific methodological approach does the generation-based model, proposed by the paper, employ to mimic human knowledge selection in dialogue response generation?", "reference_answer": "The generation-based model employs a methodological approach that includes an extra knowledge selection paradigm enhanced by a knowledge-aware generator. This generator uses a combination of a prior distribution and a posterior distribution to mimic human knowledge selection. The prior distribution is based on the dialogue context and the dialogue goal, while the posterior distribution also considers the response. The model minimizes the Kullback-Leibler divergence between these two distributions to mimic human knowledge selection."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "2c6cb418-11b7-581d-bedb-6f3897871248", "question": "Consider the paper that introduces the method that has a score of 73.6 in the CB dataset with 4-shot prompting. How does the model's performance with 12 source tasks compare to its performance with 6 source tasks on the MRQA and Others benchmarks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a score of 73.6 in the CB dataset with 4-shot prompting. How does the model's performance with 12 source tasks compare to its performance with 6 source tasks on the MRQA and Others benchmarks?", "reference_answer": "MPT with 12 source tasks outperforms MPT with 6 source tasks on the MRQA and Others benchmarks, achieving an average F1 of 72.6% and accuracy of 85.6% respectively, compared to 72.2% and 85.5% with 6 source tasks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "2c826c83-36a4-5558-a0f0-b08e4d46bd7f", "question": "Consider the paper that introduces the dataset that corresponds to the second chart from the left. What is the percentage of questions that can be answered using a boolean response?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["8dca380b-0d1b-5c49-a9b6-0581864c7909"], "reference_pdf": ["5b0d44de-0d1d-5f43-a9b0-89b5338732d7", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "84449b22-c7ae-5253-8295-9d74a378fcc3", "8433f894-a217-54d3-9ae5-5c17f951797a", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "79b4a9b3-0759-50f7-a801-83cad821e867", "0337fff3-2745-5430-b1ca-9d43c836a09c", "d699a785-3fb8-5b5b-8487-72d2dbd4dcbd", "90e3610c-c0b5-5b1d-9a9f-6f0f62dd9c89", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "11f9746f-503b-573f-8781-04477603c994", "e3ef9171-b0b7-58c0-8e98-051bfde10ef7", "7908763f-3a9d-5ce5-af59-f68888750583", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "739c8432-c687-5220-89f6-f84e7c860800", "6f4d0a2f-4457-55af-b519-da2a1df140da", "36a1c245-8803-586f-a39c-57a149b16892", "7c278568-4bb8-5a1f-af34-4df3980282eb", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "5a533ef5-84ee-5448-8375-b683864484bc", "1e7d9f86-3567-55b8-be98-064a3d297af1", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "dd39e75b-40a4-5ec5-9943-79277ed1cd00", "819d0208-b342-5a31-a2ab-da64c204544e", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that corresponds to the second chart from the left. What is the percentage of questions that can be answered using a boolean response?", "reference_answer": "14%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12836/ratio_figure.png"]}
{"uuid": "2ee40b7a-ae8d-574f-9a41-ad94db4c005d", "question": "Consider the paper that introduces the method that has a lower F1 score than BROS and a higher F1 score than LayoutXLM. What is the F1 score improvement percentage when applying multi-task learning (MTL) with entity labeling and relation extraction tasks on the FUNSD dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than BROS and a higher F1 score than LayoutXLM. What is the F1 score improvement percentage when applying multi-task learning (MTL) with entity labeling and relation extraction tasks on the FUNSD dataset?", "reference_answer": "0.86%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "2efd1b32-25cb-5034-9f0d-fae9b78efaa7", "question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What specific component of the model's architecture proposed in the paper is directly responsible for propagating the semantic matching information along the directed edges on KGs?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What specific component of the model's architecture proposed in the paper is directly responsible for propagating the semantic matching information along the directed edges on KGs?", "reference_answer": "matching information propagation module"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "2f1f51e6-d100-58ec-8ab8-f32de8cdb58d", "question": "Consider the paper that discusses the dataset located at the bottom left of the figure. What is the Fleiss kappa inter-annotator agreement score for the Yoruba language when considering the 3-class sentiment classification?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that discusses the dataset located at the bottom left of the figure. What is the Fleiss kappa inter-annotator agreement score for the Yoruba language when considering the 3-class sentiment classification?", "reference_answer": "0.600"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "3124245c-8aac-5232-9fa3-91fa17e2749d", "question": "Consider the paper that introduces the method that achieves a higher EA score than Fixed set but a lower EA score than Diverse KATE in the FinQA task. What is the model's, proposed by the paper, EM score using the reverse order of in-context examples on the NQ dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a higher EA score than Fixed set but a lower EA score than Diverse KATE in the FinQA task. What is the model's, proposed by the paper, EM score using the reverse order of in-context examples on the NQ dataset?", "reference_answer": "42.8"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "31892b8e-8f2e-5623-95a6-e34d0ebde565", "question": "Consider the paper that introduces the model which has a lower mac-F1 score than Longformer but a higher mac-F1 score than CaselawBERT. What is the primary reason this model has faster training and inference times compared to ALBERT and ALBERT-large, despite having more parameters?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5d7df310-479d-5fea-aedd-572cdb181b5d"], "reference_pdf": ["5c12db52-9752-56ab-ade8-f9e6e1c9f1e5", "9a106ec5-136d-5944-896b-78f122e41d78", "606bc274-d6e5-5e9a-8c7e-68c4e47e038c", "1831f50a-3d4e-54eb-9a1e-18eaaa4cf019", "46c0d816-f49b-5890-b64f-5ff9e7ee016b", "f0e5dee8-1409-5d41-9e15-e42bbe9c54ce", "9e48134a-b4b2-5c38-8f21-4cd55adbcb17", "0caf6da7-1ec5-5f0e-9e6a-655f574d2bf5", "64ee757d-3fab-5132-aadf-376825399f6b", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "dbe6cf51-ba01-5f0d-83b3-e29f71bafbf1", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "d3f113b1-43ab-55f2-bc01-e3ff9a22ad13"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model which has a lower mac-F1 score than Longformer but a higher mac-F1 score than CaselawBERT. What is the primary reason this model has faster training and inference times compared to ALBERT and ALBERT-large, despite having more parameters?", "reference_answer": "LEGAL-BERTsmall has faster training and inference times due to its smaller size in terms of hidden units' dimensionality and the number of attention heads, which affects gradient accumulation in feed-forward and multi-head attention layers, rather than the total number of parameters."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11368/comparison_table.png"]}
{"uuid": "318a6803-4543-53d8-9c43-673d42f73abe", "question": "Consider the paper that introduces the first method shown in Explicit --> Internet-enhanced category. What is the relative performance increase range observed for language generation tasks when conditioning the largest LSLMs on the web through few-shot prompting by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in Explicit --> Internet-enhanced category. What is the relative performance increase range observed for language generation tasks when conditioning the largest LSLMs on the web through few-shot prompting by the model proposed in the paper?", "reference_answer": "15%-30%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "32c1dc02-e9bd-5beb-9219-3b437c1a43b7", "question": "Consider the paper that introduces the model in the table that corresponds to a 12.79% TP. What specific architectural feature allows the model to avoid the computational steps of class-aware NMS and RoI Align during feature extraction?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["9906dc9c-eae7-5352-82ca-533b23d498a1"], "reference_pdf": ["f2c45532-0d1d-52f3-8293-a28562dca0c2", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "a9e9314b-4cc2-58e5-bbbd-e0908b71d865", "120aa43e-5a6b-5fc6-9e11-fecd0d3ca36e", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "411227b7-53f4-546d-9c14-70bf07f74473", "1b95bbb6-5c74-52f2-8c79-8fa03ff4879c", "cbb30373-01f6-5707-81b7-fd36a3e42c87", "d4223ac7-9d75-531d-9113-b52397da2e1e", "aa4f0205-fd37-5154-9b71-ce252dccab5c", "4a87a9d9-1977-5796-b15b-18eeb2537ea3", "884e57aa-78e0-5621-958c-8681a2d6f61f", "b95e3586-0087-5079-8c32-66506a0ba806", "c3e48be8-b991-5cfe-bd59-05d2496a094d", "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1", "e4ad4c66-c12f-5367-a923-7342a3a48ac0", "19b4c2c4-42f6-595f-8a56-13b3d241ee6d", "d62a70d3-39eb-57b2-854c-06ae086c4b84", "eb335bea-aa4d-5fb1-9e60-189c2f979d4f", "45decdf4-f524-52d5-8385-3da8d839888b", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "a039db49-aed3-57e6-8720-913aaac61942", "51e5bebd-9870-5529-875f-710339447ecb", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "95c63efc-ff02-585d-bcdf-75e933c5816a", "9baa42c9-b79b-5654-85d3-860ee3241d5e", "c466be66-c99c-5dcd-90a5-5b86d4a6638a", "a229d47a-0069-5d45-8bac-7e5eb2e8b8d1", "0b363526-f924-5baa-be50-c665bd10cb5b", "fa4b52f4-0a73-5305-bf28-adee87c842ec", "72e031f9-130a-5dd0-9f2c-bb29e197a8c2", "14028d43-a37a-52d4-8869-f174ff05ca4c", "d88358e9-efe9-5844-8bfa-b1d3ed22ce82", "45b99aad-66f7-5bc9-a6ef-cc7eb8d66567", "ded8818d-5039-5cc2-b3c7-9f4908153210", "4b918831-da2b-5123-8351-ffdf3abde7c2", "04873797-c04f-5d4b-bab4-fcace1b87c1b", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "5da677b6-dec7-57c9-afb4-5c1af7801b8c", "82a80b14-aa33-57ed-b666-c182235bc860", "5a09a7b9-bceb-58cc-a560-2845b8774e26", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "5fabde11-10a7-5fc8-a1b5-57a6237b5535", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e41d952a-d067-52a4-9fea-12aa78420924", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "b82c062d-e25e-560b-9fe8-47a56901fc74", "1ee90f2d-74b4-5c24-ade4-7608f608d42b", "a02bef04-a577-5433-8a32-7d3786ccfd02", "345e1ebc-c05b-59ea-9619-557ba7bc6e3c", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "0178ef4d-109b-512b-8194-c5debb2014b1", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd4cf2bd-a308-5ae4-8718-2eb04418d7e5", "5c347f12-43c5-57a5-832b-bcf310dfad98", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "ef55b6d8-d37c-5a62-95ca-83bd707306cd", "c5227d39-0b3c-5458-a976-982cdd8d4015", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "1c5aa016-c6ba-5928-87b6-b71a0c952504", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the table that corresponds to a 12.79% TP. What specific architectural feature allows the model to avoid the computational steps of class-aware NMS and RoI Align during feature extraction?", "reference_answer": "Deformable DETR-based detector"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.11523/comparison_table.png"]}
{"uuid": "3338236c-a541-56c1-b522-2603c6f82f48", "question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Pre-training --> Architectural-based category. What specific improvement in P@1 does this method achieve over $\\text{RoBERTa}_{LARGE}$ on the LAMA-UHN-T-REx corpus?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Pre-training --> Architectural-based category. What specific improvement in P@1 does this method achieve over $\\text{RoBERTa}_{LARGE}$ on the LAMA-UHN-T-REx corpus?", "reference_answer": "2.9%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "333cbb4d-64c4-5497-a942-650407cd4044", "question": "Consider the paper that introduces the method that has a lower F1 score than SERA and a higher F1 score than Doc2Graph. What specific adaptation does the model proposed in the paper employ to handle the challenge of language-specific pre-processing for its Multilingual Masked Visual-Language Modeling objective?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than SERA and a higher F1 score than Doc2Graph. What specific adaptation does the model proposed in the paper employ to handle the challenge of language-specific pre-processing for its Multilingual Masked Visual-Language Modeling objective?", "reference_answer": "To prevent the language-specific pre-processing, LayoutXLM decides to obtain the character-level bounding boxes. After the tokenization using SentencePiece with a unigram language model, it calculates the bounding box of each token by merging the bounding boxes of all characters it contains, efficiently unifying the multilingual multimodal inputs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "33d935f2-101e-5877-b282-c2c85b8352ed", "question": "Consider the paper that introduces the model that scores a 91.5 in the NER task. What specific dynamic masking rate formula is adopted for the tasks $\\hat{\\texttt{t}}$\\texttt{g2t} and \\texttt{t}$\\hat{\\texttt{g}}$\\texttt{2g} during its pre-training phase?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["eafc1f76-8bd5-594c-90b4-d91531781383"], "reference_pdf": ["5b3aeee6-b982-5fe7-b9b3-6e409408b8ff", "c5534576-a4c3-5084-9038-2c4da11e73ea", "8e6dbffb-603e-551d-8f75-08f37ca07b56", "0a3d5361-f6a6-5a7a-8868-3a1b9387ba2a", "003f56f8-651c-535b-8983-3f448ef1addd", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "1bc8e7cd-fc7a-568e-aa09-c80f67d1e15d", "48eb0527-1a31-5dad-ae9b-832f6138c259", "2ae30032-1e18-5733-b75f-f1d23053f7a2", "8de2532b-6746-59ad-bb7d-7a42ce02682d", "a451e98e-19c1-5141-98d9-bec4da2cb764", "4837c79a-37bb-5d5c-9e26-57d3a5840ca0", "86010c1c-ca15-5fb0-836e-878e2d5b16d5", "c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6", "f6e91a91-0b1e-5280-8522-a20492033f16", "61675c6f-d249-51a5-b949-4ff32c8087d6", "3aec6c04-8061-54a0-b7ec-0910254593e9", "348e185c-b302-5857-bebc-3211c107e7aa", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "96f67ba7-08ce-577a-b675-b560bb668e23", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd22293d-9762-5675-9ef9-60d70e09600e", "4f82b0a7-782b-5d83-abfc-146affe81aea", "87303739-1cdc-53ae-9ca3-9e01d144cd12", "ebaab94f-c9fb-5186-951c-d7259a580fde", "28fbbed5-8ae5-55a0-82be-876292cf5d18", "2bfb964e-fb62-59b5-bb75-05c7fe86ee62", "81f14584-369f-51cd-b3ad-c34dcf1b45a1", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "6d8e0fc1-a6bb-5260-874f-59723d196b81", "d1fe605a-9183-5991-aec7-b474cadcd387"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores a 91.5 in the NER task. What specific dynamic masking rate formula is adopted for the tasks $\\hat{\\texttt{t}}$\\texttt{g2t} and \\texttt{t}$\\hat{\\texttt{g}}$\\texttt{2g} during its pre-training phase?", "reference_answer": "$p = 0.1 + 0.75 * t/T$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11964/comparison_table.png"]}
{"uuid": "342b8cf7-a09f-5185-a12d-cbc2eade8a73", "question": "Consider the paper that discusses the dataset which has more dev set samples than UIT-VSMEC but fewer dev set samples than ViSpamReviews. What specific linguistic phenomenon, as detailed in the paper, can cause annotators to re-read multiple times due to issues like lack of punctuation, diacritics, and ambiguous text meaning, particularly when the text could be interpreted as inappropriate in multiple ways?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that discusses the dataset which has more dev set samples than UIT-VSMEC but fewer dev set samples than ViSpamReviews. What specific linguistic phenomenon, as detailed in the paper, can cause annotators to re-read multiple times due to issues like lack of punctuation, diacritics, and ambiguous text meaning, particularly when the text could be interpreted as inappropriate in multiple ways?", "reference_answer": "Non-diacritical marks comments"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "34aa851c-ccd4-5995-ab14-1baa6b35b71c", "question": "Consider the paper that introduces the dataset in the table that has a validation set size of 1250. Which model demonstrated the highest percentage of factual hallucinations among the evaluated systems?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["36658338-c3d6-5b36-89d0-3ae79fa52f44"], "reference_pdf": ["7b88ef21-46b9-5491-8b41-5ba7e5f89bb4", "5ab64734-2725-57c3-95ba-75a693bf4922", "1165b8f0-4261-5c50-9583-bfc199324e61", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "413aacbe-98fe-526a-9b0f-9d9cbe19ef5b", "34417770-67d7-5cab-b9d4-76999c97bc02", "2987b2aa-67ad-5312-91c3-067762156456", "e0fe58d1-5915-5058-a0d9-fead5d6c3cde", "fe26770b-ff50-56e9-8546-8310b7215de7", "059ebe26-3869-5ac6-9b02-3c8f4cc40d4c", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "87b6b442-cb9b-52b0-bda4-c5315b366b48", "1e52b704-faf6-5269-9ab2-c13bc8be1042", "1e5af690-d43f-573a-9426-eae1c86f4c12", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "dba5b637-a3a2-54f2-9284-034b062db02a", "cac30ce0-51b1-54ef-bfc5-fa365d4131e4", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "e77a8699-a9b0-5923-9ee7-6b40ebe9c61f", "d0ad987a-c189-5059-9b97-48ec131780a4", "e9c37d5e-a9e4-5f5d-a0b7-2d96e98c1048", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "7908763f-3a9d-5ce5-af59-f68888750583", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "281a6af0-616c-5163-995a-77801d30adbd", "295776b5-bd82-5def-96e7-ee7bb8cc6b99", "eb8ba2b8-b5a6-516b-b762-19465f9eaaed", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "041c4689-b5ad-5878-81ab-afc3101acdb6", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "58b68b03-a6a4-5977-a584-6f7b13dab877", "608838ef-8a4c-50f0-a78e-db6f2709edc5"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has a validation set size of 1250. Which model demonstrated the highest percentage of factual hallucinations among the evaluated systems?", "reference_answer": "\\bencdec"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11648/comparison_table.png"]}
{"uuid": "353fef6e-2f4a-5405-af0a-418e6ab39903", "question": "Consider the paper that introduces the model that performs the best on the BBBP dataset. What specific advantage does it demonstrate over Galactica in terms of pre-training data utilization?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["75156ea6-7402-5a33-9303-ec6f543e9999"], "reference_pdf": ["7aa1a28a-1256-5732-9581-f2538bfcaf8e", "adf24566-930f-5a42-8118-6aeb65e4f6f4", "825de5ef-3ab4-5629-9fc4-4b0805f419b8", "a1002509-bd90-5cde-9fd2-7b6216144d71", "653e5d86-f991-5533-bd83-a5d95f760b18", "aa22dd10-f8dc-5b74-893f-4f3b21431f24", "766ea9a1-a447-5963-a71f-c9d0a0562d57", "7ea7979f-d2cf-58e4-b00e-2b4027aaf436", "a2401db7-a8bd-588a-856c-4d9ad4f85409", "3a2ae924-5f60-5905-abab-631f660f7bb6", "54fbf9e2-28d0-54ce-ba51-27f90b206c6e", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "3b7baa1d-606b-5481-9c27-fec60e4c7533", "6d068e18-8fb7-5dff-b0bf-b95297a79dc5", "7908763f-3a9d-5ce5-af59-f68888750583", "4ef708b0-51b3-5527-91fc-a55d70b49671", "e2b71dfc-0678-5451-82f6-42650b5ca0dc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "05397506-c619-548a-9f1f-18f85acc151e", "cf69528e-9892-5b27-ab66-0b66a1304268", "a2677b99-9e0d-5c14-8e19-f1c7d5cfa93f", "7908763f-3a9d-5ce5-af59-f68888750583", "7d25556e-bc5e-58ba-b1d8-294c67ed7d98", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6fd2a9e7-7fea-5866-b0c4-120b7cc5baae", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "d97c36ef-e3d9-5f53-a6ff-00d5ee2f2777", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "d4f91c73-f4cf-5209-bec5-6ff66eb29d19", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "5161fb60-4394-5446-9e6e-ce1f1e9e393a", "1777f12e-991e-52d4-8b6b-03807d589e87", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "964db907-da57-5f8b-b1ef-1054c077ca89", "4a697112-1b30-569a-8fee-c4eace04cb3f", "33130f85-57c8-54d5-b050-075bb1ccab97"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that performs the best on the BBBP dataset. What specific advantage does it demonstrate over Galactica in terms of pre-training data utilization?", "reference_answer": "MolXPT leverages the information from surrounding text by wrapping SMILES sequences with text, which is not explicitly done by Galactica."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07276/performance_table.png"]}
{"uuid": "35707719-65f0-5a85-ac56-f47143c68094", "question": "Consider the paper that introduces the model that achieves the highest score on the MNLI dataset. What is the Dev F1 score for its feature-based approach using only embeddings on the CoNLL-2003 NER task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["00ae9127-82dd-5bbd-9d0f-c2a7a58d65fa"], "reference_pdf": ["7e44dc95-9f92-5653-9246-572cc25c5d22", "7bc3753a-e1cb-5635-805e-bdb98255c704", "91f2e795-bf7f-52df-bfae-2b6525a56d60", "fdb748a6-d777-5a99-8537-5c0d524d277d", "193b12c4-871c-53cf-9497-523742859b8d", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "f32f540f-cb2f-51b7-9bb9-89934eb68916", "e8b94d55-54d3-5c7e-ab41-e6af7c9b8b03", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "77146f7f-edd6-57d3-a190-c37c96243ea3", "8fbd30bf-37b1-5741-8aaa-e4fdbb0468f5", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "4f312f60-4fb7-53a0-b6d7-7810cd39eb43", "26e45afd-1c91-5f0f-bb47-33707acec072", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "afaf79d2-ff40-538d-9a27-d932a5d41d8e", "c811c5a5-c22a-5fd6-9f1c-1ffa1bde7c47", "ae10df12-cb06-58ac-a746-6f941ee929e3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the highest score on the MNLI dataset. What is the Dev F1 score for its feature-based approach using only embeddings on the CoNLL-2003 NER task?", "reference_answer": "91.0"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18343/result_table.png"]}
{"uuid": "35e6f495-4465-5e51-b380-9d8a2feac989", "question": "Consider the paper that introduces the model that exhibits the second best execution accuracy in few-shot prompting. How does its performance on natural language reasoning tasks, based on the evaluation of the model proposed in the paper on the HELM benchmark, compare to other open-access models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that exhibits the second best execution accuracy in few-shot prompting. How does its performance on natural language reasoning tasks, based on the evaluation of the model proposed in the paper on the HELM benchmark, compare to other open-access models?", "reference_answer": "StarCoderBase generally obtains substantially stronger performance than all other models with released weights and often performs comparably to or better than much larger models."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/execution_accuracy_figure.png"]}
{"uuid": "361f2069-2fd0-5dd8-a7d8-fa3efa37dde2", "question": "Consider the paper that introduces the model in the figure that has the lowest diversity score for each of p1, p2, p3, and p4. What specific architectural change was made to the Transformer model in its framework to potentially improve computational efficiency during unsupervised pre-training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["b868c871-5514-505d-8587-367e156e1e28"], "reference_pdf": ["aeb9b828-4aff-5f24-a169-6fe27f0e1e2c", "675768f2-88cd-54a4-b359-f29fe975fcef", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "ad72f105-7a2a-5959-8f49-342eb4469f36", "9f2e58b0-9d4e-56b0-a504-e5f77a2f1476", "d8388017-45ea-5dfa-9238-3d88f2c1ce6a", "f7306500-2b64-5ee2-9f7e-f4beb3b0ebcf", "799320b2-1e80-56c8-9084-73737c3fbfb5", "7415a335-10d7-55f3-af82-07c08f608ecd", "a24d04a0-5d7b-518f-97d3-5202a6f549a4", "947f07f1-5d2a-554e-a441-9838afd4a779", "34417770-67d7-5cab-b9d4-76999c97bc02", "6f696630-3060-5bd1-9be1-a00e8d89edfe", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "ad6fa17b-383b-53da-8737-9038180d5159", "0801ed2c-711f-5ffe-94d6-c264e679e00e", "7908763f-3a9d-5ce5-af59-f68888750583", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "40862fb4-44fd-5785-91f9-e24afaa2923d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "80772a52-97c8-5bf8-9893-0de1cc8c02f4", "07caf8ef-950f-50c9-8989-70d482d73168", "3f2695ed-eeac-5dcc-9200-fa2eaa0f02ad", "2173fe79-3e5b-52f6-bd51-a63b747394c0", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the figure that has the lowest diversity score for each of p1, p2, p3, and p4. What specific architectural change was made to the Transformer model in its framework to potentially improve computational efficiency during unsupervised pre-training?", "reference_answer": "using objectives that produce short target sequences"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05030/diversity_score.png"]}
{"uuid": "369d251d-6c5b-5834-ba0e-ee4d270f0919", "question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. What specific method did the authors employ to encode sentence positions in the encoder input of the model proposed in the paper, and how does it differ from using a fixed BOS token index?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4db47b23-f7bf-5d2e-a957-279ddcc3310c"], "reference_pdf": ["56f3aaed-b2b7-5df1-97cc-7cf6236a892f", "fa9a9ad6-66e9-5bd8-b1a2-862836bceb4b", "c3a61f79-d156-54a9-9888-813475b4d3d1", "0015561a-99bb-5b95-b457-3e43c7751331", "0d601b2e-069f-5bab-ae99-f37eb696b06a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9d2e017c-b25e-5cbc-8493-ccb4d9ab7443", "bcf8872a-b92d-5cbe-8be5-350bcf7d5e15", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "ca40df32-58b7-52fe-b2b5-458f848e4210", "4e513417-bbb2-55e1-b572-ec68a60fc6be", "64ee757d-3fab-5132-aadf-376825399f6b", "edd36969-0b52-50f9-b08c-9b0ba9e514e7", "502590c0-bb29-53ab-8095-a2c68e3e42ab", "3134099b-d3ac-56d3-898d-c77c7a99370e", "1ddc4f93-70fd-5397-a6f3-ee8837ea208e", "afbe2f7a-2754-5da7-97f6-b56a58fe47a4", "eeda9a9d-5d4e-5579-9a3b-f2e546a7bf4b", "00dd4300-de92-5712-9ce8-ccdb844b6314", "3790e4a5-ff47-586a-b09c-c11ab395909d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "510d6fc0-d3e0-5dc1-8e0d-4d470f964287", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. What specific method did the authors employ to encode sentence positions in the encoder input of the model proposed in the paper, and how does it differ from using a fixed BOS token index?", "reference_answer": "At the encoder input for the \\(i^\\text{th}\\) sentence, the authors used the \\(i^\\text{th}\\) vocabulary token embedding in place of a fixed BOS token index."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11772/comparison_table.png"]}
{"uuid": "36a852ff-1625-5d61-9a32-8cb596b47093", "question": "Consider the paper that introduces the method that corresponds to the first row of the table. What specific regularization techniques were applied to the $\\mathcal{U}_v$, $\\mathcal{U}_a$, and $\\mathcal{U}_s$ subnetworks in the model proposed in the paper, and what were their parameter values?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the first row of the table. What specific regularization techniques were applied to the $\\mathcal{U}_v$, $\\mathcal{U}_a$, and $\\mathcal{U}_s$ subnetworks in the model proposed in the paper, and what were their parameter values?", "reference_answer": "Dropout with p=0.15 and L2 norm with coefficient 0.01."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "38428e95-a11b-50bf-b999-063c0af902b1", "question": "Consider the paper that introduces the dataset which is shown in the second row of the table. What specific aspect of the conversation goal completion rate significantly demonstrates the effectiveness of the knowledge posterior/prior distribution learning in the model proposed by the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which is shown in the second row of the table. What specific aspect of the conversation goal completion rate significantly demonstrates the effectiveness of the knowledge posterior/prior distribution learning in the model proposed by the paper?", "reference_answer": "more knowledge to achieve the conversation goal  (much higher rate on score '2')"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "38e8bef6-f2da-5bcd-8c3a-19089db3a95b", "question": "Consider the paper that introduces the method which has a perplexity of 60. What is the minimum number of tokens in the set \\(\\gV_m\\) that maintains at least \\(\\rho\\) in cumulative probability mass in \\(P_w(x_t|x_{<t},c)\\) during the model's-guided generation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has a perplexity of 60. What is the minimum number of tokens in the set \\(\\gV_m\\) that maintains at least \\(\\rho\\) in cumulative probability mass in \\(P_w(x_t|x_{<t},c)\\) during the model's-guided generation?", "reference_answer": "n=m"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "3988f401-4cfc-5f90-8759-6b84899d376f", "question": "Consider the paper that introduces the large language model that corresponds to an HVI score of 47. What specific methodological difference in the evaluation setup might have impacted the reported performance of this model, specifically on the USABO and SAT reading/writing exams compared to other exams?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9b154fc7-cac7-5a8f-89ac-1ea50638b087"], "reference_pdf": ["87b70047-b849-5220-a3df-28e992c41bf2", "d4de27d2-08b9-57ae-b0a7-a4b9b26047bf", "507be7a7-d7c2-5c15-8ffe-9e6bfe40e5b0", "54eb4a06-225f-5814-ae97-c54611c3f95c", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "4d2120b1-212d-52ad-a0e5-c56245349f00", "34417770-67d7-5cab-b9d4-76999c97bc02", "a0863db0-4018-56ff-81bf-bdb1ff2ed4b7", "e59b32f7-7a87-5940-b581-3e110d2fd77d", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "884e57aa-78e0-5621-958c-8681a2d6f61f", "98b88819-fa1f-503b-9e15-3b078e676975", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "3caa80e4-e308-5fd8-b45f-6b55c8a7a835", "ad6fa17b-383b-53da-8737-9038180d5159", "a1302ac9-0f53-556b-96cd-38977a533888", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "7908763f-3a9d-5ce5-af59-f68888750583", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "dd073182-00f0-5a9f-800b-7779293ab2ae", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "17623cac-c243-591b-b7bc-d261f6ebd607"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the large language model that corresponds to an HVI score of 47. What specific methodological difference in the evaluation setup might have impacted the reported performance of this model, specifically on the USABO and SAT reading/writing exams compared to other exams?", "reference_answer": "The specific methodological difference in the evaluation setup for GPT-4's performance on the USABO and SAT reading/writing exams compared to other exams that might have impacted its reported performance is the sampling of a letter choice at temperature 0 using the already-sampled explanation for these exams, rather than extracting the model's letter choice directly from the explanation as done for most other exam runs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.04988/HVI_figure.png"]}
{"uuid": "39b4f5fe-205b-566b-a1e0-ad43cc86219b", "question": "Consider the paper that introduces the method that corresponds to a higher F1 score than that of LDSGM but a lower F1 score than 65.76 for PDTB-Top. What is the primary reason it underperforms compared to the model proposed in the paper on the Temporal sense?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to a higher F1 score than that of LDSGM but a lower F1 score than 65.76 for PDTB-Top. What is the primary reason it underperforms compared to the model proposed in the paper on the Temporal sense?", "reference_answer": "The PIDRP method underperforms compared to the PCP method on the Temporal sense primarily because connective prediction is closer to the natural language patterns when the model is in the pre-training stage than direct implicit discourse relation prediction."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "3bf6a0e7-640c-517a-b656-ac7dbf5b0a8d", "question": "Consider the paper that introduces the method which is at the rightmost part of the figure. What specific computational advantage does GeDi's method of computing classification probabilities for next tokens have over a unidirectional classifier in terms of the number of forward passes required?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is at the rightmost part of the figure. What specific computational advantage does GeDi's method of computing classification probabilities for next tokens have over a unidirectional classifier in terms of the number of forward passes required?", "reference_answer": "GeDi's method can compute classification probabilities for every possible next token with only two parallel forward passes, whereas a unidirectional classifier would require a forward pass for every token in the vocabulary, resulting in orders of magnitude less computation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "3bf7f1f5-625f-50de-b265-3b6b69094be7", "question": "Consider the paper that introduces the model that corresponds to the brown bars in the figure. What specific performance improvement does it demonstrate over the Falcon 40B model in terms of the Commonsense Reasoning benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the brown bars in the figure. What specific performance improvement does it demonstrate over the Falcon 40B model in terms of the Commonsense Reasoning benchmark?", "reference_answer": "37.5%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/prompt_setting_figure.png"]}
{"uuid": "3c9e88a7-d1d6-5e73-bbcf-bdf60f0887c8", "question": "Consider the paper that introduces the dataset that corresponds to the second chart from the left. What specific operational limitation does the Rigel model have when predicting answers from it?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["8dca380b-0d1b-5c49-a9b6-0581864c7909"], "reference_pdf": ["5b0d44de-0d1d-5f43-a9b0-89b5338732d7", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "84449b22-c7ae-5253-8295-9d74a378fcc3", "8433f894-a217-54d3-9ae5-5c17f951797a", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "79b4a9b3-0759-50f7-a801-83cad821e867", "0337fff3-2745-5430-b1ca-9d43c836a09c", "d699a785-3fb8-5b5b-8487-72d2dbd4dcbd", "90e3610c-c0b5-5b1d-9a9f-6f0f62dd9c89", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "11f9746f-503b-573f-8781-04477603c994", "e3ef9171-b0b7-58c0-8e98-051bfde10ef7", "7908763f-3a9d-5ce5-af59-f68888750583", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "739c8432-c687-5220-89f6-f84e7c860800", "6f4d0a2f-4457-55af-b519-da2a1df140da", "36a1c245-8803-586f-a39c-57a149b16892", "7c278568-4bb8-5a1f-af34-4df3980282eb", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "5a533ef5-84ee-5448-8375-b683864484bc", "1e7d9f86-3567-55b8-be98-064a3d297af1", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "dd39e75b-40a4-5ec5-9943-79277ed1cd00", "819d0208-b342-5a31-a2ab-da64c204544e", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that corresponds to the second chart from the left. What specific operational limitation does the Rigel model have when predicting answers from it?", "reference_answer": "Rigel cannot perform sorting or filtering."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12836/ratio_figure.png"]}
{"uuid": "3da65291-4b19-5fcb-a88f-c16930d493bb", "question": "Consider the paper that introduces the method that has approximately 30 perplexity and the highest average max toxicity. What specific strategy does the paper propose for ensuring the appearance of guide words in the model's generated text without requiring pre-defined ordering of constraints?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has approximately 30 perplexity and the highest average max toxicity. What specific strategy does the paper propose for ensuring the appearance of guide words in the model's generated text without requiring pre-defined ordering of constraints?", "reference_answer": "Guide Closest"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "3e441631-f6e3-51f9-b658-e7cbbec0a054", "question": "Consider the paper that discusses the dataset in which KALMV achieves a score of 66.48 for the Large model. What specific operational limitation does the Rigel model have when predicting answers from this dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8dca380b-0d1b-5c49-a9b6-0581864c7909"], "reference_pdf": ["5b0d44de-0d1d-5f43-a9b0-89b5338732d7", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "84449b22-c7ae-5253-8295-9d74a378fcc3", "8433f894-a217-54d3-9ae5-5c17f951797a", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "79b4a9b3-0759-50f7-a801-83cad821e867", "0337fff3-2745-5430-b1ca-9d43c836a09c", "d699a785-3fb8-5b5b-8487-72d2dbd4dcbd", "90e3610c-c0b5-5b1d-9a9f-6f0f62dd9c89", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "11f9746f-503b-573f-8781-04477603c994", "e3ef9171-b0b7-58c0-8e98-051bfde10ef7", "7908763f-3a9d-5ce5-af59-f68888750583", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "739c8432-c687-5220-89f6-f84e7c860800", "6f4d0a2f-4457-55af-b519-da2a1df140da", "36a1c245-8803-586f-a39c-57a149b16892", "7c278568-4bb8-5a1f-af34-4df3980282eb", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "5a533ef5-84ee-5448-8375-b683864484bc", "1e7d9f86-3567-55b8-be98-064a3d297af1", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "dd39e75b-40a4-5ec5-9943-79277ed1cd00", "819d0208-b342-5a31-a2ab-da64c204544e", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that discusses the dataset in which KALMV achieves a score of 66.48 for the Large model. What specific operational limitation does the Rigel model have when predicting answers from this dataset?", "reference_answer": "Rigel cannot perform sorting or filtering."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12836/results_table.png"]}
{"uuid": "3e5bda47-a1cb-5cb4-b77e-7a77b2d0f919", "question": "Consider the paper that examines the Twitter dataset that has the most number of languages compared to all other Twitter datasets. What was the highest zero-shot cross-lingual transfer performance F1 score achieved for the target language Tigrinya, and which source language was it transferred from?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that examines the Twitter dataset that has the most number of languages compared to all other Twitter datasets. What was the highest zero-shot cross-lingual transfer performance F1 score achieved for the target language Tigrinya, and which source language was it transferred from?", "reference_answer": "68.6, Hausa"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "3f003c51-b591-501c-9b77-aaf5a1dc7e44", "question": "Consider the paper that introduces the optimization method that has a BLEU score of 27.3. Which optimization method, demonstrating a BLEU score of 27.3, shows specific achievement over RNN sequence-to-sequence models in English constituency parsing when trained solely on the WSJ training set?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5c7fb1dc-efe9-585f-a52c-656bed6b1c72"], "reference_pdf": ["cb54e44a-db51-5a8d-b3e5-e6387543389a", "c8717e4f-8ff0-5152-8082-266d0bb88071", "9f83b120-1a28-5397-b764-7b99e62db40d", "969d0c84-5046-5233-a9ce-015454c17e10", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "5015464f-7f34-5403-90e6-e0476fd5febc", "ee1e6c69-30cf-5f9e-b4a8-bfb51a657d08", "35ec5422-c394-5eac-854d-28233a5f9f68", "5aab03c9-0e38-5818-90e3-3b5f882ce28d", "565aa06f-5a94-59e2-9b9a-d8de69a00b54", "d6ea3099-8dd9-5844-a96c-388a86582ee8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "00541e26-04b4-520c-8fee-a656c0bc652c", "4d70e58b-2262-56d0-b3ec-957f8d6132d5", "808a8c71-5485-5683-88e6-b4616d8e7ead", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "b0b8f08f-5cc3-51bd-9834-5c7e50ae692e", "d537f355-a76b-5894-856f-7fbd3328d16e", "0dbcbe8e-2d15-50c7-a52a-9aea7f74fa95", "5d15ac0c-f847-534d-ae40-0007ec49f2b0", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "09a1e967-c629-5c69-b12c-782dd3e017ac", "9066c5d4-3831-59c9-b803-b593a6ef8083", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "3134099b-d3ac-56d3-898d-c77c7a99370e", "42fd3669-c60f-5d28-b51d-4523bebf0734", "1f098267-9697-5fbb-bf8f-a585caad8bf8", "9d24c743-9966-5400-a5f9-6825eca1d557", "b80e3d5b-034c-5f7a-9375-022d87904ee4", "c1c0f24c-58ff-5141-8a9e-a279b49c9213", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "0f92bb2b-b658-5689-914a-8c0ef2dffc3a", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "14c9ea98-903d-52bc-b706-f869a7ff6c91", "0494f66b-dc26-5683-9804-25b245ddba54", "69e18e42-778d-5f47-92ec-bdfe3b03ed37", "0956d0ef-a936-5d49-a5aa-9be966fc7470"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that has a BLEU score of 27.3. Which optimization method, demonstrating a BLEU score of 27.3, shows specific achievement over RNN sequence-to-sequence models in English constituency parsing when trained solely on the WSJ training set?", "reference_answer": "Outperforms the BerkeleyParser"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/BLEU.png"]}
{"uuid": "3f103328-1cf4-5a50-8aca-ad6cb9058cec", "question": "Consider the paper that introduces the method that has approximately 30 perplexity and the highest average max toxicity. What is the initial value of the shift parameter \\(\\lambda_0\\) used in the remaining experiments after analyzing its effect on perplexity and repetition scores?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has approximately 30 perplexity and the highest average max toxicity. What is the initial value of the shift parameter \\(\\lambda_0\\) used in the remaining experiments after analyzing its effect on perplexity and repetition scores?", "reference_answer": "5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "3f225fd7-9385-5173-87d5-f1cc6cacb1d3", "question": "Consider the paper that introduces the method that has 638K tunable parameters. How does its parameter efficiency compare to the adapter model in terms of scaling with the number of tasks and layers?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has 638K tunable parameters. How does its parameter efficiency compare to the adapter model in terms of scaling with the number of tasks and layers?", "reference_answer": "The \\methodefficient model is more parameter-efficient compared to the \\adapter model, especially in settings with a large number of tasks and layers. This efficiency is due to the \\methodefficient model's use of shared hypernetworks across tasks and layers, which significantly reduces the number of parameters that scale with the number of tasks or layers."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "3f7cdcb2-ff09-5961-8ee4-a3b3ed61d5b9", "question": "Consider the paper that introduces the model that demonstrates the highest score in the 'T3' column. What is the observed accuracy drop percentage for the model proposed in the paper on the FewRel dataset for relations with maximum similarity in the range [0.85, 1.00)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that demonstrates the highest score in the 'T3' column. What is the observed accuracy drop percentage for the model proposed in the paper on the FewRel dataset for relations with maximum similarity in the range [0.85, 1.00)?", "reference_answer": "9.7"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "3fa8a5b4-488f-5553-b9ef-5e09c71a8dfe", "question": "Consider the paper that introduces the model that has a diversity score of 2.58 for p2. What specific architectural change was made to the Transformer's layer normalization compared to its originally proposed form?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["b868c871-5514-505d-8587-367e156e1e28"], "reference_pdf": ["aeb9b828-4aff-5f24-a169-6fe27f0e1e2c", "675768f2-88cd-54a4-b359-f29fe975fcef", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "ad72f105-7a2a-5959-8f49-342eb4469f36", "9f2e58b0-9d4e-56b0-a504-e5f77a2f1476", "d8388017-45ea-5dfa-9238-3d88f2c1ce6a", "f7306500-2b64-5ee2-9f7e-f4beb3b0ebcf", "799320b2-1e80-56c8-9084-73737c3fbfb5", "7415a335-10d7-55f3-af82-07c08f608ecd", "a24d04a0-5d7b-518f-97d3-5202a6f549a4", "947f07f1-5d2a-554e-a441-9838afd4a779", "34417770-67d7-5cab-b9d4-76999c97bc02", "6f696630-3060-5bd1-9be1-a00e8d89edfe", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "ad6fa17b-383b-53da-8737-9038180d5159", "0801ed2c-711f-5ffe-94d6-c264e679e00e", "7908763f-3a9d-5ce5-af59-f68888750583", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "40862fb4-44fd-5785-91f9-e24afaa2923d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "80772a52-97c8-5bf8-9893-0de1cc8c02f4", "07caf8ef-950f-50c9-8989-70d482d73168", "3f2695ed-eeac-5dcc-9200-fa2eaa0f02ad", "2173fe79-3e5b-52f6-bd51-a63b747394c0", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a diversity score of 2.58 for p2. What specific architectural change was made to the Transformer's layer normalization compared to its originally proposed form?", "reference_answer": "a simplified version of layer normalization where the activations are only rescaled and no additive bias is applied."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05030/diversity_score.png"]}
{"uuid": "3fd00dc8-c29c-50ea-b6f7-37f9f1995cf2", "question": "Consider the paper that introduces the method that consistently achieves a higher MRR score than NodePiece. What is the primary reason for the performance variance in the model proposed by the paper's ablation studies across different datasets?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that consistently achieves a higher MRR score than NodePiece. What is the primary reason for the performance variance in the model proposed by the paper's ablation studies across different datasets?", "reference_answer": "The primary reason for the performance variance in EARL's ablation studies across different datasets is the different characteristics of the datasets, particularly the number of relations. Datasets with more relations (e.g., FB15k-237 and CoDEx-L) provide enough distinguishable information for entity embeddings through connected relation information (ConRel), making the performance less affected by the removal of other components like reserved entities or $k$NResEnt. In contrast, datasets with fewer relations (e.g., WN18RR and YAGO3-10) rely more on the distinguishable information provided by reserved entities and $k$NResEnt, showing more significant performance variance in the ablation studies."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_comparison_figure.png"]}
{"uuid": "3fe1a710-d28b-5c65-af78-8cbc604776e9", "question": "Consider the paper that introduces the method that has a CoLA score equal to 55.9 on the GLUE task. What specific advantage does the model proposed in the paper offer for handling long-context out-of-domain datasets in MRQA compared to a simple linear classifier?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a CoLA score equal to 55.9 on the GLUE task. What specific advantage does the model proposed in the paper offer for handling long-context out-of-domain datasets in MRQA compared to a simple linear classifier?", "reference_answer": "The Hyperdecoder approach offers the specific advantage of generating unique decoder layers for every input into a model, which allows for more flexible adaptation to long-context out-of-domain datasets in MRQA by leveraging similarities between samples across datasets and avoiding potential interference within the same dataset."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "405ed5c4-2868-5fa8-9a94-dc2d9ee142a7", "question": "Consider the paper that introduces the model that scores higher than ACA but lower than RationaleCL in the 'T5' column. What specific hyperparameter values were determined through grid search for the FewRel dataset in the implementation of the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores higher than ACA but lower than RationaleCL in the 'T5' column. What specific hyperparameter values were determined through grid search for the FewRel dataset in the implementation of the model proposed in the paper?", "reference_answer": "$\\alpha=0.5$, $\\beta=0.5$, $\\tau_1=0.1$, $\\mu=0.5$, $\\omega=0.1$, $\\tau_2=0.5$, $\\gamma=1.25$, $\\lambda_1=0.5$, $\\lambda_2=1.1$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "41818398-22b8-57a6-b9c4-b4fa16b2f4b8", "question": "Consider the paper that introduces the optimization method that has a BLEU score of 27.3. What specific advantage does its use of multi-head attention provide over single-head attention in terms of model quality and computational cost, as evidenced by the experimental variations?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5c7fb1dc-efe9-585f-a52c-656bed6b1c72"], "reference_pdf": ["cb54e44a-db51-5a8d-b3e5-e6387543389a", "c8717e4f-8ff0-5152-8082-266d0bb88071", "9f83b120-1a28-5397-b764-7b99e62db40d", "969d0c84-5046-5233-a9ce-015454c17e10", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "5015464f-7f34-5403-90e6-e0476fd5febc", "ee1e6c69-30cf-5f9e-b4a8-bfb51a657d08", "35ec5422-c394-5eac-854d-28233a5f9f68", "5aab03c9-0e38-5818-90e3-3b5f882ce28d", "565aa06f-5a94-59e2-9b9a-d8de69a00b54", "d6ea3099-8dd9-5844-a96c-388a86582ee8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "00541e26-04b4-520c-8fee-a656c0bc652c", "4d70e58b-2262-56d0-b3ec-957f8d6132d5", "808a8c71-5485-5683-88e6-b4616d8e7ead", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "b0b8f08f-5cc3-51bd-9834-5c7e50ae692e", "d537f355-a76b-5894-856f-7fbd3328d16e", "0dbcbe8e-2d15-50c7-a52a-9aea7f74fa95", "5d15ac0c-f847-534d-ae40-0007ec49f2b0", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "09a1e967-c629-5c69-b12c-782dd3e017ac", "9066c5d4-3831-59c9-b803-b593a6ef8083", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "3134099b-d3ac-56d3-898d-c77c7a99370e", "42fd3669-c60f-5d28-b51d-4523bebf0734", "1f098267-9697-5fbb-bf8f-a585caad8bf8", "9d24c743-9966-5400-a5f9-6825eca1d557", "b80e3d5b-034c-5f7a-9375-022d87904ee4", "c1c0f24c-58ff-5141-8a9e-a279b49c9213", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "0f92bb2b-b658-5689-914a-8c0ef2dffc3a", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "14c9ea98-903d-52bc-b706-f869a7ff6c91", "0494f66b-dc26-5683-9804-25b245ddba54", "69e18e42-778d-5f47-92ec-bdfe3b03ed37", "0956d0ef-a936-5d49-a5aa-9be966fc7470"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that has a BLEU score of 27.3. What specific advantage does its use of multi-head attention provide over single-head attention in terms of model quality and computational cost, as evidenced by the experimental variations?", "reference_answer": "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions, overcoming the limitation of single-head attention where averaging inhibits this capability. Despite the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/BLEU.png"]}
{"uuid": "42251ea1-8903-5665-be5b-914facd90aa2", "question": "Consider the paper that introduces the dataset in the table that has an average answer length of 83.71. What is the average improvement in accuracy that the model proposed in the paper achieved over LLaMA-13B across the XCOPA tasks for languages other than English?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b7315180-e811-5a4a-882f-d4a8e0ffe866"], "reference_pdf": ["25905c58-6108-5577-b948-fbaa6aa23e6e", "7d06b7cd-d351-5e13-a0d1-d72ac792b3e7", "b846c66a-a177-5119-af8d-ec4757d6a06c", "2ee103a7-04e2-53fe-83fe-da3bee6579f6", "42c5c7c9-6099-53c2-8868-147e11467288", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "f92811a6-b9ce-519e-9346-f3b892d7f535", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "70d90498-b24e-5af4-84e5-c40377652bce", "01c9329e-9789-52dc-9eed-c99a8ef88a5c"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has an average answer length of 83.71. What is the average improvement in accuracy that the model proposed in the paper achieved over LLaMA-13B across the XCOPA tasks for languages other than English?", "reference_answer": "7.6%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2402.04588/comparison_table.png"]}
{"uuid": "425402c6-9ba4-586d-b34c-5a662d7733be", "question": "Consider the paper that introduces the method that achieves a score of 28.62 in the WQ-B task. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a score of 28.62 in the WQ-B task. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "reference_answer": "0.949"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "43645e95-273c-500e-a02a-6e997676808e", "question": "Consider the paper that introduces the method that corresponds to the first row of the table. What specific feature of spoken language does the Spoken Language Embedding Subnetwork in the model proposed in the paper focus on to handle the volatile nature of spoken opinions?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the first row of the table. What specific feature of spoken language does the Spoken Language Embedding Subnetwork in the model proposed in the paper focus on to handle the volatile nature of spoken opinions?", "reference_answer": "focusing on important parts of speech"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "43cda16c-3ea1-5ac1-a171-f695bc805bda", "question": "Consider the paper that introduces the model that results in the highest Self-BLEU score on the TellMeWhy dataset. What is the K-L divergence between the prediction results of the model proposed in the paper and ground-truth for question type distribution learning on the test set?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5cb4f0ee-6979-5de3-9228-7707e6240704"], "reference_pdf": ["78b201f5-8cc7-5580-a1e9-3e61fd50a3b0", "412f0d4e-18e1-50b9-9029-b2f3dc0f7eff", "a239e827-0d3f-5f3a-9757-0b218e376c95", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "c48ce7f0-0f60-568a-a32a-61dac182a786", "6f6a00e8-6bd2-5287-ab63-6b0b5f3e422d", "6440959d-ac81-5a2c-ae6e-9082bf5ee380", "28a47974-2035-5575-9a75-7df451faf18d", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "f6e91a91-0b1e-5280-8522-a20492033f16", "822d7c33-cc29-503d-96f9-a82f49f90f06", "977a0308-a19f-537c-940c-4064e7796e83", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "e756a768-abbe-52e1-8416-6c24deaa43ff", "f96ef4a4-88c2-52dd-bcad-82b7d77045f0", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that results in the highest Self-BLEU score on the TellMeWhy dataset. What is the K-L divergence between the prediction results of the model proposed in the paper and ground-truth for question type distribution learning on the test set?", "reference_answer": "0.0089"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16446/tell_me_why_table.png"]}
{"uuid": "44038e1c-c7d5-567e-aa5f-fb0e78a8ec10", "question": "Consider the paper that introduces the method that has a score of 87.3 in the SciTail dataset with 16-shot prompting. How does the performance of the model proposed in the paper change when the prompt length is increased from 300 to 400?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a score of 87.3 in the SciTail dataset with 16-shot prompting. How does the performance of the model proposed in the paper change when the prompt length is increased from 300 to 400?", "reference_answer": "absolute 1.8% drop in accuracy"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "44428d56-3835-5561-995b-0c6107292453", "question": "Consider the paper that introduces the method, with an average max toxicity of more than 0.3, is represented by a circle. What specific strategy does the model proposed in the paper utilize for ensuring the appearance of guide words in generated text without necessitating a pre-defined ordering of constraints?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method, with an average max toxicity of more than 0.3, is represented by a circle. What specific strategy does the model proposed in the paper utilize for ensuring the appearance of guide words in generated text without necessitating a pre-defined ordering of constraints?", "reference_answer": "Guide Closest"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "44bd8895-5f6d-526e-b00b-5ca0f25afab3", "question": "Consider the paper that introduces the method that has a score of 71.4 in the CB dataset with 4-shot prompting. What is the relative error reduction achieved by the model proposed in the paper when using a source prompt from MNLI for the BoolQ target task, despite its low cosine similarity?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a score of 71.4 in the CB dataset with 4-shot prompting. What is the relative error reduction achieved by the model proposed in the paper when using a source prompt from MNLI for the BoolQ target task, despite its low cosine similarity?", "reference_answer": "19.0%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "454f39db-4108-5e43-bc20-cd75a4c6520a", "question": "Consider the paper that introduces the method in the table that corresponds to the highest ROUGE 2 score. What specific performance improvement, in terms of ROUGE-1 score, does the integration of normalizing flow into the PEGASUS+NTM model achieve over using a VAE-based neural topic model without gating on the XSum test set?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52dd679b-8475-5f7a-b960-da2093d8dbe3"], "reference_pdf": ["2b4f3800-c515-559d-aa36-85d34f6fd899", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "f8566398-9ed0-577d-9f9c-78c1b182920b", "872f2c5a-cf6e-5b97-9db7-5202225e6ffb", "7305a38b-a07e-5e95-8462-d583bc1e90c8", "b513d596-2606-5a5f-9891-664942fb1488", "6617e100-5326-5f77-89fc-58086d9008bc", "0fd254fb-0bb3-596a-9199-4463e1bed74d", "6dc11137-351a-5db7-a5dd-3bed39195d89", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "5ba21c89-fb4e-5966-a738-55d18340ed19", "b5dfa69f-e462-54ae-afc6-069808c1b469", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "5b08f953-b4e3-5d1d-9a7f-4c3728a4b0b4", "c76b968a-995a-5109-a4eb-f329fa710f26", "3e23a677-9f88-5a36-a751-7eaaca56c05f", "f5a196f6-0141-5856-880a-c064fd0a7ae4", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "75f411aa-b7b8-53e9-a462-676a7c43af57", "d77ebf73-718c-584e-83ef-4b263f378f1c", "d086f9d2-e87c-5292-925f-26f489250673", "a2349860-0574-558e-8142-b5eeb03efb7c", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "1939c6ce-d2d4-5c9f-999c-4d416f0f2ff7", "bbe57e9c-d84e-5bea-b912-640a33ee042c", "8de91fd4-65e1-519f-b17c-1f889ead8ea7", "a6cf032e-ddb4-561d-bd17-941b9bd28a0e", "58b68b03-a6a4-5977-a584-6f7b13dab877", "0fd254fb-0bb3-596a-9199-4463e1bed74d", "9610c218-3fc1-50c1-9412-849cb6c143c0", "d1586d70-b85f-506c-bf13-16816c8debdc", "13f37e61-5d92-5688-94e4-81c5c80ee126", "25dfb38b-fc5c-50f0-aa8a-59e9fd41943f", "ced47103-b45c-5707-818d-d3151961186c", "6cc62946-4f47-57f5-b109-b923f5840e29", "5d668c9c-fe3c-544d-8aa7-a2a4d7ecb90c", "f894b5e9-2253-54a3-affc-218df494d358", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "99dd3a08-02e8-501f-9353-8153b5764ad3", "fc11469f-1375-57f9-802c-06094e17834e", "397588f0-a421-5b51-8535-5cc1694e2921", "ebaab94f-c9fb-5186-951c-d7259a580fde", "28ad8a82-46ea-55d5-9c2d-4faaf0e88ab0", "1e17d663-53fb-59ea-b642-18a00e2ce376", "3327fb1f-7d25-5b78-9328-a1a471faecd3", "c090d857-0bb9-5075-9ec6-07b11d317089", "0fd254fb-0bb3-596a-9199-4463e1bed74d", "54169656-141d-58b2-afd6-5f26cb2889ed", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "c18fb95e-8ca9-5822-bd59-666d91a6554d", "a5e24ec8-9605-58e8-994a-32576d2b9cc6", "348ad27b-a8bd-57b1-b591-b5bcebd5a3c0", "ae10df12-cb06-58ac-a746-6f941ee929e3", "193f0d17-74ac-53cd-b79e-680fa62356c7", "87aa5397-d9a3-535a-9804-e1b84488bf43", "4a324a22-6bd2-5602-84bc-07231c819440", "9660596b-5980-5a5a-9310-06f00c53405a", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "df53ebe7-ed7e-56b5-9a14-1c0b4dbe2f7d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the table that corresponds to the highest ROUGE 2 score. What specific performance improvement, in terms of ROUGE-1 score, does the integration of normalizing flow into the PEGASUS+NTM model achieve over using a VAE-based neural topic model without gating on the XSum test set?", "reference_answer": "0.4"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00588/comparison_table.png"]}
{"uuid": "45ad6ba8-0894-5c85-ad91-2ccfbc2f7ba7", "question": "Consider the paper that identifies the dataset with the largest number of Queries|Aspects in the OABS category. What specific threshold value was chosen for the matching score to ensure the inclusion of abstract sentences in the aspect-based summaries during its construction, and how was this value determined?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that identifies the dataset with the largest number of Queries|Aspects in the OABS category. What specific threshold value was chosen for the matching score to ensure the inclusion of abstract sentences in the aspect-based summaries during its construction, and how was this value determined?", "reference_answer": "0.5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "45b8d4ae-c44f-57ed-bd7e-1bcbd43c7ad3", "question": "Consider the paper that introduces the method that is in the last row of the Full Training category. What specific aspect of the paraphrasing-based approach does the paper identify as potentially more effective for instances with simple expressions compared to this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the last row of the Full Training category. What specific aspect of the paraphrasing-based approach does the paper identify as potentially more effective for instances with simple expressions compared to this method?", "reference_answer": "Word-level diversity"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "45f3fdbb-34d6-5d77-9977-5ffc9f4d2c48", "question": "Consider the paper that introduces the model that has the highest performance on the En-Fr task in the MSCOCO dataset. What specific loss function does the paper introduce to reduce the mismatch between training and inference in its framework?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["c653b597-b831-535e-bdb1-af03d3f3f1e7"], "reference_pdf": ["dd2f2eae-81f5-5525-971f-5540dde42f6c", "fffd1c97-f03e-5210-8dce-f0eb709b9199", "f1ea3e20-3942-5edd-9c70-f73b10f2da1e", "40d27262-e113-523f-9533-3ee949bdfb05", "c89e402d-2dd4-57dc-883b-be5c04e54b3a", "ad354a8b-1b60-517d-a7fa-d22b435b7f8f", "5052872f-0692-5df0-b02c-ce0f895d539b", "f17feaa7-e8e8-5559-9cf7-fd4b153b811c", "a0c50dc5-15b6-5924-bb70-08d2617f583f", "7821eda8-5710-57df-96c4-89cf30bf7a77", "884e57aa-78e0-5621-958c-8681a2d6f61f", "3b8af772-96a1-578e-a3de-272d2cb9ad7f", "5b08577d-f73f-56d5-be75-931a10239a0d", "f0266918-92ed-5f40-8bd8-499d2979a4e4", "d38dfa65-c493-5cc7-a20d-a01897d7fdc2", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "88185cdb-ff85-5600-bbcb-5bb65ecd6665", "5671a75b-4bcf-5446-82c0-481b1cd418f2", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "e26e48f8-0721-56f6-89dd-9e96448a75c5", "67c0b261-9f6d-50ac-b824-816f48441fa8", "ef1fd71c-6764-5364-8f8f-18d147a69e6d", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "9d24c743-9966-5400-a5f9-6825eca1d557", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "4b2861dc-27c5-57f4-8e01-b018654b3e25", "d7894a4b-2b2f-5355-8193-5c68ffd30928", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "0e854ebb-88e7-55c4-952b-818ce54bc014", "d9b0f39f-60aa-53f3-8382-532440370fdf", "ac65b094-5a2c-5ab7-8497-a3cd526fa8ca", "dfac74e2-051a-5a1f-98fc-d5497a48f44b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest performance on the En-Fr task in the MSCOCO dataset. What specific loss function does the paper introduce to reduce the mismatch between training and inference in its framework?", "reference_answer": "Consistency loss"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13361/result_table.png"]}
{"uuid": "47057e50-bf57-5805-a489-75e68d6d0ce7", "question": "Consider the paper that introduces the model shown on the penultimate line of the table. What specific tokenization method is used for SMILES sequences in its pre-training corpus, MolXPT, and how does this method differ from the tokenization of text?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["75156ea6-7402-5a33-9303-ec6f543e9999"], "reference_pdf": ["7aa1a28a-1256-5732-9581-f2538bfcaf8e", "adf24566-930f-5a42-8118-6aeb65e4f6f4", "825de5ef-3ab4-5629-9fc4-4b0805f419b8", "a1002509-bd90-5cde-9fd2-7b6216144d71", "653e5d86-f991-5533-bd83-a5d95f760b18", "aa22dd10-f8dc-5b74-893f-4f3b21431f24", "766ea9a1-a447-5963-a71f-c9d0a0562d57", "7ea7979f-d2cf-58e4-b00e-2b4027aaf436", "a2401db7-a8bd-588a-856c-4d9ad4f85409", "3a2ae924-5f60-5905-abab-631f660f7bb6", "54fbf9e2-28d0-54ce-ba51-27f90b206c6e", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "3b7baa1d-606b-5481-9c27-fec60e4c7533", "6d068e18-8fb7-5dff-b0bf-b95297a79dc5", "7908763f-3a9d-5ce5-af59-f68888750583", "4ef708b0-51b3-5527-91fc-a55d70b49671", "e2b71dfc-0678-5451-82f6-42650b5ca0dc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "05397506-c619-548a-9f1f-18f85acc151e", "cf69528e-9892-5b27-ab66-0b66a1304268", "a2677b99-9e0d-5c14-8e19-f1c7d5cfa93f", "7908763f-3a9d-5ce5-af59-f68888750583", "7d25556e-bc5e-58ba-b1d8-294c67ed7d98", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6fd2a9e7-7fea-5866-b0c4-120b7cc5baae", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "d97c36ef-e3d9-5f53-a6ff-00d5ee2f2777", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "d4f91c73-f4cf-5209-bec5-6ff66eb29d19", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "5161fb60-4394-5446-9e6e-ce1f1e9e393a", "1777f12e-991e-52d4-8b6b-03807d589e87", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "964db907-da57-5f8b-b1ef-1054c077ca89", "4a697112-1b30-569a-8fee-c4eace04cb3f", "33130f85-57c8-54d5-b050-075bb1ccab97"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown on the penultimate line of the table. What specific tokenization method is used for SMILES sequences in its pre-training corpus, MolXPT, and how does this method differ from the tokenization of text?", "reference_answer": "For SMILES sequences, the tokenization method used involves tokenizing them with a regular expression from Schwaller et al., 2018. Additionally, for each SMILES sequence, a start-of-molecule token is added at the beginning, and an end-of-molecule token is appended at the end. This method differs from the tokenization of text, where byte-pair encoding (BPE) is used to split words into subwords, with the number of BPE merge operations being 40k."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07276/performance_table.png"]}
{"uuid": "47901b9a-3233-5578-a487-7229bfa1f5ef", "question": "Consider the paper that introduces the method that corresponds to the fifth row of the table. What is the primary reason for the degeneration of neural language models, specifically focusing on this method, as proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c1a8f43-9394-59e5-b73c-ad4f9306e57d"], "reference_pdf": ["0d40e5ba-8bd1-5835-99fa-82735099730a", "79fb9402-0283-5c7a-ae54-72967aec6549", "0e564d1d-6aaa-59bb-8be4-6bc51657f150", "9f4c8e70-1c59-506c-acd1-9396e1bdaca4", "5d766fc4-866a-51f1-ab46-6edcf811da10", "e7fd4df5-9610-55db-bbc0-5e4dc59f1a82", "dc69ab19-1148-5de0-88be-2c610277ffd8", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "31dcceac-3a4d-5402-95db-072a568513a0", "a239e827-0d3f-5f3a-9757-0b218e376c95", "af825ce1-e5f8-5bd6-8d57-b9fb30859749", "2d2a70db-7f2b-5c64-ac09-7c53c67628ed", "379fd373-9dae-52dd-aeaf-1db616b52199", "45623893-36dd-538c-baee-ee76f85adef7", "22779eba-4d92-5a33-8d44-0a83b31620bd", "e2f6853e-82cd-5b6d-9880-5f2677fd92a5", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "35b48813-1deb-5375-ac6a-948e906c5f54", "393e9431-63b0-589d-88bb-62335baaf8bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "977a0308-a19f-537c-940c-4064e7796e83", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "2820cbba-a917-5456-b732-e1e8972ede48", "d763c0b0-1131-555a-8861-c96dad3901b9", "427a6763-1a3c-5d70-b6d4-f7e4e8cca2e2", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "d51a9214-fff1-52cb-8bbc-d55f87c0cd9c", "59ea8eee-d229-5bcf-b743-f5c5527a6644", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the fifth row of the table. What is the primary reason for the degeneration of neural language models, specifically focusing on this method, as proposed in the paper?", "reference_answer": "The anisotropic distribution of token representations"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08943/result_table.png"]}
{"uuid": "484f6590-217d-5272-9511-8c301b181788", "question": "Consider the paper that introduces the method that has a METEOR cross entropy score lower than ours but higher than X-Transformer. How does the performance of the model proposed in the paper, when using concepts extracted from captions, compare to using concepts derived from an object detector in terms of CIDEr scores on the COCO-caption Karpathy split?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e30a2f94-a104-572f-b30f-3ae7ff87f6e7"], "reference_pdf": ["d3c84791-eee6-5f1b-8500-1c0a84375f47", "f8d549ad-783d-591b-9ed4-4be9b95e7d9a", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "6c4dc282-e455-530e-9a34-4900a85e2964", "0a4a6ae4-afd1-5807-8417-fcd4b4809799", "1ad58efb-6d3b-5d50-b516-a01ae90f0787", "ee1dfb4c-7988-5a4c-bb1c-a26a7a03b8bf", "7aa9fab2-572b-5e8c-a92a-7b09e4f4c306", "4d3092f6-d683-5121-b9a5-7fca4ff91894", "a76b882d-198d-56d9-9ced-191f44ac95e8", "c6401b44-ad7a-5948-88ad-b180075d7dbe", "60b654b7-5847-56a5-8aaf-2e22fb679dc2", "0466db28-e878-5df8-8ebf-4a9aa8eb7b8e", "fc840122-59b3-5e1d-8c9b-4469f9395fda", "79c9710e-50b0-5c46-8210-1c5539a5328d", "cffe9204-ae34-53b2-adfc-ba74227619b8", "29322424-fba7-5659-a1df-8acb9f557bd8", "4974e1c8-fbd5-5689-ab45-78f2829161d3", "f4f54d07-2fac-59ba-ad99-7e60fba39833", "7ccc7830-102e-567f-9853-bed1eec59176", "f5b9aa98-8d6c-59b7-8883-d1339aeddd97", "949e1567-7aad-545b-b6ec-f5bad4d8bb4e", "6f26f6da-6cc3-5aa4-9f91-ca29b2d64729", "5baa788b-6e39-5587-8800-43f1801adef3", "69728e8c-59e5-5c53-a3cc-f245d1f7af59", "01d0de9d-f910-5674-841b-39ed4688eed7", "a941564b-e52c-55b7-8ded-59c510643621", "f3fe57c2-c6c8-5707-afaf-8f889823dffc", "facc9abe-bac6-5c51-8c10-0d2c28e15868", "cd71e042-6d38-56be-b014-7b9e02e8733e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "70aa012e-fef9-59af-8957-7d698937f537", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "2e3cfef4-fac0-5942-9361-f1321fc394b3", "2b8f1988-37a8-5fc1-b6c3-40b70dd2867f", "d4f2933e-e3ec-5035-bb6c-90041be7751c", "d95266e3-9e89-592a-b1fe-b55d3279249d", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "01d0de9d-f910-5674-841b-39ed4688eed7"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a METEOR cross entropy score lower than ours but higher than X-Transformer. How does the performance of the model proposed in the paper, when using concepts extracted from captions, compare to using concepts derived from an object detector in terms of CIDEr scores on the COCO-caption Karpathy split?", "reference_answer": "Using concepts extracted from captions leads to better performance (121.8 CIDEr) compared to using concepts derived from an object detector (117.4 CIDEr for BUTD and 119.7 CIDEr for VinVL)."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.08223/result_table.png"]}
{"uuid": "4a986e11-ef21-5ffc-9612-08b06d4ab957", "question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. How does the model's performance, proposed by the paper, in terms of win rate against reference completions in the TL;DR summarization task compare to PPO at its optimal sampling temperature?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["d1251ff0-e100-545c-8a1c-664b75854f3c"], "reference_pdf": ["32d04289-3862-5912-a136-6a3d0fe472a2", "3e5b43f1-9b31-5edd-b334-46d5175e1900", "842c1145-6b9e-5d34-bd53-8169d537b66f", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "972a1223-29a4-5304-b9bd-ddec4829d163", "13daa5ee-4b7d-55ec-a5ea-7b19c5cf6e4b", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "37de84b9-2cd0-57ce-8d94-36a43b6c323d", "df2afc9e-2480-567e-84f6-bf4fb97fc1f5", "2adf1c9b-6b9e-59fd-a899-7262b2bd3179", "2ee0ee87-1989-50b9-b896-742ee506c1cc", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "17623cac-c243-591b-b7bc-d261f6ebd607", "f5c3d2bd-4221-5873-a520-589a585f6f93", "ca191c58-f83a-59e0-ad3f-fc6d9a125d9c", "2d4ccd49-4eeb-58ae-bd4f-134be8ae2c11", "945d086d-178d-52d6-aeb4-3988380b6b68", "90aad2c8-22fb-5293-9f5b-58c74b828bc1", "361c3f6a-401c-5854-b618-e7df40b3fa96", "d527d6bb-30ef-5662-971b-78311f082434", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "7169514d-e320-5e1e-8541-b8ca0f8ccc67", "bd4f2699-b1c4-5b76-8e8c-55f84e1e7fe0", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "c7633d80-8236-5a67-a4e5-88fdeadcd1ea", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a239e827-0d3f-5f3a-9757-0b218e376c95", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "342d6620-30f0-5382-b7d7-d3d5f798498f", "e2cbc3e9-68fb-5796-b54d-738df1ac3b67", "d777ea51-80c0-5cd7-873e-3695a75adea4", "880a06dc-f0c4-5e19-9201-2861f952fb32", "3a69cec2-a986-57db-8ea0-bfb4e9e3b548", "8d3ce001-929d-5c83-985e-0268ecc95532", "7908763f-3a9d-5ce5-af59-f68888750583", "dfd4aeaf-4735-5e61-92ff-f8b040f6eb55", "35b48813-1deb-5375-ac6a-948e906c5f54", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "dd073182-00f0-5a9f-800b-7779293ab2ae", "2bc7f244-8607-5501-a3c5-916c66efc615", "e1af3dcf-dee1-50e0-a72b-6c43dc428784", "977a0308-a19f-537c-940c-4064e7796e83", "58b68b03-a6a4-5977-a584-6f7b13dab877", "ebaab94f-c9fb-5186-951c-d7259a580fde", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "d27ee810-3a49-5970-b14a-c71604d54388"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. How does the model's performance, proposed by the paper, in terms of win rate against reference completions in the TL;DR summarization task compare to PPO at its optimal sampling temperature?", "reference_answer": "DPO has a win rate of approximately 61% at a temperature of 0.0, exceeding PPO's performance of ~57% at its optimal sampling temperature of 0.0."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05857/comparison_dpo.png"]}
{"uuid": "4af3983c-0bec-57e8-8689-43a266d31bae", "question": "Consider the paper that introduces the first method shown in Explicit --> Retrieval-enhanced --> Single-Stage category. What is the success rate of targeted in-context knowledge updating for FEVER when using a prompt composed of Original Examples + Edited Relevant Examples + Edited Irrelevant Examples, employing IC-Retrieval?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in Explicit --> Retrieval-enhanced --> Single-Stage category. What is the success rate of targeted in-context knowledge updating for FEVER when using a prompt composed of Original Examples + Edited Relevant Examples + Edited Irrelevant Examples, employing IC-Retrieval?", "reference_answer": "99.9"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "4ba092bd-4f0c-5c65-8bf4-5ac57469cdcd", "question": "Consider the paper that introduces the LLM model that demonstrates the lowest MSE score. What is the specific improvement in percentage points of the model proposed in the paper over GPT-3.5 in internal adversarially-designed factuality evaluations?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["afd759ef-87a1-55e5-a5c5-b0102325830d"], "reference_pdf": ["17623cac-c243-591b-b7bc-d261f6ebd607", "e43b9042-e85e-52ba-b1bb-bb5416f836fa", "636b10fe-f0e5-50c6-b53a-1b9b5c636864", "e3181c7f-c92f-5e72-8419-d97634cf5535", "a4166c00-143a-57ce-8929-537667e11cc4", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "2eaaf347-a894-5b0d-9d6b-39fe1f869854", "5fe9c4e7-cf60-5a3a-8550-26c2aa1b910c", "e62ca3c9-15fe-5a2f-8f57-5914991cbae4", "1d1ff063-3059-5b5b-abe0-0e41a62ac920", "f3728bd2-f6be-585c-8ced-36649229dde9", "dc135cea-016f-534b-bfe5-39bb5aca25dc", "c67a9286-46c2-57f7-9a58-2c7ab8755152", "d99202a8-0fbe-5032-a962-e65c745d3595", "cd07dec7-94b7-573f-abda-fa59cdcacf82", "eb8ba2b8-b5a6-516b-b762-19465f9eaaed", "8da0435b-edc5-55b1-8983-ba5e662a3d0c", "2feed15d-e321-5ac8-8a27-568759e429dd", "fafb5d80-163e-59f2-a365-16a37f4fd351", "f23baff0-753e-5787-b392-d67f27d48d2c", "1d259046-2a97-578c-a3f9-40fe2e138e73", "00b65d5a-72d7-5d45-b93d-aed20dd49192", "bfc4e2c5-a593-5974-bd48-8220a9ee00b7", "f1071e3a-5534-5cf9-a612-30b6e7986a75", "2077ab9c-e416-5734-b43b-df2a5d91ec67", "1adb8a6f-ba9b-5307-8758-5fde1de8fc44", "60088993-59e3-5ca4-8e90-cddaec9589ae", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the LLM model that demonstrates the lowest MSE score. What is the specific improvement in percentage points of the model proposed in the paper over GPT-3.5 in internal adversarially-designed factuality evaluations?", "reference_answer": "19"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.17428/mse_table.png"]}
{"uuid": "4bdc8d1b-2710-59d9-98a5-bf1511fbd302", "question": "Consider the paper that introduces the method that achieves sentence-level precision of 60.32. How does its performance change in the ablation study for WikiHop when it is pretrained with only the extra position embeddings being trainable compared to its full configuration?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["79a856b0-ea50-5dad-b4a1-f0f0c8e17443"], "reference_pdf": ["8ad564f3-f634-5b41-9dbb-c7b55efd34ed", "4774dafb-8266-57ac-ba3b-3fb7302f43e8", "e544d7c3-0ea0-5f06-accd-9044fb2df8ce", "2ad75cc6-aa85-532e-a8cc-d487ad70ac1d", "8ac0dc8f-2cdc-5363-ab17-2cbe2cd98611", "7913138b-027d-5e7a-a4f9-c94fa676607b", "501de3a1-2bdc-5bea-9259-4731a2df35ab", "68be5d29-f16d-506f-a4e5-215438f13409", "9dab5ed2-4f76-52b3-b13a-ee7c9342d254", "64ee757d-3fab-5132-aadf-376825399f6b", "a672b5e1-0460-5bcf-9f96-189e0687079d", "19037637-5fca-5021-a9c2-464b3eaf7fb1", "167219f2-ecf4-59b5-8ea1-cdcb400400b2", "7eb3a633-8d11-5b91-af60-4030ff538882", "aefc8eb9-7238-561a-8055-858362dc6a0c", "3157ccdb-a5d3-5ddb-93af-99dcbba44f15", "f9ea4f73-3191-5d9c-8121-e490cc81af65", "2e88d873-bc67-51d3-a17e-8eda7c844dd6", "79c58b97-75e2-590f-ab73-90c71c7af2a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "4fd8fdc1-1bd4-58dd-9c4e-0659d9c11ee4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "167219f2-ecf4-59b5-8ea1-cdcb400400b2"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves sentence-level precision of 60.32. How does its performance change in the ablation study for WikiHop when it is pretrained with only the extra position embeddings being trainable compared to its full configuration?", "reference_answer": "73.5 / -0.3"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18544/result_table.png"]}
{"uuid": "4d2147f6-9bbd-5253-be91-a5a9d979640c", "question": "Consider the paper that introduces the method that has a lower F1 score than TPP and a higher F1 score than BROS. How does the inclusion of Coordinate Convolution (CoordConv) specifically impact the model's F1 scores for both Entity Labeling and Entity Linking tasks, according to the ablation study results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than TPP and a higher F1 score than BROS. How does the inclusion of Coordinate Convolution (CoordConv) specifically impact the model's F1 scores for both Entity Labeling and Entity Linking tasks, according to the ablation study results?", "reference_answer": "The inclusion of Coordinate Convolution (CoordConv) specifically impacts the F1 scores for both Entity Labeling and Entity Linking tasks in the MSAU-PAF model by increasing the F1 score by 0.02 in both tasks, according to the ablation study results."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "4d9406ac-9cb2-5a0a-9636-08c07088a5dd", "question": "Consider the paper that introduces the method which has a GPT backbone and 7B parameters. What specific role does the guidance mechanism play in improving the quality of generated subquestions by a smaller model in the context of the Socratic CoT approach?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has a GPT backbone and 7B parameters. What specific role does the guidance mechanism play in improving the quality of generated subquestions by a smaller model in the context of the Socratic CoT approach?", "reference_answer": "The guidance mechanism conditions the generation of subquestions on the equations describing the intermediate solutions, improving the quality of the generated questions across all metrics considered."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "4ded5af2-6feb-5dd4-978d-8d72a3783418", "question": "Consider the paper that introduces the model that exhibits the most negative Spearman's Correlation Coefficient. Which variant of DialoGPT was statistically indistinguishable from human responses in terms of relevance based on the human evaluation results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that exhibits the most negative Spearman's Correlation Coefficient. Which variant of DialoGPT was statistically indistinguishable from human responses in terms of relevance based on the human evaluation results?", "reference_answer": "DialoGPT (345M, w/ MMI)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "4dfc8aed-1c10-5c55-8058-d2a4ca693610", "question": "Consider the paper that introduces the method that achieves a higher accuracy than DExpert but lower than Air-Decoding. How does the gradient expression for the logit corresponding to the unlikely token ($h_{\\text{unlike}}$) in the simplified theoretical analysis of the model's, proposed by the paper, loss function indicate the direction of model optimization?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b25f702e-6afa-5d3f-86a5-5388f5061a30"], "reference_pdf": ["840b01f4-c1fb-56e6-92f1-2c41e39373ec", "2916ff3a-f5cc-5c0e-8960-e693e402ade5", "44f0985f-d1a0-5379-a29c-ea77b96bb1f2", "24589e0c-b589-5704-813b-5ddcc80ce624", "1d6fa876-022c-518c-89fc-73b4ddb349d1", "e538ca11-a05e-58a1-a22a-7cca1d0d3f33", "90b9b399-75fe-5bc8-ad54-e3cf42964bf4", "a239e827-0d3f-5f3a-9757-0b218e376c95", "693d6239-f05e-5428-9c4e-9557251caaa9", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "b0661806-4056-510f-b3ef-bcfe1a7e5603", "7ff14e93-55ec-58f1-b134-9b603b7fd053", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "daf59047-5c23-56ab-9cc4-245eb1a6f397", "7908763f-3a9d-5ce5-af59-f68888750583", "137a4bca-d156-529e-8ee7-5a841286190d", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "dd073182-00f0-5a9f-800b-7779293ab2ae", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1398ab3c-cb2d-593e-9d68-02a0d484e643", "da29dae2-1a88-5793-8149-81c0b63122ca", "bd0d5234-9da1-5808-a85a-3e4c08824c1a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a higher accuracy than DExpert but lower than Air-Decoding. How does the gradient expression for the logit corresponding to the unlikely token ($h_{\\text{unlike}}$) in the simplified theoretical analysis of the model's, proposed by the paper, loss function indicate the direction of model optimization?", "reference_answer": "-2*p_{\\text {unlike}}"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14892/result_table.png"]}
{"uuid": "5032f0e0-aa3f-5c00-8fc5-86b8a9ee2357", "question": "Consider the paper that introduces the optimization method that has the lowest BLEU score among all models in the table. What specific advantage does the model's use of multi-head attention provide over single-head attention in terms of model quality and computational cost, as evidenced by the experimental variations?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5c7fb1dc-efe9-585f-a52c-656bed6b1c72"], "reference_pdf": ["cb54e44a-db51-5a8d-b3e5-e6387543389a", "c8717e4f-8ff0-5152-8082-266d0bb88071", "9f83b120-1a28-5397-b764-7b99e62db40d", "969d0c84-5046-5233-a9ce-015454c17e10", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "5015464f-7f34-5403-90e6-e0476fd5febc", "ee1e6c69-30cf-5f9e-b4a8-bfb51a657d08", "35ec5422-c394-5eac-854d-28233a5f9f68", "5aab03c9-0e38-5818-90e3-3b5f882ce28d", "565aa06f-5a94-59e2-9b9a-d8de69a00b54", "d6ea3099-8dd9-5844-a96c-388a86582ee8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "00541e26-04b4-520c-8fee-a656c0bc652c", "4d70e58b-2262-56d0-b3ec-957f8d6132d5", "808a8c71-5485-5683-88e6-b4616d8e7ead", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "b0b8f08f-5cc3-51bd-9834-5c7e50ae692e", "d537f355-a76b-5894-856f-7fbd3328d16e", "0dbcbe8e-2d15-50c7-a52a-9aea7f74fa95", "5d15ac0c-f847-534d-ae40-0007ec49f2b0", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "09a1e967-c629-5c69-b12c-782dd3e017ac", "9066c5d4-3831-59c9-b803-b593a6ef8083", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "3134099b-d3ac-56d3-898d-c77c7a99370e", "42fd3669-c60f-5d28-b51d-4523bebf0734", "1f098267-9697-5fbb-bf8f-a585caad8bf8", "9d24c743-9966-5400-a5f9-6825eca1d557", "b80e3d5b-034c-5f7a-9375-022d87904ee4", "c1c0f24c-58ff-5141-8a9e-a279b49c9213", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "0f92bb2b-b658-5689-914a-8c0ef2dffc3a", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "14c9ea98-903d-52bc-b706-f869a7ff6c91", "0494f66b-dc26-5683-9804-25b245ddba54", "69e18e42-778d-5f47-92ec-bdfe3b03ed37", "0956d0ef-a936-5d49-a5aa-9be966fc7470"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that has the lowest BLEU score among all models in the table. What specific advantage does the model's use of multi-head attention provide over single-head attention in terms of model quality and computational cost, as evidenced by the experimental variations?", "reference_answer": "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions, overcoming the limitation of single-head attention where averaging inhibits this capability. Despite the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/BLEU.png"]}
{"uuid": "507fee65-aa23-5415-9ac2-44e58721ebbb", "question": "Consider the paper that introduces the dataset which includes 1 SM task and 4 languages. What is the primary reason that applying Language Adaptive Fine-tuning (LAFT) on its Twitter domain did not improve performance?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which includes 1 SM task and 4 languages. What is the primary reason that applying Language Adaptive Fine-tuning (LAFT) on its Twitter domain did not improve performance?", "reference_answer": "The primary reason applying Language Adaptive Fine-tuning (LAFT) on the Twitter domain did not improve performance is the small size of the Twitter data."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "50869806-3a86-504d-b0e7-52f1bb539011", "question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What is the core innovation of the model proposed in the paper in the context of unifying retrieval and reasoning for multi-hop KGQA tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What is the core innovation of the model proposed in the paper in the context of unifying retrieval and reasoning for multi-hop KGQA tasks?", "reference_answer": "The core innovation of UniKGQA in the context of unifying retrieval and reasoning for multi-hop KGQA tasks is the unification of retrieval and reasoning in both model architecture and parameter learning."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "50c0ae3b-de81-5b74-8809-d6c0971480c4", "question": "Consider the paper that introduces the model that has a Recall@7 score of 92.97 for the MWOZ task. What specific performance improvement does it achieve on the Entity F1 metric for the SMD dataset when comparing the system with a fine-tuned retriever against the off-the-shelf retriever?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["690e4131-3330-5bd8-9132-669280baa458"], "reference_pdf": ["74ab3845-0eef-54a0-8c11-ec17231ff70f", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "dc374d6f-8af0-5f68-8836-a5734a95f24a", "27a3e973-f2ba-53eb-829b-7bee289d51f2", "4d63e299-19a6-57dd-946b-2f8256c90192", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "aefe2914-5fdb-5ef7-bf50-ad38e28832c4", "d27f5f12-140e-5048-8152-426067d8fad1", "dccb63d4-f203-5a8b-8f8a-10fb38fda9b4", "edf72dc4-d79d-5f52-98de-5c008797474f", "cf0c242a-86be-5d3e-b394-ef45e639af53", "c1f4221a-e7e5-5df3-8d1b-0acc89e315f6", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "493cad14-fb60-56ac-a1dd-0a7756de59cd", "82c7eacc-bdad-5c51-a9f8-651bc244721a", "1e7d9f86-3567-55b8-be98-064a3d297af1", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "772c62b6-0932-5321-86ee-61dccbda8108", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "371fc0fa-bcec-5ffa-95e3-71879321564b", "d24c4e1f-1b12-5af1-a7ea-054861015af6", "42d6954b-5fc1-5d50-9830-1a3db7d6e98a", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a Recall@7 score of 92.97 for the MWOZ task. What specific performance improvement does it achieve on the Entity F1 metric for the SMD dataset when comparing the system with a fine-tuned retriever against the off-the-shelf retriever?", "reference_answer": "0.06%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08877/result_table.png"]}
{"uuid": "50f00ca8-5a05-5fe3-9c57-2196656eb677", "question": "Consider the paper that introduces the first method shown in Explicit --> Internet-enhanced category. What specific performance improvement does the model proposed in the paper show over the simpler model across all datasets, and how is this improvement quantitatively described in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in Explicit --> Internet-enhanced category. What specific performance improvement does the model proposed in the paper show over the simpler model across all datasets, and how is this improvement quantitatively described in the paper?", "reference_answer": "Consistent outperformance"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "5159477f-61eb-5e63-a37c-59617fea2272", "question": "Consider the paper that introduces the LLM shown in the figure with a model size of 1.7T. What specific methodological difference in the evaluation setup for the model's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9b154fc7-cac7-5a8f-89ac-1ea50638b087"], "reference_pdf": ["87b70047-b849-5220-a3df-28e992c41bf2", "d4de27d2-08b9-57ae-b0a7-a4b9b26047bf", "507be7a7-d7c2-5c15-8ffe-9e6bfe40e5b0", "54eb4a06-225f-5814-ae97-c54611c3f95c", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "4d2120b1-212d-52ad-a0e5-c56245349f00", "34417770-67d7-5cab-b9d4-76999c97bc02", "a0863db0-4018-56ff-81bf-bdb1ff2ed4b7", "e59b32f7-7a87-5940-b581-3e110d2fd77d", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "884e57aa-78e0-5621-958c-8681a2d6f61f", "98b88819-fa1f-503b-9e15-3b078e676975", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "3caa80e4-e308-5fd8-b45f-6b55c8a7a835", "ad6fa17b-383b-53da-8737-9038180d5159", "a1302ac9-0f53-556b-96cd-38977a533888", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "7908763f-3a9d-5ce5-af59-f68888750583", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "dd073182-00f0-5a9f-800b-7779293ab2ae", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "17623cac-c243-591b-b7bc-d261f6ebd607"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the LLM shown in the figure with a model size of 1.7T. What specific methodological difference in the evaluation setup for the model's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "reference_answer": "The use of sampling a letter choice at temperature 0 using the already-sampled explanation for certain exams, rather than extracting the model's letter choice directly from the explanation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.04988/HVI_figure.png"]}
{"uuid": "51765cdb-07fd-50d3-9a31-917b08357554", "question": "Consider the paper that introduces the model that achieves a mean classification accuracy of 0.6712 on the Hate dataset. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of AI venue classification?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a mean classification accuracy of 0.6712 on the Hate dataset. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of AI venue classification?", "reference_answer": "0.9303959931770183"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "52616e37-4f09-5052-b7fc-1a00464afea8", "question": "Consider the paper that introduces the Seq2Seq/Tree model that has a Test Accuracy of 79.6. What specific method does the model's solution discrimination module employ to enhance the association between a math word problem and its correct solution?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the Seq2Seq/Tree model that has a Test Accuracy of 79.6. What specific method does the model's solution discrimination module employ to enhance the association between a math word problem and its correct solution?", "reference_answer": "Gradient-guided token selection"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "52bb6245-445a-5548-b5a2-5b488ab34a61", "question": "Consider the paper that introduces the method shown in the first row of the table. What specific feature of the BERT model's output is utilized in the policy network for dynamic prompting via policy gradient in the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the first row of the table. What specific feature of the BERT model's output is utilized in the policy network for dynamic prompting via policy gradient in the model proposed in the paper?", "reference_answer": "\\texttt{[CLS]} token representation"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "5312a259-371c-5ebc-9394-a65cbd759a58", "question": "Consider the paper that introduces the dataset associated with the task 'Hate Speech Spans Detection (HSSD)'. What is the F1-score improvement for the model proposed in the paper, specifically PhoBERT_Large, when additional clean comments are included in the dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset associated with the task 'Hate Speech Spans Detection (HSSD)'. What is the F1-score improvement for the model proposed in the paper, specifically PhoBERT_Large, when additional clean comments are included in the dataset?", "reference_answer": "0.0849"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "53bbe48d-c401-5b78-bd1f-97bbd9a7e9db", "question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. What specific modification to the few-shot prompts used in the model's generation, as proposed in the paper, is highlighted as key for improving the quality of generated data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. What specific modification to the few-shot prompts used in the model's generation, as proposed in the paper, is highlighted as key for improving the quality of generated data?", "reference_answer": "Providing the model with the target after posing the question and before providing example CoT."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "545a95fc-9706-56c0-8f7e-32f477d5901e", "question": "Consider the paper that introduces the model that results in the highest Self-BLEU score on the TellMeWhy dataset. What is the K-L divergence between the model's predicted and ground-truth question type distributions on the test set?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5cb4f0ee-6979-5de3-9228-7707e6240704"], "reference_pdf": ["78b201f5-8cc7-5580-a1e9-3e61fd50a3b0", "412f0d4e-18e1-50b9-9029-b2f3dc0f7eff", "a239e827-0d3f-5f3a-9757-0b218e376c95", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "c48ce7f0-0f60-568a-a32a-61dac182a786", "6f6a00e8-6bd2-5287-ab63-6b0b5f3e422d", "6440959d-ac81-5a2c-ae6e-9082bf5ee380", "28a47974-2035-5575-9a75-7df451faf18d", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "f6e91a91-0b1e-5280-8522-a20492033f16", "822d7c33-cc29-503d-96f9-a82f49f90f06", "977a0308-a19f-537c-940c-4064e7796e83", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "e756a768-abbe-52e1-8416-6c24deaa43ff", "f96ef4a4-88c2-52dd-bcad-82b7d77045f0", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that results in the highest Self-BLEU score on the TellMeWhy dataset. What is the K-L divergence between the model's predicted and ground-truth question type distributions on the test set?", "reference_answer": "0.0089"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16446/tell_me_why_table.png"]}
{"uuid": "55630a72-1e52-5882-b496-06dd681a1766", "question": "Consider the paper that introduces the method which demonstrates the highest BLEU-1 score for the Test Seen task according to the table. What is the effect of the contrastive loss margin \\(\\rho\\) on the model's perplexity when it is set to either too small or too large values?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c1a8f43-9394-59e5-b73c-ad4f9306e57d"], "reference_pdf": ["0d40e5ba-8bd1-5835-99fa-82735099730a", "79fb9402-0283-5c7a-ae54-72967aec6549", "0e564d1d-6aaa-59bb-8be4-6bc51657f150", "9f4c8e70-1c59-506c-acd1-9396e1bdaca4", "5d766fc4-866a-51f1-ab46-6edcf811da10", "e7fd4df5-9610-55db-bbc0-5e4dc59f1a82", "dc69ab19-1148-5de0-88be-2c610277ffd8", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "31dcceac-3a4d-5402-95db-072a568513a0", "a239e827-0d3f-5f3a-9757-0b218e376c95", "af825ce1-e5f8-5bd6-8d57-b9fb30859749", "2d2a70db-7f2b-5c64-ac09-7c53c67628ed", "379fd373-9dae-52dd-aeaf-1db616b52199", "45623893-36dd-538c-baee-ee76f85adef7", "22779eba-4d92-5a33-8d44-0a83b31620bd", "e2f6853e-82cd-5b6d-9880-5f2677fd92a5", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "35b48813-1deb-5375-ac6a-948e906c5f54", "393e9431-63b0-589d-88bb-62335baaf8bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "977a0308-a19f-537c-940c-4064e7796e83", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "2820cbba-a917-5456-b732-e1e8972ede48", "d763c0b0-1131-555a-8861-c96dad3901b9", "427a6763-1a3c-5d70-b6d4-f7e4e8cca2e2", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "d51a9214-fff1-52cb-8bbc-d55f87c0cd9c", "59ea8eee-d229-5bcf-b743-f5c5527a6644", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which demonstrates the highest BLEU-1 score for the Test Seen task according to the table. What is the effect of the contrastive loss margin \\(\\rho\\) on the model's perplexity when it is set to either too small or too large values?", "reference_answer": "When the contrastive loss margin \\(\\rho\\) is set to either too small or too large values, it leads to a sub-optimal perplexity."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08943/result_table.png"]}
{"uuid": "57cee5d6-843b-52a9-91cb-88604e92b558", "question": "Consider the paper that introduces the method that is missing a result for the WQ-M task in the table. How does the paraphrasing-based approach differ from the model proposed in the paper in handling instances with simple expressions, according to the limitations section?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is missing a result for the WQ-M task in the table. How does the paraphrasing-based approach differ from the model proposed in the paper in handling instances with simple expressions, according to the limitations section?", "reference_answer": "The paraphrasing-based approach focuses on words, while the proposed method focuses more on the structure of the sentences."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "5931b0f2-6ae4-5f46-af45-fd3d445195f8", "question": "Consider the paper that introduces the method that has an F1 score of 64.95 on PDTB-Top. What is the Macro-F1 score improvement of the model proposed in the paper, PCP-large without the segment token </s>, over the LDSGM model for the second-level sense 'Exp.List' in PDTB 2.0?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an F1 score of 64.95 on PDTB-Top. What is the Macro-F1 score improvement of the model proposed in the paper, PCP-large without the segment token </s>, over the LDSGM model for the second-level sense 'Exp.List' in PDTB 2.0?", "reference_answer": "3.55"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "5a1e3d92-bd6e-5bd9-88ce-2796c4431192", "question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. What specific distribution is used for sampling span lengths in the model's span masking scheme proposed in the paper, and what is the mean span length resulting from this distribution?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1821bd0b-d55e-5dbf-bfcd-2fde02a07633"], "reference_pdf": ["67602490-afd8-569f-b463-35cd7a8a7b46", "4d856727-33a4-59aa-90a6-6245d8bd1918", "778c3b86-7d0f-58fa-b177-972efaec7c5f", "ca80f95d-2b88-55ca-ab3f-8f7c86b723e4", "0c61720f-b625-5082-b5fe-8fbc3206d656", "51b6e073-e1a7-51c0-8a23-314d84c6d9cd", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "afc322a1-0cca-5ce0-9e44-3b904630f337", "5be16d27-4c22-576f-be7f-16715bf49ffc", "fad9fe2b-872e-5d61-9149-ef7c915db5a4", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "7c278568-4bb8-5a1f-af34-4df3980282eb", "d2e0dc47-0423-50ea-9dd9-872548a733d2", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "09523922-5ff7-5682-9e59-2b903b7d7a35", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "52f46313-b1a0-5e5e-b415-a54c42ca1496", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "cb57171c-5fc1-56c6-b168-4d122a1427cd", "ca236447-69ca-57c4-8a5c-8891e4230b8b", "9e0baaab-f75d-5b52-b965-a5b427196392", "e3c2e045-3afc-5d1d-aad1-3389f80aea7f", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "cf94c43f-2a86-5ba2-a52d-20126e193c68", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. What specific distribution is used for sampling span lengths in the model's span masking scheme proposed in the paper, and what is the mean span length resulting from this distribution?", "reference_answer": "Geometric distribution with $p=0.2$, mean span length = $3.8$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14478/comparison_table.png"]}
{"uuid": "5a8ba029-7181-5213-9109-1131a00d7043", "question": "Consider the paper that introduces the method that scores higher than 69.0 but lower than 70.0 in the Forgotten Realms category. What specific method does the model proposed in the paper use to generate high-quality synthetic data for few-shot entity linking?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e5476c7f-2b14-520b-81df-8783aebf59f5"], "reference_pdf": ["e897e2cd-c196-532e-8273-358b4878e270", "7e10ecb3-9428-53a7-8edf-83c7f2ca9bbe", "e0f03057-5bdd-575d-a691-7493ccc1bfb9", "98ac518b-1b74-562f-9913-2a494f1417c2", "f781ad75-0ee9-572a-bf0e-6ec0c4faf7c2", "cb764bcf-9005-5541-8cf0-55e47ee0ff91", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6", "560b3014-4a65-57cc-bda5-e3610828782e", "071d6f10-df74-5f8a-ba5f-4b3cfa33e65b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that scores higher than 69.0 but lower than 70.0 in the Forgotten Realms category. What specific method does the model proposed in the paper use to generate high-quality synthetic data for few-shot entity linking?", "reference_answer": "MetaBLINK uses a two-stage architecture for generating high-quality synthetic data for few-shot entity linking. Initially, it employs a heuristic method to generate mention-entity pairs. Then, it adopts a weak supervision strategy based on these mention-entity pairs to generate synthetic data. This process leverages a natural language generation model (NLG), specifically the T5 model, to rewrite mentions for generating more effective synthetic samples in the target domain. Additionally, MetaBLINK incorporates a meta-learning mechanism to automatically assign different weights to each synthetic data instance, improving the quality of the synthetic data used for model training."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12444/comparison_table.png"]}
{"uuid": "5adc6b61-2600-5aca-8a90-0fbf85ac2f19", "question": "Consider the paper that introduces the model that achieves a score of 3.84 in the Grounding task. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87061b7c-1d22-547a-8872-d4aeab4af856"], "reference_pdf": ["494cb703-b95f-5e14-a0e7-a3fd11506fc1", "6f3f28fe-d2d7-586a-88ad-9221a4b30d73", "34417770-67d7-5cab-b9d4-76999c97bc02", "d8294ff2-583e-51c8-800f-d71a9308007f", "2ca6dd33-bf5b-50cf-b091-3282a484d4a8", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "04eb3bcf-5a3a-574f-84e5-2bf5ad50cde4", "3eebefdb-5ed6-51bf-92c6-b28841844f45", "4d93d596-b0bd-54c6-bd9e-041037077bc7", "ffa6aa03-6f5b-56a1-9120-8d8c625c0880", "e201f724-c783-5300-baeb-1379ae22f643", "7aacee49-58db-593f-9a47-44846ba2ed23", "7908763f-3a9d-5ce5-af59-f68888750583", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "ec5a0dc4-0a52-55b2-a4a2-54e1006e50b9", "8d432bf0-21eb-51f9-b126-078fe08a3012", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "3e2528f0-84e9-5fa9-a440-22ae6fcc2500", "c8260bf5-7dd8-5066-8aa4-1a512fa40f12", "1b61dc63-60bb-51d1-9935-260cf324487f", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a score of 3.84 in the Grounding task. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "reference_answer": "6 and 6.2 points"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15129/human_eval_table.png"]}
{"uuid": "5be2d398-debc-5263-9199-830b4e5837b4", "question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. What specific performance gain does the model proposed in the paper achieve on the TACRED relation extraction benchmark compared to the BERT baseline reimplementation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1821bd0b-d55e-5dbf-bfcd-2fde02a07633"], "reference_pdf": ["67602490-afd8-569f-b463-35cd7a8a7b46", "4d856727-33a4-59aa-90a6-6245d8bd1918", "778c3b86-7d0f-58fa-b177-972efaec7c5f", "ca80f95d-2b88-55ca-ab3f-8f7c86b723e4", "0c61720f-b625-5082-b5fe-8fbc3206d656", "51b6e073-e1a7-51c0-8a23-314d84c6d9cd", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "afc322a1-0cca-5ce0-9e44-3b904630f337", "5be16d27-4c22-576f-be7f-16715bf49ffc", "fad9fe2b-872e-5d61-9149-ef7c915db5a4", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "7c278568-4bb8-5a1f-af34-4df3980282eb", "d2e0dc47-0423-50ea-9dd9-872548a733d2", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "09523922-5ff7-5682-9e59-2b903b7d7a35", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "52f46313-b1a0-5e5e-b415-a54c42ca1496", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "cb57171c-5fc1-56c6-b168-4d122a1427cd", "ca236447-69ca-57c4-8a5c-8891e4230b8b", "9e0baaab-f75d-5b52-b965-a5b427196392", "e3c2e045-3afc-5d1d-aad1-3389f80aea7f", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "cf94c43f-2a86-5ba2-a52d-20126e193c68", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. What specific performance gain does the model proposed in the paper achieve on the TACRED relation extraction benchmark compared to the BERT baseline reimplementation?", "reference_answer": "3.3% F1"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14478/comparison_table.png"]}
{"uuid": "5c6a748d-3b01-55b7-a96d-f0ab32cc336b", "question": "Consider the paper that introduces the model that has the highest performance on the En-Fr task in the MSCOCO dataset. How does its performance with hallucinated visual tokens (\\texttt{V}) compare to using ground-truth visual representations (\\texttt{VM}) on the Multi30K dataset for the Transformer-Tiny model in terms of BLEU score?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["c653b597-b831-535e-bdb1-af03d3f3f1e7"], "reference_pdf": ["dd2f2eae-81f5-5525-971f-5540dde42f6c", "fffd1c97-f03e-5210-8dce-f0eb709b9199", "f1ea3e20-3942-5edd-9c70-f73b10f2da1e", "40d27262-e113-523f-9533-3ee949bdfb05", "c89e402d-2dd4-57dc-883b-be5c04e54b3a", "ad354a8b-1b60-517d-a7fa-d22b435b7f8f", "5052872f-0692-5df0-b02c-ce0f895d539b", "f17feaa7-e8e8-5559-9cf7-fd4b153b811c", "a0c50dc5-15b6-5924-bb70-08d2617f583f", "7821eda8-5710-57df-96c4-89cf30bf7a77", "884e57aa-78e0-5621-958c-8681a2d6f61f", "3b8af772-96a1-578e-a3de-272d2cb9ad7f", "5b08577d-f73f-56d5-be75-931a10239a0d", "f0266918-92ed-5f40-8bd8-499d2979a4e4", "d38dfa65-c493-5cc7-a20d-a01897d7fdc2", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "88185cdb-ff85-5600-bbcb-5bb65ecd6665", "5671a75b-4bcf-5446-82c0-481b1cd418f2", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "e26e48f8-0721-56f6-89dd-9e96448a75c5", "67c0b261-9f6d-50ac-b824-816f48441fa8", "ef1fd71c-6764-5364-8f8f-18d147a69e6d", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "9d24c743-9966-5400-a5f9-6825eca1d557", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "4b2861dc-27c5-57f4-8e01-b018654b3e25", "d7894a4b-2b2f-5355-8193-5c68ffd30928", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "0e854ebb-88e7-55c4-952b-818ce54bc014", "d9b0f39f-60aa-53f3-8382-532440370fdf", "ac65b094-5a2c-5ab7-8497-a3cd526fa8ca", "dfac74e2-051a-5a1f-98fc-d5497a48f44b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest performance on the En-Fr task in the MSCOCO dataset. How does its performance with hallucinated visual tokens (\\texttt{V}) compare to using ground-truth visual representations (\\texttt{VM}) on the Multi30K dataset for the Transformer-Tiny model in terms of BLEU score?", "reference_answer": "Very similar"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13361/result_table.png"]}
{"uuid": "5cc6fa2c-5e06-516e-a408-9cf76f1ae518", "question": "Consider the paper that introduces the dataset which exhibits the highest accuracy for Method 2. What specific performance improvement does using dropout as a regularizer provide for solution-level verifiers compared to token-level verifiers?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa7d95d4-dd69-5849-8f0b-119726938dac"], "reference_pdf": ["3ea1a5e9-0057-54a5-b359-7d99fc882842", "06e77679-09f0-5936-b00f-dcad7a604f75", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "c7cf8100-fcbd-575b-a980-7f6d3c4f6761", "b44607d8-7587-53ed-be67-22b3668a1644", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "1b151a0b-8156-5a1d-9459-ba2037900807", "bf80182b-c2b3-5553-bfcf-3d83d1c71d9d", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "cb83c58c-fefc-566d-b291-b27faf9eec2b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "e69ef270-7428-50f6-b47b-63a2455841ac", "7908763f-3a9d-5ce5-af59-f68888750583", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "20847c00-ada9-56f4-aab2-d67eb2ace27b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which exhibits the highest accuracy for Method 2. What specific performance improvement does using dropout as a regularizer provide for solution-level verifiers compared to token-level verifiers?", "reference_answer": "Similar level of performance as token-level verifiers"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14628/comparison_figure.png"]}
{"uuid": "5d221cf4-e217-567c-b199-9fd819ca6e11", "question": "Consider the paper that introduces the method that exhibits the lowest BLEU score in the De->En task over Average Lagging from 5 to 11. What specific methodological adjustment is made to the model's variant, proposed by the paper, to address the potential issue of outlier attention heads affecting latency or attention span?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the lowest BLEU score in the De->En task over Average Lagging from 5 to 11. What specific methodological adjustment is made to the model's variant, proposed by the paper, to address the potential issue of outlier attention heads affecting latency or attention span?", "reference_answer": "attention variance loss to MMA-H"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "5fab02a0-f0c0-58de-85fa-5dd8738ee7c4", "question": "Consider the paper that introduces the method which is in the second row of the table. What specific algorithm does the model proposed in the paper apply to prevent loops and token redundancy in parses, and how does it function?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is in the second row of the table. What specific algorithm does the model proposed in the paper apply to prevent loops and token redundancy in parses, and how does it function?", "reference_answer": "Tail collision avoidance algorithm"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "60ebd9b5-0076-524f-9834-c9bc24eca4b9", "question": "Consider the paper that introduces the model that achieves a P_k score of 24.8 in the en_disease category. What specific approach does the paper employ to improve the model's ability to generate accurate sentence positions for generative segmentation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4db47b23-f7bf-5d2e-a957-279ddcc3310c"], "reference_pdf": ["56f3aaed-b2b7-5df1-97cc-7cf6236a892f", "fa9a9ad6-66e9-5bd8-b1a2-862836bceb4b", "c3a61f79-d156-54a9-9888-813475b4d3d1", "0015561a-99bb-5b95-b457-3e43c7751331", "0d601b2e-069f-5bab-ae99-f37eb696b06a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9d2e017c-b25e-5cbc-8493-ccb4d9ab7443", "bcf8872a-b92d-5cbe-8be5-350bcf7d5e15", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "ca40df32-58b7-52fe-b2b5-458f848e4210", "4e513417-bbb2-55e1-b572-ec68a60fc6be", "64ee757d-3fab-5132-aadf-376825399f6b", "edd36969-0b52-50f9-b08c-9b0ba9e514e7", "502590c0-bb29-53ab-8095-a2c68e3e42ab", "3134099b-d3ac-56d3-898d-c77c7a99370e", "1ddc4f93-70fd-5397-a6f3-ee8837ea208e", "afbe2f7a-2754-5da7-97f6-b56a58fe47a4", "eeda9a9d-5d4e-5579-9a3b-f2e546a7bf4b", "00dd4300-de92-5712-9ce8-ccdb844b6314", "3790e4a5-ff47-586a-b09c-c11ab395909d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "510d6fc0-d3e0-5dc1-8e0d-4d470f964287", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a P_k score of 24.8 in the en_disease category. What specific approach does the paper employ to improve the model's ability to generate accurate sentence positions for generative segmentation?", "reference_answer": "Using the $i^\\text{th}$ vocabulary token embedding in place of a fixed BOS token index for the $i^\\text{th}$ sentence."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11772/comparison_table.png"]}
{"uuid": "61203f16-f818-5391-ae70-8777b287c820", "question": "Consider the paper that introduces the method that is in the second row of the table. What is the recall value for the model proposed in the paper using BERT-large (Bl) as the language model encoder in the UFET task before applying the Prior Knowledge about Labels (PKL) strategy?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["09e64ec3-5f93-5ee7-a81a-5bc1dd99f004"], "reference_pdf": ["0ed7c020-1b01-5cb4-a990-280fdfcfd830", "f393f359-5002-5544-88cf-484f811f9de0", "df4d0a6f-162d-5a17-a7e2-c949dcb008fe", "8c672eae-46ec-5a53-ac32-3c72cc49ded9", "fb059017-6ff5-5b9f-9a51-d6ab436eed1e", "5ee7745a-e70f-5bec-b49d-1d0fabdf453d", "cc1ac0c9-340a-5ae3-8410-c000b2696eb8", "69ac39b0-3765-5232-93b7-01b3ef16b580", "f4bb3b0b-0f4f-50a9-9be5-cee4752f8038", "73dc0489-e9e0-52b0-bdf4-5f39ae3b0693", "243c5488-19f9-5ddf-82ce-2c13c5b6c76f", "436473bc-4190-5d91-9004-71ef63cee599", "d112b9d1-d4d4-5a03-b2f9-9107954158b4", "be79a7b9-9e94-52e9-9d4d-2784cfc33987", "006134c0-3d8a-522f-98bc-3d15db04df18", "2f3a116d-c852-5487-bbf0-587ee8db7379", "79c58b97-75e2-590f-ab73-90c71c7af2a6", "cf51bf0c-3d81-5337-a640-b6c88e5ee0c1", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "65b54391-8920-574c-adb0-f323aa10cbb1", "76b6a5b6-5439-591e-bf61-ca971f3ad23e", "5a4e3f5d-2c2b-5c59-bb0a-edcd3b40ed7e", "8903812c-bb72-5ff3-8faf-3787d56c1ceb", "0ed7c020-1b01-5cb4-a990-280fdfcfd830", "26e45afd-1c91-5f0f-bb47-33707acec072", "5a922b70-446f-5cac-a455-3d725f110ca0", "0f9c5f89-7c6f-5bd2-bd90-727a9980a494", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the second row of the table. What is the recall value for the model proposed in the paper using BERT-large (Bl) as the language model encoder in the UFET task before applying the Prior Knowledge about Labels (PKL) strategy?", "reference_answer": "47.5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14793/comparison_table.png"]}
{"uuid": "618b95d7-065b-5922-957b-54404d1306ab", "question": "Consider the paper that introduces the model that performs the second best in the ClinTox dataset. What is the peak learning rate used during its pre-training?\n\nA) 1e-3\nB) 5e-4\nC) 2e-5\nD) 1e-6", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["75156ea6-7402-5a33-9303-ec6f543e9999"], "reference_pdf": ["7aa1a28a-1256-5732-9581-f2538bfcaf8e", "adf24566-930f-5a42-8118-6aeb65e4f6f4", "825de5ef-3ab4-5629-9fc4-4b0805f419b8", "a1002509-bd90-5cde-9fd2-7b6216144d71", "653e5d86-f991-5533-bd83-a5d95f760b18", "aa22dd10-f8dc-5b74-893f-4f3b21431f24", "766ea9a1-a447-5963-a71f-c9d0a0562d57", "7ea7979f-d2cf-58e4-b00e-2b4027aaf436", "a2401db7-a8bd-588a-856c-4d9ad4f85409", "3a2ae924-5f60-5905-abab-631f660f7bb6", "54fbf9e2-28d0-54ce-ba51-27f90b206c6e", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "3b7baa1d-606b-5481-9c27-fec60e4c7533", "6d068e18-8fb7-5dff-b0bf-b95297a79dc5", "7908763f-3a9d-5ce5-af59-f68888750583", "4ef708b0-51b3-5527-91fc-a55d70b49671", "e2b71dfc-0678-5451-82f6-42650b5ca0dc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "05397506-c619-548a-9f1f-18f85acc151e", "cf69528e-9892-5b27-ab66-0b66a1304268", "a2677b99-9e0d-5c14-8e19-f1c7d5cfa93f", "7908763f-3a9d-5ce5-af59-f68888750583", "7d25556e-bc5e-58ba-b1d8-294c67ed7d98", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6fd2a9e7-7fea-5866-b0c4-120b7cc5baae", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "d97c36ef-e3d9-5f53-a6ff-00d5ee2f2777", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "d4f91c73-f4cf-5209-bec5-6ff66eb29d19", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "5161fb60-4394-5446-9e6e-ce1f1e9e393a", "1777f12e-991e-52d4-8b6b-03807d589e87", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "964db907-da57-5f8b-b1ef-1054c077ca89", "4a697112-1b30-569a-8fee-c4eace04cb3f", "33130f85-57c8-54d5-b050-075bb1ccab97"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that performs the second best in the ClinTox dataset. What is the peak learning rate used during its pre-training?\n\nA) 1e-3\nB) 5e-4\nC) 2e-5\nD) 1e-6", "reference_answer": "0.0005"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07276/performance_table.png"]}
{"uuid": "61954534-7d67-543f-95b1-0cd80bdc6692", "question": "Consider the paper that introduces the model that achieves the second highest score in the Stance column. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the second highest score in the Stance column. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "61f52e81-d8ba-5364-868d-a43eddfc3cdb", "question": "Consider the paper that introduces the method that is represented by the square marker. What specific methodological adjustment is made to its variant, named MMA-H, to address the potential issue of outlier attention heads affecting latency or attention span?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is represented by the square marker. What specific methodological adjustment is made to its variant, named MMA-H, to address the potential issue of outlier attention heads affecting latency or attention span?", "reference_answer": "attention variance loss to MMA-H"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "6204e83a-79e4-56f6-811a-f1591b603391", "question": "Consider the paper that introduces the method that has an average score of 82.8 with zero-shot prompting. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["2479f89b-b7c0-534f-b51d-d24093d3a1f9"], "reference_pdf": ["7aacee49-58db-593f-9a47-44846ba2ed23", "881f50d7-f0cf-59e7-8351-429ea3655e0b", "57c06ca1-608a-5816-86dd-0f35be577ce0", "1165b8f0-4261-5c50-9583-bfc199324e61", "1c848190-6829-5b07-a439-3452fd19617b", "ea8d0d91-a08c-547f-aa61-fc136ce41e58", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "003269db-f43b-57bc-a219-825c655fab01", "16e73621-a0c1-5f1d-ae72-fa60befecf05", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "b31b84cd-d7c7-50d1-9dc2-cb340ea4d218", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "a76fdb50-d95e-5db2-83a6-ece16257796b", "e0523cf0-8310-565e-9d91-c539c15adcb7", "be395337-c3e2-5e16-b2ef-1ed22e6736dd", "729f79df-1057-5418-89cd-592408770592", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "1e0413f9-466d-57a0-be12-cbfb9da4056a", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "8f02441e-aa43-5abf-bd9b-cfd760b7cc20", "e5c8fae9-734a-54d1-bde4-03ec07d10c86", "b5798106-2737-52fa-b1e5-010749d19c2c", "6677d3c0-7aea-5795-a934-d93933e25157", "02cf0294-1961-54c5-a745-0d99126e65d3", "c76b968a-995a-5109-a4eb-f329fa710f26", "de0470bf-d650-5f5c-9fb8-926b7ed2c806", "65c601c1-c571-5d9e-aa32-e37fcc3e0097", "445e9197-1321-57c3-93bf-7084e795848d", "da29dae2-1a88-5793-8149-81c0b63122ca", "02193a94-398e-57da-bb53-0c5800ca743a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an average score of 82.8 with zero-shot prompting. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "reference_answer": "6 and 6.2 points"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15746/comparison_table.png"]}
{"uuid": "626ec309-30ab-58e9-b674-bd25d16d1d53", "question": "Consider the paper that introduces the method that achieves a score of 28.62 in the WQ-B task. How does the model proposed in the paper address the challenge of generating questions with both word-level and structure-level diversity?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a score of 28.62 in the WQ-B task. How does the model proposed in the paper address the challenge of generating questions with both word-level and structure-level diversity?", "reference_answer": "The proposed approach addresses the challenge of generating questions with both word-level and structure-level diversity by introducing a dual model framework that leverages external natural questions. This framework consists of a forward model and a backward model, which are interwoven by two selection strategies. These strategies are designed to select diverse natural expressions from external questions and integrate them into the generation model. This method enables the injection of diverse expressions into the generation process, thereby enhancing the diversity of the generated questions at both the word level and the structure level."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "62b8664a-4106-5cbc-868a-c494c5ee65ad", "question": "Consider the paper that introduces the model in the second-to-last row of the table. What mathematical modification is applied in its methodology of quantifying temporal degradation (TD) to ensure that, as performance deteriorates, the calculated value increases regardless of the direction of time between the training and evaluation timestamps?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the second-to-last row of the table. What mathematical modification is applied in its methodology of quantifying temporal degradation (TD) to ensure that, as performance deteriorates, the calculated value increases regardless of the direction of time between the training and evaluation timestamps?", "reference_answer": "-\\left(S_{t' \\shortto t} - S_{t \\shortto t} \\right) \\times \\text{sign}(t' - t)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "634225de-17e7-572e-818d-2ff5268c65d3", "question": "Consider the paper that introduces the method that corresponds to the leftmost bar in the figure. Which theoretical connection underlies the model proposed in the paper for detecting abnormal samples?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["810b0721-c498-57eb-93f3-4687d2dc64f8"], "reference_pdf": ["96ffb0d8-e291-596b-8c52-bcb4f183ed44", "74bcffe4-c1bb-5022-8e6a-7a9fef895ed0", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "8f328ef8-5248-5492-b3c9-d115046efc43", "9523ad64-fad9-5352-bc32-ceb1a8f5adbc", "83cd0d28-4378-5b49-8949-01f5181b7b17", "1047803c-3229-546d-8a93-9027fcbe4df0", "8f13f0c9-2b92-5a09-8369-41969fc0924d", "e879e81b-c392-5e42-8658-34e328f1b1ca", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "82058002-7940-5f07-be28-abac6954e278", "f3dd87c3-4705-546b-ac6c-93d9d1692249", "78a2a197-944e-5f53-91c7-265b771d4c06", "de5ec475-b70f-5190-a798-98df54b25136", "d05f95b6-53e2-5fa5-a256-7c4c232feb64", "b3afe895-977b-58d5-89a8-69bf5f6d84a3", "d7e4e761-411b-5c7a-8d24-3a7b71ea2719", "37a5f603-9e5f-5fa5-bdfd-9dc0318ef668", "7c403e43-6318-5a9f-a3c8-40ff27f52369", "f554c584-7f48-587f-9f9b-4e4debbc5cad", "80686b1b-4ffa-54fb-a2fe-79152313a396", "8a533609-59b9-5837-a2c4-669dea41251a", "baa84a82-a8d5-5bc3-8896-82f9ef647504", "c811c5a5-c22a-5fd6-9f1c-1ffa1bde7c47", "65999ca9-2672-51e5-b596-2c9bb3cee2dd", "4a324a22-6bd2-5602-84bc-07231c819440", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the leftmost bar in the figure. Which theoretical connection underlies the model proposed in the paper for detecting abnormal samples?", "reference_answer": "The theoretical connection underlies the proposed method for detecting abnormal samples in the paper is the equivalence of the posterior distribution defined by the generative classifier under Gaussian Discriminant Analysis (GDA) with tied covariance assumption to the softmax classifier."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05083/comparison_figure.png"]}
{"uuid": "635f9448-0ab5-55aa-8672-8d54627afcb0", "question": "Consider the paper that introduces the method that corresponds to the third row of the table. What is the primary reason for the performance drop in the model proposed in the paper when the hyperparameter gamma is set to 1?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["26feec2d-e6df-532b-9f63-ab9b73e8266f"], "reference_pdf": ["8b28a50c-b93f-5426-adbf-c8a139d518de", "c02fd012-1287-5268-94e6-aaae4ee61dda", "686c19e6-39d7-5bb4-a324-ba2bd5c26db2", "c260bf67-2731-5445-96eb-94baa3e5f834", "51e05e32-8367-58b9-b753-6c6a6c1d665a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "60105831-0210-599b-a410-f12e2df3cffc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "0e0746e6-8044-5c49-b46e-0a66569438a8", "e2a2d7b1-a02c-58e5-8d14-272810335de1", "7908763f-3a9d-5ce5-af59-f68888750583", "c5833e1d-8813-56da-99d1-bf61d9ac33df", "5d474441-0098-5521-b6d2-4219837f18c9", "3134099b-d3ac-56d3-898d-c77c7a99370e", "311f9316-6c35-5c33-b61a-f25d90866412", "c76b968a-995a-5109-a4eb-f329fa710f26", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "da510970-00ea-5853-a68c-9741c0d1fd4d", "81de543a-91c2-5035-9617-724abb93a839", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "206abdf4-f071-58ab-8bd6-206bb79786f1", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "d3344458-d106-52ed-be5c-505f8b07af06", "b4ce79f8-4a56-5bb4-b15c-13fee270a57d", "cbb28401-7af5-577d-b36c-a50a87e88b96", "27810986-0584-5a03-9944-a70637604b0f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the third row of the table. What is the primary reason for the performance drop in the model proposed in the paper when the hyperparameter gamma is set to 1?", "reference_answer": "The primary reason for the performance drop when the hyperparameter gamma is set to 1 in the CSN model is that it results in no document content being selected, effectively degenerating the model to non-document-grounded response selection, which sharply decreases performance."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06390/result_table.png"]}
{"uuid": "63880f1d-5f2a-5c68-a6ef-2e998bb085bc", "question": "Consider the paper that introduces the method which is placed below the row for R-Former but above the row for NeurJudge. What is the percentage improvement in F1-score for law article prediction on dataset CAIL-big when comparing the model proposed in the paper with the state-of-the-art MPBFN-WCA?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4f12dd13-6c81-5c0e-90e0-a879ef970a6d"], "reference_pdf": ["e111dd29-50ea-5b75-b563-b1721822b94a", "29258fbc-289f-5221-9c42-16b87d1197b9", "5a1fa4c3-fd03-576e-a4bf-29fd77bec899", "2f6551e2-3835-5c86-9a91-da8b6c8bd429", "2a4d76a8-5d9e-550d-8294-03798da0a973", "34417770-67d7-5cab-b9d4-76999c97bc02", "e4c8595f-5b4c-560d-8306-ea3b13b97928", "42d7a286-5fb0-52be-bd7d-62dc2af2d1c2", "5e549c77-a92b-5ee7-85bc-5a30491d7767", "7eb9a7f2-f640-5526-b434-8d8ff6df167f", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "c3336863-3e6d-56b5-b725-bf73fa23aea9", "33490461-6a37-5409-9d29-f44ad28db91e", "413e7de9-03c4-5c1f-9e42-cd48030c9369", "28e3f907-ee87-5f90-8513-9c64c27051b7", "c023321f-ab7c-57f3-afd8-0f845bca0d1d", "64e5de88-4c23-5099-ac1a-6a8c52b14a49", "d2e0ec1b-f3da-54d8-bda6-b45aa4c22abb", "7908763f-3a9d-5ce5-af59-f68888750583", "df53ebe7-ed7e-56b5-9a14-1c0b4dbe2f7d", "e35f3dc3-713f-5d38-a8d7-2ea61040467d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6324dff1-f1c0-52cb-a0e9-2251c1928303", "2ee016c2-fb4d-5b47-a5cc-d51e4ef61c63", "f6649e84-3c02-54c7-9740-66cc22a0a9da", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is placed below the row for R-Former but above the row for NeurJudge. What is the percentage improvement in F1-score for law article prediction on dataset CAIL-big when comparing the model proposed in the paper with the state-of-the-art MPBFN-WCA?", "reference_answer": "3.18%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09241/results_table.png"]}
{"uuid": "63942298-3e6c-5d38-8615-fd7f52df5785", "question": "Consider the paper that introduces the dataset which has a test set size of 1,106. What specific linguistic phenomenon is used in the model proposed in the paper as an example to illustrate the challenge of detecting hate speech when comments use phrases that only make sense when read backwards?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has a test set size of 1,106. What specific linguistic phenomenon is used in the model proposed in the paper as an example to illustrate the challenge of detecting hate speech when comments use phrases that only make sense when read backwards?", "reference_answer": "Puns"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "647e67f2-1708-5ce3-94e8-1919eb24201f", "question": "Consider the paper that introduces the dataset that has the fewest number of languages but the most number of SM tasks. What is the exact match score between the labels and predictions for Flan-T5 on this benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that has the fewest number of languages but the most number of SM tasks. What is the exact match score between the labels and predictions for Flan-T5 on this benchmark?", "reference_answer": "29.07"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "6602fa9c-7d48-5744-bb97-9ada9af6185d", "question": "Consider the paper that introduces the method that has a lower F1 score than BROS and a higher F1 score than LayoutXLM. What specific layout features are used in the GCN encoder for updating the representation of the entity and edge in the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than BROS and a higher F1 score than LayoutXLM. What specific layout features are used in the GCN encoder for updating the representation of the entity and edge in the model proposed in the paper?", "reference_answer": "\\mathbf{r}_{i, j} = [x_{i,j}, y_{i,j}] here $x_{ij}$ and $y_{ij}$ are horizontal and vertical distance between the two entity boxes respectively: \\begin{equation} \\begin{aligned} \\label{ra} \\scriptsize &x_{i, j} = min(| x_i^1 - x_j^2 |, | x_j^1 - x_i^2 |) \\\\ &y_{i, j} = min(| y_i^1 - y_j^2 |, | y_j^1 - y_i^2 |) \\end{aligned} \\end{equation}"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "662b9502-8b99-5828-a078-4659b806bee3", "question": "Consider the paper that introduces the method that results in a better score than MOCA but worse score than LACMA in the Seen, Val, SR dataset. What specific performance improvement does the model proposed in the paper provide through pretraining and joint training with synthetic instructions on the ALFRED benchmark's unseen test split?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that results in a better score than MOCA but worse score than LACMA in the Seen, Val, SR dataset. What specific performance improvement does the model proposed in the paper provide through pretraining and joint training with synthetic instructions on the ALFRED benchmark's unseen test split?", "reference_answer": "8.5% task success rates on unseen test splits"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "667c6c9a-39c2-56e4-bac5-47d83dce3d67", "question": "Consider the paper that introduces the method that has 638K tunable parameters. How does the model proposed in the paper ensure parameter efficiency while enabling task-specific adaptation in the context of multi-task learning?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has 638K tunable parameters. How does the model proposed in the paper ensure parameter efficiency while enabling task-specific adaptation in the context of multi-task learning?", "reference_answer": "The \\methodefficient model ensures parameter efficiency while enabling task-specific adaptation in the context of multi-task learning by employing a compact hypernetwork shared across tasks and layers. This hypernetwork learns to generate task and layer-specific adapter parameters, conditioned on task and layer id embeddings. The shared hypernetwork captures information across tasks, enabling positive transfer between related domains and transferable tasks, while adapters reduce negative interference by encapsulating task-specific information. For each new task, the model only requires learning an additional task embedding, significantly reducing the number of trained parameters."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "66b3a5cb-ea1f-5f17-ae70-7449b2396d5d", "question": "Consider the paper that introduces the model that corresponds to the lowest BERTScore F1 score on the TellMeWhy dataset. What is the primary limitation of using the model proposed in the paper for event-centric summary generation in educational question generation, as identified in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5cb4f0ee-6979-5de3-9228-7707e6240704"], "reference_pdf": ["78b201f5-8cc7-5580-a1e9-3e61fd50a3b0", "412f0d4e-18e1-50b9-9029-b2f3dc0f7eff", "a239e827-0d3f-5f3a-9757-0b218e376c95", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "c48ce7f0-0f60-568a-a32a-61dac182a786", "6f6a00e8-6bd2-5287-ab63-6b0b5f3e422d", "6440959d-ac81-5a2c-ae6e-9082bf5ee380", "28a47974-2035-5575-9a75-7df451faf18d", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "f6e91a91-0b1e-5280-8522-a20492033f16", "822d7c33-cc29-503d-96f9-a82f49f90f06", "977a0308-a19f-537c-940c-4064e7796e83", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "e756a768-abbe-52e1-8416-6c24deaa43ff", "f96ef4a4-88c2-52dd-bcad-82b7d77045f0", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the lowest BERTScore F1 score on the TellMeWhy dataset. What is the primary limitation of using the model proposed in the paper for event-centric summary generation in educational question generation, as identified in the paper?", "reference_answer": "Factuality error"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16446/tell_me_why_table.png"]}
{"uuid": "670d897e-409b-51d7-ba93-2ad733afafc5", "question": "Consider the paper that introduces the model that demonstrates the highest score in the 'T3' column. What specific hyperparameter values were used for the FewRel dataset in its experiments, and how do these values compare to those used for the TACRED dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that demonstrates the highest score in the 'T3' column. What specific hyperparameter values were used for the FewRel dataset in its experiments, and how do these values compare to those used for the TACRED dataset?", "reference_answer": "For FewRel, the values were α=0.5, β=0.5, τ1=0.1, μ=0.5, ω=0.1, τ2=0.5, γ=1.25, λ1=0.5, λ2=1.1. For TACRED, the values were α=0.6, β=0.2, τ1=0.1, μ=0.8, ω=0.15, τ2=0.5, γ=2.0, λ1=0.5, λ2=0.7."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "672a3aca-9441-5040-9cbb-be24f319d0ba", "question": "Consider the paper that introduces the method shown in the fifth row of the table. What is the model's, proposed by the paper, EM score using the reverse order of in-context examples on the NQ dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the fifth row of the table. What is the model's, proposed by the paper, EM score using the reverse order of in-context examples on the NQ dataset?", "reference_answer": "42.8"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "679b1845-d31e-531b-a823-520c971c8f6f", "question": "Consider the paper that introduces the method which exhibits a score of 34.9 in the Acc-7 metric on MOSI. What specific feature of spoken language does the Spoken Language Embedding Subnetwork in the model focus on to handle the volatile nature of spoken opinions?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which exhibits a score of 34.9 in the Acc-7 metric on MOSI. What specific feature of spoken language does the Spoken Language Embedding Subnetwork in the model focus on to handle the volatile nature of spoken opinions?", "reference_answer": "focusing on important parts of speech"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "67d59995-4275-5092-8d58-f364c2983d26", "question": "Consider the paper that introduces the dataset which exhibits the highest accuracy for Method 2. What specific architectural feature allows the model proposed in the paper to simultaneously perform language modeling and correctness prediction tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa7d95d4-dd69-5849-8f0b-119726938dac"], "reference_pdf": ["3ea1a5e9-0057-54a5-b359-7d99fc882842", "06e77679-09f0-5936-b00f-dcad7a604f75", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "c7cf8100-fcbd-575b-a980-7f6d3c4f6761", "b44607d8-7587-53ed-be67-22b3668a1644", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "1b151a0b-8156-5a1d-9459-ba2037900807", "bf80182b-c2b3-5553-bfcf-3d83d1c71d9d", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "cb83c58c-fefc-566d-b291-b27faf9eec2b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "e69ef270-7428-50f6-b47b-63a2455841ac", "7908763f-3a9d-5ce5-af59-f68888750583", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "20847c00-ada9-56f4-aab2-d67eb2ace27b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which exhibits the highest accuracy for Method 2. What specific architectural feature allows the model proposed in the paper to simultaneously perform language modeling and correctness prediction tasks?", "reference_answer": "A small scalar head that outputs predictions on a per-token basis."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14628/comparison_figure.png"]}
{"uuid": "695a5724-9e95-5dc7-88c9-79f19b81a3bb", "question": "Consider the paper that introduces the model that has the highest Recall@7 score in the CamRest task. What specific token is used to represent a null query in cases where no query is required, such as greetings or thanks, within the system proposed by the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["690e4131-3330-5bd8-9132-669280baa458"], "reference_pdf": ["74ab3845-0eef-54a0-8c11-ec17231ff70f", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "dc374d6f-8af0-5f68-8836-a5734a95f24a", "27a3e973-f2ba-53eb-829b-7bee289d51f2", "4d63e299-19a6-57dd-946b-2f8256c90192", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "aefe2914-5fdb-5ef7-bf50-ad38e28832c4", "d27f5f12-140e-5048-8152-426067d8fad1", "dccb63d4-f203-5a8b-8f8a-10fb38fda9b4", "edf72dc4-d79d-5f52-98de-5c008797474f", "cf0c242a-86be-5d3e-b394-ef45e639af53", "c1f4221a-e7e5-5df3-8d1b-0acc89e315f6", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "493cad14-fb60-56ac-a1dd-0a7756de59cd", "82c7eacc-bdad-5c51-a9f8-651bc244721a", "1e7d9f86-3567-55b8-be98-064a3d297af1", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "772c62b6-0932-5321-86ee-61dccbda8108", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "371fc0fa-bcec-5ffa-95e3-71879321564b", "d24c4e1f-1b12-5af1-a7ea-054861015af6", "42d6954b-5fc1-5d50-9830-1a3db7d6e98a", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest Recall@7 score in the CamRest task. What specific token is used to represent a null query in cases where no query is required, such as greetings or thanks, within the system proposed by the paper?", "reference_answer": "[NOTHING]"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08877/result_table.png"]}
{"uuid": "69d7b052-b905-5ce7-9082-bfe5710d9edc", "question": "Consider the paper that introduces the model that achieves the highest score in the 'T2' column. What specific hyperparameter values were determined through grid search for the FewRel dataset in the implementation of the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the highest score in the 'T2' column. What specific hyperparameter values were determined through grid search for the FewRel dataset in the implementation of the model proposed in the paper?", "reference_answer": "$\\alpha=0.5$, $\\beta=0.5$, $\\tau_1=0.1$, $\\mu=0.5$, $\\omega=0.1$, $\\tau_2=0.5$, $\\gamma=1.25$, $\\lambda_1=0.5$, $\\lambda_2=1.1$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "6b007500-7330-5b42-ae03-35bb185bd9b1", "question": "Consider the paper that introduces the method shown in the fifth row of the table. What is the impact of the order of in-context examples on the model's results for the NQ dataset using the method, specifically when applying KATE$_{\\text{nli+sts-b}}$?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the fifth row of the table. What is the impact of the order of in-context examples on the model's results for the NQ dataset using the method, specifically when applying KATE$_{\\text{nli+sts-b}}$?", "reference_answer": "The reverse order performs the best."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "6bcb47af-98bb-5d25-9e1e-64690584a10d", "question": "Consider the paper that introduces the model that has the largest number of updated parameters. What specific effect does the removal of the path ending strategy have on its Hits@1 retrieval performance on the WebQSP dataset according to the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the largest number of updated parameters. What specific effect does the removal of the path ending strategy have on its Hits@1 retrieval performance on the WebQSP dataset according to the paper?", "reference_answer": "2.1% to 18.5% drop"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_table.png"]}
{"uuid": "6c120f14-3889-52f0-8325-53d508207454", "question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. What specific loss function modification does the model proposed in the paper suggest implementing in the context of its algorithm to mitigate the issue of model degeneration observed with a naive probability ratio objective?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["d1251ff0-e100-545c-8a1c-664b75854f3c"], "reference_pdf": ["32d04289-3862-5912-a136-6a3d0fe472a2", "3e5b43f1-9b31-5edd-b334-46d5175e1900", "842c1145-6b9e-5d34-bd53-8169d537b66f", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "972a1223-29a4-5304-b9bd-ddec4829d163", "13daa5ee-4b7d-55ec-a5ea-7b19c5cf6e4b", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "37de84b9-2cd0-57ce-8d94-36a43b6c323d", "df2afc9e-2480-567e-84f6-bf4fb97fc1f5", "2adf1c9b-6b9e-59fd-a899-7262b2bd3179", "2ee0ee87-1989-50b9-b896-742ee506c1cc", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "17623cac-c243-591b-b7bc-d261f6ebd607", "f5c3d2bd-4221-5873-a520-589a585f6f93", "ca191c58-f83a-59e0-ad3f-fc6d9a125d9c", "2d4ccd49-4eeb-58ae-bd4f-134be8ae2c11", "945d086d-178d-52d6-aeb4-3988380b6b68", "90aad2c8-22fb-5293-9f5b-58c74b828bc1", "361c3f6a-401c-5854-b618-e7df40b3fa96", "d527d6bb-30ef-5662-971b-78311f082434", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "7169514d-e320-5e1e-8541-b8ca0f8ccc67", "bd4f2699-b1c4-5b76-8e8c-55f84e1e7fe0", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "c7633d80-8236-5a67-a4e5-88fdeadcd1ea", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a239e827-0d3f-5f3a-9757-0b218e376c95", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "342d6620-30f0-5382-b7d7-d3d5f798498f", "e2cbc3e9-68fb-5796-b54d-738df1ac3b67", "d777ea51-80c0-5cd7-873e-3695a75adea4", "880a06dc-f0c4-5e19-9201-2861f952fb32", "3a69cec2-a986-57db-8ea0-bfb4e9e3b548", "8d3ce001-929d-5c83-985e-0268ecc95532", "7908763f-3a9d-5ce5-af59-f68888750583", "dfd4aeaf-4735-5e61-92ff-f8b040f6eb55", "35b48813-1deb-5375-ac6a-948e906c5f54", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "dd073182-00f0-5a9f-800b-7779293ab2ae", "2bc7f244-8607-5501-a3c5-916c66efc615", "e1af3dcf-dee1-50e0-a72b-6c43dc428784", "977a0308-a19f-537c-940c-4064e7796e83", "58b68b03-a6a4-5977-a584-6f7b13dab877", "ebaab94f-c9fb-5186-951c-d7259a580fde", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "d27ee810-3a49-5970-b14a-c71604d54388"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. What specific loss function modification does the model proposed in the paper suggest implementing in the context of its algorithm to mitigate the issue of model degeneration observed with a naive probability ratio objective?", "reference_answer": "Dynamic, per-example importance weight"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05857/comparison_dpo.png"]}
{"uuid": "6ca58a9b-2953-5c8e-b0e8-b1686e7c5a36", "question": "Consider the paper that introduces the method that scores a 69.56 in the Forgotten Realms category. What specific improvement in U.Acc. does the model proposed in the paper achieve on the Yugioh domain under the few-shot entity linking task when comparing the performance of Syn+Seed data to the Name Matching method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e5476c7f-2b14-520b-81df-8783aebf59f5"], "reference_pdf": ["e897e2cd-c196-532e-8273-358b4878e270", "7e10ecb3-9428-53a7-8edf-83c7f2ca9bbe", "e0f03057-5bdd-575d-a691-7493ccc1bfb9", "98ac518b-1b74-562f-9913-2a494f1417c2", "f781ad75-0ee9-572a-bf0e-6ec0c4faf7c2", "cb764bcf-9005-5541-8cf0-55e47ee0ff91", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6", "560b3014-4a65-57cc-bda5-e3610828782e", "071d6f10-df74-5f8a-ba5f-4b3cfa33e65b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that scores a 69.56 in the Forgotten Realms category. What specific improvement in U.Acc. does the model proposed in the paper achieve on the Yugioh domain under the few-shot entity linking task when comparing the performance of Syn+Seed data to the Name Matching method?", "reference_answer": "14.94"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12444/comparison_table.png"]}
{"uuid": "6d22e50e-08d1-59fa-b351-1376f7333c01", "question": "Consider the paper that introduces the optimization method that has a BLEU score of 27.3. What specific behavior related to the structure of the sentence do the attention heads from the encoder self-attention at layer 5 of 6 exhibit, as shown in the attention visualizations?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5c7fb1dc-efe9-585f-a52c-656bed6b1c72"], "reference_pdf": ["cb54e44a-db51-5a8d-b3e5-e6387543389a", "c8717e4f-8ff0-5152-8082-266d0bb88071", "9f83b120-1a28-5397-b764-7b99e62db40d", "969d0c84-5046-5233-a9ce-015454c17e10", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "5015464f-7f34-5403-90e6-e0476fd5febc", "ee1e6c69-30cf-5f9e-b4a8-bfb51a657d08", "35ec5422-c394-5eac-854d-28233a5f9f68", "5aab03c9-0e38-5818-90e3-3b5f882ce28d", "565aa06f-5a94-59e2-9b9a-d8de69a00b54", "d6ea3099-8dd9-5844-a96c-388a86582ee8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "00541e26-04b4-520c-8fee-a656c0bc652c", "4d70e58b-2262-56d0-b3ec-957f8d6132d5", "808a8c71-5485-5683-88e6-b4616d8e7ead", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "b0b8f08f-5cc3-51bd-9834-5c7e50ae692e", "d537f355-a76b-5894-856f-7fbd3328d16e", "0dbcbe8e-2d15-50c7-a52a-9aea7f74fa95", "5d15ac0c-f847-534d-ae40-0007ec49f2b0", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "09a1e967-c629-5c69-b12c-782dd3e017ac", "9066c5d4-3831-59c9-b803-b593a6ef8083", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "3134099b-d3ac-56d3-898d-c77c7a99370e", "42fd3669-c60f-5d28-b51d-4523bebf0734", "1f098267-9697-5fbb-bf8f-a585caad8bf8", "9d24c743-9966-5400-a5f9-6825eca1d557", "b80e3d5b-034c-5f7a-9375-022d87904ee4", "c1c0f24c-58ff-5141-8a9e-a279b49c9213", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "0f92bb2b-b658-5689-914a-8c0ef2dffc3a", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "14c9ea98-903d-52bc-b706-f869a7ff6c91", "0494f66b-dc26-5683-9804-25b245ddba54", "69e18e42-778d-5f47-92ec-bdfe3b03ed37", "0956d0ef-a936-5d49-a5aa-9be966fc7470"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that has a BLEU score of 27.3. What specific behavior related to the structure of the sentence do the attention heads from the encoder self-attention at layer 5 of 6 exhibit, as shown in the attention visualizations?", "reference_answer": "The attention heads exhibit behavior that seems related to the structure of the sentence, such as attending to a distant dependency of the verb 'making', completing the phrase 'making...more difficult', and apparently involved in anaphora resolution."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/BLEU.png"]}
{"uuid": "6d82a420-807e-5270-b1d8-29fc1329ba4c", "question": "Consider the paper that introduces the method that corresponds to the leftmost bar in the figure. What is the improvement in True Negative Rate (TNR) for detecting LSUN samples using DenseNet, when comparing the model proposed in the paper to ODIN, given that 95% of CIFAR-100 samples are correctly detected?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["810b0721-c498-57eb-93f3-4687d2dc64f8"], "reference_pdf": ["96ffb0d8-e291-596b-8c52-bcb4f183ed44", "74bcffe4-c1bb-5022-8e6a-7a9fef895ed0", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "8f328ef8-5248-5492-b3c9-d115046efc43", "9523ad64-fad9-5352-bc32-ceb1a8f5adbc", "83cd0d28-4378-5b49-8949-01f5181b7b17", "1047803c-3229-546d-8a93-9027fcbe4df0", "8f13f0c9-2b92-5a09-8369-41969fc0924d", "e879e81b-c392-5e42-8658-34e328f1b1ca", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "82058002-7940-5f07-be28-abac6954e278", "f3dd87c3-4705-546b-ac6c-93d9d1692249", "78a2a197-944e-5f53-91c7-265b771d4c06", "de5ec475-b70f-5190-a798-98df54b25136", "d05f95b6-53e2-5fa5-a256-7c4c232feb64", "b3afe895-977b-58d5-89a8-69bf5f6d84a3", "d7e4e761-411b-5c7a-8d24-3a7b71ea2719", "37a5f603-9e5f-5fa5-bdfd-9dc0318ef668", "7c403e43-6318-5a9f-a3c8-40ff27f52369", "f554c584-7f48-587f-9f9b-4e4debbc5cad", "80686b1b-4ffa-54fb-a2fe-79152313a396", "8a533609-59b9-5837-a2c4-669dea41251a", "baa84a82-a8d5-5bc3-8896-82f9ef647504", "c811c5a5-c22a-5fd6-9f1c-1ffa1bde7c47", "65999ca9-2672-51e5-b596-2c9bb3cee2dd", "4a324a22-6bd2-5602-84bc-07231c819440", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the leftmost bar in the figure. What is the improvement in True Negative Rate (TNR) for detecting LSUN samples using DenseNet, when comparing the model proposed in the paper to ODIN, given that 95% of CIFAR-100 samples are correctly detected?", "reference_answer": "50.2%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05083/comparison_figure.png"]}
{"uuid": "6f2cc36d-f207-50e6-9874-98548550d1f8", "question": "Consider the paper that introduces the model shown in the figure that is consistently better than MPT-7B-Instruct but consistently worse than LLaMA-30B. How does the model proposed in the paper's base version perform on the Asleep at the Keyboard security benchmark in terms of valid and insecure code generation when comparing completion and insertion formats?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the figure that is consistently better than MPT-7B-Instruct but consistently worse than LLaMA-30B. How does the model proposed in the paper's base version perform on the Asleep at the Keyboard security benchmark in terms of valid and insecure code generation when comparing completion and insertion formats?", "reference_answer": "StarCoderBase has a higher rate of valid code generation in the insertion format (98.70%) compared to the completion format (85.50%), but a slightly lower rate of insecure code generation in the insertion format (35.87%) compared to the completion format (39.77%)."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/average_relative_performance.png"]}
{"uuid": "70e5ef54-765f-5490-ab1d-2c34715bf2da", "question": "Consider the paper that introduces the method that exhibits the highest accuracy on the VQA-v2 task. What specific strategy does the model proposed in the paper employ during finetuning and inference to address the inefficiency and potential for generating invalid labels in classification tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the highest accuracy on the VQA-v2 task. What specific strategy does the model proposed in the paper employ during finetuning and inference to address the inefficiency and potential for generating invalid labels in classification tasks?", "reference_answer": "Trie-based search"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "71f60e49-e980-5829-a4e9-2644c3c53980", "question": "Consider the paper that introduces the model that achieves the highest score in the 'T2' column. What specific hyperparameter values were used for the FewRel dataset in its experiments, and how do these values compare to those used for the TACRED dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the highest score in the 'T2' column. What specific hyperparameter values were used for the FewRel dataset in its experiments, and how do these values compare to those used for the TACRED dataset?", "reference_answer": "For FewRel, the values were α=0.5, β=0.5, τ1=0.1, μ=0.5, ω=0.1, τ2=0.5, γ=1.25, λ1=0.5, λ2=1.1. For TACRED, the values were α=0.6, β=0.2, τ1=0.1, μ=0.8, ω=0.15, τ2=0.5, γ=2.0, λ1=0.5, λ2=0.7."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "7241edab-57a1-5935-97fc-01bc20a9078e", "question": "Consider the paper that introduces the specific hyperparameter settings for generating narratives from sentence-form commonsense knowledge using GPT-3.5 in the framework of the dataset used for the 'dialogue response' task. What specific hyperparameter settings were used?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["db2754aa-bf0b-52b1-a544-2cafb659b753"], "reference_pdf": ["c8717e4f-8ff0-5152-8082-266d0bb88071", "5f861444-411b-5c95-80cf-3aa93ff28763", "f7afa50e-c73f-5bef-9acb-4944c13f1533", "34417770-67d7-5cab-b9d4-76999c97bc02", "93f2b359-d6c0-5c0e-8b53-ad03af3ac946", "f92811a6-b9ce-519e-9346-f3b892d7f535", "47952b13-8f8a-5402-8c8a-17b461aaa1cc", "98971f11-6faa-5050-845f-caecdf06f97a", "41982a4d-b3c2-5e5f-bb78-4c0a480299c1", "da90e201-7d72-5390-82f0-8549c85e4fba", "6c5168e1-a3f3-5263-84b3-29de388a544b", "ec5ed5f8-d390-59f2-8299-03115ca2c742", "cb79f244-a7d6-5793-9199-512a482911f8", "c0bc2a7b-a0a6-5785-823a-a24f24ac099b", "8231e6be-dbce-5906-969a-b7fa846b672f", "c497371c-17dd-5bac-a8f4-a047d15a0ee7", "6b474476-57a6-5296-8664-c0cad7717810", "109d0033-172c-50fb-96ac-084259f65089", "f803a6a1-a7a5-5d45-a5ef-8aae55d2858e", "f1a88572-1160-54ad-922f-f66cc1c22315", "15d8d13b-7f13-54bf-87a6-f40d75167eb9", "808a8c71-5485-5683-88e6-b4616d8e7ead", "edfe70ca-6ad5-5b43-a1af-87d5886f44c3", "393e9431-63b0-589d-88bb-62335baaf8bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "0b48d3a0-c352-5afd-8dc7-9c186316d538", "ebaab94f-c9fb-5186-951c-d7259a580fde", "a94d47ed-ede8-5a71-af1a-5ce44e897b38", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "a5e24ec8-9605-58e8-994a-32576d2b9cc6", "003f56f8-651c-535b-8983-3f448ef1addd", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the specific hyperparameter settings for generating narratives from sentence-form commonsense knowledge using GPT-3.5 in the framework of the dataset used for the 'dialogue response' task. What specific hyperparameter settings were used?", "reference_answer": "We leverage \\texttt{text-davinci-002} GPT-3.5 for generating narratives. We set temperature to 0.9, top-p to 0.95, frequency penalty to 1.0, presence penalty to 0.6, and max tokens to 1024."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/CFQ_table.png"]}
{"uuid": "7298d4c3-bc4d-5929-a239-32b9cfe0be07", "question": "Consider the paper that introduces the model in the figure that has a more negative Spearman's Correlation than 0.60 when the alternative set size is set to 100 in the Mean Cosine setting. What specific methodological approach did the model proposed in the paper employ to address the challenge of generating bland, uninformative samples in open-domain text generation models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the figure that has a more negative Spearman's Correlation than 0.60 when the alternative set size is set to 100 in the Mean Cosine setting. What specific methodological approach did the model proposed in the paper employ to address the challenge of generating bland, uninformative samples in open-domain text generation models?", "reference_answer": "Maximum Mutual Information (MMI) scoring function"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "73f059c0-a1c1-5767-bcda-43d0fdb15fb8", "question": "Consider the paper that introduces the method that has a lower F1 score than SERA and a higher F1 score than Doc2Graph. What specific strategy does the model proposed in the paper employ to unify multilingual multimodal inputs efficiently?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than SERA and a higher F1 score than Doc2Graph. What specific strategy does the model proposed in the paper employ to unify multilingual multimodal inputs efficiently?", "reference_answer": "LayoutXLM employs a strategy of obtaining character-level bounding boxes after tokenization using SentencePiece with a unigram language model, and then calculating the bounding box of each token by merging the bounding boxes of all characters it contains. This approach efficiently unifies the multilingual multimodal inputs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "73f25fa0-bf04-58e9-b8f8-6bcbc1236c72", "question": "Consider the paper that introduces the dataset in the table that has the second shortest average question length. How does the performance of the model proposed in the paper on the TyDiQA-GoldP benchmark in Arabic compare to its performance in Korean?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b7315180-e811-5a4a-882f-d4a8e0ffe866"], "reference_pdf": ["25905c58-6108-5577-b948-fbaa6aa23e6e", "7d06b7cd-d351-5e13-a0d1-d72ac792b3e7", "b846c66a-a177-5119-af8d-ec4757d6a06c", "2ee103a7-04e2-53fe-83fe-da3bee6579f6", "42c5c7c9-6099-53c2-8868-147e11467288", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "f92811a6-b9ce-519e-9346-f3b892d7f535", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "70d90498-b24e-5af4-84e5-c40377652bce", "01c9329e-9789-52dc-9eed-c99a8ef88a5c"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has the second shortest average question length. How does the performance of the model proposed in the paper on the TyDiQA-GoldP benchmark in Arabic compare to its performance in Korean?", "reference_answer": "Higher in Arabic"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2402.04588/comparison_table.png"]}
{"uuid": "7486bbdc-81a6-5588-816d-18fbacf2a3df", "question": "Consider the paper that introduces the dataset which has the largest number of Queries|Aspects in the OABS category. What specific methodological approach did the authors use to ensure the aspect-based summaries in the model proposed by the paper had sufficient content overlap with their corresponding sections?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the largest number of Queries|Aspects in the OABS category. What specific methodological approach did the authors use to ensure the aspect-based summaries in the model proposed by the paper had sufficient content overlap with their corresponding sections?", "reference_answer": "They used a greedy mapping algorithm to ensure content overlap, assigning a matching score based on ROUGE-1-recall between the abstract sentence and the aspect section, filtering out sentences with a score below a predefined threshold."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "749f7b47-857b-530a-a975-b7c38a3986b1", "question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What is the core component of the method that enables the propagation of matching information along the directed edges on Knowledge Graphs (KGs)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure represented by the 'x' (cross) marker. What is the core component of the method that enables the propagation of matching information along the directed edges on Knowledge Graphs (KGs)?", "reference_answer": "matching information propagation module"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "7534be2c-6ce2-5c7c-b9fc-31cefbee8742", "question": "Consider the paper that introduces the method that is listed in the table right below the PCP method. How does its utilization of the local hierarchy-aware contrastive loss $\\mathcal{L}_{L}$ compare to its hard-label version $\\mathcal{L}_{L'}$ in terms of performance impact?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is listed in the table right below the PCP method. How does its utilization of the local hierarchy-aware contrastive loss $\\mathcal{L}_{L}$ compare to its hard-label version $\\mathcal{L}_{L'}$ in terms of performance impact?", "reference_answer": "The performance drops notably when replacing $\\mathcal{L}_{L}$ with $\\mathcal{L}_{L'}$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "759567e0-efc1-5013-8d42-a810c1bc324f", "question": "Consider the paper that introduces the method for which the BLEU-1 score is missing in the table. What specific performance gain does the model proposed in the paper achieve on the Google-CC dataset compared to the CC-12M model?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e30a2f94-a104-572f-b30f-3ae7ff87f6e7"], "reference_pdf": ["d3c84791-eee6-5f1b-8500-1c0a84375f47", "f8d549ad-783d-591b-9ed4-4be9b95e7d9a", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "6c4dc282-e455-530e-9a34-4900a85e2964", "0a4a6ae4-afd1-5807-8417-fcd4b4809799", "1ad58efb-6d3b-5d50-b516-a01ae90f0787", "ee1dfb4c-7988-5a4c-bb1c-a26a7a03b8bf", "7aa9fab2-572b-5e8c-a92a-7b09e4f4c306", "4d3092f6-d683-5121-b9a5-7fca4ff91894", "a76b882d-198d-56d9-9ced-191f44ac95e8", "c6401b44-ad7a-5948-88ad-b180075d7dbe", "60b654b7-5847-56a5-8aaf-2e22fb679dc2", "0466db28-e878-5df8-8ebf-4a9aa8eb7b8e", "fc840122-59b3-5e1d-8c9b-4469f9395fda", "79c9710e-50b0-5c46-8210-1c5539a5328d", "cffe9204-ae34-53b2-adfc-ba74227619b8", "29322424-fba7-5659-a1df-8acb9f557bd8", "4974e1c8-fbd5-5689-ab45-78f2829161d3", "f4f54d07-2fac-59ba-ad99-7e60fba39833", "7ccc7830-102e-567f-9853-bed1eec59176", "f5b9aa98-8d6c-59b7-8883-d1339aeddd97", "949e1567-7aad-545b-b6ec-f5bad4d8bb4e", "6f26f6da-6cc3-5aa4-9f91-ca29b2d64729", "5baa788b-6e39-5587-8800-43f1801adef3", "69728e8c-59e5-5c53-a3cc-f245d1f7af59", "01d0de9d-f910-5674-841b-39ed4688eed7", "a941564b-e52c-55b7-8ded-59c510643621", "f3fe57c2-c6c8-5707-afaf-8f889823dffc", "facc9abe-bac6-5c51-8c10-0d2c28e15868", "cd71e042-6d38-56be-b014-7b9e02e8733e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "70aa012e-fef9-59af-8957-7d698937f537", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "2e3cfef4-fac0-5942-9361-f1321fc394b3", "2b8f1988-37a8-5fc1-b6c3-40b70dd2867f", "d4f2933e-e3ec-5035-bb6c-90041be7751c", "d95266e3-9e89-592a-b1fe-b55d3279249d", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "01d0de9d-f910-5674-841b-39ed4688eed7"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method for which the BLEU-1 score is missing in the table. What specific performance gain does the model proposed in the paper achieve on the Google-CC dataset compared to the CC-12M model?", "reference_answer": "3.2"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.08223/result_table.png"]}
{"uuid": "75c3038f-dea3-529a-9c06-825f0ce33f9f", "question": "Consider the paper that introduces the method that is placed directly above the PHA method in the table. What specific advantage does the HyperDecoder approach offer for handling long-context out-of-domain datasets in MRQA compared to a simple linear classifier?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is placed directly above the PHA method in the table. What specific advantage does the HyperDecoder approach offer for handling long-context out-of-domain datasets in MRQA compared to a simple linear classifier?", "reference_answer": "The Hyperdecoder approach offers the specific advantage of generating unique decoder layers for every input into a model, which allows for more flexible adaptation to long-context out-of-domain datasets in MRQA by leveraging similarities between samples across datasets and avoiding potential interference within the same dataset."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "75c7bfb3-f115-50ba-9a45-3c6efbccd6f9", "question": "Consider the paper that introduces the dataset which has a training set size of 8,844. What specific linguistic phenomenon is used in the model proposed in the paper as an example to illustrate the challenge of detecting hate speech when comments use phrases that only make sense when read backwards?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has a training set size of 8,844. What specific linguistic phenomenon is used in the model proposed in the paper as an example to illustrate the challenge of detecting hate speech when comments use phrases that only make sense when read backwards?", "reference_answer": "Puns"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "75f1d2de-3f75-5653-acfb-45f12d8a7bef", "question": "Consider the paper that introduces the model that is in the second-to-last row of the table. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that is in the second-to-last row of the table. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "794c9915-af63-5672-aa26-b971d2f63a25", "question": "Consider the paper that introduces the dataset located at the bottom left of the figure. What specific method did the authors identify as competitive or even superior to Language Adaptive Fine-Tuning (LAFT) for Nigerian languages, particularly for Nigerian Pidgin (pcm)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset located at the bottom left of the figure. What specific method did the authors identify as competitive or even superior to Language Adaptive Fine-Tuning (LAFT) for Nigerian languages, particularly for Nigerian Pidgin (pcm)?", "reference_answer": "AfriBERTa"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "7a3ba065-04c6-5193-b6db-c68fdfa39766", "question": "Consider the paper that introduces the method that results in a score of 22.4 in the GSM8K dataset. What specific dynamic programming algorithm does the paper tweak for aligning the tokenizers between GPT and T5 models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that results in a score of 22.4 in the GSM8K dataset. What specific dynamic programming algorithm does the paper tweak for aligning the tokenizers between GPT and T5 models?", "reference_answer": "Needleman–Wunsch algorithm"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "7a7d05e5-2ada-552a-adf8-e056d5e72389", "question": "Consider the paper that introduces the model that has an overall average score of 45.68 in Previous Image-free Systems. How does its performance with hallucinated visual tokens (\\texttt{V}) compare to using ground-truth visual representations (\\texttt{VM}) on the Multi30K dataset for the Transformer-Tiny model in terms of BLEU score?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["c653b597-b831-535e-bdb1-af03d3f3f1e7"], "reference_pdf": ["dd2f2eae-81f5-5525-971f-5540dde42f6c", "fffd1c97-f03e-5210-8dce-f0eb709b9199", "f1ea3e20-3942-5edd-9c70-f73b10f2da1e", "40d27262-e113-523f-9533-3ee949bdfb05", "c89e402d-2dd4-57dc-883b-be5c04e54b3a", "ad354a8b-1b60-517d-a7fa-d22b435b7f8f", "5052872f-0692-5df0-b02c-ce0f895d539b", "f17feaa7-e8e8-5559-9cf7-fd4b153b811c", "a0c50dc5-15b6-5924-bb70-08d2617f583f", "7821eda8-5710-57df-96c4-89cf30bf7a77", "884e57aa-78e0-5621-958c-8681a2d6f61f", "3b8af772-96a1-578e-a3de-272d2cb9ad7f", "5b08577d-f73f-56d5-be75-931a10239a0d", "f0266918-92ed-5f40-8bd8-499d2979a4e4", "d38dfa65-c493-5cc7-a20d-a01897d7fdc2", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "88185cdb-ff85-5600-bbcb-5bb65ecd6665", "5671a75b-4bcf-5446-82c0-481b1cd418f2", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "e26e48f8-0721-56f6-89dd-9e96448a75c5", "67c0b261-9f6d-50ac-b824-816f48441fa8", "ef1fd71c-6764-5364-8f8f-18d147a69e6d", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "9d24c743-9966-5400-a5f9-6825eca1d557", "0ce272f4-2ce0-5e5a-8889-2dac88f783a4", "4b2861dc-27c5-57f4-8e01-b018654b3e25", "d7894a4b-2b2f-5355-8193-5c68ffd30928", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "0e854ebb-88e7-55c4-952b-818ce54bc014", "d9b0f39f-60aa-53f3-8382-532440370fdf", "ac65b094-5a2c-5ab7-8497-a3cd526fa8ca", "dfac74e2-051a-5a1f-98fc-d5497a48f44b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has an overall average score of 45.68 in Previous Image-free Systems. How does its performance with hallucinated visual tokens (\\texttt{V}) compare to using ground-truth visual representations (\\texttt{VM}) on the Multi30K dataset for the Transformer-Tiny model in terms of BLEU score?", "reference_answer": "Very similar"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13361/result_table.png"]}
{"uuid": "7b2320f3-1298-53ce-8d70-b8737964bc9a", "question": "Consider the paper that introduces the model which exhibits the highest score on the BC5CDR (Big Dict) and BC5CDR (Small Dict) datasets. What was its MNLI Dev set result in the ablation study when using a 100% 'Mask' strategy without incorporating any 'Same' or 'Rnd' strategies?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["eff6094c-a576-5ec6-afae-8313bcf6d538"], "reference_pdf": ["1690c4b3-e4f2-5b00-9eff-84221fa7f0ab", "1f5110f9-63db-5e8e-adef-c2f33b58c5ab", "404bcd7c-20d3-5290-aad4-e056e19d16c1", "8714d81d-6d1e-5732-ac3e-029f7f8ce347", "8860e51f-7c25-5d5c-b0ba-b3726371476c", "a090084d-4a93-5bd5-b857-8b6d674e99a8", "357ce269-1acb-5dec-95f1-33073aa86b0b", "11a21829-d857-5f65-8038-ee3c761ef026", "2697ec60-b994-5ce0-9c67-06ecde1dc5de", "5d8db771-2bdf-5acb-88ec-9572ecc4187b", "bdcbede8-4961-585e-8744-c8c825dd1719", "62b009dd-f233-5060-b1f9-3b23b42dfc2b", "6ea6e60a-4178-50f1-b755-3955a84a9b07", "7c2317c6-aa9d-5ccf-96b6-01037899dd5b", "e488eded-0ba4-58ca-ad26-53799d8e9393", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "7c70448c-cb61-54ea-a9d9-d7ecc5477ba2", "274a4c1b-05a9-54c1-b0eb-24791f11be74", "a2d0d4b5-9596-52df-9c19-667c871cd76f", "558c9b7e-3b09-5823-995f-c881438116a3", "c88a9f90-9a50-5ab9-b5b1-42982d8e7cc7", "9e0baaab-f75d-5b52-b965-a5b427196392", "1de0052f-f719-5c9b-8f53-7df3e9379a0d", "cb64ebe5-e66a-5777-8fe6-7538ffadb7c2", "09db8b38-eab6-58d5-a08b-643db0b5e543", "eee65441-957d-5caa-a5e1-e063d3b1526f", "207e9d08-6c41-5a36-979e-05b3dca39eb3", "8639620d-31d1-5510-bf3f-2cedcfa80b1e", "ffdb65b1-741c-5b1f-8468-2f3601aa347f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model which exhibits the highest score on the BC5CDR (Big Dict) and BC5CDR (Small Dict) datasets. What was its MNLI Dev set result in the ablation study when using a 100% 'Mask' strategy without incorporating any 'Same' or 'Rnd' strategies?", "reference_answer": "84.3"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08298/overall_performance.png"]}
{"uuid": "7b238f97-b5b7-581f-ba5d-590d40adbcaa", "question": "Consider the paper that introduces the method which exhibits the highest accuracy on the VQA-v2 task. How does the model's performance on the visual question answering (VQA) task compare when using images of resolution 480x480 versus 640x640 during finetuning?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which exhibits the highest accuracy on the VQA-v2 task. How does the model's performance on the visual question answering (VQA) task compare when using images of resolution 480x480 versus 640x640 during finetuning?", "reference_answer": "An improvement"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "7b7d796f-c3bc-5181-a158-45e243d51d95", "question": "Consider the paper that introduces the method that has an average score of 82.8 with zero-shot prompting. What specific adaptation in the text embeddings allows the model proposed in the paper to build correspondence among query text, label text, and objects in grounding tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["2479f89b-b7c0-534f-b51d-d24093d3a1f9"], "reference_pdf": ["7aacee49-58db-593f-9a47-44846ba2ed23", "881f50d7-f0cf-59e7-8351-429ea3655e0b", "57c06ca1-608a-5816-86dd-0f35be577ce0", "1165b8f0-4261-5c50-9583-bfc199324e61", "1c848190-6829-5b07-a439-3452fd19617b", "ea8d0d91-a08c-547f-aa61-fc136ce41e58", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "003269db-f43b-57bc-a219-825c655fab01", "16e73621-a0c1-5f1d-ae72-fa60befecf05", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "b31b84cd-d7c7-50d1-9dc2-cb340ea4d218", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "a76fdb50-d95e-5db2-83a6-ece16257796b", "e0523cf0-8310-565e-9d91-c539c15adcb7", "be395337-c3e2-5e16-b2ef-1ed22e6736dd", "729f79df-1057-5418-89cd-592408770592", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "1e0413f9-466d-57a0-be12-cbfb9da4056a", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "8f02441e-aa43-5abf-bd9b-cfd760b7cc20", "e5c8fae9-734a-54d1-bde4-03ec07d10c86", "b5798106-2737-52fa-b1e5-010749d19c2c", "6677d3c0-7aea-5795-a934-d93933e25157", "02cf0294-1961-54c5-a745-0d99126e65d3", "c76b968a-995a-5109-a4eb-f329fa710f26", "de0470bf-d650-5f5c-9fb8-926b7ed2c806", "65c601c1-c571-5d9e-aa32-e37fcc3e0097", "445e9197-1321-57c3-93bf-7084e795848d", "da29dae2-1a88-5793-8149-81c0b63122ca", "02193a94-398e-57da-bb53-0c5800ca743a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an average score of 82.8 with zero-shot prompting. What specific adaptation in the text embeddings allows the model proposed in the paper to build correspondence among query text, label text, and objects in grounding tasks?", "reference_answer": "Embedding sharing"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15746/comparison_table.png"]}
{"uuid": "7b7d7d69-7a52-5bd5-a223-9e35b146d167", "question": "Consider the paper that introduces the model which has a lower mean classification accuracy than VIBE but higher mean classification accuracy than UDALM on the Stance dataset. What is the Pearson's r correlation coefficient between word overlap and the performance of DPT for the task of AI venue classification?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model which has a lower mean classification accuracy than VIBE but higher mean classification accuracy than UDALM on the Stance dataset. What is the Pearson's r correlation coefficient between word overlap and the performance of DPT for the task of AI venue classification?", "reference_answer": "0.9303959931770183"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "7c530ede-49f8-575f-a446-5674f6c7ac5a", "question": "Consider the paper that introduces the method that corresponds to the penultimate row of the table. Which specific scheme achieved the highest micro F1 score in the 1-shot setting for the CoNLL'03 dataset in the contextual label representations experiment?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["debf097e-fb5e-52e6-ba62-bf1714b5ccec"], "reference_pdf": ["9441027e-e7d4-59d3-8377-3e68c3f8d6d5", "8860e51f-7c25-5d5c-b0ba-b3726371476c", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "dca70611-4c00-5e95-960e-f6c42eabfd2e", "47d497a4-55b6-5cc1-8d54-2ba8244156c6", "2925c847-385a-5175-a215-e2e46465d755", "bc1c15b7-674b-5686-b3e5-59a4745eefd7", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "8f9d03a3-9cf4-5e26-a59f-6abb1b6eb278", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "a0894fa0-47f3-55ac-9405-9e0652f7a695", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the penultimate row of the table. Which specific scheme achieved the highest micro F1 score in the 1-shot setting for the CoNLL'03 dataset in the contextual label representations experiment?", "reference_answer": "(BIO-TAG) LABEL"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11715/few-shot_NER_table.png"]}
{"uuid": "7c7cfa79-e373-5b0d-9661-f91cea6eb7e2", "question": "Consider the paper that introduces the method for which a certain benchmark results in the highest execution accuracy. What specific approach does the model proposed in the paper employ to minimize the SQL annotation error rate, and how does it ensure the selection of semantically equivalent and efficient SQL as ground truth?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["ba614015-ae38-5939-8106-728d33b07d78"], "reference_pdf": ["b16e8b8f-0d45-58db-b7ec-72837add121d", "befe32c2-c0d6-520c-b7df-ddfcfeb79028", "a0ce147c-98bf-52ba-8365-84983999c80a", "6103a65c-dea4-59ae-bcc4-5f7420478289", "a87515b4-ac31-5ecb-a261-cc3c8d5f4c8b", "0b9362a1-e422-5331-a3ec-a8abc9c8c249", "8ff266a0-ac5b-543b-b908-bdea848acd2d", "79c6d4f0-99c6-5051-bc74-19bc136089f4", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "73172932-ae8b-5d7d-bee0-6bc34aea20e7", "d135e939-c86d-56a7-8840-c346de4706f9", "1d0dae01-2fe3-5971-86b2-965007cceb0c", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "45fbbb5f-4e5d-52b2-8956-84eedc7cba9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method for which a certain benchmark results in the highest execution accuracy. What specific approach does the model proposed in the paper employ to minimize the SQL annotation error rate, and how does it ensure the selection of semantically equivalent and efficient SQL as ground truth?", "reference_answer": "The \\textsc{Bird} benchmark employs a double-blind annotation approach to minimize the SQL annotation error rate. This approach involves two independent SQL annotators generating SQLs for the same question without discussion. SQLs yielding identical results are collected, and those with discrepancies are reviewed by experts until a consensus is reached. This method dramatically reduces the SQL annotation error rate by ensuring a low probability for two skilled annotators to generate the same incorrect results when databases have large values. To ensure the selection of semantically equivalent and efficient SQL as ground truth, the more semantic-equivalent and efficient SQL selected by experts for each question is picked as ground truth SQL in \\textsc{Bird}. Additionally, external knowledge evidence sentences are recorded for each SQL if utilized, enhancing the model's comprehension of database values and promoting the generation of efficient SQL queries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18538/result_table.png"]}
{"uuid": "7c9beaa4-cd10-56a8-85ff-61b2f75d3156", "question": "Consider the paper that introduces the model represented by a blue line in the figure. Which specific architectural feature allows it to efficiently handle the full context in a computationally efficient manner?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented by a blue line in the figure. Which specific architectural feature allows it to efficiently handle the full context in a computationally efficient manner?", "reference_answer": "multi-layer self-attentive mechanism"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "7cbbf234-6d0c-5077-98bc-aa4f44903b22", "question": "Consider the paper that introduces the model that has a macro-F1 score of 27.34. What specific aspect of its pre-training process distinguishes the model's adaptation for the legal domain from the adaptation strategies of BERT models in other specialized domains, as discussed in previous studies?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5d7df310-479d-5fea-aedd-572cdb181b5d"], "reference_pdf": ["5c12db52-9752-56ab-ade8-f9e6e1c9f1e5", "9a106ec5-136d-5944-896b-78f122e41d78", "606bc274-d6e5-5e9a-8c7e-68c4e47e038c", "1831f50a-3d4e-54eb-9a1e-18eaaa4cf019", "46c0d816-f49b-5890-b64f-5ff9e7ee016b", "f0e5dee8-1409-5d41-9e15-e42bbe9c54ce", "9e48134a-b4b2-5c38-8f21-4cd55adbcb17", "0caf6da7-1ec5-5f0e-9e6a-655f574d2bf5", "64ee757d-3fab-5132-aadf-376825399f6b", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "dbe6cf51-ba01-5f0d-83b3-e29f71bafbf1", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "d3f113b1-43ab-55f2-bc01-e3ff9a22ad13"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a macro-F1 score of 27.34. What specific aspect of its pre-training process distinguishes the model's adaptation for the legal domain from the adaptation strategies of BERT models in other specialized domains, as discussed in previous studies?", "reference_answer": "Pre-training BERT from scratch on domain-specific corpora with a new vocabulary of sub-word units."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11368/comparison_table.png"]}
{"uuid": "7d135439-7113-5f96-9bf7-3aa444585f09", "question": "Consider the paper that introduces the dataset in the table that has the fewest dialogues. What specific advantage does the curriculum learning strategy offer for the model's performance on low-resource languages according to the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b7315180-e811-5a4a-882f-d4a8e0ffe866"], "reference_pdf": ["25905c58-6108-5577-b948-fbaa6aa23e6e", "7d06b7cd-d351-5e13-a0d1-d72ac792b3e7", "b846c66a-a177-5119-af8d-ec4757d6a06c", "2ee103a7-04e2-53fe-83fe-da3bee6579f6", "42c5c7c9-6099-53c2-8868-147e11467288", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "f92811a6-b9ce-519e-9346-f3b892d7f535", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "70d90498-b24e-5af4-84e5-c40377652bce", "01c9329e-9789-52dc-9eed-c99a8ef88a5c"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has the fewest dialogues. What specific advantage does the curriculum learning strategy offer for the model's performance on low-resource languages according to the paper?", "reference_answer": "The curriculum learning strategy enables the transfer of general knowledge from English to other languages, leading to significant improvements in overall performance on low-resource languages."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2402.04588/comparison_table.png"]}
{"uuid": "7d212822-a533-54df-bebc-eab6d3824762", "question": "Consider the paper that introduces the dataset represented by the smallest blue circle. What specific method did the authors find to be competitive or even superior to Language Adaptive Fine-Tuning (LAFT) for Nigerian languages, particularly for Nigerian Pidgin (pcm)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset represented by the smallest blue circle. What specific method did the authors find to be competitive or even superior to Language Adaptive Fine-Tuning (LAFT) for Nigerian languages, particularly for Nigerian Pidgin (pcm)?", "reference_answer": "AfriBERTa"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "7d73496e-e554-5f75-9751-3d2d082f9c4f", "question": "Consider the paper that introduces the method that has a lower J_k score than Random Entity Quantization but a higher J_k score than NodePiece in the FB15k-237 dataset for all values of k between 400 and 1000. How is the initial representation for non-reserved entities generated in the model's entity-agnostic encoding process before being input into the GNN?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower J_k score than Random Entity Quantization but a higher J_k score than NodePiece in the FB15k-237 dataset for all values of k between 400 and 1000. How is the initial representation for non-reserved entities generated in the model's entity-agnostic encoding process before being input into the GNN?", "reference_answer": "For non-reserved entities, their initial representation before being input into the GNN is generated by combining the encoded connected relation information (\\(\\mathbf{h}_{e}^{\\rm c}\\)) and the encoded \\(k\\)-nearest reserved entity information (\\(\\mathbf{h}_{e}^{\\rm k}\\)) through a 2-layer MLP (\\(f_{m}\\)), as described in Equation (\\ref{eq:info-combine})."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_2_comparison_figure.png"]}
{"uuid": "7d82ebb2-c272-5fa1-ae9b-b6510a8a5516", "question": "Consider the paper that introduces the model in the LLM section of the table that corresponds to the highest test accuracy. Why does the model proposed in the paper using beam search to decode each reasoning path result in worse performance compared to sampling?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the LLM section of the table that corresponds to the highest test accuracy. Why does the model proposed in the paper using beam search to decode each reasoning path result in worse performance compared to sampling?", "reference_answer": "Beam search tends to produce a lower diversity in the outputs, which is less effective for tasks that benefit from exploring a diverse set of reasoning paths."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "7d974f68-d2ad-56bf-a3ef-539a1c48d80e", "question": "Consider the paper that introduces the method that results in a token-level F1 score equal to 37.03. What specific configuration led to the best performance in the WikiHop development set ablation study for the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["79a856b0-ea50-5dad-b4a1-f0f0c8e17443"], "reference_pdf": ["8ad564f3-f634-5b41-9dbb-c7b55efd34ed", "4774dafb-8266-57ac-ba3b-3fb7302f43e8", "e544d7c3-0ea0-5f06-accd-9044fb2df8ce", "2ad75cc6-aa85-532e-a8cc-d487ad70ac1d", "8ac0dc8f-2cdc-5363-ab17-2cbe2cd98611", "7913138b-027d-5e7a-a4f9-c94fa676607b", "501de3a1-2bdc-5bea-9259-4731a2df35ab", "68be5d29-f16d-506f-a4e5-215438f13409", "9dab5ed2-4f76-52b3-b13a-ee7c9342d254", "64ee757d-3fab-5132-aadf-376825399f6b", "a672b5e1-0460-5bcf-9f96-189e0687079d", "19037637-5fca-5021-a9c2-464b3eaf7fb1", "167219f2-ecf4-59b5-8ea1-cdcb400400b2", "7eb3a633-8d11-5b91-af60-4030ff538882", "aefc8eb9-7238-561a-8055-858362dc6a0c", "3157ccdb-a5d3-5ddb-93af-99dcbba44f15", "f9ea4f73-3191-5d9c-8121-e490cc81af65", "2e88d873-bc67-51d3-a17e-8eda7c844dd6", "79c58b97-75e2-590f-ab73-90c71c7af2a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "4fd8fdc1-1bd4-58dd-9c4e-0659d9c11ee4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "167219f2-ecf4-59b5-8ea1-cdcb400400b2"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that results in a token-level F1 score equal to 37.03. What specific configuration led to the best performance in the WikiHop development set ablation study for the model proposed in the paper?", "reference_answer": "seqlen: 4,096, 15 epochs"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18544/result_table.png"]}
{"uuid": "7ed7dd37-a45b-5e25-8b38-0929c0081488", "question": "Consider the paper that introduces the method that is represented by the purple line. How does the model proposed in the paper ensure that all attention heads do not deviate significantly in their reading speeds during training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is represented by the purple line. How does the model proposed in the paper ensure that all attention heads do not deviate significantly in their reading speeds during training?", "reference_answer": "The MMA model ensures that all attention heads do not deviate significantly in their reading speeds during training by introducing a head divergence loss, which is the average variance of expected delays at each step. This loss function encourages the attention heads to maintain similar positions, preventing the latency from being dominated by a single or a few heads."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "7f9ee291-d248-5f3d-917b-13413f13b2c1", "question": "Consider the paper that introduces the model that performs the best on the BBBP dataset. What is the exact improvement in ROC-AUC score for the ClinTox dataset achieved by the model proposed in the paper over GEM?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["75156ea6-7402-5a33-9303-ec6f543e9999"], "reference_pdf": ["7aa1a28a-1256-5732-9581-f2538bfcaf8e", "adf24566-930f-5a42-8118-6aeb65e4f6f4", "825de5ef-3ab4-5629-9fc4-4b0805f419b8", "a1002509-bd90-5cde-9fd2-7b6216144d71", "653e5d86-f991-5533-bd83-a5d95f760b18", "aa22dd10-f8dc-5b74-893f-4f3b21431f24", "766ea9a1-a447-5963-a71f-c9d0a0562d57", "7ea7979f-d2cf-58e4-b00e-2b4027aaf436", "a2401db7-a8bd-588a-856c-4d9ad4f85409", "3a2ae924-5f60-5905-abab-631f660f7bb6", "54fbf9e2-28d0-54ce-ba51-27f90b206c6e", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "3b7baa1d-606b-5481-9c27-fec60e4c7533", "6d068e18-8fb7-5dff-b0bf-b95297a79dc5", "7908763f-3a9d-5ce5-af59-f68888750583", "4ef708b0-51b3-5527-91fc-a55d70b49671", "e2b71dfc-0678-5451-82f6-42650b5ca0dc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "05397506-c619-548a-9f1f-18f85acc151e", "cf69528e-9892-5b27-ab66-0b66a1304268", "a2677b99-9e0d-5c14-8e19-f1c7d5cfa93f", "7908763f-3a9d-5ce5-af59-f68888750583", "7d25556e-bc5e-58ba-b1d8-294c67ed7d98", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6fd2a9e7-7fea-5866-b0c4-120b7cc5baae", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "d97c36ef-e3d9-5f53-a6ff-00d5ee2f2777", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "d4f91c73-f4cf-5209-bec5-6ff66eb29d19", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "5161fb60-4394-5446-9e6e-ce1f1e9e393a", "1777f12e-991e-52d4-8b6b-03807d589e87", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "964db907-da57-5f8b-b1ef-1054c077ca89", "4a697112-1b30-569a-8fee-c4eace04cb3f", "33130f85-57c8-54d5-b050-075bb1ccab97"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that performs the best on the BBBP dataset. What is the exact improvement in ROC-AUC score for the ClinTox dataset achieved by the model proposed in the paper over GEM?", "reference_answer": "5.2"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07276/performance_table.png"]}
{"uuid": "8080cca7-19ef-55b7-9285-e1a703a9a38c", "question": "Consider the paper that introduces the benchmark that has a higher 'Generation Token Length' than ShareGPT and GSM8k. What specific improvement does CoT prompting provide over answer-only prompting for the Codex model on the 'Tracking Shuffled Objects' task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark that has a higher 'Generation Token Length' than ShareGPT and GSM8k. What specific improvement does CoT prompting provide over answer-only prompting for the Codex model on the 'Tracking Shuffled Objects' task?", "reference_answer": "CoT prompting enables a significant improvement in performance on the 'Tracking Shuffled Objects' task, with a gain of +28.5% accuracy over answer-only prompting for the Codex model."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "8171282e-ccff-5700-8a2f-17a0b30166e4", "question": "Consider the paper that introduces the last method shown in Explicit --> Memory-enhanced --> Feedback or Corrections category. What specific performance metric does the model proposed in the paper achieve on multi-hop questions in the {\\dscf} dataset when using GPT-3 as the base model, considering instances where all associated edited facts are successfully retrieved from memory?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the last method shown in Explicit --> Memory-enhanced --> Feedback or Corrections category. What specific performance metric does the model proposed in the paper achieve on multi-hop questions in the {\\dscf} dataset when using GPT-3 as the base model, considering instances where all associated edited facts are successfully retrieved from memory?", "reference_answer": "73.1%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "825ba676-52c2-51be-b87c-d92f8650d49a", "question": "Consider the paper that introduces the method that is represented by the square marker. What specific mechanism does its variant, referred to as the model proposed in the paper, use to calculate the expected attention for each head?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is represented by the square marker. What specific mechanism does its variant, referred to as the model proposed in the paper, use to calculate the expected attention for each head?", "reference_answer": "The MMA-IL variant calculates the expected attention for each head by first calculating the softmax energy for each head as follows: \\(u_{i,j}^{l, h} = \\textrm{SoftEnergy} = \\left(\\frac{m_{j}\\hat{W}_{l,h}^K(s_{i-1}\\hat{W}_{l,h}^Q)^T}{{\\sqrt{d_k}}}\\right)_{i,j}\\) and then using Equation \\(\\beta_{i,j} = \\sum_{k=j}^{|\\vx|} \\left( \\frac{\\alpha_{i, k} \\exp(u_{i,j})}{\\sum_{l=1}^k  \\exp(u_{i,l})} \\right)\\) to calculate the expected attention."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "8275ba98-0565-5e18-9e83-5febb30766ef", "question": "Consider the paper that introduces the model in the table that corresponds to a 12.79% TP. What specific computational advantage does it have over VinVL and ${\\cal M}^2$ Transformer in terms of feature extraction inference time, and how is this achieved?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["9906dc9c-eae7-5352-82ca-533b23d498a1"], "reference_pdf": ["f2c45532-0d1d-52f3-8293-a28562dca0c2", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "a9e9314b-4cc2-58e5-bbbd-e0908b71d865", "120aa43e-5a6b-5fc6-9e11-fecd0d3ca36e", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "411227b7-53f4-546d-9c14-70bf07f74473", "1b95bbb6-5c74-52f2-8c79-8fa03ff4879c", "cbb30373-01f6-5707-81b7-fd36a3e42c87", "d4223ac7-9d75-531d-9113-b52397da2e1e", "aa4f0205-fd37-5154-9b71-ce252dccab5c", "4a87a9d9-1977-5796-b15b-18eeb2537ea3", "884e57aa-78e0-5621-958c-8681a2d6f61f", "b95e3586-0087-5079-8c32-66506a0ba806", "c3e48be8-b991-5cfe-bd59-05d2496a094d", "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1", "e4ad4c66-c12f-5367-a923-7342a3a48ac0", "19b4c2c4-42f6-595f-8a56-13b3d241ee6d", "d62a70d3-39eb-57b2-854c-06ae086c4b84", "eb335bea-aa4d-5fb1-9e60-189c2f979d4f", "45decdf4-f524-52d5-8385-3da8d839888b", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "a039db49-aed3-57e6-8720-913aaac61942", "51e5bebd-9870-5529-875f-710339447ecb", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "95c63efc-ff02-585d-bcdf-75e933c5816a", "9baa42c9-b79b-5654-85d3-860ee3241d5e", "c466be66-c99c-5dcd-90a5-5b86d4a6638a", "a229d47a-0069-5d45-8bac-7e5eb2e8b8d1", "0b363526-f924-5baa-be50-c665bd10cb5b", "fa4b52f4-0a73-5305-bf28-adee87c842ec", "72e031f9-130a-5dd0-9f2c-bb29e197a8c2", "14028d43-a37a-52d4-8869-f174ff05ca4c", "d88358e9-efe9-5844-8bfa-b1d3ed22ce82", "45b99aad-66f7-5bc9-a6ef-cc7eb8d66567", "ded8818d-5039-5cc2-b3c7-9f4908153210", "4b918831-da2b-5123-8351-ffdf3abde7c2", "04873797-c04f-5d4b-bab4-fcace1b87c1b", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "5da677b6-dec7-57c9-afb4-5c1af7801b8c", "82a80b14-aa33-57ed-b666-c182235bc860", "5a09a7b9-bceb-58cc-a560-2845b8774e26", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "5fabde11-10a7-5fc8-a1b5-57a6237b5535", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e41d952a-d067-52a4-9fea-12aa78420924", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "b82c062d-e25e-560b-9fe8-47a56901fc74", "1ee90f2d-74b4-5c24-ade4-7608f608d42b", "a02bef04-a577-5433-8a32-7d3786ccfd02", "345e1ebc-c05b-59ea-9619-557ba7bc6e3c", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "0178ef4d-109b-512b-8194-c5debb2014b1", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd4cf2bd-a308-5ae4-8718-2eb04418d7e5", "5c347f12-43c5-57a5-832b-bcf310dfad98", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "ef55b6d8-d37c-5a62-95ca-83bd707306cd", "c5227d39-0b3c-5458-a976-982cdd8d4015", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "1c5aa016-c6ba-5928-87b6-b71a0c952504", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the table that corresponds to a 12.79% TP. What specific computational advantage does it have over VinVL and ${\\cal M}^2$ Transformer in terms of feature extraction inference time, and how is this achieved?", "reference_answer": "GRIT achieves a computational advantage over VinVL and ${\\cal M}^2$ Transformer in terms of feature extraction inference time by reducing it by a factor of 10 compared to the others. This is achieved by employing a DETR-based detector for extracting region features without using computationally expensive regional operations such as class-aware Non-Maximum Suppression (NMS) and Region of Interest (RoI) Align, which are used by the other methods."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.11523/comparison_table.png"]}
{"uuid": "830f182d-9120-52fd-beb4-920f6ffd3149", "question": "Consider the paper that introduces the method which corresponds to the penultimate row in the figure. How does the MSG^2 method ensure the prevention of cycles in the resulting subtask graph proposed by the paper, which could lead to a causality paradox?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["3d664c0a-c339-5327-ac7f-75649bdb338a"], "reference_pdf": ["60fc9153-9d1a-5c9a-ad54-c32d4ab08666", "4818eb61-00f6-5b9a-85c1-021bae7bedeb", "73efee7b-8ec3-56c9-be0c-24a85d109316", "250db219-8940-5f99-9c3a-cce7f8cc8aa8", "16bddbcb-697c-503c-954b-a7e97254d77b", "38ac12d2-26b3-54e0-977a-a396cc1bf1e8", "474fcd7e-fef4-580f-8333-abe02fe9d592", "0716e9d6-0d10-58ca-9afe-76d199106155", "63266047-43b6-5c01-866f-9ed6680939a5", "fa248633-ed2a-5eff-b162-4f28be7b7035", "a06173ea-6789-5ed2-b47b-5048b973ff05", "d1480712-bbfd-569d-b6b5-65ad6aede816", "874df9a4-8882-5470-b472-583f4db25491", "7c5d604c-1932-5a29-af78-55afa1b08aad", "d75cb6f3-13fd-5cf3-b918-afcc2ec09c8e", "4619e153-2d35-52e3-837e-87503e05d70e", "82a4e164-ad3d-57b2-88b5-09376594126d", "a4590e5a-0ff0-5af7-8c22-a67d6a04148c", "7da92b77-adad-501d-908d-7567c57dca50", "77d20de3-ab1b-516d-ba65-ebd1b33ee6f9", "c92baf87-5abf-5c8a-b425-ce9c4f42eb34", "27bb462f-a64d-572a-8061-e56203f7d0af", "3e132e47-5f94-5714-8418-b99db20dbfc1", "3ee4ec6d-b23b-56dd-a29a-4907d2cc9865"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which corresponds to the penultimate row in the figure. How does the MSG^2 method ensure the prevention of cycles in the resulting subtask graph proposed by the paper, which could lead to a causality paradox?", "reference_answer": "By performing precondition inference in a layer-wise fashion."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04668/comparison_table.png"]}
{"uuid": "83a8140c-bc8c-51d4-a0cf-dff9ae826891", "question": "Consider the paper that introduces the method that scores a 70.1 in the 'Revised Persona' column. What is the primary reason for the performance drop when the hyperparameter gamma is set to 1 in the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["26feec2d-e6df-532b-9f63-ab9b73e8266f"], "reference_pdf": ["8b28a50c-b93f-5426-adbf-c8a139d518de", "c02fd012-1287-5268-94e6-aaae4ee61dda", "686c19e6-39d7-5bb4-a324-ba2bd5c26db2", "c260bf67-2731-5445-96eb-94baa3e5f834", "51e05e32-8367-58b9-b753-6c6a6c1d665a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "60105831-0210-599b-a410-f12e2df3cffc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "0e0746e6-8044-5c49-b46e-0a66569438a8", "e2a2d7b1-a02c-58e5-8d14-272810335de1", "7908763f-3a9d-5ce5-af59-f68888750583", "c5833e1d-8813-56da-99d1-bf61d9ac33df", "5d474441-0098-5521-b6d2-4219837f18c9", "3134099b-d3ac-56d3-898d-c77c7a99370e", "311f9316-6c35-5c33-b61a-f25d90866412", "c76b968a-995a-5109-a4eb-f329fa710f26", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "da510970-00ea-5853-a68c-9741c0d1fd4d", "81de543a-91c2-5035-9617-724abb93a839", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "206abdf4-f071-58ab-8bd6-206bb79786f1", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "d3344458-d106-52ed-be5c-505f8b07af06", "b4ce79f8-4a56-5bb4-b15c-13fee270a57d", "cbb28401-7af5-577d-b36c-a50a87e88b96", "27810986-0584-5a03-9944-a70637604b0f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that scores a 70.1 in the 'Revised Persona' column. What is the primary reason for the performance drop when the hyperparameter gamma is set to 1 in the model proposed in the paper?", "reference_answer": "The primary reason for the performance drop when the hyperparameter gamma is set to 1 in the CSN model is that it results in no document content being selected, effectively degenerating the model to non-document-grounded response selection, which sharply decreases performance."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06390/result_table.png"]}
{"uuid": "842046a6-54c0-5f8d-bc6c-01a5d82c12e5", "question": "Consider the paper that introduces the method which has 11.0 rounds to completion. What is the effect of using a death mask on the model's performance in the SMAC domain compared to ignoring states in which an agent is dead when computing GAE?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["db2cacba-a6d6-5de3-8b45-95a4a07883c3"], "reference_pdf": ["8de6d12b-9dcd-5a37-aaf6-c9295ce1e8a9", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "74746a87-dab3-59c9-be08-3ecfcf6438eb", "3141fa52-db69-539c-8979-fbae34e9747a", "02193a94-398e-57da-bb53-0c5800ca743a", "fbe2cad7-8871-57e9-99a5-041bd72a96d1", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "3b56c40b-e3c0-5ab0-8303-818cadcbfd0b", "95286e49-8ec0-51d4-b4af-8a0cb4b59b63", "feb416bd-1fd2-59c4-b5e3-5cd152775a17", "56bb5074-0a00-578b-ad44-e24096458b1e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "a84ef890-5c36-506a-b8ea-79837d85ae3b", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "446b417e-0e23-5098-afe3-0790a06ab23e", "25b64ade-68d0-5d1f-a552-4169ec42054f", "d22f49c8-5ad1-5151-adaa-41d9c94fdbc0", "118cac21-d91b-55b6-bfce-0742348b4c2d", "79a7862f-22dd-56b1-affd-42f774cf64fb", "172b7dad-d436-5ced-9eb4-0f5702d227b2", "dd21cb7c-5752-5764-b486-bbf8f2e53f84", "177b1aea-89bc-52c2-bf91-6f27f1964f71", "34ef8fe5-e5a0-5401-8a39-e8944a3ea356"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has 11.0 rounds to completion. What is the effect of using a death mask on the model's performance in the SMAC domain compared to ignoring states in which an agent is dead when computing GAE?", "reference_answer": "Using a death mask on MAPPO's performance in the SMAC domain compared to ignoring states in which an agent is dead when computing GAE significantly improves the final performance and stability of MAPPO."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10701/result_table.png"]}
{"uuid": "843fdcce-c0f7-58cf-9080-9405fe1f92aa", "question": "Consider the paper that introduces the method that is in the last row of the Full Training category. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the last row of the Full Training category. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by this method?", "reference_answer": "0.949"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "8485bc93-aae7-5f49-8f00-11ffbc376fe9", "question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. What is the erroneous output fraction for the model proposed in the paper when tested on the QMSum dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4db47b23-f7bf-5d2e-a957-279ddcc3310c"], "reference_pdf": ["56f3aaed-b2b7-5df1-97cc-7cf6236a892f", "fa9a9ad6-66e9-5bd8-b1a2-862836bceb4b", "c3a61f79-d156-54a9-9888-813475b4d3d1", "0015561a-99bb-5b95-b457-3e43c7751331", "0d601b2e-069f-5bab-ae99-f37eb696b06a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9d2e017c-b25e-5cbc-8493-ccb4d9ab7443", "bcf8872a-b92d-5cbe-8be5-350bcf7d5e15", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "ca40df32-58b7-52fe-b2b5-458f848e4210", "4e513417-bbb2-55e1-b572-ec68a60fc6be", "64ee757d-3fab-5132-aadf-376825399f6b", "edd36969-0b52-50f9-b08c-9b0ba9e514e7", "502590c0-bb29-53ab-8095-a2c68e3e42ab", "3134099b-d3ac-56d3-898d-c77c7a99370e", "1ddc4f93-70fd-5397-a6f3-ee8837ea208e", "afbe2f7a-2754-5da7-97f6-b56a58fe47a4", "eeda9a9d-5d4e-5579-9a3b-f2e546a7bf4b", "00dd4300-de92-5712-9ce8-ccdb844b6314", "3790e4a5-ff47-586a-b09c-c11ab395909d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "510d6fc0-d3e0-5dc1-8e0d-4d470f964287", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. What is the erroneous output fraction for the model proposed in the paper when tested on the QMSum dataset?", "reference_answer": "0"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11772/comparison_table.png"]}
{"uuid": "8758a4fa-49e1-5884-baa0-603e071a40a4", "question": "Consider the paper that introduces the method that has the highest score in the WQ-R task. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the highest score in the WQ-R task. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "reference_answer": "0.949"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "87ac5784-3415-58b4-b241-979fbda65b00", "question": "Consider the paper that introduces the model that scores an 84.2 in the 'T10' column. What specific hyperparameter values were determined through grid search for the FewRel dataset in its implementation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores an 84.2 in the 'T10' column. What specific hyperparameter values were determined through grid search for the FewRel dataset in its implementation?", "reference_answer": "$\\alpha=0.5$, $\\beta=0.5$, $\\tau_1=0.1$, $\\mu=0.5$, $\\omega=0.1$, $\\tau_2=0.5$, $\\gamma=1.25$, $\\lambda_1=0.5$, $\\lambda_2=1.1$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "888c2bfa-69c2-50ef-9068-3deb9a78e4b5", "question": "Consider the paper that introduces the model on the last line of the Seq2Seq/Tree block of the table. What specific methodological limitation does the paper acknowledge regarding the model's ability to incorporate commonsense knowledge, and how does it suggest addressing this limitation in future work?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model on the last line of the Seq2Seq/Tree block of the table. What specific methodological limitation does the paper acknowledge regarding the model's ability to incorporate commonsense knowledge, and how does it suggest addressing this limitation in future work?", "reference_answer": "The paper acknowledges the methodological limitation of the solver's inability to incorporate commonsense knowledge when such knowledge is not explicitly given in the problem description. It suggests addressing this limitation in future work by injecting commonsense knowledge into MWP solvers."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "894186e4-5665-50ac-8e7b-af30146a4f8b", "question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Knowledge Editing category. What specific configuration arguments are used in the proposed sampling algorithm to control the dynamics of query streams in the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Knowledge Editing category. What specific configuration arguments are used in the proposed sampling algorithm to control the dynamics of query streams in the model proposed in the paper?", "reference_answer": "$(\\alpha, \\beta, \\gamma)$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "89914d2e-d404-5a6c-82fd-26e6b20602d8", "question": "Consider the paper that introduces the method shown in the first row of the table. What specific aspect of the policy gradient strategy allows the model proposed in the paper, PromptPG, to outperform heuristic-based example selection strategies in the context of few-shot GPT-3?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the first row of the table. What specific aspect of the policy gradient strategy allows the model proposed in the paper, PromptPG, to outperform heuristic-based example selection strategies in the context of few-shot GPT-3?", "reference_answer": "The specific aspect of the policy gradient strategy that allows PromptPG to outperform heuristic-based example selection strategies in the context of few-shot GPT-3 is its ability to learn to select in-context examples from a small amount of training data dynamically, thereby constructing the optimal prompt for the test example. This approach significantly reduces the prediction variance compared to random selection and improves the selection of in-context examples over existing strategies."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "8abeff2d-cd4f-5cb0-9f01-3187c58ce2fe", "question": "Consider the paper that introduces the model represented by the orange bar. What specific achievement does the Vanilla Transformer model demonstrate over RNN sequence-to-sequence models in terms of performance on English constituency parsing when trained solely on the WSJ training set?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["6b729c10-15e8-5eaa-8b40-8c8eafbd3ddb"], "reference_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b", "e1e2bf66-bde7-58c0-98f6-6414d50c1311", "34417770-67d7-5cab-b9d4-76999c97bc02", "776bb6da-c5c2-5c73-b8ac-f038fc55bb6a", "9c9e036b-576a-5a70-923f-4d33da527760", "1cbc9c7a-e562-5d6a-af83-4f9a1520dce2", "ce99c350-ea64-53eb-b705-c33884619d64", "53504791-99de-5143-a351-a080bdcc3bc8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "696b4e72-71ad-5357-b60a-7cd5121619dc", "a4c0cf83-a1d0-57b1-84d9-9b7d365f5ad9", "9775a2f4-5880-5569-8cff-46fce5420bf0", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "2eaf2338-0cce-5f50-8917-338a927b7e1a", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "42fd3669-c60f-5d28-b51d-4523bebf0734", "24c55b93-968f-5a40-8520-acfd6229bde6", "ea02c473-42cb-5fbe-9287-aea0fa4a842e", "e5036d4f-b1eb-5a28-b5e0-4887f14183d2", "837e7fdc-f434-546f-9a83-81afc1529b90", "ff84e2fe-51c3-5208-8002-402a7d477b19", "94993d82-6d3b-5b04-b25f-13e33faf6822", "4fe1db4a-687c-55c3-b8c1-3c6ca2a8b302", "0ce323c7-bde8-560b-98c9-6c2c9b5cdf08", "47cbfa6b-6a2f-521e-a7e2-19a3c3460b47", "42fd3669-c60f-5d28-b51d-4523bebf0734"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented by the orange bar. What specific achievement does the Vanilla Transformer model demonstrate over RNN sequence-to-sequence models in terms of performance on English constituency parsing when trained solely on the WSJ training set?", "reference_answer": "Outperforms the BerkeleyParser"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15040/accuracy_figure.png"]}
{"uuid": "8ae5c6ef-316d-59c0-9843-9696b7aa5823", "question": "Consider the paper that introduces the dataset which exhibits the highest accuracy for Method 2. What specific aspect of the token-level verifiers' training procedure in the model proposed by the paper is likely responsible for their initial uncertainty in solution correctness, as observed in the verifier visualization section?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa7d95d4-dd69-5849-8f0b-119726938dac"], "reference_pdf": ["3ea1a5e9-0057-54a5-b359-7d99fc882842", "06e77679-09f0-5936-b00f-dcad7a604f75", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "c7cf8100-fcbd-575b-a980-7f6d3c4f6761", "b44607d8-7587-53ed-be67-22b3668a1644", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "1b151a0b-8156-5a1d-9459-ba2037900807", "bf80182b-c2b3-5553-bfcf-3d83d1c71d9d", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "cb83c58c-fefc-566d-b291-b27faf9eec2b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "e69ef270-7428-50f6-b47b-63a2455841ac", "7908763f-3a9d-5ce5-af59-f68888750583", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "20847c00-ada9-56f4-aab2-d67eb2ace27b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which exhibits the highest accuracy for Method 2. What specific aspect of the token-level verifiers' training procedure in the model proposed by the paper is likely responsible for their initial uncertainty in solution correctness, as observed in the verifier visualization section?", "reference_answer": "The token-level verifiers' training procedure likely causes initial uncertainty in solution correctness due to the large fraction of incorrect model-generated samples they are trained on, which makes them initially unsure about the correctness of a solution and gradually gain certainty as the solution progresses."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14628/comparison_figure.png"]}
{"uuid": "8ae6bdf8-c866-5c62-95e4-e3fbc7ff011a", "question": "Consider the paper that introduces the Seq2Exp model that exhibits the highest test accuracy. What specific advantage does the model proposed in the paper demonstrate over FinQANet in terms of handling operands in the extended FinQA dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the Seq2Exp model that exhibits the highest test accuracy. What specific advantage does the model proposed in the paper demonstrate over FinQANet in terms of handling operands in the extended FinQA dataset?", "reference_answer": "ELASTIC is adaptable to the number of operands following an operator, making it domain agnostic to support diverse operators."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "8b44f28d-d163-559f-8402-245d3b64caba", "question": "Consider the paper that introduces the method that has a lower J_k score than Random Entity Quantization but a higher J_k score than NodePiece in the FB15k-237 dataset for all values of k between 400 and 1000. According to the ablation studies, which dataset experienced a significant performance degradation when multi-hop neighbor information was removed?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower J_k score than Random Entity Quantization but a higher J_k score than NodePiece in the FB15k-237 dataset for all values of k between 400 and 1000. According to the ablation studies, which dataset experienced a significant performance degradation when multi-hop neighbor information was removed?", "reference_answer": "WN18RR"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_2_comparison_figure.png"]}
{"uuid": "8b65a4b6-5ab3-50ba-8ee4-62a0d8cc6c64", "question": "Consider the paper that introduces the method that exhibits a score of 34.9 in the Acc-7 metric on MOSI. Which specific example in the qualitative analysis section demonstrates a scenario where the spoken words are ambiguous, but the acoustic and visual modalities provide complementary evidence leading to a correct positive sentiment prediction by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits a score of 34.9 in the Acc-7 metric on MOSI. Which specific example in the qualitative analysis section demonstrates a scenario where the spoken words are ambiguous, but the acoustic and visual modalities provide complementary evidence leading to a correct positive sentiment prediction by the model proposed in the paper?", "reference_answer": "The second example"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "8bc59ff4-f13f-5dc1-a2e5-9d01114f4241", "question": "Consider the paper that introduces the method shown in the figure corresponds to the solid red line. How does the sequential training approach of the model proposed in the paper specifically address the negative transfer problem observed in certain evaluation dimensions?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["872650ac-af1b-5ead-bff8-975b0ce8d32d"], "reference_pdf": ["cd28f82e-0927-58c3-b17d-bfd6b5888b79", "3c47cf47-b671-55d5-a396-e294638f7023", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "450c1e1c-8f69-5d85-9a26-df3a876f65e1", "fe26770b-ff50-56e9-8546-8310b7215de7", "43042c01-285d-53a4-8e75-a14921ddd5b7", "060cedb0-10c7-53d3-a4f3-4610a1cb854f", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "deef91b8-6c7c-5fbc-b196-a248c88cb07b", "e3b247ba-4ea5-5d11-9653-e6df72b1c84d", "8bd7983c-5a5b-50cb-99ab-62297274885c", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "6106e3f0-e82c-5ded-a9c2-0d8444beb47b", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "917794fc-6091-585f-9aca-18d5d7fe492b", "98f94381-9ab9-5337-a63e-99c8ad892b6f", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "dea2fddd-8066-5173-ab2b-c960d55f2de1", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "85ba33aa-25d1-526b-a87d-42cfd55a08c9", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "eb251b7d-833d-54cd-9374-0481e7af7292", "c50df058-1617-58f1-9b89-c397fcdceb6f", "f3354010-9feb-5b44-afec-0f6be57ca4d6", "03280b0e-c24d-50a6-a988-b6ca1b7d3519", "ab8d017f-8645-5337-aa84-f52783391b99", "67f97fa1-4d75-5346-8e7f-4701de843e11"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the figure corresponds to the solid red line. How does the sequential training approach of the model proposed in the paper specifically address the negative transfer problem observed in certain evaluation dimensions?", "reference_answer": "The sequential training approach of UniEval specifically addresses the negative transfer problem observed in certain evaluation dimensions by employing a method from continual learning: whenever a new dimension is introduced, a small portion of data from all previous dimensions is added to replay. This strategy allows for easy extension of the evaluator to new dimensions without training from scratch and enables explicit learning of dimensions related to basic linguistic features before moving on to dimensions that require a better understanding of the text."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13189/calibration_figure.png"]}
{"uuid": "8bda83ac-4121-59e4-9185-ae7c656ed30d", "question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has a score lower than 0.82 but higher than 0.815 in the Stance column. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "8bea2f95-672c-5625-a686-7e969aa1e94a", "question": "Consider the paper that introduces the method demonstrated by the solid lavender line. What specific computational advantage does the model proposed in the paper have over VinVL and ${\\cal M}^2$ Transformer in terms of feature extraction inference time?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9906dc9c-eae7-5352-82ca-533b23d498a1"], "reference_pdf": ["f2c45532-0d1d-52f3-8293-a28562dca0c2", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "a9e9314b-4cc2-58e5-bbbd-e0908b71d865", "120aa43e-5a6b-5fc6-9e11-fecd0d3ca36e", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "411227b7-53f4-546d-9c14-70bf07f74473", "1b95bbb6-5c74-52f2-8c79-8fa03ff4879c", "cbb30373-01f6-5707-81b7-fd36a3e42c87", "d4223ac7-9d75-531d-9113-b52397da2e1e", "aa4f0205-fd37-5154-9b71-ce252dccab5c", "4a87a9d9-1977-5796-b15b-18eeb2537ea3", "884e57aa-78e0-5621-958c-8681a2d6f61f", "b95e3586-0087-5079-8c32-66506a0ba806", "c3e48be8-b991-5cfe-bd59-05d2496a094d", "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1", "e4ad4c66-c12f-5367-a923-7342a3a48ac0", "19b4c2c4-42f6-595f-8a56-13b3d241ee6d", "d62a70d3-39eb-57b2-854c-06ae086c4b84", "eb335bea-aa4d-5fb1-9e60-189c2f979d4f", "45decdf4-f524-52d5-8385-3da8d839888b", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "a039db49-aed3-57e6-8720-913aaac61942", "51e5bebd-9870-5529-875f-710339447ecb", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "95c63efc-ff02-585d-bcdf-75e933c5816a", "9baa42c9-b79b-5654-85d3-860ee3241d5e", "c466be66-c99c-5dcd-90a5-5b86d4a6638a", "a229d47a-0069-5d45-8bac-7e5eb2e8b8d1", "0b363526-f924-5baa-be50-c665bd10cb5b", "fa4b52f4-0a73-5305-bf28-adee87c842ec", "72e031f9-130a-5dd0-9f2c-bb29e197a8c2", "14028d43-a37a-52d4-8869-f174ff05ca4c", "d88358e9-efe9-5844-8bfa-b1d3ed22ce82", "45b99aad-66f7-5bc9-a6ef-cc7eb8d66567", "ded8818d-5039-5cc2-b3c7-9f4908153210", "4b918831-da2b-5123-8351-ffdf3abde7c2", "04873797-c04f-5d4b-bab4-fcace1b87c1b", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "5da677b6-dec7-57c9-afb4-5c1af7801b8c", "82a80b14-aa33-57ed-b666-c182235bc860", "5a09a7b9-bceb-58cc-a560-2845b8774e26", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "5fabde11-10a7-5fc8-a1b5-57a6237b5535", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e41d952a-d067-52a4-9fea-12aa78420924", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "b82c062d-e25e-560b-9fe8-47a56901fc74", "1ee90f2d-74b4-5c24-ade4-7608f608d42b", "a02bef04-a577-5433-8a32-7d3786ccfd02", "345e1ebc-c05b-59ea-9619-557ba7bc6e3c", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "0178ef4d-109b-512b-8194-c5debb2014b1", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd4cf2bd-a308-5ae4-8718-2eb04418d7e5", "5c347f12-43c5-57a5-832b-bcf310dfad98", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "ef55b6d8-d37c-5a62-95ca-83bd707306cd", "c5227d39-0b3c-5458-a976-982cdd8d4015", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "1c5aa016-c6ba-5928-87b6-b71a0c952504", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method demonstrated by the solid lavender line. What specific computational advantage does the model proposed in the paper have over VinVL and ${\\cal M}^2$ Transformer in terms of feature extraction inference time?", "reference_answer": "GRIT reduces the feature extraction inference time to 31 ms, compared to 304 ms for VinVL and 736 ms for ${\\cal M}^2$ Transformer."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.11523/figure.png"]}
{"uuid": "8c8aef32-3a8d-54ea-a289-c34fa47d3bd7", "question": "Consider the paper that introduces the method which is placed below the row for R-Former but above the row for NeurJudge. What specific feature does the model's, proposed by the paper, fact re-encoder focus on to effectively distinguish between Article 385 and Article 163?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4f12dd13-6c81-5c0e-90e0-a879ef970a6d"], "reference_pdf": ["e111dd29-50ea-5b75-b563-b1721822b94a", "29258fbc-289f-5221-9c42-16b87d1197b9", "5a1fa4c3-fd03-576e-a4bf-29fd77bec899", "2f6551e2-3835-5c86-9a91-da8b6c8bd429", "2a4d76a8-5d9e-550d-8294-03798da0a973", "34417770-67d7-5cab-b9d4-76999c97bc02", "e4c8595f-5b4c-560d-8306-ea3b13b97928", "42d7a286-5fb0-52be-bd7d-62dc2af2d1c2", "5e549c77-a92b-5ee7-85bc-5a30491d7767", "7eb9a7f2-f640-5526-b434-8d8ff6df167f", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "c3336863-3e6d-56b5-b725-bf73fa23aea9", "33490461-6a37-5409-9d29-f44ad28db91e", "413e7de9-03c4-5c1f-9e42-cd48030c9369", "28e3f907-ee87-5f90-8513-9c64c27051b7", "c023321f-ab7c-57f3-afd8-0f845bca0d1d", "64e5de88-4c23-5099-ac1a-6a8c52b14a49", "d2e0ec1b-f3da-54d8-bda6-b45aa4c22abb", "7908763f-3a9d-5ce5-af59-f68888750583", "df53ebe7-ed7e-56b5-9a14-1c0b4dbe2f7d", "e35f3dc3-713f-5d38-a8d7-2ea61040467d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6324dff1-f1c0-52cb-a0e9-2251c1928303", "2ee016c2-fb4d-5b47-a5cc-d51e4ef61c63", "f6649e84-3c02-54c7-9740-66cc22a0a9da", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is placed below the row for R-Former but above the row for NeurJudge. What specific feature does the model's, proposed by the paper, fact re-encoder focus on to effectively distinguish between Article 385 and Article 163?", "reference_answer": "Defendants' identity information"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09241/results_table.png"]}
{"uuid": "8cc7e55e-5b0f-5e85-93c2-bdaf594ca6db", "question": "Consider the paper that introduces the dataset which has the fewest number of languages but the most number of SM tasks. What specific linguistic phenomenon, as mentioned in the paper, requires familiarity with social media to interpret correctly, and how is it expressed in Chinese?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the fewest number of languages but the most number of SM tasks. What specific linguistic phenomenon, as mentioned in the paper, requires familiarity with social media to interpret correctly, and how is it expressed in Chinese?", "reference_answer": "您说的都对"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "8d175929-6f0c-506b-991c-45abf09e17d0", "question": "Consider the paper that introduces the method shown in the table which is above the 'Magister et al' row but below the 'UL2' row. What specific role does the guidance mechanism play in improving the quality of generated subquestions by a smaller model, according to the DecomDistill method proposed by Magister et al.?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the table which is above the 'Magister et al' row but below the 'UL2' row. What specific role does the guidance mechanism play in improving the quality of generated subquestions by a smaller model, according to the DecomDistill method proposed by Magister et al.?", "reference_answer": "The guidance mechanism conditions the generation of subquestions on the equations describing the intermediate solutions, improving the quality of the generated questions across all metrics considered."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "8f66bd7b-2f7a-50f7-a548-a7571979a73f", "question": "Consider the paper that introduces the model that achieves the lowest execution accuracy in few-shot prompting. What specific method does the paper propose to address its limitations in maintaining multi-turn consistency in dialogues?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the lowest execution accuracy in few-shot prompting. What specific method does the paper propose to address its limitations in maintaining multi-turn consistency in dialogues?", "reference_answer": "Ghost Attention (GAtt)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/execution_accuracy_figure.png"]}
{"uuid": "8ff053b7-665b-537f-b18b-d88b703e61c0", "question": "Consider the paper that introduces the model represented by a blue line in the figure. What specific performance improvement does it show over the standard version of the same model in terms of METEOR score according to the DSTC-7 Dialogue Generation Challenge results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented by a blue line in the figure. What specific performance improvement does it show over the standard version of the same model in terms of METEOR score according to the DSTC-7 Dialogue Generation Challenge results?", "reference_answer": "3.03%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "90f4b32e-e0e4-5f0b-b659-614681f756c2", "question": "Consider the paper that introduces the model that achieves a 16.5 Top-1 score on the SQuAD dataset. How does the \\ednascore metric, utilized by the model, balance the evaluation of faithfulness and diversity in generated summaries?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["910767c8-1586-5180-971e-4d17a0ca4839"], "reference_pdf": ["099a1379-7476-57f9-8219-3e5ca22a0fbf", "3665daf2-f865-553a-8593-6ce9441d8a71", "6410dbbb-74cc-57a5-a88f-d1fccc0405b0", "ddd6c8da-4823-579d-8ac9-62f2c0ca8373", "20ec131c-808d-59b3-8554-b5a68b02968e", "f610d79f-d4e8-51b2-835c-5c39652d1350", "d3897354-5b81-501b-b0bf-ca4a50e7e689", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "0eb01fdd-2e18-5cf6-a973-16420f3d9ee5", "739c8432-c687-5220-89f6-f84e7c860800", "903c5f8d-dc70-5a8f-9660-d960ffecd438", "476cba4c-ceae-57ab-917e-f7730c29f794", "11df7bc5-755c-581a-a2a3-0bbec7933e37", "162d7068-3b55-5fa9-855f-b58c60d80709", "03987706-84be-5081-8b7c-02e03c230e4b", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "14940fd5-af90-5198-a293-1f2fb25ed521", "1e7d9f86-3567-55b8-be98-064a3d297af1", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "6ce47eb8-8d60-58f4-b30b-9b0095f622d8", "822d7c33-cc29-503d-96f9-a82f49f90f06", "9f926a21-6cf7-5f20-ad71-351277b28374", "23c06bf5-933c-5615-8591-5a730260880b", "8c6f2d13-c5f0-5fc4-b7ae-65c3b10e24ed", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "03e6bdfb-abd2-58f9-8c54-862c60db09a0", "43c8d87f-b0bb-51e8-b5d5-797407a011ca", "e677e145-f273-5788-b753-f2592858e1fb", "570a9df6-abb2-506f-945b-de350d19bbcf", "d25cb257-5c78-57a5-b917-49646a796958", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "860b745c-6cb4-5933-b802-cd1848e39229", "fb93f23b-657e-55a4-95a0-7174820f65b4", "7622ac08-15d7-5102-89b2-6891803cd8af", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9c000611-9964-5c0c-866c-95892d0aadde", "06e23bcd-3d01-5478-a8ac-b95dd8f42ac9", "54e72037-97b1-54cc-8aa1-5290454d3f5f", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "86a65848-28d0-5381-9222-52d0f9032e24", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a 16.5 Top-1 score on the SQuAD dataset. How does the \\ednascore metric, utilized by the model, balance the evaluation of faithfulness and diversity in generated summaries?", "reference_answer": "The \\ednascore metric balances the evaluation of faithfulness and diversity in generated summaries by being the harmonic mean of Entailment and (1-Self-Entailment). Higher values of \\ednascore imply more faithful and diverse summaries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14503/comparison_table.png"]}
{"uuid": "91476a74-91df-5f99-9289-5ca70d8691a6", "question": "Consider the paper that introduces the model which is placed fourth in the table. What specific improvement in F1 score was observed for the 'lease details' subset when comparing LegalBERT to the tuned BERT base?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5d7df310-479d-5fea-aedd-572cdb181b5d"], "reference_pdf": ["5c12db52-9752-56ab-ade8-f9e6e1c9f1e5", "9a106ec5-136d-5944-896b-78f122e41d78", "606bc274-d6e5-5e9a-8c7e-68c4e47e038c", "1831f50a-3d4e-54eb-9a1e-18eaaa4cf019", "46c0d816-f49b-5890-b64f-5ff9e7ee016b", "f0e5dee8-1409-5d41-9e15-e42bbe9c54ce", "9e48134a-b4b2-5c38-8f21-4cd55adbcb17", "0caf6da7-1ec5-5f0e-9e6a-655f574d2bf5", "64ee757d-3fab-5132-aadf-376825399f6b", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "dbe6cf51-ba01-5f0d-83b3-e29f71bafbf1", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "d3f113b1-43ab-55f2-bc01-e3ff9a22ad13"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model which is placed fourth in the table. What specific improvement in F1 score was observed for the 'lease details' subset when comparing LegalBERT to the tuned BERT base?", "reference_answer": "1.1%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11368/comparison_table.png"]}
{"uuid": "91a85fc5-b790-543a-9c35-573d3820b3a5", "question": "Consider the paper that introduces the dataset which has 1 language but 13 SM tasks. What specific linguistic phenomenon, as discussed in the paper, necessitates an understanding of social media for accurate interpretation, especially in its expression within the Chinese language?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has 1 language but 13 SM tasks. What specific linguistic phenomenon, as discussed in the paper, necessitates an understanding of social media for accurate interpretation, especially in its expression within the Chinese language?", "reference_answer": "您说的都对"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "92cd06b2-9514-5a10-949f-308446e0cb85", "question": "Consider the paper that introduces the model shown on the first line of the table, specifically BERT. How does the performance of BERT on the NER task compare when using a fine-tuning approach versus a feature-based approach with different masking strategies during pre-training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["eff6094c-a576-5ec6-afae-8313bcf6d538"], "reference_pdf": ["1690c4b3-e4f2-5b00-9eff-84221fa7f0ab", "1f5110f9-63db-5e8e-adef-c2f33b58c5ab", "404bcd7c-20d3-5290-aad4-e056e19d16c1", "8714d81d-6d1e-5732-ac3e-029f7f8ce347", "8860e51f-7c25-5d5c-b0ba-b3726371476c", "a090084d-4a93-5bd5-b857-8b6d674e99a8", "357ce269-1acb-5dec-95f1-33073aa86b0b", "11a21829-d857-5f65-8038-ee3c761ef026", "2697ec60-b994-5ce0-9c67-06ecde1dc5de", "5d8db771-2bdf-5acb-88ec-9572ecc4187b", "bdcbede8-4961-585e-8744-c8c825dd1719", "62b009dd-f233-5060-b1f9-3b23b42dfc2b", "6ea6e60a-4178-50f1-b755-3955a84a9b07", "7c2317c6-aa9d-5ccf-96b6-01037899dd5b", "e488eded-0ba4-58ca-ad26-53799d8e9393", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "7c70448c-cb61-54ea-a9d9-d7ecc5477ba2", "274a4c1b-05a9-54c1-b0eb-24791f11be74", "a2d0d4b5-9596-52df-9c19-667c871cd76f", "558c9b7e-3b09-5823-995f-c881438116a3", "c88a9f90-9a50-5ab9-b5b1-42982d8e7cc7", "9e0baaab-f75d-5b52-b965-a5b427196392", "1de0052f-f719-5c9b-8f53-7df3e9379a0d", "cb64ebe5-e66a-5777-8fe6-7538ffadb7c2", "09db8b38-eab6-58d5-a08b-643db0b5e543", "eee65441-957d-5caa-a5e1-e063d3b1526f", "207e9d08-6c41-5a36-979e-05b3dca39eb3", "8639620d-31d1-5510-bf3f-2cedcfa80b1e", "ffdb65b1-741c-5b1f-8468-2f3601aa347f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown on the first line of the table, specifically BERT. How does the performance of BERT on the NER task compare when using a fine-tuning approach versus a feature-based approach with different masking strategies during pre-training?", "reference_answer": "The performance of BERT on the NER task using a fine-tuning approach generally outperforms the feature-based approach, as the fine-tuning approach allows for minimal task-specific architecture modifications and leverages the deep bidirectional nature of BERT, which is crucial for understanding the context of entities in text. Different masking strategies during pre-training, such as random masking or keeping the word unchanged, are used to mitigate the mismatch between pre-training and fine-tuning stages, but the paper does not provide a direct comparison of these strategies' impact on the NER task specifically."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08298/overall_performance.png"]}
{"uuid": "92e3a103-e847-5805-8097-1e826168e21a", "question": "Consider the paper that introduces the model in the figure that has the lowest diversity score for each of p1, p2, p3, and p4. What is the average span length that slightly outperformed the i.i.d. objective on most non-translation benchmarks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["b868c871-5514-505d-8587-367e156e1e28"], "reference_pdf": ["aeb9b828-4aff-5f24-a169-6fe27f0e1e2c", "675768f2-88cd-54a4-b359-f29fe975fcef", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "ad72f105-7a2a-5959-8f49-342eb4469f36", "9f2e58b0-9d4e-56b0-a504-e5f77a2f1476", "d8388017-45ea-5dfa-9238-3d88f2c1ce6a", "f7306500-2b64-5ee2-9f7e-f4beb3b0ebcf", "799320b2-1e80-56c8-9084-73737c3fbfb5", "7415a335-10d7-55f3-af82-07c08f608ecd", "a24d04a0-5d7b-518f-97d3-5202a6f549a4", "947f07f1-5d2a-554e-a441-9838afd4a779", "34417770-67d7-5cab-b9d4-76999c97bc02", "6f696630-3060-5bd1-9be1-a00e8d89edfe", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "ad6fa17b-383b-53da-8737-9038180d5159", "0801ed2c-711f-5ffe-94d6-c264e679e00e", "7908763f-3a9d-5ce5-af59-f68888750583", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "40862fb4-44fd-5785-91f9-e24afaa2923d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "80772a52-97c8-5bf8-9893-0de1cc8c02f4", "07caf8ef-950f-50c9-8989-70d482d73168", "3f2695ed-eeac-5dcc-9200-fa2eaa0f02ad", "2173fe79-3e5b-52f6-bd51-a63b747394c0", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the figure that has the lowest diversity score for each of p1, p2, p3, and p4. What is the average span length that slightly outperformed the i.i.d. objective on most non-translation benchmarks?", "reference_answer": "3"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05030/diversity_score.png"]}
{"uuid": "9399ce7d-668d-519a-a565-dc3beee7574e", "question": "Consider the paper that introduces the model that results in the second lowest accuracy in the COGS-all dataset. What specific mechanism does it employ to prevent positions in the decoder from attending to subsequent positions, thereby preserving its auto-regressive property?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["6b729c10-15e8-5eaa-8b40-8c8eafbd3ddb"], "reference_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b", "e1e2bf66-bde7-58c0-98f6-6414d50c1311", "34417770-67d7-5cab-b9d4-76999c97bc02", "776bb6da-c5c2-5c73-b8ac-f038fc55bb6a", "9c9e036b-576a-5a70-923f-4d33da527760", "1cbc9c7a-e562-5d6a-af83-4f9a1520dce2", "ce99c350-ea64-53eb-b705-c33884619d64", "53504791-99de-5143-a351-a080bdcc3bc8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "696b4e72-71ad-5357-b60a-7cd5121619dc", "a4c0cf83-a1d0-57b1-84d9-9b7d365f5ad9", "9775a2f4-5880-5569-8cff-46fce5420bf0", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "2eaf2338-0cce-5f50-8917-338a927b7e1a", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "42fd3669-c60f-5d28-b51d-4523bebf0734", "24c55b93-968f-5a40-8520-acfd6229bde6", "ea02c473-42cb-5fbe-9287-aea0fa4a842e", "e5036d4f-b1eb-5a28-b5e0-4887f14183d2", "837e7fdc-f434-546f-9a83-81afc1529b90", "ff84e2fe-51c3-5208-8002-402a7d477b19", "94993d82-6d3b-5b04-b25f-13e33faf6822", "4fe1db4a-687c-55c3-b8c1-3c6ca2a8b302", "0ce323c7-bde8-560b-98c9-6c2c9b5cdf08", "47cbfa6b-6a2f-521e-a7e2-19a3c3460b47", "42fd3669-c60f-5d28-b51d-4523bebf0734"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that results in the second lowest accuracy in the COGS-all dataset. What specific mechanism does it employ to prevent positions in the decoder from attending to subsequent positions, thereby preserving its auto-regressive property?", "reference_answer": "This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position $i$ can depend only on the known outputs at positions less than $i$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15040/accuracy_figure.png"]}
{"uuid": "93b2226b-83a5-5159-ab72-8e09c42d42cb", "question": "Consider the paper that introduces the method that achieves an average EA score of 67.07 in the FinQA task. What is the impact of the order of in-context examples on the model's results for the NQ dataset using the method proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an average EA score of 67.07 in the FinQA task. What is the impact of the order of in-context examples on the model's results for the NQ dataset using the method proposed in the paper?", "reference_answer": "The reverse order performs the best."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "93ba6376-f220-5782-bd11-cea5b13dccaf", "question": "Consider the paper that introduces the model that is seventh in the table. What is the primary reason the PIDRP method underperforms compared to PCP, specifically on the Temporal sense?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that is seventh in the table. What is the primary reason the PIDRP method underperforms compared to PCP, specifically on the Temporal sense?", "reference_answer": "The PIDRP method underperforms compared to the PCP method on the Temporal sense primarily because connective prediction is closer to the natural language patterns when the model is in the pre-training stage than direct implicit discourse relation prediction."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "94a88582-a8b5-5fc8-b202-bf3c592bbdbf", "question": "Consider the paper that introduces the model that has the second lowest MCD 1 score. Which specific modification in the ablation experiments led to the most significant performance deterioration on the CLUTRR task when trained on relation lengths k=2,3?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5c7fb1dc-efe9-585f-a52c-656bed6b1c72"], "reference_pdf": ["cb54e44a-db51-5a8d-b3e5-e6387543389a", "c8717e4f-8ff0-5152-8082-266d0bb88071", "9f83b120-1a28-5397-b764-7b99e62db40d", "969d0c84-5046-5233-a9ce-015454c17e10", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "5015464f-7f34-5403-90e6-e0476fd5febc", "ee1e6c69-30cf-5f9e-b4a8-bfb51a657d08", "35ec5422-c394-5eac-854d-28233a5f9f68", "5aab03c9-0e38-5818-90e3-3b5f882ce28d", "565aa06f-5a94-59e2-9b9a-d8de69a00b54", "d6ea3099-8dd9-5844-a96c-388a86582ee8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "00541e26-04b4-520c-8fee-a656c0bc652c", "4d70e58b-2262-56d0-b3ec-957f8d6132d5", "808a8c71-5485-5683-88e6-b4616d8e7ead", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "b0b8f08f-5cc3-51bd-9834-5c7e50ae692e", "d537f355-a76b-5894-856f-7fbd3328d16e", "0dbcbe8e-2d15-50c7-a52a-9aea7f74fa95", "5d15ac0c-f847-534d-ae40-0007ec49f2b0", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "09a1e967-c629-5c69-b12c-782dd3e017ac", "9066c5d4-3831-59c9-b803-b593a6ef8083", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "3134099b-d3ac-56d3-898d-c77c7a99370e", "42fd3669-c60f-5d28-b51d-4523bebf0734", "1f098267-9697-5fbb-bf8f-a585caad8bf8", "9d24c743-9966-5400-a5f9-6825eca1d557", "b80e3d5b-034c-5f7a-9375-022d87904ee4", "c1c0f24c-58ff-5141-8a9e-a279b49c9213", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "0f92bb2b-b658-5689-914a-8c0ef2dffc3a", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "14c9ea98-903d-52bc-b706-f869a7ff6c91", "0494f66b-dc26-5683-9804-25b245ddba54", "69e18e42-778d-5f47-92ec-bdfe3b03ed37", "0956d0ef-a936-5d49-a5aa-9be966fc7470"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the second lowest MCD 1 score. Which specific modification in the ablation experiments led to the most significant performance deterioration on the CLUTRR task when trained on relation lengths k=2,3?", "reference_answer": "Value ablation"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/CFQ_table.png"]}
{"uuid": "94b41be7-bf3b-5026-a0e7-4d161ee6a743", "question": "Consider the paper that introduces the method that corresponds to a score of 42.0 in the Seen, Val, GC dataset. What specific method does it leverage to enhance its understanding of complex human instructions and handling of long sequences of subtasks in dynamic environments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to a score of 42.0 in the Seen, Val, GC dataset. What specific method does it leverage to enhance its understanding of complex human instructions and handling of long sequences of subtasks in dynamic environments?", "reference_answer": "The Episodic Transformer leverages encoding the full episode history of visual observations and actions with a transformer, and it improves training by using synthetic instructions as an intermediate representation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "95236a53-f0c4-5644-b094-924a6970ac26", "question": "Consider the paper that introduces the model that achieves the highest score on the MNLI dataset. What specific strategy does the model use during the Masked LM pre-training to reduce the mismatch between pre-training and fine-tuning, and what are the probabilities associated with each part of this strategy?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["00ae9127-82dd-5bbd-9d0f-c2a7a58d65fa"], "reference_pdf": ["7e44dc95-9f92-5653-9246-572cc25c5d22", "7bc3753a-e1cb-5635-805e-bdb98255c704", "91f2e795-bf7f-52df-bfae-2b6525a56d60", "fdb748a6-d777-5a99-8537-5c0d524d277d", "193b12c4-871c-53cf-9497-523742859b8d", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "f32f540f-cb2f-51b7-9bb9-89934eb68916", "e8b94d55-54d3-5c7e-ab41-e6af7c9b8b03", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "77146f7f-edd6-57d3-a190-c37c96243ea3", "8fbd30bf-37b1-5741-8aaa-e4fdbb0468f5", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "4f312f60-4fb7-53a0-b6d7-7810cd39eb43", "26e45afd-1c91-5f0f-bb47-33707acec072", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "afaf79d2-ff40-538d-9a27-d932a5d41d8e", "c811c5a5-c22a-5fd6-9f1c-1ffa1bde7c47", "ae10df12-cb06-58ac-a746-6f941ee929e3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the highest score on the MNLI dataset. What specific strategy does the model use during the Masked LM pre-training to reduce the mismatch between pre-training and fine-tuning, and what are the probabilities associated with each part of this strategy?", "reference_answer": "BERT uses a mixed strategy for masking the target tokens during the Masked LM pre-training. The probabilities associated with each part of this strategy are as follows:\n- 80% of the time, the word is replaced with the [MASK] token.\n- 10% of the time, the word is replaced with a random word.\n- 10% of the time, the original word is kept unchanged."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18343/result_table.png"]}
{"uuid": "95b61770-e67e-576d-816b-01b78137dbc0", "question": "Consider the paper that introduces the model shown in the first row of the table. What specific advantage does the model proposed in the paper demonstrate over the \\textsc{WPM-Sep} model in terms of model deployment for GWLAN tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["45365386-d73b-545a-81cb-bb43f2d2e768"], "reference_pdf": ["99b7199a-58d2-5034-85e1-b7e95e0bce74", "de85e921-9bde-5b35-a54f-ba9dff36a285", "99f4474f-02db-5d68-b9e5-5a310ea38545", "d1b7f589-5748-5ea1-89ce-8a37f47ff04e", "20c2e833-7d1f-55b9-9ae9-9b39a2e1cbca", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the first row of the table. What specific advantage does the model proposed in the paper demonstrate over the \\textsc{WPM-Sep} model in terms of model deployment for GWLAN tasks?", "reference_answer": "The \\textsc{WPM-Joint} model demonstrates the specific advantage of enabling simpler deployment over the \\textsc{WPM-Sep} model for GWLAN tasks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14523/comparison_table.png"]}
{"uuid": "9607a4b6-334f-5e93-9d8e-03801854266c", "question": "Consider the paper that introduces the method in the table that is listed right above One-Round Distillation and right below Specialization. What specific modification to the few-shot prompts used in its generation is highlighted as a key factor for improving the quality of generated data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the table that is listed right above One-Round Distillation and right below Specialization. What specific modification to the few-shot prompts used in its generation is highlighted as a key factor for improving the quality of generated data?", "reference_answer": "Providing the model with the target after posing the question and before providing example CoT."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "981131a3-ed29-5043-afa8-d37a85ee1de3", "question": "Consider the paper that introduces the dataset which has the largest number of instances in the ABS category. What is the precision achieved for aspect discovery in the Software domain with a threshold \\(\\lambda\\) set to 0.9?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the largest number of instances in the ABS category. What is the precision achieved for aspect discovery in the Software domain with a threshold \\(\\lambda\\) set to 0.9?", "reference_answer": "45.1"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "987ed17b-b3a9-57e2-a644-baefe622a9be", "question": "Consider the paper that introduces the method that has the highest score in the WQ-R task. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the highest score in the WQ-R task. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "reference_answer": "0.949"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "98adb71b-69b0-560c-90a8-963cd0b860be", "question": "Consider the paper that introduces the dataset with the largest number of dialogues. What specific aspect of the conversation goal completion rate significantly demonstrates the effectiveness of the knowledge posterior/prior distribution learning in the model proposed by the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset with the largest number of dialogues. What specific aspect of the conversation goal completion rate significantly demonstrates the effectiveness of the knowledge posterior/prior distribution learning in the model proposed by the paper?", "reference_answer": "more knowledge to achieve the conversation goal  (much higher rate on score '2')"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "990168c9-ef5d-5705-ba92-8bfe7e9f98ca", "question": "Consider the paper that introduces the method shown in the table that demonstrates the highest BLEU-1 score for the Test Seen task. What specific aspect of the model's representation space, as proposed in the paper, potentially allows contrastive search to be directly applicable without contrastive training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c1a8f43-9394-59e5-b73c-ad4f9306e57d"], "reference_pdf": ["0d40e5ba-8bd1-5835-99fa-82735099730a", "79fb9402-0283-5c7a-ae54-72967aec6549", "0e564d1d-6aaa-59bb-8be4-6bc51657f150", "9f4c8e70-1c59-506c-acd1-9396e1bdaca4", "5d766fc4-866a-51f1-ab46-6edcf811da10", "e7fd4df5-9610-55db-bbc0-5e4dc59f1a82", "dc69ab19-1148-5de0-88be-2c610277ffd8", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "31dcceac-3a4d-5402-95db-072a568513a0", "a239e827-0d3f-5f3a-9757-0b218e376c95", "af825ce1-e5f8-5bd6-8d57-b9fb30859749", "2d2a70db-7f2b-5c64-ac09-7c53c67628ed", "379fd373-9dae-52dd-aeaf-1db616b52199", "45623893-36dd-538c-baee-ee76f85adef7", "22779eba-4d92-5a33-8d44-0a83b31620bd", "e2f6853e-82cd-5b6d-9880-5f2677fd92a5", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "35b48813-1deb-5375-ac6a-948e906c5f54", "393e9431-63b0-589d-88bb-62335baaf8bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "977a0308-a19f-537c-940c-4064e7796e83", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "2820cbba-a917-5456-b732-e1e8972ede48", "d763c0b0-1131-555a-8861-c96dad3901b9", "427a6763-1a3c-5d70-b6d4-f7e4e8cca2e2", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "d51a9214-fff1-52cb-8bbc-d55f87c0cd9c", "59ea8eee-d229-5bcf-b743-f5c5527a6644", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the table that demonstrates the highest BLEU-1 score for the Test Seen task. What specific aspect of the model's representation space, as proposed in the paper, potentially allows contrastive search to be directly applicable without contrastive training?", "reference_answer": "The anisotropic distribution of token representations"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08943/result_table.png"]}
{"uuid": "99994ce5-11a2-5448-afd6-009b6fc5f75c", "question": "Consider the paper that introduces the method that has a score of 73.6 in the CB dataset with 4-shot prompting. How does the model's performance, as proposed in the paper, change when increasing the prompt length from 300 to 400?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a score of 73.6 in the CB dataset with 4-shot prompting. How does the model's performance, as proposed in the paper, change when increasing the prompt length from 300 to 400?", "reference_answer": "absolute 1.8% drop in accuracy"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "9a03cf72-ea61-5a32-9797-5bc733f30521", "question": "Consider the paper that introduces the method which has a score of 73.6 in the CB dataset with 4-shot prompting. What is the relative improvement percentage of this method over vanilla PT on the SuperGLUE benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has a score of 73.6 in the CB dataset with 4-shot prompting. What is the relative improvement percentage of this method over vanilla PT on the SuperGLUE benchmark?", "reference_answer": "16.3\\%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "9a0d6208-4699-5dc5-9e8d-0ae63b2740eb", "question": "Consider the paper that introduces the method that achieves a score of 28.62 in the WQ-B task. How does the model proposed in the paper address the challenge of generating questions with both word-level and structure-level diversity?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b7315180-e811-5a4a-882f-d4a8e0ffe866"], "reference_pdf": ["25905c58-6108-5577-b948-fbaa6aa23e6e", "7d06b7cd-d351-5e13-a0d1-d72ac792b3e7", "b846c66a-a177-5119-af8d-ec4757d6a06c", "2ee103a7-04e2-53fe-83fe-da3bee6579f6", "42c5c7c9-6099-53c2-8868-147e11467288", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "f92811a6-b9ce-519e-9346-f3b892d7f535", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "70d90498-b24e-5af4-84e5-c40377652bce", "01c9329e-9789-52dc-9eed-c99a8ef88a5c"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a score of 28.62 in the WQ-B task. How does the model proposed in the paper address the challenge of generating questions with both word-level and structure-level diversity?", "reference_answer": "Higher in Arabic"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2402.04588/comparison_table.png"]}
{"uuid": "9a6bca3f-b65f-50b7-83df-cb739c605e6f", "question": "Consider the paper that introduces the first method shown in Explicit --> Retrieval-enhanced --> Single-Stage category. What was the success rate in the targeted in-context knowledge updating experiment for FEVER when the prompt included original examples, edited relevant examples, and edited irrelevant examples, using this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in Explicit --> Retrieval-enhanced --> Single-Stage category. What was the success rate in the targeted in-context knowledge updating experiment for FEVER when the prompt included original examples, edited relevant examples, and edited irrelevant examples, using this method?", "reference_answer": "99.9"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "9aabe9ef-0d13-555e-8d4f-78c2a7f7d91c", "question": "Consider the paper that introduces the method represented by the blue line in the figure. Based on the ablation studies, which component's removal from the model proposed in the paper resulted in the most dramatic performance decrease on the WN18RR dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method represented by the blue line in the figure. Based on the ablation studies, which component's removal from the model proposed in the paper resulted in the most dramatic performance decrease on the WN18RR dataset?", "reference_answer": "w/o MulHop"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_comparison_figure.png"]}
{"uuid": "9b13ef13-80ca-5bf1-b45e-1ce329036180", "question": "Consider the paper that introduces the model that corresponds to the lowest BERTScore F1 score on the TellMeWhy dataset. What specific methodological approach does the paper propose to address the challenge of generating high-cognitive-demand educational questions from children's storybooks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5cb4f0ee-6979-5de3-9228-7707e6240704"], "reference_pdf": ["78b201f5-8cc7-5580-a1e9-3e61fd50a3b0", "412f0d4e-18e1-50b9-9029-b2f3dc0f7eff", "a239e827-0d3f-5f3a-9757-0b218e376c95", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "c48ce7f0-0f60-568a-a32a-61dac182a786", "6f6a00e8-6bd2-5287-ab63-6b0b5f3e422d", "6440959d-ac81-5a2c-ae6e-9082bf5ee380", "28a47974-2035-5575-9a75-7df451faf18d", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "f6e91a91-0b1e-5280-8522-a20492033f16", "822d7c33-cc29-503d-96f9-a82f49f90f06", "977a0308-a19f-537c-940c-4064e7796e83", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "e756a768-abbe-52e1-8416-6c24deaa43ff", "f96ef4a4-88c2-52dd-bcad-82b7d77045f0", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the lowest BERTScore F1 score on the TellMeWhy dataset. What specific methodological approach does the paper propose to address the challenge of generating high-cognitive-demand educational questions from children's storybooks?", "reference_answer": "The paper proposes a novel framework that combines question type prediction and event-centric summarization to generate educational questions for storybooks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16446/tell_me_why_table.png"]}
{"uuid": "9b7a1571-39a9-5ff3-bd65-73b0178b4b40", "question": "Consider the paper that introduces the benchmark represented by the triangle marker in the figure. What specific criteria were used to exclude tasks from the subset known as BIG-Bench Hard (BBH), due to their reliance on specialized knowledge or being outside the scope of the work?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark represented by the triangle marker in the figure. What specific criteria were used to exclude tasks from the subset known as BIG-Bench Hard (BBH), due to their reliance on specialized knowledge or being outside the scope of the work?", "reference_answer": "Not solvable by authors within 60 minutes, requires specialized knowledge, or not even worth attempting with chain-of-thought."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "9bd70b44-52f0-5f7c-99c1-7938bc9bb309", "question": "Consider the paper that introduces the method that has a lower F1 score than TPP and a higher F1 score than BROS. What specific advantage does the integration of Coordinate Convolution (CoordConv) provide to the model proposed in the paper in terms of performance on the Entity Labeling and Entity Linking tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than TPP and a higher F1 score than BROS. What specific advantage does the integration of Coordinate Convolution (CoordConv) provide to the model proposed in the paper in terms of performance on the Entity Labeling and Entity Linking tasks?", "reference_answer": "A total gain of 0.02 in F1 score for both Entity Labeling and Entity Linking tasks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "9bf4f892-6b0f-5365-8dfe-711d2d7a6926", "question": "Consider the paper that introduces the method that achieves the lowest J_k scores in the WN18RR dataset. According to the ablation studies, which dataset experienced a significant performance degradation when multi-hop neighbor information was removed from the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves the lowest J_k scores in the WN18RR dataset. According to the ablation studies, which dataset experienced a significant performance degradation when multi-hop neighbor information was removed from the model proposed in the paper?", "reference_answer": "WN18RR"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_2_comparison_figure.png"]}
{"uuid": "9c6bcefb-cebc-55b9-9d61-475fea1dc994", "question": "Consider the paper that introduces the model that is placed below TransferNet but above UniKGQA in the table. What specific strategy does the model proposed in the paper employ to update the question embedding during the path expansion process?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that is placed below TransferNet but above UniKGQA in the table. What specific strategy does the model proposed in the paper employ to update the question embedding during the path expansion process?", "reference_answer": "The specific strategy employed by the subgraph retriever (\\model) to update the question embedding during the path expansion process involves concatenating the original question with the historical expanded relations in the path as the input of RoBERTa, i.e., \\(f(q^{(t)}) = \\mbox{RoBERTa}([q;r_{1};\\cdots;r_{t}])\\)."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_table.png"]}
{"uuid": "9ce0d3b1-b457-57f8-ab26-21cd240232b9", "question": "Consider the paper that introduces the model that has an F1 score higher than PCP's but lower than DiscoPrompt's on PDTB-Top. How does the model's utilization of the local hierarchy-aware contrastive loss $\\mathcal{L}_{L}$ compare to its hard-label version $\\mathcal{L}_{L'}$ in terms of performance impact, and what does this indicate about the scoring function's effectiveness?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has an F1 score higher than PCP's but lower than DiscoPrompt's on PDTB-Top. How does the model's utilization of the local hierarchy-aware contrastive loss $\\mathcal{L}_{L}$ compare to its hard-label version $\\mathcal{L}_{L'}$ in terms of performance impact, and what does this indicate about the scoring function's effectiveness?", "reference_answer": "Replacing the Local Hierarchy-aware Contrastive loss $\\mathcal{L}_{L}$ with the hard-label version $\\mathcal{L}_{L'}$ results in a notable performance drop, indicating the scoring function's effectiveness in considering more subtle semantic structures of the local hierarchy."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "9d3add1e-9842-570e-91c5-de05a22a2945", "question": "Consider the paper that introduces the method that has a lower F1 score than LayoutXLM and a higher F1 score than SPADE. What specific architectural component in the model proposed by the paper is responsible for mapping the representation of each node into the number of target classes?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than LayoutXLM and a higher F1 score than SPADE. What specific architectural component in the model proposed by the paper is responsible for mapping the representation of each node into the number of target classes?", "reference_answer": "Node Predictor"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "9d6e4ceb-1323-52a2-a296-fa066af7dccc", "question": "Consider the paper that introduces the dataset that contains 3,747,569 instances. What specific methodological approach did the authors use to ensure the aspect-based summaries in the model proposed by the paper had sufficient content overlap with their corresponding sections?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that contains 3,747,569 instances. What specific methodological approach did the authors use to ensure the aspect-based summaries in the model proposed by the paper had sufficient content overlap with their corresponding sections?", "reference_answer": "They used a greedy mapping algorithm to ensure content overlap, assigning a matching score based on ROUGE-1-recall between the abstract sentence and the aspect section, filtering out sentences with a score below a predefined threshold."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "9e983c3b-9ea5-534d-a215-ef6b8a62d437", "question": "Consider the paper that introduces the model that scores higher than ACA but lower than RationaleCL in the 'T5' column. What specific hyperparameter values were used for the FewRel dataset in the experiments, and how do these values compare to those used for the TACRED dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores higher than ACA but lower than RationaleCL in the 'T5' column. What specific hyperparameter values were used for the FewRel dataset in the experiments, and how do these values compare to those used for the TACRED dataset?", "reference_answer": "For FewRel, the values were α=0.5, β=0.5, τ1=0.1, μ=0.5, ω=0.1, τ2=0.5, γ=1.25, λ1=0.5, λ2=1.1. For TACRED, the values were α=0.6, β=0.2, τ1=0.1, μ=0.8, ω=0.15, τ2=0.5, γ=2.0, λ1=0.5, λ2=0.7."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "9eb83722-1f24-50f1-8dc1-5216d05c5c2b", "question": "Consider the paper that introduces the dataset represented by the smallest blue circle. What is the Fleiss kappa inter-annotator agreement score for the Yoruba language when considering the 3-class sentiment classification?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset represented by the smallest blue circle. What is the Fleiss kappa inter-annotator agreement score for the Yoruba language when considering the 3-class sentiment classification?", "reference_answer": "0.600"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "9f40a675-12bb-509f-a9d7-fdf9d31a7146", "question": "Consider the paper that examines the dataset with the largest number of dialogues. What specific distribution statistics were analyzed in the paper to assess goal completion and knowledge exploitation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that examines the dataset with the largest number of dialogues. What specific distribution statistics were analyzed in the paper to assess goal completion and knowledge exploitation?", "reference_answer": "goal completion: 0, 1, 2\n\nknowledge used: # triplets, # properties"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "a102c131-ea49-57c8-8193-12a63e5b85a1", "question": "Consider the paper that introduces the model that demonstrates the highest Oracle score. How does its \\ednascore metric balance the evaluation of faithfulness and diversity in the generated summaries?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["910767c8-1586-5180-971e-4d17a0ca4839"], "reference_pdf": ["099a1379-7476-57f9-8219-3e5ca22a0fbf", "3665daf2-f865-553a-8593-6ce9441d8a71", "6410dbbb-74cc-57a5-a88f-d1fccc0405b0", "ddd6c8da-4823-579d-8ac9-62f2c0ca8373", "20ec131c-808d-59b3-8554-b5a68b02968e", "f610d79f-d4e8-51b2-835c-5c39652d1350", "d3897354-5b81-501b-b0bf-ca4a50e7e689", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "0eb01fdd-2e18-5cf6-a973-16420f3d9ee5", "739c8432-c687-5220-89f6-f84e7c860800", "903c5f8d-dc70-5a8f-9660-d960ffecd438", "476cba4c-ceae-57ab-917e-f7730c29f794", "11df7bc5-755c-581a-a2a3-0bbec7933e37", "162d7068-3b55-5fa9-855f-b58c60d80709", "03987706-84be-5081-8b7c-02e03c230e4b", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "14940fd5-af90-5198-a293-1f2fb25ed521", "1e7d9f86-3567-55b8-be98-064a3d297af1", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "6ce47eb8-8d60-58f4-b30b-9b0095f622d8", "822d7c33-cc29-503d-96f9-a82f49f90f06", "9f926a21-6cf7-5f20-ad71-351277b28374", "23c06bf5-933c-5615-8591-5a730260880b", "8c6f2d13-c5f0-5fc4-b7ae-65c3b10e24ed", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "03e6bdfb-abd2-58f9-8c54-862c60db09a0", "43c8d87f-b0bb-51e8-b5d5-797407a011ca", "e677e145-f273-5788-b753-f2592858e1fb", "570a9df6-abb2-506f-945b-de350d19bbcf", "d25cb257-5c78-57a5-b917-49646a796958", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "860b745c-6cb4-5933-b802-cd1848e39229", "fb93f23b-657e-55a4-95a0-7174820f65b4", "7622ac08-15d7-5102-89b2-6891803cd8af", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9c000611-9964-5c0c-866c-95892d0aadde", "06e23bcd-3d01-5478-a8ac-b95dd8f42ac9", "54e72037-97b1-54cc-8aa1-5290454d3f5f", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "86a65848-28d0-5381-9222-52d0f9032e24", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that demonstrates the highest Oracle score. How does its \\ednascore metric balance the evaluation of faithfulness and diversity in the generated summaries?", "reference_answer": "The \\ednascore metric balances the evaluation of faithfulness and diversity in generated summaries by being the harmonic mean of Entailment and (1-Self-Entailment). Higher values of \\ednascore imply more faithful and diverse summaries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14503/comparison_table.png"]}
{"uuid": "a108e505-1cbf-55c8-a2ec-8924c7470382", "question": "Consider the paper that introduces the method that results in a better score than MOCA but worse score than LACMA in the Seen, Val, SR dataset. What specific method does the model proposed in the paper leverage to enhance its understanding of complex human instructions and handling of long sequences of subtasks in dynamic environments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that results in a better score than MOCA but worse score than LACMA in the Seen, Val, SR dataset. What specific method does the model proposed in the paper leverage to enhance its understanding of complex human instructions and handling of long sequences of subtasks in dynamic environments?", "reference_answer": "The Episodic Transformer leverages encoding the full episode history of visual observations and actions with a transformer, and it improves training by using synthetic instructions as an intermediate representation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "a2776d55-fba9-51c0-a83a-300c47fc401e", "question": "Consider the paper that introduces the dataset that has a test set size of 1,106. What specific error type in the error analysis indicates a failure due to the model proposed in the paper's inability to understand comments with indirect and disrespectful references?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that has a test set size of 1,106. What specific error type in the error analysis indicates a failure due to the model proposed in the paper's inability to understand comments with indirect and disrespectful references?", "reference_answer": "Allusion: The comment refers to another person or subject in an indirect and disrespectful way."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "a28b9bdc-145d-5e58-977c-90273ed93f8f", "question": "Consider the paper that introduces the method that is in the last row of the upper half of the table. How does the model proposed in the paper ensure the selection of high-quality synthetic data over poor-quality data during training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e5476c7f-2b14-520b-81df-8783aebf59f5"], "reference_pdf": ["e897e2cd-c196-532e-8273-358b4878e270", "7e10ecb3-9428-53a7-8edf-83c7f2ca9bbe", "e0f03057-5bdd-575d-a691-7493ccc1bfb9", "98ac518b-1b74-562f-9913-2a494f1417c2", "f781ad75-0ee9-572a-bf0e-6ec0c4faf7c2", "cb764bcf-9005-5541-8cf0-55e47ee0ff91", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6", "560b3014-4a65-57cc-bda5-e3610828782e", "071d6f10-df74-5f8a-ba5f-4b3cfa33e65b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the last row of the upper half of the table. How does the model proposed in the paper ensure the selection of high-quality synthetic data over poor-quality data during training?", "reference_answer": "The MetaBLINK model ensures the selection of high-quality synthetic data over poor-quality data during training by designing a meta-learning mechanism to automatically assign different weights to each synthetic entity-mention pair."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12444/comparison_table.png"]}
{"uuid": "a2b15946-16e5-5f76-aa73-1dfc7b7831ee", "question": "Consider the paper that introduces the model that is placed below TransferNet but above UniKGQA in the table. What is the impact on Hits@1 of QA when removing the subgraph merging strategy (GM) in the model proposed in the paper+NSM on the CWQ dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that is placed below TransferNet but above UniKGQA in the table. What is the impact on Hits@1 of QA when removing the subgraph merging strategy (GM) in the model proposed in the paper+NSM on the CWQ dataset?", "reference_answer": "drop by 0.1%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_table.png"]}
{"uuid": "a334cd91-138f-59f7-b1d0-10faaf307f95", "question": "Consider the paper that introduces the method that has a perplexity of approximately 30 and an average max toxicity of around 0.4. What is the initial value of the shift parameter \\(\\lambda_0\\) used in the remaining experiments after its effect on perplexity and repetition scores was analyzed?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a perplexity of approximately 30 and an average max toxicity of around 0.4. What is the initial value of the shift parameter \\(\\lambda_0\\) used in the remaining experiments after its effect on perplexity and repetition scores was analyzed?", "reference_answer": "5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "a4291895-ad78-5b05-9cab-ec2c52909097", "question": "Consider the paper that introduces the model represented with a dot marker. What specific performance improvement does the model, DialoGPT Large, show over the standard DialoGPT (345M) model in terms of METEOR score according to the DSTC-7 Dialogue Generation Challenge results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented with a dot marker. What specific performance improvement does the model, DialoGPT Large, show over the standard DialoGPT (345M) model in terms of METEOR score according to the DSTC-7 Dialogue Generation Challenge results?", "reference_answer": "3.03%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "a45b6678-1e50-52ea-940a-2b9707bf1634", "question": "Consider the paper that introduces the method that is in the last row of the Full Training category. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the last row of the Full Training category. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "reference_answer": "0.949"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "a4a594e1-9f91-5ff5-acbe-afa2c8ff13a7", "question": "Consider the paper that introduces the method that scores a 70.1 in the 'Revised Persona' column. What is the best setting of the hyperparameter \\(\\gamma\\) for both its sentence and word versions on the original PersonaChat dataset, and why?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["26feec2d-e6df-532b-9f63-ab9b73e8266f"], "reference_pdf": ["8b28a50c-b93f-5426-adbf-c8a139d518de", "c02fd012-1287-5268-94e6-aaae4ee61dda", "686c19e6-39d7-5bb4-a324-ba2bd5c26db2", "c260bf67-2731-5445-96eb-94baa3e5f834", "51e05e32-8367-58b9-b753-6c6a6c1d665a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "60105831-0210-599b-a410-f12e2df3cffc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "0e0746e6-8044-5c49-b46e-0a66569438a8", "e2a2d7b1-a02c-58e5-8d14-272810335de1", "7908763f-3a9d-5ce5-af59-f68888750583", "c5833e1d-8813-56da-99d1-bf61d9ac33df", "5d474441-0098-5521-b6d2-4219837f18c9", "3134099b-d3ac-56d3-898d-c77c7a99370e", "311f9316-6c35-5c33-b61a-f25d90866412", "c76b968a-995a-5109-a4eb-f329fa710f26", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "da510970-00ea-5853-a68c-9741c0d1fd4d", "81de543a-91c2-5035-9617-724abb93a839", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "206abdf4-f071-58ab-8bd6-206bb79786f1", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "d3344458-d106-52ed-be5c-505f8b07af06", "b4ce79f8-4a56-5bb4-b15c-13fee270a57d", "cbb28401-7af5-577d-b36c-a50a87e88b96", "27810986-0584-5a03-9944-a70637604b0f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that scores a 70.1 in the 'Revised Persona' column. What is the best setting of the hyperparameter \\(\\gamma\\) for both its sentence and word versions on the original PersonaChat dataset, and why?", "reference_answer": "0.3"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06390/result_table.png"]}
{"uuid": "a4e37dfe-9538-5ce3-8659-7e4630791a15", "question": "Consider the paper that introduces the model that achieves the second highest score in the Stance column. What is the Pearson's correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the second highest score in the Stance column. What is the Pearson's correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "a5fd2d90-6cd0-5811-a41b-6e5a3961c4f1", "question": "Consider the paper that introduces the method which has a METEOR cross entropy score lower than ours but higher than X-Transformer. What is the performance of the model, when comparing the use of concepts extracted from captions to using concepts from an object detector in terms of CIDEr scores on the COCO-caption Karpathy split?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e30a2f94-a104-572f-b30f-3ae7ff87f6e7"], "reference_pdf": ["d3c84791-eee6-5f1b-8500-1c0a84375f47", "f8d549ad-783d-591b-9ed4-4be9b95e7d9a", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "6c4dc282-e455-530e-9a34-4900a85e2964", "0a4a6ae4-afd1-5807-8417-fcd4b4809799", "1ad58efb-6d3b-5d50-b516-a01ae90f0787", "ee1dfb4c-7988-5a4c-bb1c-a26a7a03b8bf", "7aa9fab2-572b-5e8c-a92a-7b09e4f4c306", "4d3092f6-d683-5121-b9a5-7fca4ff91894", "a76b882d-198d-56d9-9ced-191f44ac95e8", "c6401b44-ad7a-5948-88ad-b180075d7dbe", "60b654b7-5847-56a5-8aaf-2e22fb679dc2", "0466db28-e878-5df8-8ebf-4a9aa8eb7b8e", "fc840122-59b3-5e1d-8c9b-4469f9395fda", "79c9710e-50b0-5c46-8210-1c5539a5328d", "cffe9204-ae34-53b2-adfc-ba74227619b8", "29322424-fba7-5659-a1df-8acb9f557bd8", "4974e1c8-fbd5-5689-ab45-78f2829161d3", "f4f54d07-2fac-59ba-ad99-7e60fba39833", "7ccc7830-102e-567f-9853-bed1eec59176", "f5b9aa98-8d6c-59b7-8883-d1339aeddd97", "949e1567-7aad-545b-b6ec-f5bad4d8bb4e", "6f26f6da-6cc3-5aa4-9f91-ca29b2d64729", "5baa788b-6e39-5587-8800-43f1801adef3", "69728e8c-59e5-5c53-a3cc-f245d1f7af59", "01d0de9d-f910-5674-841b-39ed4688eed7", "a941564b-e52c-55b7-8ded-59c510643621", "f3fe57c2-c6c8-5707-afaf-8f889823dffc", "facc9abe-bac6-5c51-8c10-0d2c28e15868", "cd71e042-6d38-56be-b014-7b9e02e8733e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "70aa012e-fef9-59af-8957-7d698937f537", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "2e3cfef4-fac0-5942-9361-f1321fc394b3", "2b8f1988-37a8-5fc1-b6c3-40b70dd2867f", "d4f2933e-e3ec-5035-bb6c-90041be7751c", "d95266e3-9e89-592a-b1fe-b55d3279249d", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "01d0de9d-f910-5674-841b-39ed4688eed7"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has a METEOR cross entropy score lower than ours but higher than X-Transformer. What is the performance of the model, when comparing the use of concepts extracted from captions to using concepts from an object detector in terms of CIDEr scores on the COCO-caption Karpathy split?", "reference_answer": "Using concepts extracted from captions leads to better performance (121.8 CIDEr scores) compared to using concepts from an object detector."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.08223/result_table.png"]}
{"uuid": "a60b7d7d-fbd8-5a7c-b5b4-34257803ddf5", "question": "Consider the paper that introduces the method that achieves a higher EA score than Fixed set but a lower EA score than Diverse KATE in the FinQA task. How does the order of in-context examples influence the model's performance on the NQ dataset, and what is the observed effect when the examples are arranged in reverse order?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a higher EA score than Fixed set but a lower EA score than Diverse KATE in the FinQA task. How does the order of in-context examples influence the model's performance on the NQ dataset, and what is the observed effect when the examples are arranged in reverse order?", "reference_answer": "The reverse order performs the best."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "a648d0f6-93f4-5285-8e8f-e0574a1115f5", "question": "Consider the paper that introduces the method that has a perplexity of 60. What specific computational advantage does the model proposed in the paper's online classification trick offer over a unidirectional classifier in terms of the number of forward passes required for computing $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a perplexity of 60. What specific computational advantage does the model proposed in the paper's online classification trick offer over a unidirectional classifier in terms of the number of forward passes required for computing $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$?", "reference_answer": "GeDi's online classification trick can compute $P_{\\theta}(c|x_t,x_{<t})$ for every possible next token $x_t$ on the order of 10k fold less computation as compared with a unidirectional classifier."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "a87e461d-a56e-58d5-87a4-49e2d46a805a", "question": "Consider the paper that introduces the method for which the BLEU-1 score is missing in the table. What specific loss parameters are set for the concept classification task in the model proposed by the paper to handle the imbalanced distribution of semantic concepts?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e30a2f94-a104-572f-b30f-3ae7ff87f6e7"], "reference_pdf": ["d3c84791-eee6-5f1b-8500-1c0a84375f47", "f8d549ad-783d-591b-9ed4-4be9b95e7d9a", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "6c4dc282-e455-530e-9a34-4900a85e2964", "0a4a6ae4-afd1-5807-8417-fcd4b4809799", "1ad58efb-6d3b-5d50-b516-a01ae90f0787", "ee1dfb4c-7988-5a4c-bb1c-a26a7a03b8bf", "7aa9fab2-572b-5e8c-a92a-7b09e4f4c306", "4d3092f6-d683-5121-b9a5-7fca4ff91894", "a76b882d-198d-56d9-9ced-191f44ac95e8", "c6401b44-ad7a-5948-88ad-b180075d7dbe", "60b654b7-5847-56a5-8aaf-2e22fb679dc2", "0466db28-e878-5df8-8ebf-4a9aa8eb7b8e", "fc840122-59b3-5e1d-8c9b-4469f9395fda", "79c9710e-50b0-5c46-8210-1c5539a5328d", "cffe9204-ae34-53b2-adfc-ba74227619b8", "29322424-fba7-5659-a1df-8acb9f557bd8", "4974e1c8-fbd5-5689-ab45-78f2829161d3", "f4f54d07-2fac-59ba-ad99-7e60fba39833", "7ccc7830-102e-567f-9853-bed1eec59176", "f5b9aa98-8d6c-59b7-8883-d1339aeddd97", "949e1567-7aad-545b-b6ec-f5bad4d8bb4e", "6f26f6da-6cc3-5aa4-9f91-ca29b2d64729", "5baa788b-6e39-5587-8800-43f1801adef3", "69728e8c-59e5-5c53-a3cc-f245d1f7af59", "01d0de9d-f910-5674-841b-39ed4688eed7", "a941564b-e52c-55b7-8ded-59c510643621", "f3fe57c2-c6c8-5707-afaf-8f889823dffc", "facc9abe-bac6-5c51-8c10-0d2c28e15868", "cd71e042-6d38-56be-b014-7b9e02e8733e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "70aa012e-fef9-59af-8957-7d698937f537", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "2e3cfef4-fac0-5942-9361-f1321fc394b3", "2b8f1988-37a8-5fc1-b6c3-40b70dd2867f", "d4f2933e-e3ec-5035-bb6c-90041be7751c", "d95266e3-9e89-592a-b1fe-b55d3279249d", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "01d0de9d-f910-5674-841b-39ed4688eed7"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method for which the BLEU-1 score is missing in the table. What specific loss parameters are set for the concept classification task in the model proposed by the paper to handle the imbalanced distribution of semantic concepts?", "reference_answer": "$\\gamma_{+}=0$ and $\\gamma_{-}=1$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.08223/result_table.png"]}
{"uuid": "a8d8e06b-4c4a-5a62-9206-82ff24cbb5cf", "question": "Consider the paper that introduces the model in the figure corresponds to the grey line with a star marker. What is the percentage of responses flagged as toxic using a toxicity classifier in the RealToxicityPrompts evaluation for the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the figure corresponds to the grey line with a star marker. What is the percentage of responses flagged as toxic using a toxicity classifier in the RealToxicityPrompts evaluation for the model proposed in the paper?", "reference_answer": "0.42"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/average_relative_performance.png"]}
{"uuid": "a97c0c8f-f748-5b8d-9e62-2dca16875725", "question": "Consider the paper that introduces the quant method that achieves a lower score than APQ-ViT but still scores higher than 76.0 on Deit-S with a Weight/Activation (W/A) precision of 6/6. What specific advantage does its twin uniform quantization offer for post-softmax and post-GELU activation values in terms of hardware efficiency?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87c327a8-cd52-5d23-93de-c4486887da8b"], "reference_pdf": ["bc431e93-410f-5eb0-a4a5-314a37e129a0", "34417770-67d7-5cab-b9d4-76999c97bc02", "720ede7a-1362-532b-b4b5-4436c03c5363", "95808d88-d437-55ec-9af6-cb7399b1010c", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "60495988-448a-5919-9470-d8561310a40d", "81528b8c-c326-567e-a3ed-4ca2b0295ff2", "52d72671-969b-5840-8808-73be9745a07f", "720ede7a-1362-532b-b4b5-4436c03c5363", "93502213-3277-5df7-a02f-39b12077c0c2", "08e29bf5-665b-561e-8672-d90363383d43", "e7184da4-f850-5562-ba39-441760b58a7d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "3b9340d4-5374-5613-a1a4-bc3c125639c6", "7908763f-3a9d-5ce5-af59-f68888750583", "1ffa6ac4-663b-5498-84b3-3148948fcba4", "332d0f2a-9d5a-54b3-8d5e-e24081633c0e", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "b9f85125-14a8-502f-8717-f38768038090", "acce625f-be46-56f5-b5f6-13b331e2efdf", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "b9fa129c-7848-536a-b464-b4090dd72a9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the quant method that achieves a lower score than APQ-ViT but still scores higher than 76.0 on Deit-S with a Weight/Activation (W/A) precision of 6/6. What specific advantage does its twin uniform quantization offer for post-softmax and post-GELU activation values in terms of hardware efficiency?", "reference_answer": "It enables efficient processing on existing hardware devices including CPUs and GPUs by using a shift operation to align the two quantization ranges, avoiding the need for format transformation and extra FP32 multiplication and FP32 addition."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16836/comparison_table.png"]}
{"uuid": "a9fccd94-9e4d-5687-822d-6d17d6720370", "question": "Consider the paper that introduces the model that performs the best on the BBBP dataset. What specific finetuning strategy did the authors find to yield slightly better results for MoleculeNet tasks, and how is it characterized?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["75156ea6-7402-5a33-9303-ec6f543e9999"], "reference_pdf": ["7aa1a28a-1256-5732-9581-f2538bfcaf8e", "adf24566-930f-5a42-8118-6aeb65e4f6f4", "825de5ef-3ab4-5629-9fc4-4b0805f419b8", "a1002509-bd90-5cde-9fd2-7b6216144d71", "653e5d86-f991-5533-bd83-a5d95f760b18", "aa22dd10-f8dc-5b74-893f-4f3b21431f24", "766ea9a1-a447-5963-a71f-c9d0a0562d57", "7ea7979f-d2cf-58e4-b00e-2b4027aaf436", "a2401db7-a8bd-588a-856c-4d9ad4f85409", "3a2ae924-5f60-5905-abab-631f660f7bb6", "54fbf9e2-28d0-54ce-ba51-27f90b206c6e", "cb5cba33-3521-52d7-abbc-9d4f70cabb4d", "3b7baa1d-606b-5481-9c27-fec60e4c7533", "6d068e18-8fb7-5dff-b0bf-b95297a79dc5", "7908763f-3a9d-5ce5-af59-f68888750583", "4ef708b0-51b3-5527-91fc-a55d70b49671", "e2b71dfc-0678-5451-82f6-42650b5ca0dc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "05397506-c619-548a-9f1f-18f85acc151e", "cf69528e-9892-5b27-ab66-0b66a1304268", "a2677b99-9e0d-5c14-8e19-f1c7d5cfa93f", "7908763f-3a9d-5ce5-af59-f68888750583", "7d25556e-bc5e-58ba-b1d8-294c67ed7d98", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6fd2a9e7-7fea-5866-b0c4-120b7cc5baae", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "d97c36ef-e3d9-5f53-a6ff-00d5ee2f2777", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "d4f91c73-f4cf-5209-bec5-6ff66eb29d19", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "5161fb60-4394-5446-9e6e-ce1f1e9e393a", "1777f12e-991e-52d4-8b6b-03807d589e87", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "964db907-da57-5f8b-b1ef-1054c077ca89", "4a697112-1b30-569a-8fee-c4eace04cb3f", "33130f85-57c8-54d5-b050-075bb1ccab97"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that performs the best on the BBBP dataset. What specific finetuning strategy did the authors find to yield slightly better results for MoleculeNet tasks, and how is it characterized?", "reference_answer": "finetuning the tags only"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07276/performance_table.png"]}
{"uuid": "aa93f6bc-86ff-5777-8069-34fada94e7de", "question": "Consider the paper that introduces the dataset in which KALMV achieves a score of 70.83 for the XL model. What specific operational limitation does the Rigel model exhibit when predicting answers from it?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8dca380b-0d1b-5c49-a9b6-0581864c7909"], "reference_pdf": ["5b0d44de-0d1d-5f43-a9b0-89b5338732d7", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "84449b22-c7ae-5253-8295-9d74a378fcc3", "8433f894-a217-54d3-9ae5-5c17f951797a", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "79b4a9b3-0759-50f7-a801-83cad821e867", "0337fff3-2745-5430-b1ca-9d43c836a09c", "d699a785-3fb8-5b5b-8487-72d2dbd4dcbd", "90e3610c-c0b5-5b1d-9a9f-6f0f62dd9c89", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "11f9746f-503b-573f-8781-04477603c994", "e3ef9171-b0b7-58c0-8e98-051bfde10ef7", "7908763f-3a9d-5ce5-af59-f68888750583", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "739c8432-c687-5220-89f6-f84e7c860800", "6f4d0a2f-4457-55af-b519-da2a1df140da", "36a1c245-8803-586f-a39c-57a149b16892", "7c278568-4bb8-5a1f-af34-4df3980282eb", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "5a533ef5-84ee-5448-8375-b683864484bc", "1e7d9f86-3567-55b8-be98-064a3d297af1", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "dd39e75b-40a4-5ec5-9943-79277ed1cd00", "819d0208-b342-5a31-a2ab-da64c204544e", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in which KALMV achieves a score of 70.83 for the XL model. What specific operational limitation does the Rigel model exhibit when predicting answers from it?", "reference_answer": "Rigel cannot perform sorting or filtering."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12836/results_table.png"]}
{"uuid": "aa9698f0-8296-504d-8132-abd14cba230a", "question": "Consider the paper that introduces the model that achieves the highest score on the MNLI dataset. How does its performance on the NER task compare when using a fine-tuning approach versus a feature-based approach with different masking strategies during pre-training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["00ae9127-82dd-5bbd-9d0f-c2a7a58d65fa"], "reference_pdf": ["7e44dc95-9f92-5653-9246-572cc25c5d22", "7bc3753a-e1cb-5635-805e-bdb98255c704", "91f2e795-bf7f-52df-bfae-2b6525a56d60", "fdb748a6-d777-5a99-8537-5c0d524d277d", "193b12c4-871c-53cf-9497-523742859b8d", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "f32f540f-cb2f-51b7-9bb9-89934eb68916", "e8b94d55-54d3-5c7e-ab41-e6af7c9b8b03", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "77146f7f-edd6-57d3-a190-c37c96243ea3", "8fbd30bf-37b1-5741-8aaa-e4fdbb0468f5", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "4f312f60-4fb7-53a0-b6d7-7810cd39eb43", "26e45afd-1c91-5f0f-bb47-33707acec072", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "afaf79d2-ff40-538d-9a27-d932a5d41d8e", "c811c5a5-c22a-5fd6-9f1c-1ffa1bde7c47", "ae10df12-cb06-58ac-a746-6f941ee929e3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the highest score on the MNLI dataset. How does its performance on the NER task compare when using a fine-tuning approach versus a feature-based approach with different masking strategies during pre-training?", "reference_answer": "The performance of BERT on the NER task using a fine-tuning approach generally outperforms the feature-based approach, as the fine-tuning approach allows for minimal task-specific architecture modifications and leverages the deep bidirectional nature of BERT, which is crucial for understanding the context of entities in text. Different masking strategies during pre-training, such as random masking or keeping the word unchanged, are used to mitigate the mismatch between pre-training and fine-tuning stages, but the paper does not provide a direct comparison of these strategies' impact on the NER task specifically."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18343/result_table.png"]}
{"uuid": "aabe387b-bdfa-59df-bb2b-53657f31c2fa", "question": "Consider the paper that introduces the method that has a CoLA score equal to 55.9 on the GLUE task. What was the average GLUE benchmark performance in the ablation study when the model proposed by the paper used regular adapters in both the encoder and decoder?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a CoLA score equal to 55.9 on the GLUE task. What was the average GLUE benchmark performance in the ablation study when the model proposed by the paper used regular adapters in both the encoder and decoder?", "reference_answer": "86.4"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "aaea2a90-a5dc-594d-9564-7fb1a4fa7e83", "question": "Consider the paper that introduces the LLM shown in the figure with a model size of 1.7T. What specific methodological difference in the evaluation of its performance on the USABO and SAT reading/writing runs (with and without vision) compared to other exams contributed to potential minimal impact on results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9b154fc7-cac7-5a8f-89ac-1ea50638b087"], "reference_pdf": ["87b70047-b849-5220-a3df-28e992c41bf2", "d4de27d2-08b9-57ae-b0a7-a4b9b26047bf", "507be7a7-d7c2-5c15-8ffe-9e6bfe40e5b0", "54eb4a06-225f-5814-ae97-c54611c3f95c", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "4d2120b1-212d-52ad-a0e5-c56245349f00", "34417770-67d7-5cab-b9d4-76999c97bc02", "a0863db0-4018-56ff-81bf-bdb1ff2ed4b7", "e59b32f7-7a87-5940-b581-3e110d2fd77d", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "884e57aa-78e0-5621-958c-8681a2d6f61f", "98b88819-fa1f-503b-9e15-3b078e676975", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "3caa80e4-e308-5fd8-b45f-6b55c8a7a835", "ad6fa17b-383b-53da-8737-9038180d5159", "a1302ac9-0f53-556b-96cd-38977a533888", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "7908763f-3a9d-5ce5-af59-f68888750583", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "dd073182-00f0-5a9f-800b-7779293ab2ae", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "17623cac-c243-591b-b7bc-d261f6ebd607"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the LLM shown in the figure with a model size of 1.7T. What specific methodological difference in the evaluation of its performance on the USABO and SAT reading/writing runs (with and without vision) compared to other exams contributed to potential minimal impact on results?", "reference_answer": "The specific methodological difference in the evaluation of GPT-4's performance on the USABO and SAT reading/writing runs (with and without vision) compared to other exams that contributed to potential minimal impact on results was the direct sampling of a letter choice at temperature 0 using the already-sampled explanation for these exams, as opposed to extracting the model's letter choice directly from the explanation for most other exam runs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.04988/HVI_figure.png"]}
{"uuid": "ab35b0c2-2204-5ec5-87af-d41298085852", "question": "Consider the paper that introduces the dataset that has the largest number of Queries|Aspects in the OABS category. What specific methodological approach was used to determine the threshold value for including sentences in aspect-based summaries within this dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that has the largest number of Queries|Aspects in the OABS category. What specific methodological approach was used to determine the threshold value for including sentences in aspect-based summaries within this dataset?", "reference_answer": "Manual evaluation with randomly selected Wikipedia pages and expert annotators."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "ab663776-0d92-5588-b1f3-c7fc0cce2a61", "question": "Consider the paper that introduces the model in the LLM section of the table that corresponds to the highest test accuracy. What is the reported accuracy of the model proposed in the paper using self-consistency with sampling for the AQuA task on the UL2-20B model with a beam size of 40?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the LLM section of the table that corresponds to the highest test accuracy. What is the reported accuracy of the model proposed in the paper using self-consistency with sampling for the AQuA task on the UL2-20B model with a beam size of 40?", "reference_answer": "26.9%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/Math23k_result_table.png"]}
{"uuid": "ae3f5d69-13d0-5c34-a636-68f8070128cf", "question": "Consider the paper that introduces the model in the LLM section of the table that corresponds to the highest test accuracy. What specific performance improvement does the model proposed in the paper achieve on the GSM8K task when used with PaLM-540B, compared to chain-of-thought prompting?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the LLM section of the table that corresponds to the highest test accuracy. What specific performance improvement does the model proposed in the paper achieve on the GSM8K task when used with PaLM-540B, compared to chain-of-thought prompting?", "reference_answer": "+17.9%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "afa3f602-6fd3-5ab6-a630-f46c4187a839", "question": "Consider the paper that introduces the method where the BIRD benchmark results in the highest execution accuracy for this method. What is the average time-saving percentage achieved by optimizing SQL queries using the two-stage optimization approach on the development set where ChatGPT accurately predicted the results, specifically under the benchmark which demonstrates the highest execution accuracy?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["ba614015-ae38-5939-8106-728d33b07d78"], "reference_pdf": ["b16e8b8f-0d45-58db-b7ec-72837add121d", "befe32c2-c0d6-520c-b7df-ddfcfeb79028", "a0ce147c-98bf-52ba-8365-84983999c80a", "6103a65c-dea4-59ae-bcc4-5f7420478289", "a87515b4-ac31-5ecb-a261-cc3c8d5f4c8b", "0b9362a1-e422-5331-a3ec-a8abc9c8c249", "8ff266a0-ac5b-543b-b908-bdea848acd2d", "79c6d4f0-99c6-5051-bc74-19bc136089f4", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "73172932-ae8b-5d7d-bee0-6bc34aea20e7", "d135e939-c86d-56a7-8840-c346de4706f9", "1d0dae01-2fe3-5971-86b2-965007cceb0c", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "45fbbb5f-4e5d-52b2-8956-84eedc7cba9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method where the BIRD benchmark results in the highest execution accuracy for this method. What is the average time-saving percentage achieved by optimizing SQL queries using the two-stage optimization approach on the development set where ChatGPT accurately predicted the results, specifically under the benchmark which demonstrates the highest execution accuracy?", "reference_answer": "77.75%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18538/result_table.png"]}
{"uuid": "afc250c9-71f6-5b70-81ee-9f34aedd21aa", "question": "Consider the paper that introduces the method that has an accuracy of 82.82% in the CAIL2018 task. What specific methodological weakness does the model proposed in the paper address in the context of learning attention vectors for semantically close law articles, as identified in the comparison with Luo et al.'s (2017) approach?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4f12dd13-6c81-5c0e-90e0-a879ef970a6d"], "reference_pdf": ["e111dd29-50ea-5b75-b563-b1721822b94a", "29258fbc-289f-5221-9c42-16b87d1197b9", "5a1fa4c3-fd03-576e-a4bf-29fd77bec899", "2f6551e2-3835-5c86-9a91-da8b6c8bd429", "2a4d76a8-5d9e-550d-8294-03798da0a973", "34417770-67d7-5cab-b9d4-76999c97bc02", "e4c8595f-5b4c-560d-8306-ea3b13b97928", "42d7a286-5fb0-52be-bd7d-62dc2af2d1c2", "5e549c77-a92b-5ee7-85bc-5a30491d7767", "7eb9a7f2-f640-5526-b434-8d8ff6df167f", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "c3336863-3e6d-56b5-b725-bf73fa23aea9", "33490461-6a37-5409-9d29-f44ad28db91e", "413e7de9-03c4-5c1f-9e42-cd48030c9369", "28e3f907-ee87-5f90-8513-9c64c27051b7", "c023321f-ab7c-57f3-afd8-0f845bca0d1d", "64e5de88-4c23-5099-ac1a-6a8c52b14a49", "d2e0ec1b-f3da-54d8-bda6-b45aa4c22abb", "7908763f-3a9d-5ce5-af59-f68888750583", "df53ebe7-ed7e-56b5-9a14-1c0b4dbe2f7d", "e35f3dc3-713f-5d38-a8d7-2ea61040467d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6324dff1-f1c0-52cb-a0e9-2251c1928303", "2ee016c2-fb4d-5b47-a5cc-d51e4ef61c63", "f6649e84-3c02-54c7-9740-66cc22a0a9da", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an accuracy of 82.82% in the CAIL2018 task. What specific methodological weakness does the model proposed in the paper address in the context of learning attention vectors for semantically close law articles, as identified in the comparison with Luo et al.'s (2017) approach?", "reference_answer": "Learning each law article's attention vector independently, which may result in similar attention vectors for semantically close law articles, hence ineffective in distinguishing confusing charges."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09241/results_table.png"]}
{"uuid": "b00df50c-6939-512e-af98-9643afc1e2c5", "question": "Consider the paper that introduces the dataset that has the fewest number of languages but the most number of SM tasks. What specific linguistic phenomenon mentioned in the paper requires familiarity with social media to interpret correctly in the context of Chinese sentiment analysis?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that has the fewest number of languages but the most number of SM tasks. What specific linguistic phenomenon mentioned in the paper requires familiarity with social media to interpret correctly in the context of Chinese sentiment analysis?", "reference_answer": "Understanding complex linguistic nuances and cultural specificity"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "b0dd70f2-4f05-5635-aa43-e6747919f8ce", "question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. How does its reparameterization of the reward function in terms of the corresponding optimal policy and the reference policy address the under-specification issue inherent in the Plackett-Luce family of models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["d1251ff0-e100-545c-8a1c-664b75854f3c"], "reference_pdf": ["32d04289-3862-5912-a136-6a3d0fe472a2", "3e5b43f1-9b31-5edd-b334-46d5175e1900", "842c1145-6b9e-5d34-bd53-8169d537b66f", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "972a1223-29a4-5304-b9bd-ddec4829d163", "13daa5ee-4b7d-55ec-a5ea-7b19c5cf6e4b", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "37de84b9-2cd0-57ce-8d94-36a43b6c323d", "df2afc9e-2480-567e-84f6-bf4fb97fc1f5", "2adf1c9b-6b9e-59fd-a899-7262b2bd3179", "2ee0ee87-1989-50b9-b896-742ee506c1cc", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "17623cac-c243-591b-b7bc-d261f6ebd607", "f5c3d2bd-4221-5873-a520-589a585f6f93", "ca191c58-f83a-59e0-ad3f-fc6d9a125d9c", "2d4ccd49-4eeb-58ae-bd4f-134be8ae2c11", "945d086d-178d-52d6-aeb4-3988380b6b68", "90aad2c8-22fb-5293-9f5b-58c74b828bc1", "361c3f6a-401c-5854-b618-e7df40b3fa96", "d527d6bb-30ef-5662-971b-78311f082434", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "7169514d-e320-5e1e-8541-b8ca0f8ccc67", "bd4f2699-b1c4-5b76-8e8c-55f84e1e7fe0", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "c7633d80-8236-5a67-a4e5-88fdeadcd1ea", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a239e827-0d3f-5f3a-9757-0b218e376c95", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "342d6620-30f0-5382-b7d7-d3d5f798498f", "e2cbc3e9-68fb-5796-b54d-738df1ac3b67", "d777ea51-80c0-5cd7-873e-3695a75adea4", "880a06dc-f0c4-5e19-9201-2861f952fb32", "3a69cec2-a986-57db-8ea0-bfb4e9e3b548", "8d3ce001-929d-5c83-985e-0268ecc95532", "7908763f-3a9d-5ce5-af59-f68888750583", "dfd4aeaf-4735-5e61-92ff-f8b040f6eb55", "35b48813-1deb-5375-ac6a-948e906c5f54", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "dd073182-00f0-5a9f-800b-7779293ab2ae", "2bc7f244-8607-5501-a3c5-916c66efc615", "e1af3dcf-dee1-50e0-a72b-6c43dc428784", "977a0308-a19f-537c-940c-4064e7796e83", "58b68b03-a6a4-5977-a584-6f7b13dab877", "ebaab94f-c9fb-5186-951c-d7259a580fde", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "d27ee810-3a49-5970-b14a-c71604d54388"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. How does its reparameterization of the reward function in terms of the corresponding optimal policy and the reference policy address the under-specification issue inherent in the Plackett-Luce family of models?", "reference_answer": "By canceling the partition function in the preference model equation, allowing the human preference probability to be expressed solely in terms of the optimal policy and reference policy."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05857/comparison_dpo.png"]}
{"uuid": "b1f2d8b0-3767-597b-a005-0b34cc6e2909", "question": "Consider the paper that introduces the dataset which has the largest number of Queries|Aspects in the OABS category. What specific threshold value was chosen for the matching score to include an abstract sentence in an aspect-based summary in the model proposed by the paper, and how was this value determined?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the largest number of Queries|Aspects in the OABS category. What specific threshold value was chosen for the matching score to include an abstract sentence in an aspect-based summary in the model proposed by the paper, and how was this value determined?", "reference_answer": "0.5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "b3f241f5-c791-5fd4-8e7b-abaca8d3828c", "question": "Consider the paper that introduces the method that has the third highest Avg score on the GLUE task. How does the dimension of the task feature embedding (\\(\\bm{z_{\\tau}}\\)) in the model proposed in the paper compare to the dimension of the task embedding (\\(\\bm{I_{\\tau}}\\))?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the third highest Avg score on the GLUE task. How does the dimension of the task feature embedding (\\(\\bm{z_{\\tau}}\\)) in the model proposed in the paper compare to the dimension of the task embedding (\\(\\bm{I_{\\tau}}\\))?", "reference_answer": "The dimension of the task feature embedding (\\(\\bm{z_{\\tau}}\\)) is \\(t'=512\\), and the dimension of the task embedding (\\(\\bm{I_{\\tau}}\\)) is \\(t=64\\)."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "b64da8d5-6e65-550b-90c9-9b947df76a30", "question": "Consider the paper that introduces the dataset associated with the task 'Hate Speech Spans Detection (HSSD)'. What specific linguistic phenomenon is used as an example to illustrate the challenge of detecting hate speech in the dataset, particularly when comments use phrases that only make sense when read backwards?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset associated with the task 'Hate Speech Spans Detection (HSSD)'. What specific linguistic phenomenon is used as an example to illustrate the challenge of detecting hate speech in the dataset, particularly when comments use phrases that only make sense when read backwards?", "reference_answer": "Puns"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "b6808110-dd11-5068-81e5-5d185181b7a8", "question": "Consider the paper that introduces the method that achieves a higher score than No Graph but a lower score than TOD-Flow using GPT-turbo with SGD in 24 domains. How does the recency weighting in the complexity-regularized ILP method for graph generation from subtask state labels, as proposed in the paper, influence the precondition inference?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["3d664c0a-c339-5327-ac7f-75649bdb338a"], "reference_pdf": ["60fc9153-9d1a-5c9a-ad54-c32d4ab08666", "4818eb61-00f6-5b9a-85c1-021bae7bedeb", "73efee7b-8ec3-56c9-be0c-24a85d109316", "250db219-8940-5f99-9c3a-cce7f8cc8aa8", "16bddbcb-697c-503c-954b-a7e97254d77b", "38ac12d2-26b3-54e0-977a-a396cc1bf1e8", "474fcd7e-fef4-580f-8333-abe02fe9d592", "0716e9d6-0d10-58ca-9afe-76d199106155", "63266047-43b6-5c01-866f-9ed6680939a5", "fa248633-ed2a-5eff-b162-4f28be7b7035", "a06173ea-6789-5ed2-b47b-5048b973ff05", "d1480712-bbfd-569d-b6b5-65ad6aede816", "874df9a4-8882-5470-b472-583f4db25491", "7c5d604c-1932-5a29-af78-55afa1b08aad", "d75cb6f3-13fd-5cf3-b918-afcc2ec09c8e", "4619e153-2d35-52e3-837e-87503e05d70e", "82a4e164-ad3d-57b2-88b5-09376594126d", "a4590e5a-0ff0-5af7-8c22-a67d6a04148c", "7da92b77-adad-501d-908d-7567c57dca50", "77d20de3-ab1b-516d-ba65-ebd1b33ee6f9", "c92baf87-5abf-5c8a-b425-ce9c4f42eb34", "27bb462f-a64d-572a-8061-e56203f7d0af", "3e132e47-5f94-5714-8418-b99db20dbfc1", "3ee4ec6d-b23b-56dd-a29a-4907d2cc9865"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a higher score than No Graph but a lower score than TOD-Flow using GPT-turbo with SGD in 24 domains. How does the recency weighting in the complexity-regularized ILP method for graph generation from subtask state labels, as proposed in the paper, influence the precondition inference?", "reference_answer": "It assigns higher weight to data samples where a subtask has become eligible more recently, influencing the precondition inference by prioritizing recent eligibility over older instances."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04668/comparison_table.png"]}
{"uuid": "b6a96bdc-cd4a-57ee-b294-a9ac93ad8210", "question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. What specific approach does the paper employ to improve the model's ability to generate accurate sentence positions for generative segmentation?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4db47b23-f7bf-5d2e-a957-279ddcc3310c"], "reference_pdf": ["56f3aaed-b2b7-5df1-97cc-7cf6236a892f", "fa9a9ad6-66e9-5bd8-b1a2-862836bceb4b", "c3a61f79-d156-54a9-9888-813475b4d3d1", "0015561a-99bb-5b95-b457-3e43c7751331", "0d601b2e-069f-5bab-ae99-f37eb696b06a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9d2e017c-b25e-5cbc-8493-ccb4d9ab7443", "bcf8872a-b92d-5cbe-8be5-350bcf7d5e15", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "ca40df32-58b7-52fe-b2b5-458f848e4210", "4e513417-bbb2-55e1-b572-ec68a60fc6be", "64ee757d-3fab-5132-aadf-376825399f6b", "edd36969-0b52-50f9-b08c-9b0ba9e514e7", "502590c0-bb29-53ab-8095-a2c68e3e42ab", "3134099b-d3ac-56d3-898d-c77c7a99370e", "1ddc4f93-70fd-5397-a6f3-ee8837ea208e", "afbe2f7a-2754-5da7-97f6-b56a58fe47a4", "eeda9a9d-5d4e-5579-9a3b-f2e546a7bf4b", "00dd4300-de92-5712-9ce8-ccdb844b6314", "3790e4a5-ff47-586a-b09c-c11ab395909d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "510d6fc0-d3e0-5dc1-8e0d-4d470f964287", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. What specific approach does the paper employ to improve the model's ability to generate accurate sentence positions for generative segmentation?", "reference_answer": "Using the $i^\\text{th}$ vocabulary token embedding in place of a fixed BOS token index for the $i^\\text{th}$ sentence."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11772/comparison_table.png"]}
{"uuid": "b73e7c52-3770-59f6-9678-8935024cc8b3", "question": "Consider the paper that introduces the model that achieves the lowest execution accuracy in direct prompting. What specific performance improvement does the LLaMA-7B model demonstrate over the Falcon 40B model in terms of the Commonsense Reasoning benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the lowest execution accuracy in direct prompting. What specific performance improvement does the LLaMA-7B model demonstrate over the Falcon 40B model in terms of the Commonsense Reasoning benchmark?", "reference_answer": "37.5%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/execution_accuracy_figure.png"]}
{"uuid": "b79b9f5e-83f7-56c9-8d99-336b9acb9c70", "question": "Consider the paper that introduces the score described as a \"fine-grained information-theoretic quantity whose expectation value is the amount of usable information (in bits) by the model\". What is the Pearson correlation range for its cross-model estimates in CoLA?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b4ff2883-325e-5089-86a0-fcbdfe4aa6ea"], "reference_pdf": ["9c4fd730-ee1c-555a-87c4-afc7ddb75794", "df911696-4c59-5e6d-95e4-3a2b0dbf9d76", "79a11f77-2549-54a2-8f22-605de4f94ea2", "7872a5b6-7e4d-5e8c-880b-92dc90fffceb", "6b3908c1-247a-56c8-8bcb-3f0364e6049c", "05f9c218-644f-5c4c-81b2-a66f192586c8", "6631eafb-0db6-5c75-a073-435e923e775d", "e0b8da58-c1fd-5d5c-a54a-9eebf13c8df3", "f330aa35-8578-5231-bb8b-ecc1a839b0d5", "5838d821-42b4-537f-827b-a44cdee27083", "0e6f19b8-6abc-54c4-baa8-bec3f656a0ad", "6df0c19b-6f0f-5bc1-b907-93ba1199f4c6", "7908763f-3a9d-5ce5-af59-f68888750583", "22779eba-4d92-5a33-8d44-0a83b31620bd", "e06937ac-c29f-58cf-a06e-8edc0e512327", "b0a10826-741e-5ecb-b386-873cd15ed2b0", "d08af61b-1ed0-5e37-8c83-2067886be82a", "bd08b57b-5d28-587c-ad39-d6b9215574f4", "95a21c10-a2e7-51c9-bb61-fb7a24574eed", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "876d6d80-ede0-5a04-b44a-cc4d227deb54", "93c8fae1-1766-5d56-97e5-9c4dcdfdd6f2", "5b258a8f-7b30-5e2b-8385-6336c6743dde", "d1a89928-6f27-5503-88f8-b373fab1258d", "7bc3c9de-c176-55c5-b340-9ef183168f59", "5fd5cef2-7557-5d69-bdf7-1e1c07184f79", "342ecf12-b25c-57e7-9d47-0e38e1a4ba0b", "769ca490-f11b-5591-84c5-cdbadf78e298", "ff2a876a-d3ce-5d0e-971b-847fd47be51d", "9afe1729-262e-5611-97e6-20ff991d0f25", "df27ecae-a7e1-5c89-a42e-b979691ddb43", "dbe6cf51-ba01-5f0d-83b3-e29f71bafbf1", "2173fe79-3e5b-52f6-bd51-a63b747394c0", "53031c7f-8aa8-5731-aa50-69b321c3665b", "ae11a62b-7d96-5275-9a51-cb1e366a7ff4", "e57a8d67-84e0-5858-99fb-99d57ef4cdd4", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "76df96e7-5638-5f68-b1be-b1051c1e8730"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the score described as a \"fine-grained information-theoretic quantity whose expectation value is the amount of usable information (in bits) by the model\". What is the Pearson correlation range for its cross-model estimates in CoLA?", "reference_answer": "0.40 < r < 0.65"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.16298/description_table.png"]}
{"uuid": "b919d4cf-4d19-5c2e-a519-730d504a9fc4", "question": "Consider the paper that introduces the model that scores a 91.5 in the NER task. What specific aspect of its unified pre-training framework contributes to its effectiveness in reducing the gap between pre-training and fine-tuning phases for AMR tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["eafc1f76-8bd5-594c-90b4-d91531781383"], "reference_pdf": ["5b3aeee6-b982-5fe7-b9b3-6e409408b8ff", "c5534576-a4c3-5084-9038-2c4da11e73ea", "8e6dbffb-603e-551d-8f75-08f37ca07b56", "0a3d5361-f6a6-5a7a-8868-3a1b9387ba2a", "003f56f8-651c-535b-8983-3f448ef1addd", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "1bc8e7cd-fc7a-568e-aa09-c80f67d1e15d", "48eb0527-1a31-5dad-ae9b-832f6138c259", "2ae30032-1e18-5733-b75f-f1d23053f7a2", "8de2532b-6746-59ad-bb7d-7a42ce02682d", "a451e98e-19c1-5141-98d9-bec4da2cb764", "4837c79a-37bb-5d5c-9e26-57d3a5840ca0", "86010c1c-ca15-5fb0-836e-878e2d5b16d5", "c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6", "f6e91a91-0b1e-5280-8522-a20492033f16", "61675c6f-d249-51a5-b949-4ff32c8087d6", "3aec6c04-8061-54a0-b7ec-0910254593e9", "348e185c-b302-5857-bebc-3211c107e7aa", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "96f67ba7-08ce-577a-b675-b560bb668e23", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd22293d-9762-5675-9ef9-60d70e09600e", "4f82b0a7-782b-5d83-abfc-146affe81aea", "87303739-1cdc-53ae-9ca3-9e01d144cd12", "ebaab94f-c9fb-5186-951c-d7259a580fde", "28fbbed5-8ae5-55a0-82be-876292cf5d18", "2bfb964e-fb62-59b5-bb75-05c7fe86ee62", "81f14584-369f-51cd-b3ad-c34dcf1b45a1", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "6d8e0fc1-a6bb-5260-874f-59723d196b81", "d1fe605a-9183-5991-aec7-b474cadcd387"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores a 91.5 in the NER task. What specific aspect of its unified pre-training framework contributes to its effectiveness in reducing the gap between pre-training and fine-tuning phases for AMR tasks?", "reference_answer": "Dynamic masking rate"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11964/comparison_table.png"]}
{"uuid": "baeb4f86-c4e8-5be8-8044-82a8becf6b07", "question": "Consider the paper that introduces the method which is represented by the lavender color. What is the primary goal of discriminatively training CC-LMs with this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is represented by the lavender color. What is the primary goal of discriminatively training CC-LMs with this method?", "reference_answer": "The primary goal of discriminatively training CC-LMs with GeDi training is to make them better discriminators for GeDi-guided generation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "bb19f1cf-57a7-5d2b-964e-8933dc59bb29", "question": "Consider the paper that introduces the method that has an accuracy of 82.82% in the CAIL2018 task. What is the percentage improvement in F1-score for law article prediction on dataset CAIL-big when comparing the model proposed in the paper with the state-of-the-art MPBFN-WCA?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4f12dd13-6c81-5c0e-90e0-a879ef970a6d"], "reference_pdf": ["e111dd29-50ea-5b75-b563-b1721822b94a", "29258fbc-289f-5221-9c42-16b87d1197b9", "5a1fa4c3-fd03-576e-a4bf-29fd77bec899", "2f6551e2-3835-5c86-9a91-da8b6c8bd429", "2a4d76a8-5d9e-550d-8294-03798da0a973", "34417770-67d7-5cab-b9d4-76999c97bc02", "e4c8595f-5b4c-560d-8306-ea3b13b97928", "42d7a286-5fb0-52be-bd7d-62dc2af2d1c2", "5e549c77-a92b-5ee7-85bc-5a30491d7767", "7eb9a7f2-f640-5526-b434-8d8ff6df167f", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "c3336863-3e6d-56b5-b725-bf73fa23aea9", "33490461-6a37-5409-9d29-f44ad28db91e", "413e7de9-03c4-5c1f-9e42-cd48030c9369", "28e3f907-ee87-5f90-8513-9c64c27051b7", "c023321f-ab7c-57f3-afd8-0f845bca0d1d", "64e5de88-4c23-5099-ac1a-6a8c52b14a49", "d2e0ec1b-f3da-54d8-bda6-b45aa4c22abb", "7908763f-3a9d-5ce5-af59-f68888750583", "df53ebe7-ed7e-56b5-9a14-1c0b4dbe2f7d", "e35f3dc3-713f-5d38-a8d7-2ea61040467d", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "6324dff1-f1c0-52cb-a0e9-2251c1928303", "2ee016c2-fb4d-5b47-a5cc-d51e4ef61c63", "f6649e84-3c02-54c7-9740-66cc22a0a9da", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an accuracy of 82.82% in the CAIL2018 task. What is the percentage improvement in F1-score for law article prediction on dataset CAIL-big when comparing the model proposed in the paper with the state-of-the-art MPBFN-WCA?", "reference_answer": "3.18%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09241/results_table.png"]}
{"uuid": "bb5371a1-e041-50fe-a091-4a9ff8f8cdc6", "question": "Consider the paper that introduces the model that has the highest Recall@7 score in the CamRest task. What is the Entity F1 score improvement of the model proposed in the paper, specifically Q-TOD (T5-3B), with oracle knowledge on the SMD dataset compared to its performance with a fine-tuned retriever?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["690e4131-3330-5bd8-9132-669280baa458"], "reference_pdf": ["74ab3845-0eef-54a0-8c11-ec17231ff70f", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "dc374d6f-8af0-5f68-8836-a5734a95f24a", "27a3e973-f2ba-53eb-829b-7bee289d51f2", "4d63e299-19a6-57dd-946b-2f8256c90192", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "aefe2914-5fdb-5ef7-bf50-ad38e28832c4", "d27f5f12-140e-5048-8152-426067d8fad1", "dccb63d4-f203-5a8b-8f8a-10fb38fda9b4", "edf72dc4-d79d-5f52-98de-5c008797474f", "cf0c242a-86be-5d3e-b394-ef45e639af53", "c1f4221a-e7e5-5df3-8d1b-0acc89e315f6", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "493cad14-fb60-56ac-a1dd-0a7756de59cd", "82c7eacc-bdad-5c51-a9f8-651bc244721a", "1e7d9f86-3567-55b8-be98-064a3d297af1", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "772c62b6-0932-5321-86ee-61dccbda8108", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "371fc0fa-bcec-5ffa-95e3-71879321564b", "d24c4e1f-1b12-5af1-a7ea-054861015af6", "42d6954b-5fc1-5d50-9830-1a3db7d6e98a", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest Recall@7 score in the CamRest task. What is the Entity F1 score improvement of the model proposed in the paper, specifically Q-TOD (T5-3B), with oracle knowledge on the SMD dataset compared to its performance with a fine-tuned retriever?", "reference_answer": "1.24%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08877/result_table.png"]}
{"uuid": "bc81a261-f6e3-54ef-9f80-538d421204c2", "question": "Consider the paper that introduces the transformer-based method that achieves the highest MRR score on the FB15kET dataset. How does it ensure the preservation of graph structure while integrating neighbour content?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0b1e6d16-a279-5a83-ae0d-7b8a58bf0355"], "reference_pdf": ["ab8da4b2-8830-5dc2-b901-ca484702bbbe", "8f3a0cf7-ba90-5e39-8e9a-2ebf3b91b288", "437d1762-d8da-56a8-80e2-f6b5e823ad60", "c170861e-b3c6-5f40-bad9-e98ba1f9c2d8", "cc219d54-6f1e-524d-9a4a-dc4d0a5a4eec", "9b027a68-0c67-587b-b01e-1abb132d9f19", "1f670f2d-99fb-58c5-aef3-901c956d9929", "d0b35b26-2b4c-5209-bb22-d8a44032dd05", "3801abe7-8272-532f-bf4e-a10ce43700db", "fbea0c82-5838-5d56-a4c7-3d9737ea7c08", "ab9c34bc-777c-5ba4-9831-a203fa8bd682", "128f2558-545f-58e7-ad6f-50141b4b068f", "35cfee52-9b21-542e-a4a5-dc403ccd4fba", "a208b8d1-6ff3-588a-9334-4195ba7e524c", "b99fd553-6018-563d-820f-d97c0bbe1ea0", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "4675e5b7-915c-5c6f-afeb-c6d437bb8164", "46202f6e-dfd7-5efd-816d-f285579141d0", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "1777f12e-991e-52d4-8b6b-03807d589e87", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the transformer-based method that achieves the highest MRR score on the FB15kET dataset. How does it ensure the preservation of graph structure while integrating neighbour content?", "reference_answer": "The TET approach ensures the preservation of graph structure while integrating neighbour content through the use of a context transformer that integrates neighbours' content in a differentiated way through information exchange between neighbour pairs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12008/comparison_table.png"]}
{"uuid": "bd0ef237-962f-5f84-8682-45976181e14b", "question": "Consider the paper that introduces the method which does not have results in the CSQA2.0 dev and StrategyQA test tasks shown in the table. What is the entropy value for the Winogender task using a basic prompt for the 175B PPO model proposed by this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5bf1e056-9343-55e5-967a-c63726575c9e"], "reference_pdf": ["6a643dcf-5695-5089-ab9c-7d1dd3c04ff4", "e8f47ab4-abbd-5553-b031-4d0d76afab3e", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "345aaf21-19b7-552f-9991-4549ea1995aa", "dccb63d4-f203-5a8b-8f8a-10fb38fda9b4", "80e783a2-8364-5565-8600-93cc7a0b066a", "c7304df5-0d4d-594e-9f83-cb5d9a19b350", "7072220d-1680-5120-b061-9c5d175922e2", "23b2039f-1245-5334-8452-b245c78e29cf", "c1f4221a-e7e5-5df3-8d1b-0acc89e315f6", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "1e7d9f86-3567-55b8-be98-064a3d297af1", "67479dd9-47ba-5b58-bf3d-3ee378a5030f", "3967df69-753f-527b-9c82-35378bcaa943", "2bc7f244-8607-5501-a3c5-916c66efc615", "f8406901-eed8-5981-94c2-92d667fedd98", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "fd9457ae-5f08-5f7f-aed1-f46fa2f20c2d", "7dfb54d5-b8dc-52b1-a79d-a286df0819cd"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which does not have results in the CSQA2.0 dev and StrategyQA test tasks shown in the table. What is the entropy value for the Winogender task using a basic prompt for the 175B PPO model proposed by this method?", "reference_answer": "0.618"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.18397/result_table.png"]}
{"uuid": "bdc55f92-e708-551c-b9f4-3d6d618bd39d", "question": "Consider the paper that introduces the model that has the second lowest MCD 1 score. Which specific variant of the model proposed in the paper showed the most significant performance deterioration on the CLUTRR task when trained on relation lengths k=2,3?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5c7fb1dc-efe9-585f-a52c-656bed6b1c72"], "reference_pdf": ["cb54e44a-db51-5a8d-b3e5-e6387543389a", "c8717e4f-8ff0-5152-8082-266d0bb88071", "9f83b120-1a28-5397-b764-7b99e62db40d", "969d0c84-5046-5233-a9ce-015454c17e10", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "5015464f-7f34-5403-90e6-e0476fd5febc", "ee1e6c69-30cf-5f9e-b4a8-bfb51a657d08", "35ec5422-c394-5eac-854d-28233a5f9f68", "5aab03c9-0e38-5818-90e3-3b5f882ce28d", "565aa06f-5a94-59e2-9b9a-d8de69a00b54", "d6ea3099-8dd9-5844-a96c-388a86582ee8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "00541e26-04b4-520c-8fee-a656c0bc652c", "4d70e58b-2262-56d0-b3ec-957f8d6132d5", "808a8c71-5485-5683-88e6-b4616d8e7ead", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "b0b8f08f-5cc3-51bd-9834-5c7e50ae692e", "d537f355-a76b-5894-856f-7fbd3328d16e", "0dbcbe8e-2d15-50c7-a52a-9aea7f74fa95", "5d15ac0c-f847-534d-ae40-0007ec49f2b0", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "09a1e967-c629-5c69-b12c-782dd3e017ac", "9066c5d4-3831-59c9-b803-b593a6ef8083", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "3134099b-d3ac-56d3-898d-c77c7a99370e", "42fd3669-c60f-5d28-b51d-4523bebf0734", "1f098267-9697-5fbb-bf8f-a585caad8bf8", "9d24c743-9966-5400-a5f9-6825eca1d557", "b80e3d5b-034c-5f7a-9375-022d87904ee4", "c1c0f24c-58ff-5141-8a9e-a279b49c9213", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "0f92bb2b-b658-5689-914a-8c0ef2dffc3a", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "14c9ea98-903d-52bc-b706-f869a7ff6c91", "0494f66b-dc26-5683-9804-25b245ddba54", "69e18e42-778d-5f47-92ec-bdfe3b03ed37", "0956d0ef-a936-5d49-a5aa-9be966fc7470"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the second lowest MCD 1 score. Which specific variant of the model proposed in the paper showed the most significant performance deterioration on the CLUTRR task when trained on relation lengths k=2,3?", "reference_answer": "Value ablation"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/CFQ_table.png"]}
{"uuid": "be9b2802-f7b4-540d-8f1d-f7478a4f8b51", "question": "Consider the paper that introduces the dataset represented by the smallest blue circle. What specific methodological approach did the authors use to mitigate the challenge of tweets being collected in a language different from the query language due to stopwords overlap in a multilingual society like Nigeria?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset represented by the smallest blue circle. What specific methodological approach did the authors use to mitigate the challenge of tweets being collected in a language different from the query language due to stopwords overlap in a multilingual society like Nigeria?", "reference_answer": "To mitigate the challenge of tweets being collected in a language different from the query language due to stopwords overlap, the authors collected tweets based on locations where a language is predominantly spoken, using the location, longitude, latitude, and radius parameters to specify a circular geographic area."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "bf049c55-b17c-54f4-bcf7-7ae19d01c02d", "question": "Consider the paper that introduces the method that exhibits the highest Accuracy@0.5 value on the RefCOCOg task. How does the introduction of the $\\tiny{<}obj\\tiny{>}$ token in the model's output sequence design proposed by the paper impact its performance on the referring expression comprehension task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the highest Accuracy@0.5 value on the RefCOCOg task. How does the introduction of the $\\tiny{<}obj\\tiny{>}$ token in the model's output sequence design proposed by the paper impact its performance on the referring expression comprehension task?", "reference_answer": "Improves by around 1%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "c01016f9-d0e5-5f3f-bacf-922a7d95d9df", "question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Pre-training --> Architectural-based category. What specific performance improvement does the model proposed in the paper, \\textsc{K-Adapter} (F+L), achieve over RoBERTa on the CosmosQA dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Pre-training --> Architectural-based category. What specific performance improvement does the model proposed in the paper, \\textsc{K-Adapter} (F+L), achieve over RoBERTa on the CosmosQA dataset?", "reference_answer": "1.24%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "c0207993-0a90-5e4d-b4e0-f3ffe3f29c2d", "question": "Consider the paper that introduces the model that achieves the lowest execution accuracy in direct prompting. How does the GAtt method, specifically utilized by this model, address the issue of multi-turn consistency in dialogue models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves the lowest execution accuracy in direct prompting. How does the GAtt method, specifically utilized by this model, address the issue of multi-turn consistency in dialogue models?", "reference_answer": "The GAtt (Ghost Attention) method specifically addresses the issue of multi-turn consistency in dialogue models by enabling dialogue control over multiple turns. This is achieved through a process that hacks the fine-tuning data to help the attention mechanism focus in a multi-stage process, ensuring that instructions given at the beginning of a dialogue are respected throughout all conversation turns."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/execution_accuracy_figure.png"]}
{"uuid": "c04dc7f9-23d6-5855-ba62-eb5acd8ba408", "question": "Consider the paper that discusses the dataset that contains 3,747,569 instances. What specific threshold value was chosen for the matching score to ensure the inclusion of abstract sentences in the aspect-based summaries during its construction, and how was this value determined?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that discusses the dataset that contains 3,747,569 instances. What specific threshold value was chosen for the matching score to ensure the inclusion of abstract sentences in the aspect-based summaries during its construction, and how was this value determined?", "reference_answer": "0.5"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "c1009534-d3dc-5573-8dd4-b373e0d27b37", "question": "Consider the paper that introduces the method in the figure that corresponds to the penultimate row. How does the recency weighting in the complexity-regularized ILP method for graph generation from subtask state labels, as proposed by the model, influence the precondition inference?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["3d664c0a-c339-5327-ac7f-75649bdb338a"], "reference_pdf": ["60fc9153-9d1a-5c9a-ad54-c32d4ab08666", "4818eb61-00f6-5b9a-85c1-021bae7bedeb", "73efee7b-8ec3-56c9-be0c-24a85d109316", "250db219-8940-5f99-9c3a-cce7f8cc8aa8", "16bddbcb-697c-503c-954b-a7e97254d77b", "38ac12d2-26b3-54e0-977a-a396cc1bf1e8", "474fcd7e-fef4-580f-8333-abe02fe9d592", "0716e9d6-0d10-58ca-9afe-76d199106155", "63266047-43b6-5c01-866f-9ed6680939a5", "fa248633-ed2a-5eff-b162-4f28be7b7035", "a06173ea-6789-5ed2-b47b-5048b973ff05", "d1480712-bbfd-569d-b6b5-65ad6aede816", "874df9a4-8882-5470-b472-583f4db25491", "7c5d604c-1932-5a29-af78-55afa1b08aad", "d75cb6f3-13fd-5cf3-b918-afcc2ec09c8e", "4619e153-2d35-52e3-837e-87503e05d70e", "82a4e164-ad3d-57b2-88b5-09376594126d", "a4590e5a-0ff0-5af7-8c22-a67d6a04148c", "7da92b77-adad-501d-908d-7567c57dca50", "77d20de3-ab1b-516d-ba65-ebd1b33ee6f9", "c92baf87-5abf-5c8a-b425-ce9c4f42eb34", "27bb462f-a64d-572a-8061-e56203f7d0af", "3e132e47-5f94-5714-8418-b99db20dbfc1", "3ee4ec6d-b23b-56dd-a29a-4907d2cc9865"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure that corresponds to the penultimate row. How does the recency weighting in the complexity-regularized ILP method for graph generation from subtask state labels, as proposed by the model, influence the precondition inference?", "reference_answer": "It assigns higher weight to data samples where a subtask has become eligible more recently, influencing the precondition inference by prioritizing recent eligibility over older instances."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04668/comparison_table.png"]}
{"uuid": "c128b6aa-d550-5204-aef1-bf2744d497c3", "question": "Consider the paper that introduces the model shown on the first line of the table. What is the Dev F1 score for its feature-based approach using the model's base version with embeddings only on the CoNLL-2003 NER task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["eff6094c-a576-5ec6-afae-8313bcf6d538"], "reference_pdf": ["1690c4b3-e4f2-5b00-9eff-84221fa7f0ab", "1f5110f9-63db-5e8e-adef-c2f33b58c5ab", "404bcd7c-20d3-5290-aad4-e056e19d16c1", "8714d81d-6d1e-5732-ac3e-029f7f8ce347", "8860e51f-7c25-5d5c-b0ba-b3726371476c", "a090084d-4a93-5bd5-b857-8b6d674e99a8", "357ce269-1acb-5dec-95f1-33073aa86b0b", "11a21829-d857-5f65-8038-ee3c761ef026", "2697ec60-b994-5ce0-9c67-06ecde1dc5de", "5d8db771-2bdf-5acb-88ec-9572ecc4187b", "bdcbede8-4961-585e-8744-c8c825dd1719", "62b009dd-f233-5060-b1f9-3b23b42dfc2b", "6ea6e60a-4178-50f1-b755-3955a84a9b07", "7c2317c6-aa9d-5ccf-96b6-01037899dd5b", "e488eded-0ba4-58ca-ad26-53799d8e9393", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "7c70448c-cb61-54ea-a9d9-d7ecc5477ba2", "274a4c1b-05a9-54c1-b0eb-24791f11be74", "a2d0d4b5-9596-52df-9c19-667c871cd76f", "558c9b7e-3b09-5823-995f-c881438116a3", "c88a9f90-9a50-5ab9-b5b1-42982d8e7cc7", "9e0baaab-f75d-5b52-b965-a5b427196392", "1de0052f-f719-5c9b-8f53-7df3e9379a0d", "cb64ebe5-e66a-5777-8fe6-7538ffadb7c2", "09db8b38-eab6-58d5-a08b-643db0b5e543", "eee65441-957d-5caa-a5e1-e063d3b1526f", "207e9d08-6c41-5a36-979e-05b3dca39eb3", "8639620d-31d1-5510-bf3f-2cedcfa80b1e", "ffdb65b1-741c-5b1f-8468-2f3601aa347f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown on the first line of the table. What is the Dev F1 score for its feature-based approach using the model's base version with embeddings only on the CoNLL-2003 NER task?", "reference_answer": "91.0"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08298/overall_performance.png"]}
{"uuid": "c24a36e4-0336-5f47-ba19-ff32f5787627", "question": "Consider the paper that introduces the model in the table that has 12M updated parameters. What is the core component of the model that enables the propagation of matching information along the directed edges on KGs?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the table that has 12M updated parameters. What is the core component of the model that enables the propagation of matching information along the directed edges on KGs?", "reference_answer": "matching information propagation module"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_table.png"]}
{"uuid": "c2ff8721-33eb-5dd5-a305-724b8ecaba8d", "question": "Consider the paper that introduces the method for which the BLEU-1 score is missing in the table. How does the performance of the model proposed in the paper, using ground-truth concepts for captioning, compare to using predicted concepts or a mixture of both during training?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e30a2f94-a104-572f-b30f-3ae7ff87f6e7"], "reference_pdf": ["d3c84791-eee6-5f1b-8500-1c0a84375f47", "f8d549ad-783d-591b-9ed4-4be9b95e7d9a", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "6c4dc282-e455-530e-9a34-4900a85e2964", "0a4a6ae4-afd1-5807-8417-fcd4b4809799", "1ad58efb-6d3b-5d50-b516-a01ae90f0787", "ee1dfb4c-7988-5a4c-bb1c-a26a7a03b8bf", "7aa9fab2-572b-5e8c-a92a-7b09e4f4c306", "4d3092f6-d683-5121-b9a5-7fca4ff91894", "a76b882d-198d-56d9-9ced-191f44ac95e8", "c6401b44-ad7a-5948-88ad-b180075d7dbe", "60b654b7-5847-56a5-8aaf-2e22fb679dc2", "0466db28-e878-5df8-8ebf-4a9aa8eb7b8e", "fc840122-59b3-5e1d-8c9b-4469f9395fda", "79c9710e-50b0-5c46-8210-1c5539a5328d", "cffe9204-ae34-53b2-adfc-ba74227619b8", "29322424-fba7-5659-a1df-8acb9f557bd8", "4974e1c8-fbd5-5689-ab45-78f2829161d3", "f4f54d07-2fac-59ba-ad99-7e60fba39833", "7ccc7830-102e-567f-9853-bed1eec59176", "f5b9aa98-8d6c-59b7-8883-d1339aeddd97", "949e1567-7aad-545b-b6ec-f5bad4d8bb4e", "6f26f6da-6cc3-5aa4-9f91-ca29b2d64729", "5baa788b-6e39-5587-8800-43f1801adef3", "69728e8c-59e5-5c53-a3cc-f245d1f7af59", "01d0de9d-f910-5674-841b-39ed4688eed7", "a941564b-e52c-55b7-8ded-59c510643621", "f3fe57c2-c6c8-5707-afaf-8f889823dffc", "facc9abe-bac6-5c51-8c10-0d2c28e15868", "cd71e042-6d38-56be-b014-7b9e02e8733e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "70aa012e-fef9-59af-8957-7d698937f537", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "0ecdf509-8128-595a-9a9f-46dd6d41fd71", "2e3cfef4-fac0-5942-9361-f1321fc394b3", "2b8f1988-37a8-5fc1-b6c3-40b70dd2867f", "d4f2933e-e3ec-5035-bb6c-90041be7751c", "d95266e3-9e89-592a-b1fe-b55d3279249d", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "01d0de9d-f910-5674-841b-39ed4688eed7"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method for which the BLEU-1 score is missing in the table. How does the performance of the model proposed in the paper, using ground-truth concepts for captioning, compare to using predicted concepts or a mixture of both during training?", "reference_answer": "Using predicted concepts leads to optimal results."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.08223/result_table.png"]}
{"uuid": "c3952ea3-74b0-5dc3-9814-b4507b71539f", "question": "Consider the paper that introduces the Seq2Exp model that exhibits the highest test accuracy. Which model employs a unique mechanism to prevent interactive distraction between operators and operands during the generation of numerical reasoning programs?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1afc667d-0a7b-5654-86de-a8dd0f129c65"], "reference_pdf": ["28121b9b-474d-5267-8a7f-389634cd5753", "e111dd29-50ea-5b75-b563-b1721822b94a", "f83ef0d4-1fc2-5ea1-af8c-cd796102bdcf", "a2c41209-de94-53c6-b8f4-e3ec89674d04", "d9c5beed-8c87-581c-81cf-8b1db79123f8", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "360a97d9-1cdd-5af4-8a49-ae052516f7cc", "e11ed198-6669-5f85-94e9-6a0e555b673b", "0549c4b4-e4ca-5867-bfea-64d0fb839a7b", "89f8c643-2644-5b92-aa85-62ee72e389bc", "4f140a35-4eb8-5b0a-9566-dd4d76372980", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "6967d839-7a0b-5f7c-80db-a3c0cb5ab541", "d36fb066-dfe7-529e-a297-824d7ce09c7a", "d64dcf46-f41f-5b04-b4fb-982a96bb816f", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "fd31960a-b7ab-5ea9-a83c-36ebb16ca385", "cd76861c-b9c7-5b15-be82-99658d63f21e", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "2aa5ec32-7ea0-5866-acec-a238cbcafeaa", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "620e5c6e-997e-55e4-aaf9-57f2ae520ff2", "8ebe2cd9-23d6-5b99-9400-a6dc3954c8c9", "68f3ce46-9dec-5694-ac45-89c88c01f117", "539e74fb-ee7a-573f-9bb2-e371025250de", "0c396577-695e-5111-90d1-e0eed97f88b5", "2a656d16-4802-5416-8a55-c85c71969742", "c8cecaee-7c7e-5739-85b7-f0bafd7fbf99", "60ce3df8-4328-502f-ba36-1197ae16b957", "e05cbd04-192e-5761-97ce-7250058cf895", "114ffdfa-8150-5705-8818-1052107f5cff", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "b648afd2-1cf5-5f79-b7f4-46e9f00c2e51", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0b533575-7bb0-5f96-bd18-b94f4ece0fef", "ae0b6058-dc6b-5ac1-a29d-2338f0410b5e", "e61a3438-d8c6-5412-802c-4830aeab7442", "796661a6-0000-5ace-ad8d-b93386a43860", "7244e92a-0f4e-5070-896e-e024d71905be", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "7053312e-12d2-5a47-8d9a-9bb3874f8878", "60a2fda6-e690-557b-b5a5-b4b04de1e0f3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the Seq2Exp model that exhibits the highest test accuracy. Which model employs a unique mechanism to prevent interactive distraction between operators and operands during the generation of numerical reasoning programs?", "reference_answer": "Separating the generation procedures for operators and operands"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09619/MathQA_result_table.png"]}
{"uuid": "c3b58302-feb3-55e9-9be5-5ad6c6fdd9b7", "question": "Consider the paper that introduces the quant method that achieves a lower score than APQ-ViT but still scores higher than 76.0 on Deit-S with a Weight/Activation (W/A) precision of 6/6. What is the specific range of search space for \\(\\Delta_{\\text{R1}}^s\\) during post-softmax quantization as mentioned in the experiment settings?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87c327a8-cd52-5d23-93de-c4486887da8b"], "reference_pdf": ["bc431e93-410f-5eb0-a4a5-314a37e129a0", "34417770-67d7-5cab-b9d4-76999c97bc02", "720ede7a-1362-532b-b4b5-4436c03c5363", "95808d88-d437-55ec-9af6-cb7399b1010c", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "60495988-448a-5919-9470-d8561310a40d", "81528b8c-c326-567e-a3ed-4ca2b0295ff2", "52d72671-969b-5840-8808-73be9745a07f", "720ede7a-1362-532b-b4b5-4436c03c5363", "93502213-3277-5df7-a02f-39b12077c0c2", "08e29bf5-665b-561e-8672-d90363383d43", "e7184da4-f850-5562-ba39-441760b58a7d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "3b9340d4-5374-5613-a1a4-bc3c125639c6", "7908763f-3a9d-5ce5-af59-f68888750583", "1ffa6ac4-663b-5498-84b3-3148948fcba4", "332d0f2a-9d5a-54b3-8d5e-e24081633c0e", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "b9f85125-14a8-502f-8717-f38768038090", "acce625f-be46-56f5-b5f6-13b331e2efdf", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "b9fa129c-7848-536a-b464-b4090dd72a9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the quant method that achieves a lower score than APQ-ViT but still scores higher than 76.0 on Deit-S with a Weight/Activation (W/A) precision of 6/6. What is the specific range of search space for \\(\\Delta_{\\text{R1}}^s\\) during post-softmax quantization as mentioned in the experiment settings?", "reference_answer": "\\([\\frac{1}{2^{k}},\\frac{1}{2^{k+1}},...,\\frac{1}{2^{k+10}}]\\)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16836/comparison_table.png"]}
{"uuid": "c40b5a0e-b5a6-5e9a-8f96-fd34b69fac9b", "question": "Consider the paper that introduces the method shown in the table that demonstrates the highest BLEU-1 score for the Test Seen task. What is the primary reason for the degeneration of neural language models as identified in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c1a8f43-9394-59e5-b73c-ad4f9306e57d"], "reference_pdf": ["0d40e5ba-8bd1-5835-99fa-82735099730a", "79fb9402-0283-5c7a-ae54-72967aec6549", "0e564d1d-6aaa-59bb-8be4-6bc51657f150", "9f4c8e70-1c59-506c-acd1-9396e1bdaca4", "5d766fc4-866a-51f1-ab46-6edcf811da10", "e7fd4df5-9610-55db-bbc0-5e4dc59f1a82", "dc69ab19-1148-5de0-88be-2c610277ffd8", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "31dcceac-3a4d-5402-95db-072a568513a0", "a239e827-0d3f-5f3a-9757-0b218e376c95", "af825ce1-e5f8-5bd6-8d57-b9fb30859749", "2d2a70db-7f2b-5c64-ac09-7c53c67628ed", "379fd373-9dae-52dd-aeaf-1db616b52199", "45623893-36dd-538c-baee-ee76f85adef7", "22779eba-4d92-5a33-8d44-0a83b31620bd", "e2f6853e-82cd-5b6d-9880-5f2677fd92a5", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "35b48813-1deb-5375-ac6a-948e906c5f54", "393e9431-63b0-589d-88bb-62335baaf8bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "977a0308-a19f-537c-940c-4064e7796e83", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "2820cbba-a917-5456-b732-e1e8972ede48", "d763c0b0-1131-555a-8861-c96dad3901b9", "427a6763-1a3c-5d70-b6d4-f7e4e8cca2e2", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "d51a9214-fff1-52cb-8bbc-d55f87c0cd9c", "59ea8eee-d229-5bcf-b743-f5c5527a6644", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the table that demonstrates the highest BLEU-1 score for the Test Seen task. What is the primary reason for the degeneration of neural language models as identified in the paper?", "reference_answer": "The anisotropic distribution of token representations"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08943/result_table.png"]}
{"uuid": "c4648f5e-da21-5fbb-9b96-d91bbd29c41a", "question": "Consider the paper that introduces the method that is represented by the purple line. What specific methodological adjustment is made to its variant, MMA-H, to address the potential issue of outlier attention heads affecting latency or attention span?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is represented by the purple line. What specific methodological adjustment is made to its variant, MMA-H, to address the potential issue of outlier attention heads affecting latency or attention span?", "reference_answer": "attention variance loss to MMA-H"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "c4860271-bd66-52d3-b679-8b9f65c54af3", "question": "Consider the paper that introduces the last method shown in Explicit --> Retrieval-enhanced --> Multi-Stage category. What is the percentage improvement in accuracy for LLaMA-7B + the model proposed in the paper (zero-shot) on the CommonsenseQA dataset compared to its baseline without the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the last method shown in Explicit --> Retrieval-enhanced --> Multi-Stage category. What is the percentage improvement in accuracy for LLaMA-7B + the model proposed in the paper (zero-shot) on the CommonsenseQA dataset compared to its baseline without the model proposed in the paper?", "reference_answer": "38.54%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "c4918abd-1963-5444-b9e7-8e8fbb479fe7", "question": "Consider the paper that introduces the model in the figure corresponds to the grey line with a star marker. What specific preprocessing steps were applied to the XML files during the data curation process for StarCoderBase?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the figure corresponds to the grey line with a star marker. What specific preprocessing steps were applied to the XML files during the data curation process for StarCoderBase?", "reference_answer": "Implemented a simple XML filter that checked for the presence of '<?xml version=' within the first 100 characters of the file."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/average_relative_performance.png"]}
{"uuid": "c493119b-e2bd-5122-8a7f-fcf014f95f8d", "question": "Consider the paper that introduces the model that results in the highest Self-BLEU score on the TellMeWhy dataset. What specific methodological approach does the paper propose to address the challenge of generating high-cognitive-demand educational questions from children's storybooks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5cb4f0ee-6979-5de3-9228-7707e6240704"], "reference_pdf": ["78b201f5-8cc7-5580-a1e9-3e61fd50a3b0", "412f0d4e-18e1-50b9-9029-b2f3dc0f7eff", "a239e827-0d3f-5f3a-9757-0b218e376c95", "c74ec7cd-9861-5651-92d8-d1a4d5ac53e5", "93607ae8-285d-57c6-a6ec-c6a7cf55f65c", "c48ce7f0-0f60-568a-a32a-61dac182a786", "6f6a00e8-6bd2-5287-ab63-6b0b5f3e422d", "6440959d-ac81-5a2c-ae6e-9082bf5ee380", "28a47974-2035-5575-9a75-7df451faf18d", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "39abfac3-551a-5cad-a486-e4eb0b2ea283", "f6e91a91-0b1e-5280-8522-a20492033f16", "822d7c33-cc29-503d-96f9-a82f49f90f06", "977a0308-a19f-537c-940c-4064e7796e83", "d086f9d2-e87c-5292-925f-26f489250673", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "e756a768-abbe-52e1-8416-6c24deaa43ff", "f96ef4a4-88c2-52dd-bcad-82b7d77045f0", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "101950db-b673-5061-9500-147447bfddc8", "58914b28-03d1-528c-aca8-2bcc19b55aac", "88affa18-ec3f-5871-857f-7c83b4732075", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that results in the highest Self-BLEU score on the TellMeWhy dataset. What specific methodological approach does the paper propose to address the challenge of generating high-cognitive-demand educational questions from children's storybooks?", "reference_answer": "The paper proposes a novel framework that combines question type prediction and event-centric summarization to generate educational questions for storybooks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16446/tell_me_why_table.png"]}
{"uuid": "c49c795a-11fa-530a-9d36-db1bebd4db34", "question": "Consider the paper that introduces the model that has the highest relative performance in few-shot prompting. What specific performance improvement does the model proposed in the paper demonstrate over the Falcon 40B model in terms of the Commonsense Reasoning benchmark?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the highest relative performance in few-shot prompting. What specific performance improvement does the model proposed in the paper demonstrate over the Falcon 40B model in terms of the Commonsense Reasoning benchmark?", "reference_answer": "37.5%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/prompt_setting_figure.png"]}
{"uuid": "c587f823-2339-57cb-92e0-4bac3b365cd2", "question": "Consider the paper that introduces the last method shown in Implicit --> Continual Learning --> Continual Knowledge Editing category. What is the impact of varying the $\\epsilon_\\text{init}$ parameter on the number of keys used by GRACE for 1000 edits on zsRE when editing T5's block 4?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the last method shown in Implicit --> Continual Learning --> Continual Knowledge Editing category. What is the impact of varying the $\\epsilon_\\text{init}$ parameter on the number of keys used by GRACE for 1000 edits on zsRE when editing T5's block 4?", "reference_answer": "Increasing $\\epsilon_\\text{init}$ reduces the number of keys used by GRACE for 1000 edits on zsRE when editing T5's block 4."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "c6946afe-6c7a-5b00-bc98-c8713e7561ee", "question": "Consider the paper that introduces the method that is shown in the fourth row of the table. What specific implementation detail is suggested to improve the stability of policy and value learning in the model proposed in the paper, MAPPO, when dealing with the non-stationarity of Multi-Agent Reinforcement Learning (MARL) environments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["db2cacba-a6d6-5de3-8b45-95a4a07883c3"], "reference_pdf": ["8de6d12b-9dcd-5a37-aaf6-c9295ce1e8a9", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "74746a87-dab3-59c9-be08-3ecfcf6438eb", "3141fa52-db69-539c-8979-fbae34e9747a", "02193a94-398e-57da-bb53-0c5800ca743a", "fbe2cad7-8871-57e9-99a5-041bd72a96d1", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "3b56c40b-e3c0-5ab0-8303-818cadcbfd0b", "95286e49-8ec0-51d4-b4af-8a0cb4b59b63", "feb416bd-1fd2-59c4-b5e3-5cd152775a17", "56bb5074-0a00-578b-ad44-e24096458b1e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "a84ef890-5c36-506a-b8ea-79837d85ae3b", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "446b417e-0e23-5098-afe3-0790a06ab23e", "25b64ade-68d0-5d1f-a552-4169ec42054f", "d22f49c8-5ad1-5151-adaa-41d9c94fdbc0", "118cac21-d91b-55b6-bfce-0742348b4c2d", "79a7862f-22dd-56b1-affd-42f774cf64fb", "172b7dad-d436-5ced-9eb4-0f5702d227b2", "dd21cb7c-5752-5764-b486-bbf8f2e53f84", "177b1aea-89bc-52c2-bf91-6f27f1964f71", "34ef8fe5-e5a0-5401-8a39-e8944a3ea356"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is shown in the fourth row of the table. What specific implementation detail is suggested to improve the stability of policy and value learning in the model proposed in the paper, MAPPO, when dealing with the non-stationarity of Multi-Agent Reinforcement Learning (MARL) environments?", "reference_answer": "Limiting the change in the agents' policies by using fewer epochs per update"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10701/result_table.png"]}
{"uuid": "c7393fd7-2e7d-512f-92a6-cfbaea54ae97", "question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. Based on the ablation studies, what specific performance gain does the Span Boundary Objective (SBO) provide over span masking alone in coreference resolution on the development set?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1821bd0b-d55e-5dbf-bfcd-2fde02a07633"], "reference_pdf": ["67602490-afd8-569f-b463-35cd7a8a7b46", "4d856727-33a4-59aa-90a6-6245d8bd1918", "778c3b86-7d0f-58fa-b177-972efaec7c5f", "ca80f95d-2b88-55ca-ab3f-8f7c86b723e4", "0c61720f-b625-5082-b5fe-8fbc3206d656", "51b6e073-e1a7-51c0-8a23-314d84c6d9cd", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "afc322a1-0cca-5ce0-9e44-3b904630f337", "5be16d27-4c22-576f-be7f-16715bf49ffc", "fad9fe2b-872e-5d61-9149-ef7c915db5a4", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "7c278568-4bb8-5a1f-af34-4df3980282eb", "d2e0dc47-0423-50ea-9dd9-872548a733d2", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "09523922-5ff7-5682-9e59-2b903b7d7a35", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "52f46313-b1a0-5e5e-b415-a54c42ca1496", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "cb57171c-5fc1-56c6-b168-4d122a1427cd", "ca236447-69ca-57c4-8a5c-8891e4230b8b", "9e0baaab-f75d-5b52-b965-a5b427196392", "e3c2e045-3afc-5d1d-aad1-3389f80aea7f", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "cf94c43f-2a86-5ba2-a52d-20126e193c68", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. Based on the ablation studies, what specific performance gain does the Span Boundary Objective (SBO) provide over span masking alone in coreference resolution on the development set?", "reference_answer": "2.7% F1"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14478/comparison_table.png"]}
{"uuid": "c7900d38-8816-5a85-b531-0c3e1c021bd0", "question": "Consider the paper that introduces the method that has a score of 71.4 in the CB dataset with 4-shot prompting. What is the specific performance improvement (in percentage points) observed on the SuperGLUE benchmark when using the T5 XXL model compared to the baseline Prompt Tuning?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a score of 71.4 in the CB dataset with 4-shot prompting. What is the specific performance improvement (in percentage points) observed on the SuperGLUE benchmark when using the T5 XXL model compared to the baseline Prompt Tuning?", "reference_answer": "+2.4"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "c7abc8e4-9e18-5143-b34c-13a3a67db09f", "question": "Consider the paper that introduces the dataset that corresponds to the last row of the table. Which specific error type in the error analysis indicates a failure due to the model proposed in the paper's inability to understand comments with indirect and disrespectful references?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that corresponds to the last row of the table. Which specific error type in the error analysis indicates a failure due to the model proposed in the paper's inability to understand comments with indirect and disrespectful references?", "reference_answer": "Allusion: The comment refers to another person or subject in an indirect and disrespectful way."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "c7b847e2-1819-5461-8a0a-3b1eebec1d13", "question": "Consider the paper that introduces the model shown in the figure that is consistently better than MPT-7B-Instruct but consistently worse than LLaMA-30B. What is the percentage of responses flagged as toxic using a toxicity classifier in the RealToxicityPrompts evaluation for the model's base version?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the figure that is consistently better than MPT-7B-Instruct but consistently worse than LLaMA-30B. What is the percentage of responses flagged as toxic using a toxicity classifier in the RealToxicityPrompts evaluation for the model's base version?", "reference_answer": "0.42"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/average_relative_performance.png"]}
{"uuid": "c80033a2-988c-5157-a4c6-959235c442dc", "question": "Consider the paper that introduces the first method shown in Explicit --> Internet-enhanced category. What specific method was used in the experimental setup to condition the model proposed in the paper on shorter excerpts extracted from the retrieved documents, and how was the relevance of these excerpts to the question determined?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in Explicit --> Internet-enhanced category. What specific method was used in the experimental setup to condition the model proposed in the paper on shorter excerpts extracted from the retrieved documents, and how was the relevance of these excerpts to the question determined?", "reference_answer": "TF-IDF embeddings and cosine similarity"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "c9b18ca9-ca29-54ab-9ab7-abfaa0286663", "question": "Consider the paper that introduces the model depicted in the figure that exhibits the highest fluctuation. What specific transformation rule is applied by the model proposed in the paper to construct disfluent summaries for the fluency dimension in text summarization?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["872650ac-af1b-5ead-bff8-975b0ce8d32d"], "reference_pdf": ["cd28f82e-0927-58c3-b17d-bfd6b5888b79", "3c47cf47-b671-55d5-a396-e294638f7023", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "450c1e1c-8f69-5d85-9a26-df3a876f65e1", "fe26770b-ff50-56e9-8546-8310b7215de7", "43042c01-285d-53a4-8e75-a14921ddd5b7", "060cedb0-10c7-53d3-a4f3-4610a1cb854f", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "deef91b8-6c7c-5fbc-b196-a248c88cb07b", "e3b247ba-4ea5-5d11-9653-e6df72b1c84d", "8bd7983c-5a5b-50cb-99ab-62297274885c", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "6106e3f0-e82c-5ded-a9c2-0d8444beb47b", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "917794fc-6091-585f-9aca-18d5d7fe492b", "98f94381-9ab9-5337-a63e-99c8ad892b6f", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "dea2fddd-8066-5173-ab2b-c960d55f2de1", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "85ba33aa-25d1-526b-a87d-42cfd55a08c9", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "eb251b7d-833d-54cd-9374-0481e7af7292", "c50df058-1617-58f1-9b89-c397fcdceb6f", "f3354010-9feb-5b44-afec-0f6be57ca4d6", "03280b0e-c24d-50a6-a988-b6ca1b7d3519", "ab8d017f-8645-5337-aa84-f52783391b99", "67f97fa1-4d75-5346-8e7f-4701de843e11"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model depicted in the figure that exhibits the highest fluctuation. What specific transformation rule is applied by the model proposed in the paper to construct disfluent summaries for the fluency dimension in text summarization?", "reference_answer": "We randomly draw a span from the positive sample and perform one of repeating, deleting, and shuffling to obtain the disfluent summaries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13189/calibration_figure.png"]}
{"uuid": "c9ed6584-07a0-5f4e-a7cc-f731f1ac3552", "question": "Consider the paper that introduces the method that scores higher than 69.0 but lower than 70.0 in the Forgotten Realms category. How does the model proposed in the paper leverage the generated synthetic data to improve the quality of few-shot entity linking?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["e5476c7f-2b14-520b-81df-8783aebf59f5"], "reference_pdf": ["e897e2cd-c196-532e-8273-358b4878e270", "7e10ecb3-9428-53a7-8edf-83c7f2ca9bbe", "e0f03057-5bdd-575d-a691-7493ccc1bfb9", "98ac518b-1b74-562f-9913-2a494f1417c2", "f781ad75-0ee9-572a-bf0e-6ec0c4faf7c2", "cb764bcf-9005-5541-8cf0-55e47ee0ff91", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "c2e3ddd3-4f57-5c12-a0d9-89130bfbd6e6", "560b3014-4a65-57cc-bda5-e3610828782e", "071d6f10-df74-5f8a-ba5f-4b3cfa33e65b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that scores higher than 69.0 but lower than 70.0 in the Forgotten Realms category. How does the model proposed in the paper leverage the generated synthetic data to improve the quality of few-shot entity linking?", "reference_answer": "The MetaBLINK model leverages the generated synthetic data to improve the quality of few-shot entity linking by using a meta-learning mechanism to automatically assign different weights to each synthetic entity-mention pair. This approach allows the model to exploit rich semantic information from the synthetic data more effectively, leading to improved training and performance on few-shot entity linking tasks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12444/comparison_table.png"]}
{"uuid": "ca919941-9a11-55ca-a851-94f9e79052c2", "question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Pre-training --> Replay-based category. What is the specific reason for introducing random noises into the newly copied parameters during the width expansion process in this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Pre-training --> Replay-based category. What is the specific reason for introducing random noises into the newly copied parameters during the width expansion process in this method?", "reference_answer": "To break the symmetry after the replication and accelerate later pre-training."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "cb1851ef-a53c-5490-939e-023633c366bd", "question": "Consider the paper that introduces the method that has 638K tunable parameters. What is the dimension of the task embedding (I_\\tau) used in the experiments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has 638K tunable parameters. What is the dimension of the task embedding (I_\\tau) used in the experiments?", "reference_answer": "64"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_table.png"]}
{"uuid": "cbd95b3f-1d15-5105-a65d-35c23a1a3857", "question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. What specific advantage does its span boundary objective (SBO) provide over BERT's next sentence prediction (NSP) objective in terms of model performance on coreference resolution?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1821bd0b-d55e-5dbf-bfcd-2fde02a07633"], "reference_pdf": ["67602490-afd8-569f-b463-35cd7a8a7b46", "4d856727-33a4-59aa-90a6-6245d8bd1918", "778c3b86-7d0f-58fa-b177-972efaec7c5f", "ca80f95d-2b88-55ca-ab3f-8f7c86b723e4", "0c61720f-b625-5082-b5fe-8fbc3206d656", "51b6e073-e1a7-51c0-8a23-314d84c6d9cd", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "afc322a1-0cca-5ce0-9e44-3b904630f337", "5be16d27-4c22-576f-be7f-16715bf49ffc", "fad9fe2b-872e-5d61-9149-ef7c915db5a4", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "7c278568-4bb8-5a1f-af34-4df3980282eb", "d2e0dc47-0423-50ea-9dd9-872548a733d2", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "09523922-5ff7-5682-9e59-2b903b7d7a35", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "52f46313-b1a0-5e5e-b415-a54c42ca1496", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "cb57171c-5fc1-56c6-b168-4d122a1427cd", "ca236447-69ca-57c4-8a5c-8891e4230b8b", "9e0baaab-f75d-5b52-b965-a5b427196392", "e3c2e045-3afc-5d1d-aad1-3389f80aea7f", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "cf94c43f-2a86-5ba2-a52d-20126e193c68", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an F1 score of 87.63 in the Token (I-topo) category. What specific advantage does its span boundary objective (SBO) provide over BERT's next sentence prediction (NSP) objective in terms of model performance on coreference resolution?", "reference_answer": "2.7% F1 improvement"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14478/comparison_table.png"]}
{"uuid": "cbe2e9fa-5096-5b03-806d-267226961e9d", "question": "Consider the paper that introduces the method that achieves sentence-level precision of 60.32. What specific implementation detail of its attention mechanism allows the model proposed in the paper to efficiently handle sequences of up to 32K characters on modern GPUs?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["79a856b0-ea50-5dad-b4a1-f0f0c8e17443"], "reference_pdf": ["8ad564f3-f634-5b41-9dbb-c7b55efd34ed", "4774dafb-8266-57ac-ba3b-3fb7302f43e8", "e544d7c3-0ea0-5f06-accd-9044fb2df8ce", "2ad75cc6-aa85-532e-a8cc-d487ad70ac1d", "8ac0dc8f-2cdc-5363-ab17-2cbe2cd98611", "7913138b-027d-5e7a-a4f9-c94fa676607b", "501de3a1-2bdc-5bea-9259-4731a2df35ab", "68be5d29-f16d-506f-a4e5-215438f13409", "9dab5ed2-4f76-52b3-b13a-ee7c9342d254", "64ee757d-3fab-5132-aadf-376825399f6b", "a672b5e1-0460-5bcf-9f96-189e0687079d", "19037637-5fca-5021-a9c2-464b3eaf7fb1", "167219f2-ecf4-59b5-8ea1-cdcb400400b2", "7eb3a633-8d11-5b91-af60-4030ff538882", "aefc8eb9-7238-561a-8055-858362dc6a0c", "3157ccdb-a5d3-5ddb-93af-99dcbba44f15", "f9ea4f73-3191-5d9c-8121-e490cc81af65", "2e88d873-bc67-51d3-a17e-8eda7c844dd6", "79c58b97-75e2-590f-ab73-90c71c7af2a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "4fd8fdc1-1bd4-58dd-9c4e-0659d9c11ee4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "167219f2-ecf4-59b5-8ea1-cdcb400400b2"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves sentence-level precision of 60.32. What specific implementation detail of its attention mechanism allows the model proposed in the paper to efficiently handle sequences of up to 32K characters on modern GPUs?", "reference_answer": "The use of a combination of windowed and a new dilated attention pattern."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18544/result_table.png"]}
{"uuid": "cc39b288-cf82-54a9-bf1a-2092e69c8ae6", "question": "Consider the paper that introduces the model that corresponds to the penultimate row of the table. What is the observed accuracy drop percentage for the model proposed in the paper on the FewRel dataset for relations with maximum similarity in the range [0.85, 1.00)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the penultimate row of the table. What is the observed accuracy drop percentage for the model proposed in the paper on the FewRel dataset for relations with maximum similarity in the range [0.85, 1.00)?", "reference_answer": "9.7"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "cc7dfc28-9bf7-5db5-a17f-4d87d423011a", "question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Knowledge Editing category. What specific hyperparameters were searched for and what were their final selected values for the OnlineEWC method, as it relates to CMR?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the first method shown in the Implicit --> Continual Learning --> Continual Knowledge Editing category. What specific hyperparameters were searched for and what were their final selected values for the OnlineEWC method, as it relates to CMR?", "reference_answer": "$\\lambda_{\\text{EWC}}=5$ and $\\gamma_{\\text{EWC}}=0.9$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "cc8b587f-2dd8-57d6-8195-d5bbcd247c8c", "question": "Consider the paper that introduces the model that demonstrated the highest improvement in performance on the DuConv dataset when normalized topics were introduced. What specific metric was most significantly affected?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that demonstrated the highest improvement in performance on the DuConv dataset when normalized topics were introduced. What specific metric was most significantly affected?", "reference_answer": "norm generation, F1/BLEU1/BLEU2"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "ccf54fa9-1998-5ae0-9ecd-b5b2f4a55e62", "question": "Consider the paper that introduces the model that shows 0 accuracy in the COGS-structural dataset. What specific achievement does it demonstrate over RNN sequence-to-sequence models when trained solely on the WSJ training set for English constituency parsing?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["6b729c10-15e8-5eaa-8b40-8c8eafbd3ddb"], "reference_pdf": ["eb603d6c-2a60-504d-93ed-aef55ff4655b", "e1e2bf66-bde7-58c0-98f6-6414d50c1311", "34417770-67d7-5cab-b9d4-76999c97bc02", "776bb6da-c5c2-5c73-b8ac-f038fc55bb6a", "9c9e036b-576a-5a70-923f-4d33da527760", "1cbc9c7a-e562-5d6a-af83-4f9a1520dce2", "ce99c350-ea64-53eb-b705-c33884619d64", "53504791-99de-5143-a351-a080bdcc3bc8", "1d0cd268-ff7e-55d2-8ee5-178092342836", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "696b4e72-71ad-5357-b60a-7cd5121619dc", "a4c0cf83-a1d0-57b1-84d9-9b7d365f5ad9", "9775a2f4-5880-5569-8cff-46fce5420bf0", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "2eaf2338-0cce-5f50-8917-338a927b7e1a", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "42fd3669-c60f-5d28-b51d-4523bebf0734", "24c55b93-968f-5a40-8520-acfd6229bde6", "ea02c473-42cb-5fbe-9287-aea0fa4a842e", "e5036d4f-b1eb-5a28-b5e0-4887f14183d2", "837e7fdc-f434-546f-9a83-81afc1529b90", "ff84e2fe-51c3-5208-8002-402a7d477b19", "94993d82-6d3b-5b04-b25f-13e33faf6822", "4fe1db4a-687c-55c3-b8c1-3c6ca2a8b302", "0ce323c7-bde8-560b-98c9-6c2c9b5cdf08", "47cbfa6b-6a2f-521e-a7e2-19a3c3460b47", "42fd3669-c60f-5d28-b51d-4523bebf0734"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that shows 0 accuracy in the COGS-structural dataset. What specific achievement does it demonstrate over RNN sequence-to-sequence models when trained solely on the WSJ training set for English constituency parsing?", "reference_answer": "Outperforms the BerkeleyParser"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15040/accuracy_figure.png"]}
{"uuid": "cd3f5dd0-60eb-5016-abd5-30181c1ef83e", "question": "Consider the paper that introduces the method which exhibits a score of 34.9 in the Acc-7 metric on MOSI. What specific aspect of spoken language dynamics does the Spoken Language Embedding Subnetwork in the model proposed by the paper focus on to handle the volatile nature of spoken opinions?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which exhibits a score of 34.9 in the Acc-7 metric on MOSI. What specific aspect of spoken language dynamics does the Spoken Language Embedding Subnetwork in the model proposed by the paper focus on to handle the volatile nature of spoken opinions?", "reference_answer": "The Spoken Language Embedding Subnetwork focuses on building models that are capable of operating in the presence of unreliable and idiosyncratic speech traits by focusing on important parts of speech."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "cd58ede0-844f-5f71-8438-f2849cc2fe0e", "question": "Consider the paper that introduces the method whose results are displayed in a lighter grey color in the table. How does the model's performance on the visual question answering (VQA) task compare when using images of resolution 480x480 versus 640x640 during finetuning?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method whose results are displayed in a lighter grey color in the table. How does the model's performance on the visual question answering (VQA) task compare when using images of resolution 480x480 versus 640x640 during finetuning?", "reference_answer": "An improvement"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "ce012678-0ea0-5416-a899-d1e220e07478", "question": "Consider the paper that introduces the method that achieves an MRR score equal to 0.717 in the FB15kET dataset. What are the three distinct mechanisms that compose its approach, known as Transformer-based Entity Typing (TET), and how does each contribute to the task of knowledge graph entity typing?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0b1e6d16-a279-5a83-ae0d-7b8a58bf0355"], "reference_pdf": ["ab8da4b2-8830-5dc2-b901-ca484702bbbe", "8f3a0cf7-ba90-5e39-8e9a-2ebf3b91b288", "437d1762-d8da-56a8-80e2-f6b5e823ad60", "c170861e-b3c6-5f40-bad9-e98ba1f9c2d8", "cc219d54-6f1e-524d-9a4a-dc4d0a5a4eec", "9b027a68-0c67-587b-b01e-1abb132d9f19", "1f670f2d-99fb-58c5-aef3-901c956d9929", "d0b35b26-2b4c-5209-bb22-d8a44032dd05", "3801abe7-8272-532f-bf4e-a10ce43700db", "fbea0c82-5838-5d56-a4c7-3d9737ea7c08", "ab9c34bc-777c-5ba4-9831-a203fa8bd682", "128f2558-545f-58e7-ad6f-50141b4b068f", "35cfee52-9b21-542e-a4a5-dc403ccd4fba", "a208b8d1-6ff3-588a-9334-4195ba7e524c", "b99fd553-6018-563d-820f-d97c0bbe1ea0", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "4675e5b7-915c-5c6f-afeb-c6d437bb8164", "46202f6e-dfd7-5efd-816d-f285579141d0", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "1777f12e-991e-52d4-8b6b-03807d589e87", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an MRR score equal to 0.717 in the FB15kET dataset. What are the three distinct mechanisms that compose its approach, known as Transformer-based Entity Typing (TET), and how does each contribute to the task of knowledge graph entity typing?", "reference_answer": "The three distinct mechanisms that compose the Transformer-based Entity Typing (TET) approach are:\n\n1. **Local Transformer**: This mechanism focuses on encoding the information provided by each neighbor of an entity independently. It helps in inferring missing entity types by considering the local context around an entity, allowing for a detailed understanding of immediate relationships.\n\n2. **Global Transformer**: This mechanism aggregates the information from all neighbors of an entity into a single long sequence. It enables the model to reason about more complex entity types by considering the global context and the collective influence of all neighboring entities.\n\n3. **Context Transformer**: This mechanism integrates the content of neighbors in a differentiated way through information exchange between neighbor pairs, while preserving the graph structure. It enhances the model's ability to understand the context of each entity by considering how different neighbors relate to each other and to the entity in question.\n\nEach mechanism contributes to the task of knowledge graph entity typing by encoding different levels of context (local, global, and relational) around an entity, thereby improving the model's ability to accurately infer entity types."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12008/comparison_table.png"]}
{"uuid": "cf85e6d1-11f1-5014-93c4-b86b3288eeef", "question": "Consider the paper that introduces the method that has three empty entries in the table for the mathematical reasoning and commonsense reasoning tasks. What specific modification to the few-shot prompts used in the model's, proposed by the paper, CoT generation is highlighted as a key factor for improving the quality of generated data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has three empty entries in the table for the mathematical reasoning and commonsense reasoning tasks. What specific modification to the few-shot prompts used in the model's, proposed by the paper, CoT generation is highlighted as a key factor for improving the quality of generated data?", "reference_answer": "Providing the model with the target after posing the question and before providing example CoT."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "d07eada2-2084-528c-9e8b-3e64f45782fc", "question": "Consider the paper that introduces the dataset shown in the second row of the table. Based on the experimental results on this dataset, which model demonstrated the highest improvement in performance when normalized topics were introduced, and what specific metric was most significantly affected?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset shown in the second row of the table. Based on the experimental results on this dataset, which model demonstrated the highest improvement in performance when normalized topics were introduced, and what specific metric was most significantly affected?", "reference_answer": "norm generation, F1/BLEU1/BLEU2"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "d0ecc675-d68c-5116-8b56-47c39bc23565", "question": "Consider the paper that introduces the method that corresponds to the orange line in the figure. What specific component of the model's architecture is directly responsible for propagating the semantic matching information along the directed edges on KGs?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the orange line in the figure. What specific component of the model's architecture is directly responsible for propagating the semantic matching information along the directed edges on KGs?", "reference_answer": "matching information propagation module"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "d1fd203b-6154-50f6-94ae-21c9f082d74f", "question": "Consider the paper that introduces the method that has the second lowest overall performance for the Seen condition. How does the model proposed in the paper handle the scenario when the agent's path is blocked by immovable objects during inference?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["900a2a6f-561b-528a-98d2-b3db6994132a"], "reference_pdf": ["e54396b6-b34f-5a0f-875a-fbdd755eb07c", "01c16a12-ee64-5521-95ab-988405f846c6", "da072dc2-1bd8-59a5-ba5e-92fcc00143c2", "ddb5d231-229d-5d33-8272-f6dda132ff11", "00f88ba2-daf2-5ae1-a6ea-4cc28fa560f0", "18bd25cd-ba3d-5ddb-965b-e9807e41fb06", "aaab4b3d-7428-588b-b2d7-99eb32b1e7f1", "5be4064d-9fd5-554a-8d30-7f0633ede697", "26cae332-3ea8-5f0f-854a-b8ed02739d31", "c08f2398-0747-587d-aa68-dac465b56660", "c4751155-479d-5cde-94e7-b27416febf8a", "adfc0ecd-7ed6-5ca8-8c56-f58d16097120", "eb186fc8-1d3f-58b7-8df7-151863e12ad9", "6a2a3889-79ed-5bfc-8448-331e3e0ff259", "7248442c-7932-5a5d-89af-3084716e2d44", "c9e6c663-90f0-58e7-b0ff-00a8eba701c8", "255515da-8135-5ce8-a309-f2a52629d252", "51379a5e-a1fe-5d37-ae7a-85ca311f069c", "157c2429-46a5-5b91-bb21-999bfcf07dfa", "cf2bff7f-c4f0-517e-b2be-cf39f8189e50", "579c9a58-2796-5b19-9d91-1b7fdbdf11db", "7b1f8efd-f0dd-566d-8e39-b67f95acb72e", "fca2d60a-027e-5d54-92aa-497b8d9161e7", "9f36ddad-53a9-5b02-9da2-df99c102f65f", "bd0047ab-c1a9-5a95-928a-49648d9bee24", "f72a5f34-6aa0-5ed9-b721-95ac04dbc8b7", "04239ec0-eb90-5280-a424-4bf097a3b85b", "8515c774-3725-50a8-9296-a89b4974eb1b", "10eb6999-ec5e-5eac-91f7-359a777a828e", "095ad37b-8feb-5faf-b98d-9450f280ad99", "98a602ee-2b8b-58f6-a181-9de8ce9fdb26", "1c112fbe-426b-569c-a5a8-8c75cb72d4c4", "a3252d1b-a442-5637-870b-b193f9aec120", "b763b547-a7ed-5c83-9bab-2808c30c62f6", "1b108425-ed34-58b9-909e-fde6e2bfcc3f", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "951c7612-dcf4-56a9-936f-7362568e08fa", "ac24375c-4154-5dc3-887d-f2a3477a0fed", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the second lowest overall performance for the Seen condition. How does the model proposed in the paper handle the scenario when the agent's path is blocked by immovable objects during inference?", "reference_answer": "To handle the scenario when the agent's path is blocked by immovable objects during inference, the model proposes an 'obstruction evasion' mechanism in the Action Policy Module (APM) to avoid obstacles at inference time."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12344/ALFRED_table.png"]}
{"uuid": "d35c45ec-19e2-56d4-aba5-656af1e98263", "question": "Consider the paper that introduces the dataset that corresponds to the last row of the table. What is the F1-score improvement for the model proposed in the paper, specifically the PhoBERT_Large model, when additional clean comments are included?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that corresponds to the last row of the table. What is the F1-score improvement for the model proposed in the paper, specifically the PhoBERT_Large model, when additional clean comments are included?", "reference_answer": "0.0849"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "d50677b7-6eb9-586a-b416-bbb200bfb193", "question": "Consider the paper that introduces the model that corresponds to the brown bars in the figure. What specific method does it employ to ensure the attention mechanism focuses on maintaining dialogue control over multiple turns?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the brown bars in the figure. What specific method does it employ to ensure the attention mechanism focuses on maintaining dialogue control over multiple turns?", "reference_answer": "Ghost Attention (GAtt) employs a method inspired by Context Distillation to help the attention mechanism focus on maintaining dialogue control over multiple turns."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/prompt_setting_figure.png"]}
{"uuid": "d5ea4699-94ff-5fc7-a9dd-4a5049dcb67d", "question": "Consider the paper that introduces the model labeling 'fine-tuned' shown in the table, MVQG-VL-T5. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87061b7c-1d22-547a-8872-d4aeab4af856"], "reference_pdf": ["494cb703-b95f-5e14-a0e7-a3fd11506fc1", "6f3f28fe-d2d7-586a-88ad-9221a4b30d73", "34417770-67d7-5cab-b9d4-76999c97bc02", "d8294ff2-583e-51c8-800f-d71a9308007f", "2ca6dd33-bf5b-50cf-b091-3282a484d4a8", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "04eb3bcf-5a3a-574f-84e5-2bf5ad50cde4", "3eebefdb-5ed6-51bf-92c6-b28841844f45", "4d93d596-b0bd-54c6-bd9e-041037077bc7", "ffa6aa03-6f5b-56a1-9120-8d8c625c0880", "e201f724-c783-5300-baeb-1379ae22f643", "7aacee49-58db-593f-9a47-44846ba2ed23", "7908763f-3a9d-5ce5-af59-f68888750583", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "ec5a0dc4-0a52-55b2-a4a2-54e1006e50b9", "8d432bf0-21eb-51f9-b126-078fe08a3012", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "3e2528f0-84e9-5fa9-a440-22ae6fcc2500", "c8260bf5-7dd8-5066-8aa4-1a512fa40f12", "1b61dc63-60bb-51d1-9935-260cf324487f", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model labeling 'fine-tuned' shown in the table, MVQG-VL-T5. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "reference_answer": "6 and 6.2 points"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15129/human_eval_table.png"]}
{"uuid": "d601aef7-fe38-597b-b6fe-fb269727cd77", "question": "Consider the paper that introduces the model that exhibits the most negative Spearman's Correlation Coefficient. What specific methodological approach did this model employ to address the challenge of generating bland, uninformative samples in open-domain text generation models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that exhibits the most negative Spearman's Correlation Coefficient. What specific methodological approach did this model employ to address the challenge of generating bland, uninformative samples in open-domain text generation models?", "reference_answer": "Maximum Mutual Information (MMI) scoring function"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "d64d7653-ef74-5380-b24f-a53f83b1d0ef", "question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. What specific modification to the few-shot prompts used in the model's, proposed by the paper, CoT generation is highlighted as a key factor for improving the quality of generated data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. What specific modification to the few-shot prompts used in the model's, proposed by the paper, CoT generation is highlighted as a key factor for improving the quality of generated data?", "reference_answer": "Providing the model with the target after posing the question and before providing example CoT."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "d6fb8bba-4f7c-5b64-965d-984eb68aa193", "question": "Consider the paper that introduces the method that achieves an average EA score of 67.07 in the FinQA task. What is the model's, proposed by the paper, EM score using the reverse order of in-context examples on the NQ dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an average EA score of 67.07 in the FinQA task. What is the model's, proposed by the paper, EM score using the reverse order of in-context examples on the NQ dataset?", "reference_answer": "42.8"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "d7e5ee8d-80e4-5b9f-b7a7-bba933adb837", "question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. How does its structured summarization approach ensure the generation of valid sentence boundary positions within the task semantics?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4db47b23-f7bf-5d2e-a957-279ddcc3310c"], "reference_pdf": ["56f3aaed-b2b7-5df1-97cc-7cf6236a892f", "fa9a9ad6-66e9-5bd8-b1a2-862836bceb4b", "c3a61f79-d156-54a9-9888-813475b4d3d1", "0015561a-99bb-5b95-b457-3e43c7751331", "0d601b2e-069f-5bab-ae99-f37eb696b06a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9d2e017c-b25e-5cbc-8493-ccb4d9ab7443", "bcf8872a-b92d-5cbe-8be5-350bcf7d5e15", "0c1d2108-ab01-58ec-9369-5b8e148dab5d", "ca40df32-58b7-52fe-b2b5-458f848e4210", "4e513417-bbb2-55e1-b572-ec68a60fc6be", "64ee757d-3fab-5132-aadf-376825399f6b", "edd36969-0b52-50f9-b08c-9b0ba9e514e7", "502590c0-bb29-53ab-8095-a2c68e3e42ab", "3134099b-d3ac-56d3-898d-c77c7a99370e", "1ddc4f93-70fd-5397-a6f3-ee8837ea208e", "afbe2f7a-2754-5da7-97f6-b56a58fe47a4", "eeda9a9d-5d4e-5579-9a3b-f2e546a7bf4b", "00dd4300-de92-5712-9ce8-ccdb844b6314", "3790e4a5-ff47-586a-b09c-c11ab395909d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "510d6fc0-d3e0-5dc1-8e0d-4d470f964287", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves an F1 score of 73.1 in the en_city category. How does its structured summarization approach ensure the generation of valid sentence boundary positions within the task semantics?", "reference_answer": "The structured summarization approach ensures the generation of valid sentence boundary positions within the task semantics by employing a generative segmentation method that maps target segmentation labels into target sequences. This involves turning the integer-valued positions corresponding to segment boundaries into strings and combining them in a single target sequence with delimiters. The encoder-decoder transformer model is then trained to generate this sequence, effectively learning to produce valid sentence boundary positions. Additionally, a post-processing step is applied to the decoder output to convert the generated strings back into a list of integers representing sentence positions, while ensuring they fall within the correct range (between 0 and $|S|-1$). This method, combined with the use of sentence position encoding at the encoder input, allows the model to accurately predict sentence boundary positions that are coherent with the task semantics."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11772/comparison_table.png"]}
{"uuid": "d7eb0792-6419-5867-a5e8-c48776f84a03", "question": "Consider the paper that introduces the last method shown in Explicit --> Retrieval-enhanced --> Multi-Stage category. What specific aspect of the zero-shot reasoning process of this method directly addresses the challenge of LLMs' hallucination during inference?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the last method shown in Explicit --> Retrieval-enhanced --> Multi-Stage category. What specific aspect of the zero-shot reasoning process of this method directly addresses the challenge of LLMs' hallucination during inference?", "reference_answer": "The transformation of the retrieval process into a multi-hop decision sequence."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "d822725c-0503-51f1-8e00-a09e7788fe7b", "question": "Consider the paper that introduces the method that exhibits the lowest BLEU score in the De->En task over Average Lagging from 5 to 11. What specific mechanism does the model proposed in the paper use to calculate the expected attention for each head?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the lowest BLEU score in the De->En task over Average Lagging from 5 to 11. What specific mechanism does the model proposed in the paper use to calculate the expected attention for each head?", "reference_answer": "The MMA-IL variant calculates the expected attention for each head by first calculating the softmax energy for each head as follows: \\(u_{i,j}^{l, h} = \\textrm{SoftEnergy} = \\left(\\frac{m_{j}\\hat{W}_{l,h}^K(s_{i-1}\\hat{W}_{l,h}^Q)^T}{{\\sqrt{d_k}}}\\right)_{i,j}\\) and then using Equation \\(\\beta_{i,j} = \\sum_{k=j}^{|\\vx|} \\left( \\frac{\\alpha_{i, k} \\exp(u_{i,j})}{\\sum_{l=1}^k  \\exp(u_{i,l})} \\right)\\) to calculate the expected attention."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "d84777d2-5eb0-527c-8298-6ca1ca372018", "question": "Consider the paper that introduces the model shown in the table that has an overall score of less than 3.80. What specific feature of its visual embeddings allows it to discriminate regions from different images when multiple images are given to it?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87061b7c-1d22-547a-8872-d4aeab4af856"], "reference_pdf": ["494cb703-b95f-5e14-a0e7-a3fd11506fc1", "6f3f28fe-d2d7-586a-88ad-9221a4b30d73", "34417770-67d7-5cab-b9d4-76999c97bc02", "d8294ff2-583e-51c8-800f-d71a9308007f", "2ca6dd33-bf5b-50cf-b091-3282a484d4a8", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "04eb3bcf-5a3a-574f-84e5-2bf5ad50cde4", "3eebefdb-5ed6-51bf-92c6-b28841844f45", "4d93d596-b0bd-54c6-bd9e-041037077bc7", "ffa6aa03-6f5b-56a1-9120-8d8c625c0880", "e201f724-c783-5300-baeb-1379ae22f643", "7aacee49-58db-593f-9a47-44846ba2ed23", "7908763f-3a9d-5ce5-af59-f68888750583", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "ec5a0dc4-0a52-55b2-a4a2-54e1006e50b9", "8d432bf0-21eb-51f9-b126-078fe08a3012", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "3e2528f0-84e9-5fa9-a440-22ae6fcc2500", "c8260bf5-7dd8-5066-8aa4-1a512fa40f12", "1b61dc63-60bb-51d1-9935-260cf324487f", "45decdf4-f524-52d5-8385-3da8d839888b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the table that has an overall score of less than 3.80. What specific feature of its visual embeddings allows it to discriminate regions from different images when multiple images are given to it?", "reference_answer": "Image ids"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15129/human_eval_table.png"]}
{"uuid": "d8f2f70a-f781-5a26-a892-1dd72a95559e", "question": "Consider the paper that introduces the LLM model that demonstrates the lowest MSE score. What specific methodological difference in the evaluation of the model's performance on the USABO and SAT reading/writing runs (with and without vision) compared to other exams contributed to potential minimal impact on results?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["afd759ef-87a1-55e5-a5c5-b0102325830d"], "reference_pdf": ["17623cac-c243-591b-b7bc-d261f6ebd607", "e43b9042-e85e-52ba-b1bb-bb5416f836fa", "636b10fe-f0e5-50c6-b53a-1b9b5c636864", "e3181c7f-c92f-5e72-8419-d97634cf5535", "a4166c00-143a-57ce-8929-537667e11cc4", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "2eaaf347-a894-5b0d-9d6b-39fe1f869854", "5fe9c4e7-cf60-5a3a-8550-26c2aa1b910c", "e62ca3c9-15fe-5a2f-8f57-5914991cbae4", "1d1ff063-3059-5b5b-abe0-0e41a62ac920", "f3728bd2-f6be-585c-8ced-36649229dde9", "dc135cea-016f-534b-bfe5-39bb5aca25dc", "c67a9286-46c2-57f7-9a58-2c7ab8755152", "d99202a8-0fbe-5032-a962-e65c745d3595", "cd07dec7-94b7-573f-abda-fa59cdcacf82", "eb8ba2b8-b5a6-516b-b762-19465f9eaaed", "8da0435b-edc5-55b1-8983-ba5e662a3d0c", "2feed15d-e321-5ac8-8a27-568759e429dd", "fafb5d80-163e-59f2-a365-16a37f4fd351", "f23baff0-753e-5787-b392-d67f27d48d2c", "1d259046-2a97-578c-a3f9-40fe2e138e73", "00b65d5a-72d7-5d45-b93d-aed20dd49192", "bfc4e2c5-a593-5974-bd48-8220a9ee00b7", "f1071e3a-5534-5cf9-a612-30b6e7986a75", "2077ab9c-e416-5734-b43b-df2a5d91ec67", "1adb8a6f-ba9b-5307-8758-5fde1de8fc44", "60088993-59e3-5ca4-8e90-cddaec9589ae", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the LLM model that demonstrates the lowest MSE score. What specific methodological difference in the evaluation of the model's performance on the USABO and SAT reading/writing runs (with and without vision) compared to other exams contributed to potential minimal impact on results?", "reference_answer": "The specific methodological difference in the evaluation of GPT-4's performance on the USABO and SAT reading/writing runs (with and without vision) compared to other exams that contributed to potential minimal impact on results was the direct sampling of a letter choice at temperature 0 using the already-sampled explanation for these exams, as opposed to extracting the model's letter choice directly from the explanation for most other exam runs."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.17428/mse_table.png"]}
{"uuid": "d91b74a7-06ba-54c5-a44a-64c6db64df81", "question": "Consider the paper that introduces the method that results in a score of 22.4 in the GSM8K dataset. What specific dynamic programming algorithm does the paper tweak for aligning the GPT and T5 tokenizers, and what is its original field of application?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that results in a score of 22.4 in the GSM8K dataset. What specific dynamic programming algorithm does the paper tweak for aligning the GPT and T5 tokenizers, and what is its original field of application?", "reference_answer": "Needleman–Wunsch algorithm, bioinformatics"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "d93babd0-295e-535d-b636-f9a2a4233418", "question": "Consider the paper that introduces the model that achieves a mean classification accuracy of 0.6712 on the Hate dataset. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a mean classification accuracy of 0.6712 on the Hate dataset. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "d9e9d8c0-490e-5e06-baa4-16fa34f9cc82", "question": "Consider the paper that introduces the large language model that has the second lowest HVI score among those in the figure corresponding to a purple bar. What specific methodological difference in the evaluation setup for the model proposed in the paper's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9b154fc7-cac7-5a8f-89ac-1ea50638b087"], "reference_pdf": ["87b70047-b849-5220-a3df-28e992c41bf2", "d4de27d2-08b9-57ae-b0a7-a4b9b26047bf", "507be7a7-d7c2-5c15-8ffe-9e6bfe40e5b0", "54eb4a06-225f-5814-ae97-c54611c3f95c", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "4d2120b1-212d-52ad-a0e5-c56245349f00", "34417770-67d7-5cab-b9d4-76999c97bc02", "a0863db0-4018-56ff-81bf-bdb1ff2ed4b7", "e59b32f7-7a87-5940-b581-3e110d2fd77d", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "884e57aa-78e0-5621-958c-8681a2d6f61f", "98b88819-fa1f-503b-9e15-3b078e676975", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "3caa80e4-e308-5fd8-b45f-6b55c8a7a835", "ad6fa17b-383b-53da-8737-9038180d5159", "a1302ac9-0f53-556b-96cd-38977a533888", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "7908763f-3a9d-5ce5-af59-f68888750583", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "dd073182-00f0-5a9f-800b-7779293ab2ae", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "17623cac-c243-591b-b7bc-d261f6ebd607"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the large language model that has the second lowest HVI score among those in the figure corresponding to a purple bar. What specific methodological difference in the evaluation setup for the model proposed in the paper's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "reference_answer": "The use of sampling a letter choice at temperature 0 using the already-sampled explanation for certain exams, rather than extracting the model's letter choice directly from the explanation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.04988/HVI_figure.png"]}
{"uuid": "dc578399-76b2-54be-a357-321cf58611c6", "question": "Consider the paper that introduces the method that demonstrates the lowest EA score on the FinQA task. What specific mathematical reasoning capability does the TabMWP dataset aim to assess in machines, as highlighted by the challenges presented in its design?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that demonstrates the lowest EA score on the FinQA task. What specific mathematical reasoning capability does the TabMWP dataset aim to assess in machines, as highlighted by the challenges presented in its design?", "reference_answer": "multi-hop mathematical reasoning over heterogeneous information"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "ddd3cdca-f80f-5ed4-b0a3-02022b8276a2", "question": "Consider the paper that introduces the dataset represented by the leftmost bar in the figure, GSM8K. What specific aspect of the token-level verifiers' training procedure is likely responsible for their initial uncertainty in solution correctness, as observed in the verifier visualization section?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa7d95d4-dd69-5849-8f0b-119726938dac"], "reference_pdf": ["3ea1a5e9-0057-54a5-b359-7d99fc882842", "06e77679-09f0-5936-b00f-dcad7a604f75", "a0a8ed85-32d4-58c2-b4b7-6a34ec125441", "c7cf8100-fcbd-575b-a980-7f6d3c4f6761", "b44607d8-7587-53ed-be67-22b3668a1644", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "1b151a0b-8156-5a1d-9459-ba2037900807", "bf80182b-c2b3-5553-bfcf-3d83d1c71d9d", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "cb83c58c-fefc-566d-b291-b27faf9eec2b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "e69ef270-7428-50f6-b47b-63a2455841ac", "7908763f-3a9d-5ce5-af59-f68888750583", "1e7ec69a-1a58-5bc0-a94b-c2b907d6c59d", "20847c00-ada9-56f4-aab2-d67eb2ace27b"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset represented by the leftmost bar in the figure, GSM8K. What specific aspect of the token-level verifiers' training procedure is likely responsible for their initial uncertainty in solution correctness, as observed in the verifier visualization section?", "reference_answer": "The token-level verifiers' training procedure likely causes initial uncertainty in solution correctness due to the large fraction of incorrect model-generated samples they are trained on, which makes them initially unsure about the correctness of a solution and gradually gain certainty as the solution progresses."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14628/comparison_figure.png"]}
{"uuid": "dee3ae6a-e2b5-5432-a4e7-a0d07e63791e", "question": "Consider the paper that introduces the model that has the largest number of updated parameters, specifically SR+NSM+E2E, on the CWQ dataset. What is the impact on Hits@1 of QA when removing the subgraph merging strategy (GM)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that has the largest number of updated parameters, specifically SR+NSM+E2E, on the CWQ dataset. What is the impact on Hits@1 of QA when removing the subgraph merging strategy (GM)?", "reference_answer": "drop by 0.1%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_table.png"]}
{"uuid": "dfd253e3-0d40-5fb7-b397-b4f297ef658e", "question": "Consider the paper that introduces the model that is seventh in the table. What is the main reason the PIDRP method performs worse than this model on all four top-level senses of the PDTB, especially on the Temporal sense?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that is seventh in the table. What is the main reason the PIDRP method performs worse than this model on all four top-level senses of the PDTB, especially on the Temporal sense?", "reference_answer": "The main reason the PIDRP method performs worse than the PCP method on all four top-level senses of the PDTB, especially on the Temporal sense, is that connective prediction is closer to the natural language patterns when the model is in pre-training stage than direct implicit discourse relation prediction."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "e05422ef-dd6c-5e6c-a16b-7fe0ad7676ed", "question": "Consider the paper that introduces the quantization method that achieves a score of 80.3 on Deit-B with a Weight/Activation (W/A) precision of 6/6. What is the specific range of search space for \\(\\Delta_{\\text{R1}}^s\\) during post-softmax quantization as mentioned in the experiment settings?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87c327a8-cd52-5d23-93de-c4486887da8b"], "reference_pdf": ["bc431e93-410f-5eb0-a4a5-314a37e129a0", "34417770-67d7-5cab-b9d4-76999c97bc02", "720ede7a-1362-532b-b4b5-4436c03c5363", "95808d88-d437-55ec-9af6-cb7399b1010c", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "60495988-448a-5919-9470-d8561310a40d", "81528b8c-c326-567e-a3ed-4ca2b0295ff2", "52d72671-969b-5840-8808-73be9745a07f", "720ede7a-1362-532b-b4b5-4436c03c5363", "93502213-3277-5df7-a02f-39b12077c0c2", "08e29bf5-665b-561e-8672-d90363383d43", "e7184da4-f850-5562-ba39-441760b58a7d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "3b9340d4-5374-5613-a1a4-bc3c125639c6", "7908763f-3a9d-5ce5-af59-f68888750583", "1ffa6ac4-663b-5498-84b3-3148948fcba4", "332d0f2a-9d5a-54b3-8d5e-e24081633c0e", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "b9f85125-14a8-502f-8717-f38768038090", "acce625f-be46-56f5-b5f6-13b331e2efdf", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "b9fa129c-7848-536a-b464-b4090dd72a9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the quantization method that achieves a score of 80.3 on Deit-B with a Weight/Activation (W/A) precision of 6/6. What is the specific range of search space for \\(\\Delta_{\\text{R1}}^s\\) during post-softmax quantization as mentioned in the experiment settings?", "reference_answer": "\\([\\frac{1}{2^{k}},\\frac{1}{2^{k+1}},...,\\frac{1}{2^{k+10}}]\\)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16836/comparison_table.png"]}
{"uuid": "e0b273dd-95c8-57be-97cc-bd9f9363ffcc", "question": "Consider the paper that introduces the method represented by the purple line. What is the relationship between the average attention span and the variance loss $L_{var}$, as demonstrated in the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method represented by the purple line. What is the relationship between the average attention span and the variance loss $L_{var}$, as demonstrated in the model proposed in the paper?", "reference_answer": "The relationship between the average attention span and the variance loss \\(L_{var}\\) is that the average attention span is reduced as \\(L_{var}\\) is increased."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "e14c2c23-0bd6-5818-b905-096a72222c44", "question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. What key modification did the authors make to the few-shot prompts to improve the quality of chain of thought reasoning generated by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["947fdd5e-cf71-58e9-95f9-3d9fa209c2cb"], "reference_pdf": ["aee71259-0a10-5694-bac5-7cbb85b3cba6", "80b0a0f4-7247-5b9e-8782-0a4dd4a2ae4b", "48bb7435-ed13-5557-8e9f-6cc44f1b0c0e", "c52b5ef2-45a0-55e1-bb02-343de340b806", "cfcaf2b3-218a-50e1-a929-a9dcc6ccd213", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2e150e31-dca0-581d-97e1-f74e4efd24fb", "28c91c0b-4918-5ece-a008-5c539282c189", "1270d0a1-0423-5c10-bdc5-ab2869b9ed6e", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "206fe373-bd70-5bb7-ad16-6151168a2cc7", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "e05cbd04-192e-5761-97ce-7250058cf895", "6f4d0a2f-4457-55af-b519-da2a1df140da", "7072220d-1680-5120-b061-9c5d175922e2", "65a79a3b-cadc-51a1-a156-a7abb743d5c1", "6666b1b6-588c-56c5-9199-cd16d1db2a49", "7908763f-3a9d-5ce5-af59-f68888750583", "195d81a0-1f5b-5377-8f2a-2c7b13d3f595", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "8ef8b079-8d9f-5ea8-9d92-dcba9f81d7a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "a87a7490-623a-54af-bad6-ef68b0757499"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an accuracy of 18.4 on the GSM8K dataset. What key modification did the authors make to the few-shot prompts to improve the quality of chain of thought reasoning generated by the model proposed in the paper?", "reference_answer": "The key modification was adapting the few-shot prompts to provide the model with the target after posing the question and before providing example CoT."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13332/comparison_table.png"]}
{"uuid": "e153b133-2c6d-5090-bf8a-8a9ce2d3f24b", "question": "Consider the paper that introduces the model that corresponds to the penultimate row of the table. What hyperparameter values were used for the FewRel dataset in the experiments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that corresponds to the penultimate row of the table. What hyperparameter values were used for the FewRel dataset in the experiments?", "reference_answer": "$\\alpha=0.5$, $\\beta=0.5$, $\\tau_1=0.1$, $\\mu=0.5$, $\\omega=0.1$, $\\tau_2=0.5$, $\\gamma=1.25$, $\\lambda_1=0.5$, $\\lambda_2=1.1$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "e29926de-63a0-587f-b652-2cad4da9c722", "question": "Consider the paper that introduces the Twitter dataset that has the most number of languages compared to all other Twitter datasets. What specific sentiment analysis sub-tasks do the authors of AfriSenti plan to extend their dataset to in the future?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the Twitter dataset that has the most number of languages compared to all other Twitter datasets. What specific sentiment analysis sub-tasks do the authors of AfriSenti plan to extend their dataset to in the future?", "reference_answer": "Additional African languages and other sentiment analysis sub-tasks."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "e2ac9945-f18e-569c-98b4-00450276da0d", "question": "Consider the paper that introduces the method that achieves sentence-level precision of 60.32. What specific initialization method was used for the new position embeddings in the model proposed in the paper to leverage RoBERTa's pretrained weights for supporting longer documents?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["79a856b0-ea50-5dad-b4a1-f0f0c8e17443"], "reference_pdf": ["8ad564f3-f634-5b41-9dbb-c7b55efd34ed", "4774dafb-8266-57ac-ba3b-3fb7302f43e8", "e544d7c3-0ea0-5f06-accd-9044fb2df8ce", "2ad75cc6-aa85-532e-a8cc-d487ad70ac1d", "8ac0dc8f-2cdc-5363-ab17-2cbe2cd98611", "7913138b-027d-5e7a-a4f9-c94fa676607b", "501de3a1-2bdc-5bea-9259-4731a2df35ab", "68be5d29-f16d-506f-a4e5-215438f13409", "9dab5ed2-4f76-52b3-b13a-ee7c9342d254", "64ee757d-3fab-5132-aadf-376825399f6b", "a672b5e1-0460-5bcf-9f96-189e0687079d", "19037637-5fca-5021-a9c2-464b3eaf7fb1", "167219f2-ecf4-59b5-8ea1-cdcb400400b2", "7eb3a633-8d11-5b91-af60-4030ff538882", "aefc8eb9-7238-561a-8055-858362dc6a0c", "3157ccdb-a5d3-5ddb-93af-99dcbba44f15", "f9ea4f73-3191-5d9c-8121-e490cc81af65", "2e88d873-bc67-51d3-a17e-8eda7c844dd6", "79c58b97-75e2-590f-ab73-90c71c7af2a6", "26e45afd-1c91-5f0f-bb47-33707acec072", "4fd8fdc1-1bd4-58dd-9c4e-0659d9c11ee4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "167219f2-ecf4-59b5-8ea1-cdcb400400b2"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves sentence-level precision of 60.32. What specific initialization method was used for the new position embeddings in the model proposed in the paper to leverage RoBERTa's pretrained weights for supporting longer documents?", "reference_answer": "Copying the 512 position embeddings from RoBERTa multiple times"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18544/result_table.png"]}
{"uuid": "e3457e43-ce1d-5f95-9f8e-633b976d25ac", "question": "Consider the paper that introduces the method which has the highest perplexity. What is the minimum number of tokens in the set \\(\\gV_m\\) that maintains at least \\(\\rho\\) in cumulative probability mass in \\(P_w(x_t|x_{<t},c)\\) during the generation guided by this method?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has the highest perplexity. What is the minimum number of tokens in the set \\(\\gV_m\\) that maintains at least \\(\\rho\\) in cumulative probability mass in \\(P_w(x_t|x_{<t},c)\\) during the generation guided by this method?", "reference_answer": "n=m"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "e40a8095-ce54-5066-8877-ad2cd2314e5e", "question": "Consider the paper that introduces the large language model which has the second lowest HVI score among those in the figure corresponding to a purple bar. What specific performance improvement does the model proposed in the paper exhibit over GPT-3.5 in the context of the Uniform Bar Exam?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["9b154fc7-cac7-5a8f-89ac-1ea50638b087"], "reference_pdf": ["87b70047-b849-5220-a3df-28e992c41bf2", "d4de27d2-08b9-57ae-b0a7-a4b9b26047bf", "507be7a7-d7c2-5c15-8ffe-9e6bfe40e5b0", "54eb4a06-225f-5814-ae97-c54611c3f95c", "5885cc59-7626-56ec-a3dc-7caa8e7acf8f", "4d2120b1-212d-52ad-a0e5-c56245349f00", "34417770-67d7-5cab-b9d4-76999c97bc02", "a0863db0-4018-56ff-81bf-bdb1ff2ed4b7", "e59b32f7-7a87-5940-b581-3e110d2fd77d", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "97bf5a6b-8d1c-533a-a00c-d1ca31d3256d", "d4223ac7-9d75-531d-9113-b52397da2e1e", "884e57aa-78e0-5621-958c-8681a2d6f61f", "98b88819-fa1f-503b-9e15-3b078e676975", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "3caa80e4-e308-5fd8-b45f-6b55c8a7a835", "ad6fa17b-383b-53da-8737-9038180d5159", "a1302ac9-0f53-556b-96cd-38977a533888", "67140bfe-0af6-5bb2-b96f-502358a17a1a", "7908763f-3a9d-5ce5-af59-f68888750583", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "342064c4-037b-5666-b324-15191f5c5e20", "7efa89b4-4460-5eed-b6f0-62238a690c9b", "3134099b-d3ac-56d3-898d-c77c7a99370e", "dd073182-00f0-5a9f-800b-7779293ab2ae", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "17623cac-c243-591b-b7bc-d261f6ebd607"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the large language model which has the second lowest HVI score among those in the figure corresponding to a purple bar. What specific performance improvement does the model proposed in the paper exhibit over GPT-3.5 in the context of the Uniform Bar Exam?", "reference_answer": "GPT-4 achieves a score that falls in the top 10% of test takers, contrasting with GPT-3.5, which scores in the bottom 10%."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.04988/HVI_figure.png"]}
{"uuid": "e4292dcb-5db2-518a-afeb-43f25602e605", "question": "Consider the paper that introduces MeLLo, the last method shown in Explicit --> Memory-enhanced --> Feedback or Corrections category. What specific performance improvement does the model proposed in the paper demonstrate over MEMIT in terms of multi-hop accuracy on the {\\dscf} dataset when using GPT-J as the base model?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["0cdbfd3b-33bb-558e-803c-ebc26aff80ea"], "reference_pdf": ["e013d77b-3c7f-5bb6-9836-f7c3b0d6991b", "ef45ff0a-f35f-5c6a-9725-f1e737074417", "99d6fe34-c552-5bf8-bfa3-bcec21bec435", "6d6a7008-fd11-509d-891b-fa0df412cc50", "dcc6b113-fbd2-5f9d-a736-1b761489085f", "5e551bf1-38f7-5dae-a9cf-673e2b6e09ad", "bfe9d771-0815-5bfd-b502-295c08a3e26d", "0b6a6358-b4ed-5881-950b-dc2c7a92f6e9", "206a0440-f736-52ae-bb1b-a033f4358ed3", "b7e882d3-0b6b-5401-baf7-36cdd87176ee", "c4bd8ae6-dba8-5084-b52d-b4869cbf16f1", "ff1d2197-5539-5de2-9d68-69061405cde6", "739a3a50-92df-500d-822f-5a16e07b9da2", "af38cdbf-e96a-5596-aa16-a4d08afba02f", "7aceb4e8-8d59-53ed-ad15-af3bb2315845", "ef481e2f-9568-5464-95ec-bb6df90039a6", "baf00212-88e5-52cc-86de-98c0f878646e", "4eb654a7-54b7-5270-8a8b-e0ba00d789fe", "4f47553a-508e-570d-b468-9f5170b075bb", "90a1838b-33ef-509b-9da3-f5663c13b832", "45d2861a-8d15-562c-a177-bb9bc5695af1", "4d10adba-e9d9-5d7e-b187-17c1b58d46ff", "77e2ee1d-55c3-5573-8031-cfce43812fbd", "04a8824c-cab0-5882-b94f-4419835a6417", "f06f6869-55b3-5463-af7f-7d930ae8500c", "b1a84f6f-9de9-51e5-b532-bbc1b2beeaf6", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "0fbec573-0f18-5e00-9711-49bc263e5aeb", "30401aad-d103-567d-bdd2-afd4af2815e2", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "9cf68445-ff93-5720-a711-1a28ef80bf0a", "eb787b77-5188-5411-b0f8-406356623bac", "0bbf45a0-7cc1-5b17-9848-6b70fa8560fc", "0929f9b7-8855-5f67-bc17-4eea592de0ed", "f266f3f3-019a-5e6b-b1e8-1b57aa794331", "7c412251-45ef-5fe9-8b84-1cad8f053975", "21f40b37-516d-5ea9-9d17-1562757a5445", "966e5fb6-ed12-5a2a-bdd7-9df4707f2dcb", "259f8e65-c806-51bd-9207-f0652eea30e6", "adcb0a04-b514-59e1-85a2-cfdb32069a57", "bc193108-a2b1-59de-91e3-7e9413de9e59", "66202782-84ce-53c5-886a-7e4db69d264e", "72601f56-cb93-584b-b5a8-38acab8a15e7", "06725ec1-c1b2-5b7f-ab80-370446c3434b", "8a21226d-fce0-560d-abce-cc4506e24d28", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "372f8992-5703-5c60-8019-4b75b42b6c28", "fc3a1556-cf34-5245-8053-fbb2fad60958", "12e2d54e-797c-5c2c-afd5-0bbf9ad315fc", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "5adc93c4-d1e7-5ce9-9711-2432e9c0d46a", "146b54ce-091b-5a9e-9807-6096c2f3360d", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "a07b0382-f658-598f-988b-2d8127b73e6a", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "a1e01326-a4d0-540c-92f8-037a3dd93c8e", "fdf999c8-5af6-5dc8-a845-250927fac543", "d5c608af-3444-547a-aab9-659b9e73d036", "a2032bdb-4133-5b23-9fa8-44eca0a97d8d", "52ac5710-88e1-5281-a84e-ad6cd4d90c26", "3f69a541-b3b1-56ae-95dc-3586921121bb", "84449b22-c7ae-5253-8295-9d74a378fcc3", "c21cc6c6-9c50-5a5d-a1c1-00191711bf4f", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "b5412b02-ce00-5213-938c-47499b1a148a", "62e2795c-64b9-54eb-8d86-ad458ab18b05", "21acd234-654b-537d-a411-04352c88de4a", "e820c085-297a-567a-a5a9-3c558fb2073c", "8433f894-a217-54d3-9ae5-5c17f951797a", "7f910e9d-0221-5b86-90c5-d697ccbe3852", "bd3ad280-18ad-5de3-989b-9b49fc63a9b5", "fd9348b5-0dfc-59dc-ab25-96407224db34", "3e7a9df6-4c5a-5151-b481-999cb0f68bee", "386f2214-6ec7-50f8-9ab2-c36b354b2fe3", "1047803c-3229-546d-8a93-9027fcbe4df0", "68eacc6c-474b-594d-b512-285ebb27d97b", "7e072c34-0edd-5b4a-a557-f5f1aa920dd2", "46d4aabb-5f18-5e81-8613-d3af7d3f5a8a", "0337fff3-2745-5430-b1ca-9d43c836a09c", "4f158b58-31db-5b1d-84e1-b3db9d4c6c4a", "544873f5-dab8-5f7d-9490-c8389cc1cc09", "859e8f4c-ae74-5f55-949b-a4122ccc3c14", "8d8e4058-651e-5b61-8d84-96d8846cd07c", "5b46839e-eeba-545b-a727-99d8a98839f9", "8b304a99-03dd-5530-975e-272c8f783bf9", "3e409d3a-1045-575f-b4ad-f4923916080a", "08705cdc-cb92-5119-af5c-18717ec40e6b", "386ae482-93c7-56dd-ab77-7d5daab15cb0", "d4223ac7-9d75-531d-9113-b52397da2e1e", "c77bab71-82ba-5a32-b349-3480568675fd", "4f3b5089-6bde-5eda-81fc-0ac4f9aabb88", "283b80b4-7027-58a5-8819-d3033ac0485e", "62c06c7e-dc7d-5c08-8c09-d9792f4bf7cb", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "99cdadeb-18a3-59d2-966f-5d16a5a042ef", "1555e0fc-e455-507f-b280-3d779c708615", "f3243634-506c-5de0-ab55-1ff35069e76f", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "5784ccca-8b0d-5cbd-8267-b82d2e24be49", "43f955ba-2521-5efa-91bb-86a21a137a27", "20d98185-e3a3-55c5-9e93-cde74c61d5f4", "90d02a2b-330f-5255-a4bd-e341c87e0631", "88da46a3-dc47-5e90-a933-06ada670a8b6", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "40bab98b-5b92-56e0-bae1-846a9f1fab08", "c481bb3e-8bda-50d0-a076-eb7c6cbffc3f", "11f9746f-503b-573f-8781-04477603c994", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "44c58240-57f2-5f7c-b511-e44337f6a5af", "447baaca-ad90-5258-a70b-f5682d8d89a2", "ee260130-d857-59fc-b3ab-26b5e2fb649a", "5c6ed022-fefe-56f9-89c0-3247635f2650", "36886ec1-f3fd-5f73-bbcd-04575ec56905", "f841f8ad-680a-5de6-872e-3b6b9aec1c2b", "1344aef3-7b2d-5807-947d-335f73038249", "c38b3f28-af4a-5dbf-9274-9b5027586203", "ad316381-b56c-5d70-b05a-b674f26f86d0", "71cec673-84eb-579b-9419-2032699ac0e7", "51104ba8-4144-58fb-a268-4ffebf04fb4c", "e7feb350-d59f-5df8-bcaa-3b0de755d8bc", "4d8eda47-efe5-5b38-b942-68343fe657b2", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "59ad5dc0-ed59-5b13-ad41-8edcce8ecd72", "551aef1b-1534-5f02-b856-366009f8dc8a", "e5c41e78-a697-56ef-8a46-b3d30e9a9c86", "886d1f58-ef58-5ea0-ab1d-c64e94c61410", "6af6b4b4-3f76-587e-b733-df9ca4b6ad22", "48f2ca99-2f34-5310-ac00-571357445a5c", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "ed482231-94e3-5621-835a-776a8fc788c8", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "1e7d9f86-3567-55b8-be98-064a3d297af1", "553f9789-8b5c-5e02-bf13-5458dc6c31ef", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "74496f71-38a5-5b8f-b86a-ee3044590e74", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "f9e44941-7952-55b8-9a99-6be3d55f3945", "6bc1e005-7ec2-5a8b-b8b1-e6b71c3f0693", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "8bbd5e00-c644-585d-97de-3b42b56bad8e", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "6297fbcc-4cda-5e1d-b3ab-9036a2192dcd", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "02cd2589-363c-520c-9f1b-f06d6809acc4", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "45decdf4-f524-52d5-8385-3da8d839888b", "8a3e2ef4-c943-5566-93ac-b1a370d248f7", "02193a94-398e-57da-bb53-0c5800ca743a", "5e1b0738-5c04-5daf-af64-4361b08a26be", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces MeLLo, the last method shown in Explicit --> Memory-enhanced --> Feedback or Corrections category. What specific performance improvement does the model proposed in the paper demonstrate over MEMIT in terms of multi-hop accuracy on the {\\dscf} dataset when using GPT-J as the base model?", "reference_answer": "60.8%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07343/result_figure.png"]}
{"uuid": "e4b1be59-ebcb-539f-b067-b9a98a155382", "question": "Consider the paper that introduces the method that achieves an MRR score equal to 0.679 in the FB15kET dataset. How does the model proposed in the paper's CET method's N2T mechanism specifically handle the embeddings of neighbor relations and entities to infer an entity's type?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0b1e6d16-a279-5a83-ae0d-7b8a58bf0355"], "reference_pdf": ["ab8da4b2-8830-5dc2-b901-ca484702bbbe", "8f3a0cf7-ba90-5e39-8e9a-2ebf3b91b288", "437d1762-d8da-56a8-80e2-f6b5e823ad60", "c170861e-b3c6-5f40-bad9-e98ba1f9c2d8", "cc219d54-6f1e-524d-9a4a-dc4d0a5a4eec", "9b027a68-0c67-587b-b01e-1abb132d9f19", "1f670f2d-99fb-58c5-aef3-901c956d9929", "d0b35b26-2b4c-5209-bb22-d8a44032dd05", "3801abe7-8272-532f-bf4e-a10ce43700db", "fbea0c82-5838-5d56-a4c7-3d9737ea7c08", "ab9c34bc-777c-5ba4-9831-a203fa8bd682", "128f2558-545f-58e7-ad6f-50141b4b068f", "35cfee52-9b21-542e-a4a5-dc403ccd4fba", "a208b8d1-6ff3-588a-9334-4195ba7e524c", "b99fd553-6018-563d-820f-d97c0bbe1ea0", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "4675e5b7-915c-5c6f-afeb-c6d437bb8164", "46202f6e-dfd7-5efd-816d-f285579141d0", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "1777f12e-991e-52d4-8b6b-03807d589e87", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an MRR score equal to 0.679 in the FB15kET dataset. How does the model proposed in the paper's CET method's N2T mechanism specifically handle the embeddings of neighbor relations and entities to infer an entity's type?", "reference_answer": "It conducts non-linear activation on the difference between neighbor entity and neighbor relation embeddings, then applies a linear layer."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12008/comparison_table.png"]}
{"uuid": "e5285169-6c04-5b65-87e5-918a9c77929f", "question": "Consider the paper that introduces the method that is missing a result for the WQ-M task in the table. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a144d387-0e72-5a5c-9a95-b7564833f86e"], "reference_pdf": ["ae1c6e74-8aba-5616-8134-867962b77538", "dccc19ea-3d20-5b85-ab6a-7653fe2c43ae", "e8c34623-fa57-5d42-aa8b-e2c4d1e7b45c", "6878d8bb-cea9-5b39-8b70-7bfb14e4cfb5", "6b3da471-6ef5-54dd-9ed5-d8fee1e915af", "99ac7d3d-eedb-58ea-99c9-cfefa71aba7b", "61add12c-1a79-5ef2-a38e-00e843271ad0", "a5a0e6f0-0db5-5f51-a6da-10cd953f3ba2", "5019ef03-2c2d-5edd-bec5-0f17340786cf", "6df6c8ea-705c-58f8-83cd-a2483b1c828c", "b5e47ecb-523e-5e0f-a1ba-dd3c490a5fd3", "2987b2aa-67ad-5312-91c3-067762156456", "1cce4062-2a2a-55c8-adb6-23c50e2c6b54", "2f304b1c-69d5-588d-8156-b92662ba2204", "ad37f786-00b1-5515-abc6-4a762b9dd5dc", "a76fdb50-d95e-5db2-83a6-ece16257796b", "fea606a3-b9d6-5b7a-80c3-8843bbec4414", "cc130a18-2c9b-5cdf-93d5-660e066195df", "bd72b610-c0b2-57df-949c-dcdf09bfbfd9", "2671f46a-88c3-52a2-bb15-76231d933291", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "b17dd8cd-60cb-5d4c-9a8b-a46b10a5e4a5", "ea69aa8a-081a-5b13-bb55-df26650a47da", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "583e243a-4799-52af-9f47-e23e9a065a79", "31312947-d493-5305-bfd5-1e7a19085826", "4c2ca75e-b1eb-5f6f-bbfe-9b8671d8537e", "eb83ce89-de15-5630-b60f-866a766a4730", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "058d0055-8d50-5b52-ac1a-8c36d074e246", "4af995a1-7cbc-587f-a003-541af36ebb07", "7908763f-3a9d-5ce5-af59-f68888750583", "49843327-34cf-5110-b733-157ec90cfc2c", "3f4d5a18-292d-5165-95fa-8aaf6c2ec2fd", "d8d81d9c-41e6-5ad7-9da3-05dad87905f3", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "c76b968a-995a-5109-a4eb-f329fa710f26", "462a3ea2-5cf4-556a-a5bf-8f4b2c876260", "7509abe5-a2de-50dd-9c15-3c4d714fefed", "9abee888-fdb9-50bd-bb86-2e53a6052057", "e44ba5fc-2846-5b06-923b-eb11cc9b2e51", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "58914b28-03d1-528c-aca8-2bcc19b55aac", "33130f85-57c8-54d5-b050-075bb1ccab97", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is missing a result for the WQ-M task in the table. What is the Pearson correlation coefficient between $Diverse@k$ and human evaluation for the top-5 generated questions by the model proposed in the paper?", "reference_answer": "0.949"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.08395/result_table.png"]}
{"uuid": "e5eb0900-d813-53c3-a8e6-3264e6831ea0", "question": "Consider the paper that introduces the quant method that achieves a lower score than APQ-ViT but still scores higher than 76.0 on Deit-S with a Weight/Activation (W/A) precision of 6/6. What is the specific range of values for R1 when applying twin uniform quantization to post-softmax activations of the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["87c327a8-cd52-5d23-93de-c4486887da8b"], "reference_pdf": ["bc431e93-410f-5eb0-a4a5-314a37e129a0", "34417770-67d7-5cab-b9d4-76999c97bc02", "720ede7a-1362-532b-b4b5-4436c03c5363", "95808d88-d437-55ec-9af6-cb7399b1010c", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "60495988-448a-5919-9470-d8561310a40d", "81528b8c-c326-567e-a3ed-4ca2b0295ff2", "52d72671-969b-5840-8808-73be9745a07f", "720ede7a-1362-532b-b4b5-4436c03c5363", "93502213-3277-5df7-a02f-39b12077c0c2", "08e29bf5-665b-561e-8672-d90363383d43", "e7184da4-f850-5562-ba39-441760b58a7d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "3b9340d4-5374-5613-a1a4-bc3c125639c6", "7908763f-3a9d-5ce5-af59-f68888750583", "1ffa6ac4-663b-5498-84b3-3148948fcba4", "332d0f2a-9d5a-54b3-8d5e-e24081633c0e", "f6e91a91-0b1e-5280-8522-a20492033f16", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "b9f85125-14a8-502f-8717-f38768038090", "acce625f-be46-56f5-b5f6-13b331e2efdf", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "b9fa129c-7848-536a-b464-b4090dd72a9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the quant method that achieves a lower score than APQ-ViT but still scores higher than 76.0 on Deit-S with a Weight/Activation (W/A) precision of 6/6. What is the specific range of values for R1 when applying twin uniform quantization to post-softmax activations of the model proposed in the paper?", "reference_answer": "$[0,2^{k-1}\\Delta_{\\text{R1}}^{s})$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.16836/comparison_table.png"]}
{"uuid": "e683e304-0dd7-5888-9f07-bf4b248a3ad5", "question": "Consider the paper that introduces the method which is directly above the dashed line in few-shot prompting. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["2479f89b-b7c0-534f-b51d-d24093d3a1f9"], "reference_pdf": ["7aacee49-58db-593f-9a47-44846ba2ed23", "881f50d7-f0cf-59e7-8351-429ea3655e0b", "57c06ca1-608a-5816-86dd-0f35be577ce0", "1165b8f0-4261-5c50-9583-bfc199324e61", "1c848190-6829-5b07-a439-3452fd19617b", "ea8d0d91-a08c-547f-aa61-fc136ce41e58", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "003269db-f43b-57bc-a219-825c655fab01", "16e73621-a0c1-5f1d-ae72-fa60befecf05", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "b31b84cd-d7c7-50d1-9dc2-cb340ea4d218", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "a76fdb50-d95e-5db2-83a6-ece16257796b", "e0523cf0-8310-565e-9d91-c539c15adcb7", "be395337-c3e2-5e16-b2ef-1ed22e6736dd", "729f79df-1057-5418-89cd-592408770592", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "1e0413f9-466d-57a0-be12-cbfb9da4056a", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "8f02441e-aa43-5abf-bd9b-cfd760b7cc20", "e5c8fae9-734a-54d1-bde4-03ec07d10c86", "b5798106-2737-52fa-b1e5-010749d19c2c", "6677d3c0-7aea-5795-a934-d93933e25157", "02cf0294-1961-54c5-a745-0d99126e65d3", "c76b968a-995a-5109-a4eb-f329fa710f26", "de0470bf-d650-5f5c-9fb8-926b7ed2c806", "65c601c1-c571-5d9e-aa32-e37fcc3e0097", "445e9197-1321-57c3-93bf-7084e795848d", "da29dae2-1a88-5793-8149-81c0b63122ca", "02193a94-398e-57da-bb53-0c5800ca743a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which is directly above the dashed line in few-shot prompting. What specific improvement in percentage points did the model proposed in the paper achieve over their discriminative counterparts on the out-of-domain subset for the VQA task?", "reference_answer": "6 and 6.2 points"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15746/comparison_table.png"]}
{"uuid": "e6e9d635-841d-5359-8236-25b7670b019e", "question": "Consider the paper that introduces the dataset in which KALMV achieves a score of 70.83 for the XL model. What specific adjustment was made to the Question Entity Linking task to ensure MTurk workers reached agreement on question entities?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8dca380b-0d1b-5c49-a9b6-0581864c7909"], "reference_pdf": ["5b0d44de-0d1d-5f43-a9b0-89b5338732d7", "e4c15aff-f4fb-5699-ba7b-270af46c07ab", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "0b53b7e9-c74a-53e3-911d-f614a18dcb5b", "84449b22-c7ae-5253-8295-9d74a378fcc3", "8433f894-a217-54d3-9ae5-5c17f951797a", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "79b4a9b3-0759-50f7-a801-83cad821e867", "0337fff3-2745-5430-b1ca-9d43c836a09c", "d699a785-3fb8-5b5b-8487-72d2dbd4dcbd", "90e3610c-c0b5-5b1d-9a9f-6f0f62dd9c89", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "11f9746f-503b-573f-8781-04477603c994", "e3ef9171-b0b7-58c0-8e98-051bfde10ef7", "7908763f-3a9d-5ce5-af59-f68888750583", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "739c8432-c687-5220-89f6-f84e7c860800", "6f4d0a2f-4457-55af-b519-da2a1df140da", "36a1c245-8803-586f-a39c-57a149b16892", "7c278568-4bb8-5a1f-af34-4df3980282eb", "7908763f-3a9d-5ce5-af59-f68888750583", "39f7afc4-5c63-5cc3-80e5-ac05cb088940", "5a533ef5-84ee-5448-8375-b683864484bc", "1e7d9f86-3567-55b8-be98-064a3d297af1", "3967df69-753f-527b-9c82-35378bcaa943", "30a603dc-f798-5bef-bc07-78a6882b1cff", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "2bc7f244-8607-5501-a3c5-916c66efc615", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "dd39e75b-40a4-5ec5-9943-79277ed1cd00", "819d0208-b342-5a31-a2ab-da64c204544e", "46fd03d6-7a66-5072-b2ab-61e072e5131f", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "26e45afd-1c91-5f0f-bb47-33707acec072", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in which KALMV achieves a score of 70.83 for the XL model. What specific adjustment was made to the Question Entity Linking task to ensure MTurk workers reached agreement on question entities?", "reference_answer": "The task was modified so workers only verified a span and linked the entity in Wikidata."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.12836/results_table.png"]}
{"uuid": "e7496fb5-eb57-5722-8b88-5098afc57590", "question": "Consider the paper that introduces the dataset which has the largest number of Queries|Aspects in the ABS category. What specific methodological limitation is highlighted by the authors regarding the model's aspect discovery stage's performance in the Software domain?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has the largest number of Queries|Aspects in the ABS category. What specific methodological limitation is highlighted by the authors regarding the model's aspect discovery stage's performance in the Software domain?", "reference_answer": "The aspect discovery stage has a low precision."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "e7894d71-b14c-555e-9d90-cb90272d11fb", "question": "Consider the paper that introduces the method that has a lower J_k score than Random Entity Quantization but a higher J_k score than NodePiece in the FB15k-237 dataset for all values of k between 400 and 1000. What is the primary reason for the performance variance in the model's ablation studies across different datasets?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower J_k score than Random Entity Quantization but a higher J_k score than NodePiece in the FB15k-237 dataset for all values of k between 400 and 1000. What is the primary reason for the performance variance in the model's ablation studies across different datasets?", "reference_answer": "The primary reason for the performance variance in EARL's ablation studies across different datasets is the different characteristics of the datasets, particularly the number of relations. Datasets with more relations (e.g., FB15k-237 and CoDEx-L) provide enough distinguishable information for entity embeddings through connected relation information (ConRel), making the performance less affected by the removal of other components like reserved entities or $k$NResEnt. In contrast, datasets with fewer relations (e.g., WN18RR and YAGO3-10) rely more on the distinguishable information provided by reserved entities and $k$NResEnt, showing more significant performance variance in the ablation studies."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_2_comparison_figure.png"]}
{"uuid": "e85968fe-543f-5d8e-a218-64ef84192889", "question": "Consider the paper that introduces the dataset in the last row of the 'Inconsistency Detection' category. What specific aspect of pretrained models contributes to their superior performance in generating factual summaries compared to non-pretrained models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["36658338-c3d6-5b36-89d0-3ae79fa52f44"], "reference_pdf": ["7b88ef21-46b9-5491-8b41-5ba7e5f89bb4", "5ab64734-2725-57c3-95ba-75a693bf4922", "1165b8f0-4261-5c50-9583-bfc199324e61", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "413aacbe-98fe-526a-9b0f-9d9cbe19ef5b", "34417770-67d7-5cab-b9d4-76999c97bc02", "2987b2aa-67ad-5312-91c3-067762156456", "e0fe58d1-5915-5058-a0d9-fead5d6c3cde", "fe26770b-ff50-56e9-8546-8310b7215de7", "059ebe26-3869-5ac6-9b02-3c8f4cc40d4c", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "87b6b442-cb9b-52b0-bda4-c5315b366b48", "1e52b704-faf6-5269-9ab2-c13bc8be1042", "1e5af690-d43f-573a-9426-eae1c86f4c12", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "dba5b637-a3a2-54f2-9284-034b062db02a", "cac30ce0-51b1-54ef-bfc5-fa365d4131e4", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "e77a8699-a9b0-5923-9ee7-6b40ebe9c61f", "d0ad987a-c189-5059-9b97-48ec131780a4", "e9c37d5e-a9e4-5f5d-a0b7-2d96e98c1048", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "7908763f-3a9d-5ce5-af59-f68888750583", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "281a6af0-616c-5163-995a-77801d30adbd", "295776b5-bd82-5def-96e7-ee7bb8cc6b99", "eb8ba2b8-b5a6-516b-b762-19465f9eaaed", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "041c4689-b5ad-5878-81ab-afc3101acdb6", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "58b68b03-a6a4-5977-a584-6f7b13dab877", "608838ef-8a4c-50f0-a78e-db6f2709edc5"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the last row of the 'Inconsistency Detection' category. What specific aspect of pretrained models contributes to their superior performance in generating factual summaries compared to non-pretrained models?", "reference_answer": "Exposure to vast amounts of text through pretraining"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11648/comparison_table.png"]}
{"uuid": "e8afb98d-f38d-5439-a035-f7c72b8bd34a", "question": "Consider the paper that introduces the model that achieves a mean classification accuracy of 0.6712 on the Hate dataset. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that achieves a mean classification accuracy of 0.6712 on the Hate dataset. What is the Pearson's r correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "e8c8a299-9a2c-58ad-8ab6-4a3af09967fb", "question": "Consider the paper that introduces the model shown in the figure represented by the pink line. What specific condition must hold for the kernel estimator in the WR algorithm to ensure the convergence of the cdf $F^*(x)$ of $X^*$ to the target $F_0(x)$ as $n$ approaches infinity?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the figure represented by the pink line. What specific condition must hold for the kernel estimator in the WR algorithm to ensure the convergence of the cdf $F^*(x)$ of $X^*$ to the target $F_0(x)$ as $n$ approaches infinity?", "reference_answer": "classical assumption \\begin{description} \\item {\\bf (C)} : $h_n^k + \\frac{\\log(n)}{nh_n} =O( e_n^2)$ holds and  $f \\in {\\cal C}^k$ ($k$ times derivable) for some $k\\in \\N^*$. \\end{description}$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/average_relative_performance.png"]}
{"uuid": "e9122e03-85ae-5877-8cc2-68c346cbc236", "question": "Consider the paper that introduces the method that has a lower F1 score than SERA and a higher F1 score than Doc2Graph. What is the F1 score for the semantic entity recognition (SER) task in the multitask fine-tuning setting for the Italian language using the model proposed in the paper's LARGE version?\n\nA) 92.5%\nB) 89.3%\nC) 94.7%\nD) 87.2%", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["4a71c642-ce6a-51d3-bd55-bc5764d46bb8"], "reference_pdf": ["49b4cdbd-7730-5f6c-9be1-e404ddf81009", "88ac1798-77b6-575e-bb56-686a270f2b90", "565281f7-0639-57ef-8326-b0a5736453ec", "1ad849ac-0315-597e-9953-3dc6a95ebc07", "b978ad55-c35e-5206-931e-7722a286eb77", "1d8acec7-e518-5232-876e-1239dd9798a2", "020081a0-ba8e-58cd-a3e4-92898afdbcdd", "3d59acd4-6d28-53c7-97fb-59c76ada4070", "b678de9e-7ab0-5414-b09d-e1b5330c2124", "34ea827e-75b7-5db5-8f5f-635ac55b4a5e", "c628e6e6-81bd-5601-8cef-2499ac25f581", "9048f37a-221a-5252-a6ff-2e7feb5258b3", "d9298bb6-d0eb-5b7b-a81a-47c4ae28352a", "0c590283-50e8-5f8a-b1b5-a0ba83a07b07", "626f7394-4e6e-551d-9786-dc5d0949561d", "83c3e134-0000-581c-a6f2-d311645b274b", "f09c794e-86fa-5594-90f7-3c9301329a5e", "fa3e6c04-231f-5c2b-9ae1-20f91f081351", "d0859a0a-4bc5-5b3e-828d-f5f818fd0227", "dc908cce-31ca-5bef-a3b1-552c1cb2e887", "cdef8abf-e135-5090-b146-94b4a3840672", "ca763ccd-4ec8-5b90-9067-ada1af33f8be", "097d0250-9e1c-51bf-acd7-0cb0d6baa5a4", "332fef4a-3940-5d3a-aba6-2c27ce658f5d", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e45656e2-9cd5-5c57-95dc-45d0e35c23d6", "10ff59fb-9509-502b-b27a-1cba18082292", "fc1799fc-b2be-559a-81ad-5851732795be", "91f68f07-6cb0-53d1-98a1-3f3061d6ef44", "60ae5f99-3a2c-5936-b306-3333c1463463", "2996caf3-f7a5-515a-ba60-091b02f7c9e5", "819d0208-b342-5a31-a2ab-da64c204544e", "3a6897a4-2ea0-5070-a155-1d8c36764d68", "29ca8367-936e-562d-a161-00e163499a28", "05f9c218-644f-5c4c-81b2-a66f192586c8", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower F1 score than SERA and a higher F1 score than Doc2Graph. What is the F1 score for the semantic entity recognition (SER) task in the multitask fine-tuning setting for the Italian language using the model proposed in the paper's LARGE version?\n\nA) 92.5%\nB) 89.3%\nC) 94.7%\nD) 87.2%", "reference_answer": "0.8372"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11016/comparison_table.png"]}
{"uuid": "e91c1147-9a86-5186-89c0-f8e96f520d90", "question": "Consider the paper that introduces the method shown in the table is above the 'Magister et al' row but below the 'UL2' row. What specific loss function is used for the unified student model during the training on the chain of subquestion-solution pairs for each problem in the methodology for distilling reasoning capabilities into smaller models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["a9cb1278-f520-54c7-95ce-e8f2f51779e1"], "reference_pdf": ["2e150e31-dca0-581d-97e1-f74e4efd24fb", "498585ce-5f0a-5848-8205-f47f169e5a7f", "6bf39f15-4505-5fec-a157-0d7269604c8c", "34417770-67d7-5cab-b9d4-76999c97bc02", "6ccd0e89-3d46-597a-910f-131be6ddc31c", "623d4491-e63b-5ba4-8b3b-19827be11dc9", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "5768d951-ac45-5015-8e79-e8373551d34d", "28c91c0b-4918-5ece-a008-5c539282c189", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "68eacc6c-474b-594d-b512-285ebb27d97b", "75d94b88-a11a-5e5a-bb24-b01e7b230196", "b1f5d2f0-a4a0-5938-94bf-7737b42158b1", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "4f43a3a1-e667-52b7-851e-21cffa9d29a0", "7617cedb-1166-5825-81c0-fc4b40c5bf0e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "28428662-2973-5032-9217-2aa27a59f6de", "8dde05d0-7798-5f9b-9f99-1d4823d4fbdd", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "7908763f-3a9d-5ce5-af59-f68888750583", "027e7f32-5fc6-599e-a4a1-3e12606f627a", "e05cbd04-192e-5761-97ce-7250058cf895", "9feffe2b-4a6b-5ad4-a06d-1bae1257acce", "7908763f-3a9d-5ce5-af59-f68888750583", "7622ac08-15d7-5102-89b2-6891803cd8af", "20847c00-ada9-56f4-aab2-d67eb2ace27b", "7617cedb-1166-5825-81c0-fc4b40c5bf0e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the table is above the 'Magister et al' row but below the 'UL2' row. What specific loss function is used for the unified student model during the training on the chain of subquestion-solution pairs for each problem in the methodology for distilling reasoning capabilities into smaller models?", "reference_answer": "auto-regressive language modeling loss"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05074/result_table.png"]}
{"uuid": "e91eb3e5-6dad-54dd-a15e-69585824d218", "question": "Consider the paper that introduces the method that achieves an average EA score of 67.07 in the FinQA task. What is the highest EM score obtained in the ablation study on the effect of in-context example orders for GPT-3 on the NQ dataset using the model proposed in the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves an average EA score of 67.07 in the FinQA task. What is the highest EM score obtained in the ablation study on the effect of in-context example orders for GPT-3 on the NQ dataset using the model proposed in the paper?", "reference_answer": "Reverse order"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "e97513cc-9e95-532e-8a70-f40e8919c9ea", "question": "Consider the paper that introduces the model which has a lower mean classification accuracy than VIBE but higher mean classification accuracy than UDALM on the Stance dataset. What is the Pearson's correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model which has a lower mean classification accuracy than VIBE but higher mean classification accuracy than UDALM on the Stance dataset. What is the Pearson's correlation coefficient between word overlap and the model's performance for the task of political affiliation classification on Twitter data?", "reference_answer": "0.9817159316285563"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/classification_accuracy_table.png"]}
{"uuid": "ea917948-9ab1-56a7-9fe8-3c56ef0408e5", "question": "Consider the paper that introduces the method that achieves the highest Precision score in the Token (I-topo) category. What specific distribution is used for sampling span lengths in its span masking scheme, and what is the mean span length resulting from this distribution?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1821bd0b-d55e-5dbf-bfcd-2fde02a07633"], "reference_pdf": ["67602490-afd8-569f-b463-35cd7a8a7b46", "4d856727-33a4-59aa-90a6-6245d8bd1918", "778c3b86-7d0f-58fa-b177-972efaec7c5f", "ca80f95d-2b88-55ca-ab3f-8f7c86b723e4", "0c61720f-b625-5082-b5fe-8fbc3206d656", "51b6e073-e1a7-51c0-8a23-314d84c6d9cd", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "afc322a1-0cca-5ce0-9e44-3b904630f337", "5be16d27-4c22-576f-be7f-16715bf49ffc", "fad9fe2b-872e-5d61-9149-ef7c915db5a4", "8b0379d4-7ff4-55f8-ab02-50abfbadfbda", "7c278568-4bb8-5a1f-af34-4df3980282eb", "d2e0dc47-0423-50ea-9dd9-872548a733d2", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "09523922-5ff7-5682-9e59-2b903b7d7a35", "117fcedd-ba7a-5009-9cf0-ee2e63137423", "52f46313-b1a0-5e5e-b415-a54c42ca1496", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "cb57171c-5fc1-56c6-b168-4d122a1427cd", "ca236447-69ca-57c4-8a5c-8891e4230b8b", "9e0baaab-f75d-5b52-b965-a5b427196392", "e3c2e045-3afc-5d1d-aad1-3389f80aea7f", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "cf94c43f-2a86-5ba2-a52d-20126e193c68", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves the highest Precision score in the Token (I-topo) category. What specific distribution is used for sampling span lengths in its span masking scheme, and what is the mean span length resulting from this distribution?", "reference_answer": "Geometric distribution with $p=0.2$, mean span length = $3.8$"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14478/comparison_table.png"]}
{"uuid": "eaf4c950-85f5-56c1-9851-1339b826de70", "question": "Consider the paper that introduces the dataset in the table that has a validation set size of 1250. Which model demonstrated the highest percentage of factual hallucinations among its extrinsically hallucinated summaries?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["36658338-c3d6-5b36-89d0-3ae79fa52f44"], "reference_pdf": ["7b88ef21-46b9-5491-8b41-5ba7e5f89bb4", "5ab64734-2725-57c3-95ba-75a693bf4922", "1165b8f0-4261-5c50-9583-bfc199324e61", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "413aacbe-98fe-526a-9b0f-9d9cbe19ef5b", "34417770-67d7-5cab-b9d4-76999c97bc02", "2987b2aa-67ad-5312-91c3-067762156456", "e0fe58d1-5915-5058-a0d9-fead5d6c3cde", "fe26770b-ff50-56e9-8546-8310b7215de7", "059ebe26-3869-5ac6-9b02-3c8f4cc40d4c", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "87b6b442-cb9b-52b0-bda4-c5315b366b48", "1e52b704-faf6-5269-9ab2-c13bc8be1042", "1e5af690-d43f-573a-9426-eae1c86f4c12", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "dba5b637-a3a2-54f2-9284-034b062db02a", "cac30ce0-51b1-54ef-bfc5-fa365d4131e4", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "e77a8699-a9b0-5923-9ee7-6b40ebe9c61f", "d0ad987a-c189-5059-9b97-48ec131780a4", "e9c37d5e-a9e4-5f5d-a0b7-2d96e98c1048", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "7908763f-3a9d-5ce5-af59-f68888750583", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "281a6af0-616c-5163-995a-77801d30adbd", "295776b5-bd82-5def-96e7-ee7bb8cc6b99", "eb8ba2b8-b5a6-516b-b762-19465f9eaaed", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "c16ad2d8-be0c-5eed-ae16-5950a83e34bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "041c4689-b5ad-5878-81ab-afc3101acdb6", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "58b68b03-a6a4-5977-a584-6f7b13dab877", "608838ef-8a4c-50f0-a78e-db6f2709edc5"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has a validation set size of 1250. Which model demonstrated the highest percentage of factual hallucinations among its extrinsically hallucinated summaries?", "reference_answer": "\\bencdec"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11648/comparison_table.png"]}
{"uuid": "eb092df1-0eaf-5de9-937a-8423c7aea78b", "question": "Consider the paper that introduces the LLM model that corresponds to an r score of 0.813. What specific methodological difference in the evaluation setup for the model's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["afd759ef-87a1-55e5-a5c5-b0102325830d"], "reference_pdf": ["17623cac-c243-591b-b7bc-d261f6ebd607", "e43b9042-e85e-52ba-b1bb-bb5416f836fa", "636b10fe-f0e5-50c6-b53a-1b9b5c636864", "e3181c7f-c92f-5e72-8419-d97634cf5535", "a4166c00-143a-57ce-8929-537667e11cc4", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "2eaaf347-a894-5b0d-9d6b-39fe1f869854", "5fe9c4e7-cf60-5a3a-8550-26c2aa1b910c", "e62ca3c9-15fe-5a2f-8f57-5914991cbae4", "1d1ff063-3059-5b5b-abe0-0e41a62ac920", "f3728bd2-f6be-585c-8ced-36649229dde9", "dc135cea-016f-534b-bfe5-39bb5aca25dc", "c67a9286-46c2-57f7-9a58-2c7ab8755152", "d99202a8-0fbe-5032-a962-e65c745d3595", "cd07dec7-94b7-573f-abda-fa59cdcacf82", "eb8ba2b8-b5a6-516b-b762-19465f9eaaed", "8da0435b-edc5-55b1-8983-ba5e662a3d0c", "2feed15d-e321-5ac8-8a27-568759e429dd", "fafb5d80-163e-59f2-a365-16a37f4fd351", "f23baff0-753e-5787-b392-d67f27d48d2c", "1d259046-2a97-578c-a3f9-40fe2e138e73", "00b65d5a-72d7-5d45-b93d-aed20dd49192", "bfc4e2c5-a593-5974-bd48-8220a9ee00b7", "f1071e3a-5534-5cf9-a612-30b6e7986a75", "2077ab9c-e416-5734-b43b-df2a5d91ec67", "1adb8a6f-ba9b-5307-8758-5fde1de8fc44", "60088993-59e3-5ca4-8e90-cddaec9589ae", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the LLM model that corresponds to an r score of 0.813. What specific methodological difference in the evaluation setup for the model's performance on the USABO and SAT reading/writing exams contributed to a deviation from the standard approach used for other exams?", "reference_answer": "The use of sampling a letter choice at temperature 0 using the already-sampled explanation for certain exams, rather than extracting the model's letter choice directly from the explanation."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.17428/mse_table.png"]}
{"uuid": "eb9168b5-ff41-5b31-bc8c-a8414e47c42b", "question": "Consider the paper that introduces the method that corresponds to the orange line in the figure. What is the unique aspect of the model's architecture, referred to as UniKGQA, that differentiates it from previous works in multi-hop KGQA tasks?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the orange line in the figure. What is the unique aspect of the model's architecture, referred to as UniKGQA, that differentiates it from previous works in multi-hop KGQA tasks?", "reference_answer": "The integration of a semantic matching module based on a pre-trained language model for question-relation semantic matching and a matching information propagation module."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "ec15c282-a320-5e5d-a67c-ff4adf230c84", "question": "Consider the paper that introduces the model shown in the figure that corresponds to the green line. What mathematical modification is applied to the difference in performance between aligned and misaligned models in its methodology of quantifying temporal degradation (TD) to ensure that, as performance deteriorates, the calculated value increases regardless of the direction of time between the training and evaluation timestamps?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["dedf27e6-1e46-5256-a1ff-ef86b7b9795a"], "reference_pdf": ["5fafcacb-39f9-591f-be5a-7c510efb9431", "46776752-771c-5aab-a1fd-f19a7a8c3f03", "e7f8ec66-fcc7-5f7e-9af9-e1f69763cccb", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "cfb29636-07c4-5814-b367-97e551674acb", "a1403f63-61e2-5148-a4f7-9e5b5dcc9591", "7ade11d4-01d2-59a3-b576-0fdf7b7e63a8", "2f3c31d0-97f6-53ed-a015-fa77ed3ff49e", "c69e8c17-4b5c-5d03-be86-a0f0f19cd9fc", "a412fa82-f531-5c43-bc7e-4a3dcc240384", "5bf0d02e-6fc3-5d7e-8b7e-79a0113a37e6", "d8d3751a-674d-5ca0-90ef-f16fff2a3e15", "9b6fbdfc-caf0-5d79-ac65-a0ce884cb9cf", "6bb1f536-7f4c-5a26-adc9-11154e7174a0", "ce71bd6d-c5e8-5730-95ab-8e5d96efa77c", "d75af728-525e-5784-a8c9-abc5cc9d3efb", "842587b9-a434-5463-8493-86d59dd3f925", "2b5ca079-e32a-563b-9231-599bb005d065", "fbfe5f40-bfce-5c96-9fa8-5059ab4ba7a3", "1a19e01b-854e-5242-a851-6cea01b4b0ed", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "ab1e92a1-cd80-56c1-878b-6420ed9ef600", "c2ac06b9-eeee-57e5-b704-c79774852e30", "1e7d9f86-3567-55b8-be98-064a3d297af1", "293d5adc-aa34-5d98-b38c-29153c1715b8", "81c915e3-20ad-58b8-90b2-abf6ad59277d", "0302916e-fd19-5627-95c5-4320efcadc5a", "be7b1da6-4e42-5c87-81ae-adbb8c9be0f5", "c74cfa25-c4e3-5642-9de4-343770a00dc3", "4291f117-a24f-5a67-ada9-37cba4c696da", "4a324a22-6bd2-5602-84bc-07231c819440", "278cd4b7-0439-5a94-8a43-cdc6855de6c0", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model shown in the figure that corresponds to the green line. What mathematical modification is applied to the difference in performance between aligned and misaligned models in its methodology of quantifying temporal degradation (TD) to ensure that, as performance deteriorates, the calculated value increases regardless of the direction of time between the training and evaluation timestamps?", "reference_answer": "-\\left(S_{t' \\shortto t} - S_{t \\shortto t} \\right) \\times \\text{sign}(t' - t)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10191/accuracy_figure.png"]}
{"uuid": "ecf87560-0f47-5386-ab04-1ad71879d5fb", "question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. What is the specific mathematical expression used in the model proposed by the paper to derive its objective under the Bradley-Terry model?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["d1251ff0-e100-545c-8a1c-664b75854f3c"], "reference_pdf": ["32d04289-3862-5912-a136-6a3d0fe472a2", "3e5b43f1-9b31-5edd-b334-46d5175e1900", "842c1145-6b9e-5d34-bd53-8169d537b66f", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "972a1223-29a4-5304-b9bd-ddec4829d163", "13daa5ee-4b7d-55ec-a5ea-7b19c5cf6e4b", "59d1bdaa-0e54-5669-adad-dd225b6acdf5", "37de84b9-2cd0-57ce-8d94-36a43b6c323d", "df2afc9e-2480-567e-84f6-bf4fb97fc1f5", "2adf1c9b-6b9e-59fd-a899-7262b2bd3179", "2ee0ee87-1989-50b9-b896-742ee506c1cc", "d9e5cf3c-1b25-580a-b88a-a07f9d832600", "17623cac-c243-591b-b7bc-d261f6ebd607", "f5c3d2bd-4221-5873-a520-589a585f6f93", "ca191c58-f83a-59e0-ad3f-fc6d9a125d9c", "2d4ccd49-4eeb-58ae-bd4f-134be8ae2c11", "945d086d-178d-52d6-aeb4-3988380b6b68", "90aad2c8-22fb-5293-9f5b-58c74b828bc1", "361c3f6a-401c-5854-b618-e7df40b3fa96", "d527d6bb-30ef-5662-971b-78311f082434", "4a91fb46-07a5-5ca4-8801-9afe21c4a3cd", "7169514d-e320-5e1e-8541-b8ca0f8ccc67", "bd4f2699-b1c4-5b76-8e8c-55f84e1e7fe0", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "c7633d80-8236-5a67-a4e5-88fdeadcd1ea", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a239e827-0d3f-5f3a-9757-0b218e376c95", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "342d6620-30f0-5382-b7d7-d3d5f798498f", "e2cbc3e9-68fb-5796-b54d-738df1ac3b67", "d777ea51-80c0-5cd7-873e-3695a75adea4", "880a06dc-f0c4-5e19-9201-2861f952fb32", "3a69cec2-a986-57db-8ea0-bfb4e9e3b548", "8d3ce001-929d-5c83-985e-0268ecc95532", "7908763f-3a9d-5ce5-af59-f68888750583", "dfd4aeaf-4735-5e61-92ff-f8b040f6eb55", "35b48813-1deb-5375-ac6a-948e906c5f54", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "dd073182-00f0-5a9f-800b-7779293ab2ae", "2bc7f244-8607-5501-a3c5-916c66efc615", "e1af3dcf-dee1-50e0-a72b-6c43dc428784", "977a0308-a19f-537c-940c-4064e7796e83", "58b68b03-a6a4-5977-a584-6f7b13dab877", "ebaab94f-c9fb-5186-951c-d7259a580fde", "39dfbe1e-7b6f-58ea-b0a5-b0431a8efe78", "d27ee810-3a49-5970-b14a-c71604d54388"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the optimization method that exhibits an R2 score of 0.191. What is the specific mathematical expression used in the model proposed by the paper to derive its objective under the Bradley-Terry model?", "reference_answer": "p^*(y_1\\succ y_2|x)=\\sigma\\left(\\beta \\log \\frac{\\pi^*(y_1|x)}{\\piref(y_1|x)} - \\beta \\log \\frac{\\pi^*(y_2|x)}{\\piref(y_2|x)}\\right)"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05857/comparison_dpo.png"]}
{"uuid": "ed20b892-8041-5844-ba25-4ba4df9e5be8", "question": "Consider the paper that introduces the method that exhibits the lowest BLEU score in the De->En task over Average Lagging from 5 to 11. What specific mechanism does the model proposed in the paper use to calculate the expected attention for each head, and how does it differ from the approach used by its counterpart within the same framework?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["7582f0e7-6e24-5ce8-8359-74f0573280b9"], "reference_pdf": ["f298b046-deb5-5713-b58b-3778fa0974a1", "76c89153-3613-554b-a8e1-4a815fe898d3", "239b7173-a5aa-5ebd-b3e1-ee619a7bb61e", "8f35bc2f-2d51-5e00-8fe2-6a44259cfa7c", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "be09434f-a531-569f-bd6b-bfc25cc9ceab", "414ebb44-c01b-5fab-b9b7-695cdaa5127a", "6657bb9c-1dc9-5f53-ac55-877c646b3647", "bcd581ed-d1c8-58d3-97f6-3937a7d171bb", "45535d81-7958-5c77-8900-1b9628a9a06c", "4aee357f-d44d-5032-8e07-cd6e0fb7f0f8", "4674951d-9144-5182-8c40-6e12c2fd7ef0", "29da882a-5b65-5c20-88d1-51cda121e0f6", "9ac343ee-d8e1-576e-8353-9463ed3f0532", "d6b76a71-f118-56d3-84ed-a3401238f2a3", "6851f701-d921-56d5-a4ee-5c127c7d1183", "725c8996-76d4-5ed3-953b-caff7892c741", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "3bca006e-9b8f-50d4-90ff-e851713c9040", "871d8312-5d33-5708-9511-d66d820f3e35", "7317eb83-dade-50f1-a450-b78345889411", "ec2fad1c-508b-500c-af8f-a95dd50b9980", "746c9f1c-5382-51af-b2a9-74ee611d7dd5", "0dbd14aa-3232-5969-bb88-470ee98a3a4d", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "b85188c4-5fd6-5ce7-91e4-78dc80eaf986", "460ca513-b121-5d81-b795-a032dca080ae", "d11cd80b-ef61-5a64-a760-578f700a5170", "8a5b2dc8-1f24-5aa0-ac67-5d1e36f44865", "dfac74e2-051a-5a1f-98fc-d5497a48f44b", "ae10df12-cb06-58ac-a746-6f941ee929e3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the lowest BLEU score in the De->En task over Average Lagging from 5 to 11. What specific mechanism does the model proposed in the paper use to calculate the expected attention for each head, and how does it differ from the approach used by its counterpart within the same framework?", "reference_answer": "MMA-IL calculates the expected attention for each head using a softmax energy function and then applies the Monotonic Infinite Lookback Attention (MILk) formula to calculate the expected attention. This approach allows each attention head in MMA-IL to attend to all previous encoder states, leveraging more information for translation. In contrast, MMA-H calculates the expected alignment for each head using a hard selection process based on a Bernoulli distribution, where each head hard-attends to one encoder state, which may be better suited for streaming systems with stricter efficiency requirements."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14883/figure.png"]}
{"uuid": "ed71a267-8475-5b98-a4b3-c839a7531670", "question": "Consider the paper that introduces the benchmark that achieves a 'Generation Token Length' near 400 when the 'Compression Ratio' is 1. What specific improvement does the model proposed in the paper, through CoT prompting, provide over answer-only prompting for the Codex model on the 'Tracking Shuffled Objects' task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark that achieves a 'Generation Token Length' near 400 when the 'Compression Ratio' is 1. What specific improvement does the model proposed in the paper, through CoT prompting, provide over answer-only prompting for the Codex model on the 'Tracking Shuffled Objects' task?", "reference_answer": "CoT prompting enables a significant improvement in performance on the 'Tracking Shuffled Objects' task, with a gain of +28.5% accuracy over answer-only prompting for the Codex model."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "ed8e7419-2228-52df-913e-6d3f72b1c0ac", "question": "Consider the paper that introduces the method which has 11.0 rounds to completion. What is the impact of using a death mask with agent-specific global state (AS) on the model's performance in the SMAC domain?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["db2cacba-a6d6-5de3-8b45-95a4a07883c3"], "reference_pdf": ["8de6d12b-9dcd-5a37-aaf6-c9295ce1e8a9", "3c73cc66-fb71-5c29-95c7-b2c887290e79", "74746a87-dab3-59c9-be08-3ecfcf6438eb", "3141fa52-db69-539c-8979-fbae34e9747a", "02193a94-398e-57da-bb53-0c5800ca743a", "fbe2cad7-8871-57e9-99a5-041bd72a96d1", "b52eb5dd-43d1-53c3-9438-cbe0a0e59538", "3b56c40b-e3c0-5ab0-8303-818cadcbfd0b", "95286e49-8ec0-51d4-b4af-8a0cb4b59b63", "feb416bd-1fd2-59c4-b5e3-5cd152775a17", "56bb5074-0a00-578b-ad44-e24096458b1e", "23a2cf6d-2c8a-5b75-b4f1-29b2f64ee41c", "a84ef890-5c36-506a-b8ea-79837d85ae3b", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "446b417e-0e23-5098-afe3-0790a06ab23e", "25b64ade-68d0-5d1f-a552-4169ec42054f", "d22f49c8-5ad1-5151-adaa-41d9c94fdbc0", "118cac21-d91b-55b6-bfce-0742348b4c2d", "79a7862f-22dd-56b1-affd-42f774cf64fb", "172b7dad-d436-5ced-9eb4-0f5702d227b2", "dd21cb7c-5752-5764-b486-bbf8f2e53f84", "177b1aea-89bc-52c2-bf91-6f27f1964f71", "34ef8fe5-e5a0-5401-8a39-e8944a3ea356"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has 11.0 rounds to completion. What is the impact of using a death mask with agent-specific global state (AS) on the model's performance in the SMAC domain?", "reference_answer": "Using a death mask with agent-specific global state (AS) significantly improves MAPPO's performance in the SMAC domain."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.10701/result_table.png"]}
{"uuid": "ed94437d-4156-5427-a9f0-082da0167f9c", "question": "Consider the paper that introduces the model represented by a blue line in the figure. What specific methodological approach did DialoGPT Large employ to address the challenge of generating bland, uninformative samples in open-domain text generation models?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["55abc53e-a52b-5dae-a143-9f5a1b7e61e0"], "reference_pdf": ["770824c7-74c4-56a2-96fb-f660347c5ab0", "02c713fb-34a3-52b4-abfc-87ecb9dfbe03", "d5e7e85b-65f9-5de9-8055-715323afd845", "d2e5cbce-eee7-5683-b86b-5386568fce0c", "3c559985-fd4a-53fd-bcc7-656fe2452a6a", "d4223ac7-9d75-531d-9113-b52397da2e1e", "b1509b39-7013-5138-af63-9057839e7476", "08846cfe-32f4-5a54-b88b-822df3b6bb98", "9af2c22e-ab2f-5812-9aa9-0dc3e50d1100", "7884f42d-28d1-53c4-bee5-62754d65f98f", "46c753dc-6966-5386-aea9-5782fd08aaa1", "6e541276-cef5-5b69-9036-6c65d9e6b5ca", "c97315f8-2f29-5e3e-bbf4-f0848b855663", "5c19fded-b265-5a07-b81b-580d43473e35", "393e9431-63b0-589d-88bb-62335baaf8bc", "c76b968a-995a-5109-a4eb-f329fa710f26", "b9dfe82f-3a52-57ab-9571-d4e293a722a3", "6fa32937-0b0d-5a8f-9cf7-785754c9d516", "10394dc5-9259-54c9-8868-bf2692924ffa", "206abdf4-f071-58ab-8bd6-206bb79786f1", "770824c7-74c4-56a2-96fb-f660347c5ab0", "23104b1a-a45b-50ef-9541-4627857e2b03"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model represented by a blue line in the figure. What specific methodological approach did DialoGPT Large employ to address the challenge of generating bland, uninformative samples in open-domain text generation models?", "reference_answer": "Maximum Mutual Information (MMI) scoring function"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13676/comparison_figure.png"]}
{"uuid": "ef102f22-c2c3-5837-a33c-7e741ca7f5a3", "question": "Consider the paper that introduces the method shown in the figure corresponds to the solid red line. What specific transformation rule is applied by the model proposed in the paper to construct disfluent summaries for the fluency dimension in text summarization?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["872650ac-af1b-5ead-bff8-975b0ce8d32d"], "reference_pdf": ["cd28f82e-0927-58c3-b17d-bfd6b5888b79", "3c47cf47-b671-55d5-a396-e294638f7023", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "450c1e1c-8f69-5d85-9a26-df3a876f65e1", "fe26770b-ff50-56e9-8546-8310b7215de7", "43042c01-285d-53a4-8e75-a14921ddd5b7", "060cedb0-10c7-53d3-a4f3-4610a1cb854f", "4c8916e4-996c-5c22-9e25-966c9022aa8c", "deef91b8-6c7c-5fbc-b196-a248c88cb07b", "e3b247ba-4ea5-5d11-9653-e6df72b1c84d", "8bd7983c-5a5b-50cb-99ab-62297274885c", "239edc4a-ccdc-5065-96a3-9e612c1afcc1", "6106e3f0-e82c-5ded-a9c2-0d8444beb47b", "48341d3f-eb13-529f-94b4-15ea396b7793", "5102db9f-2387-5fbe-8dfb-045a29ad21da", "917794fc-6091-585f-9aca-18d5d7fe492b", "98f94381-9ab9-5337-a63e-99c8ad892b6f", "7d73d518-86e4-5000-95a5-50c8c4daf0e7", "e606240b-8963-5ee5-b4f2-fb4949398e3a", "213e91d3-d0ba-517e-9eaa-9c30953f754b", "dea2fddd-8066-5173-ab2b-c960d55f2de1", "dbf8b926-916c-5a80-a5f8-ba8a4d2f68d8", "85ba33aa-25d1-526b-a87d-42cfd55a08c9", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "5af5e45d-f259-57ae-a99e-be98764c416c", "eb251b7d-833d-54cd-9374-0481e7af7292", "c50df058-1617-58f1-9b89-c397fcdceb6f", "f3354010-9feb-5b44-afec-0f6be57ca4d6", "03280b0e-c24d-50a6-a988-b6ca1b7d3519", "ab8d017f-8645-5337-aa84-f52783391b99", "67f97fa1-4d75-5346-8e7f-4701de843e11"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the figure corresponds to the solid red line. What specific transformation rule is applied by the model proposed in the paper to construct disfluent summaries for the fluency dimension in text summarization?", "reference_answer": "We randomly draw a span from the positive sample and perform one of repeating, deleting, and shuffling to obtain the disfluent summaries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.13189/calibration_figure.png"]}
{"uuid": "ef3acc35-8408-5007-9922-4613a597d436", "question": "Consider the paper that introduces the dataset with the largest number of dialogues. What is the percentage of dialogues in that dataset that achieved a goal completion score of 2 in the norm generation model?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1fe4dceb-0e28-5cef-8794-e9303386d11e"], "reference_pdf": ["202ff867-5a38-531d-bb71-aaf9818977ed", "af704b49-b4f8-5ee4-b76a-af903e4e62dc", "34417770-67d7-5cab-b9d4-76999c97bc02", "003269db-f43b-57bc-a219-825c655fab01", "bd169600-08fb-561b-af10-381361a9cfd7", "79fb9402-0283-5c7a-ae54-72967aec6549", "773bd309-53f3-5c7d-93a1-7ccc735a1478", "55bea9dd-19cb-5319-9e84-40f981fbde69", "72584296-7e67-500a-883d-60fff1566e16", "b6b88c8a-8892-5722-9c07-319c87bf7010", "46293c99-57d9-5ead-8078-908709313cd3", "b528f9d7-6504-56be-abbf-1a1b714760aa", "da6bc6e9-3f60-575e-868b-4a55bba673dc", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "be76575e-6c00-5476-88ea-0ee5ddb704e7", "393e9431-63b0-589d-88bb-62335baaf8bc", "b46755fc-9177-511a-bc44-a4bc792850bf", "49bde77b-fc00-53fc-b37e-a64371f3a21f", "caae1c5b-0cc2-520e-b18d-f4569d83c528", "3eb58497-86ef-5979-ab34-37ded2b70778", "0da3897b-f258-5cf7-9926-793bd73769d3"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset with the largest number of dialogues. What is the percentage of dialogues in that dataset that achieved a goal completion score of 2 in the norm generation model?", "reference_answer": "43%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07397/result_table.png"]}
{"uuid": "efc6b69c-d611-5002-b3c5-86928c11a5f2", "question": "Consider the paper that introduces the method that corresponds to the third row of the table. How does the gradient expression for the logit corresponding to the unlikely token ($h_{\\text{unlike}}$) in the simplified theoretical analysis of the model's loss function indicate the direction of model optimization?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b25f702e-6afa-5d3f-86a5-5388f5061a30"], "reference_pdf": ["840b01f4-c1fb-56e6-92f1-2c41e39373ec", "2916ff3a-f5cc-5c0e-8960-e693e402ade5", "44f0985f-d1a0-5379-a29c-ea77b96bb1f2", "24589e0c-b589-5704-813b-5ddcc80ce624", "1d6fa876-022c-518c-89fc-73b4ddb349d1", "e538ca11-a05e-58a1-a22a-7cca1d0d3f33", "90b9b399-75fe-5bc8-ad54-e3cf42964bf4", "a239e827-0d3f-5f3a-9757-0b218e376c95", "693d6239-f05e-5428-9c4e-9557251caaa9", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "b0661806-4056-510f-b3ef-bcfe1a7e5603", "7ff14e93-55ec-58f1-b134-9b603b7fd053", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "daf59047-5c23-56ab-9cc4-245eb1a6f397", "7908763f-3a9d-5ce5-af59-f68888750583", "137a4bca-d156-529e-8ee7-5a841286190d", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "dd073182-00f0-5a9f-800b-7779293ab2ae", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1398ab3c-cb2d-593e-9d68-02a0d484e643", "da29dae2-1a88-5793-8149-81c0b63122ca", "bd0d5234-9da1-5808-a85a-3e4c08824c1a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to the third row of the table. How does the gradient expression for the logit corresponding to the unlikely token ($h_{\\text{unlike}}$) in the simplified theoretical analysis of the model's loss function indicate the direction of model optimization?", "reference_answer": "-2*p_{\\text {unlike}}"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14892/result_table.png"]}
{"uuid": "f0baad93-f8f1-5cc2-870f-3ce2f75b71ca", "question": "Consider the paper that introduces the dataset in the table that has the fewest number of turns. How does its curriculum learning strategy specifically address the challenge of optimizing Large Language Models (LLMs) to learn knowledge encoded in multiple languages simultaneously?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b7315180-e811-5a4a-882f-d4a8e0ffe866"], "reference_pdf": ["25905c58-6108-5577-b948-fbaa6aa23e6e", "7d06b7cd-d351-5e13-a0d1-d72ac792b3e7", "b846c66a-a177-5119-af8d-ec4757d6a06c", "2ee103a7-04e2-53fe-83fe-da3bee6579f6", "42c5c7c9-6099-53c2-8868-147e11467288", "4b1cca20-f0e6-5877-8bdd-0e7d6a92cdfa", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "f92811a6-b9ce-519e-9346-f3b892d7f535", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "70d90498-b24e-5af4-84e5-c40377652bce", "01c9329e-9789-52dc-9eed-c99a8ef88a5c"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset in the table that has the fewest number of turns. How does its curriculum learning strategy specifically address the challenge of optimizing Large Language Models (LLMs) to learn knowledge encoded in multiple languages simultaneously?", "reference_answer": "By increasing the proportion of high-quality, low-resource languages during training."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2402.04588/comparison_table.png"]}
{"uuid": "f1252862-d82b-523f-ba7f-ff2d295facdd", "question": "Consider the paper that introduces the method that corresponds to a higher F1 score than that of LDSGM but a lower F1 score than 65.76 for PDTB-Top. What is the main reason the model proposed in the paper performs worse on all four top-level senses of the PDTB, especially on the Temporal sense?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["b24e7069-38ff-5103-b30a-c8d278132f0a"], "reference_pdf": ["6b6f8672-2e62-59ec-a636-c306fc94be60", "6376d671-e22f-58b4-bd2a-5cc3fa1d90b9", "ddf6444a-53d2-5b1e-9ef9-fb54379b6c6c", "56c7ddcb-2e52-53c5-808f-2228b8762930", "bbc63268-e95d-5caf-b75e-aca0e2f44a99", "cec4ac2b-e892-5110-824b-a62ac5247481", "a45441d6-e0fb-5dab-9da9-603663f3e3f3", "b6fda7ba-768f-5bd0-88b8-75b610919a93", "2e2eb6de-cf85-5df4-a628-3b4a469fe2ed", "5a146275-b625-5edf-822d-00877b5ca113", "4dcff28c-a2d3-5c4e-8040-9fc463120a85", "9b1b95d6-59e0-5ab9-89f5-2c2e9594fff9", "a5c6f1d4-767f-5205-a0a3-77953c9c7267", "7908763f-3a9d-5ce5-af59-f68888750583", "ce0dcf03-c681-5401-8954-111b0506efe5", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "db557612-48f9-507a-bbae-d8f4f17bc192", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "234e1d3a-aab1-5133-8362-f4ae804b268e", "38d85d58-5888-5a61-b921-a426594f4860", "d1586d70-b85f-506c-bf13-16816c8debdc", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "cb042120-1319-5a51-a270-eb61170f4631", "e40adcf7-c7a6-56d8-8280-d58c5290e392", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that corresponds to a higher F1 score than that of LDSGM but a lower F1 score than 65.76 for PDTB-Top. What is the main reason the model proposed in the paper performs worse on all four top-level senses of the PDTB, especially on the Temporal sense?", "reference_answer": "The main reason the PIDRP method performs worse than the PCP method on all four top-level senses of the PDTB, especially on the Temporal sense, is that connective prediction is closer to the natural language patterns when the model is in pre-training stage than direct implicit discourse relation prediction."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.00367/result_table.png"]}
{"uuid": "f154f1a2-43b8-5eee-b28b-6bbb54b623ae", "question": "Consider the paper that introduces the method that has the lowest MAE in the CH-SIMS task. Which specific aspect of spoken language dynamics does the Spoken Language Embedding Subnetwork in the model proposed by the paper focus on to handle the volatile nature of spoken opinions based on the critical analysis of its approach to multimodal sentiment analysis?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has the lowest MAE in the CH-SIMS task. Which specific aspect of spoken language dynamics does the Spoken Language Embedding Subnetwork in the model proposed by the paper focus on to handle the volatile nature of spoken opinions based on the critical analysis of its approach to multimodal sentiment analysis?", "reference_answer": "The Spoken Language Embedding Subnetwork focuses on building models that are capable of operating in the presence of unreliable and idiosyncratic speech traits by focusing on important parts of speech."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/result_table.png"]}
{"uuid": "f1a4a901-a7a0-5cbb-8a33-9002a394ff70", "question": "Consider the paper that introduces the dataset that contains 3,747,569 instances. What is the average number of aspects per article in the model proposed in the paper, and what percentage of articles have less than 9 aspects?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that contains 3,747,569 instances. What is the average number of aspects per article in the model proposed in the paper, and what percentage of articles have less than 9 aspects?", "reference_answer": "1.82 aspects per article and 99%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "f1f1c900-da9a-5bbd-be2b-3aadcf7a0f30", "question": "Consider the paper that introduces the method that is in the third row of the table. What specific approach does the model proposed in the paper employ to minimize the SQL annotation error rate, and how does it ensure the selection of semantically equivalent and efficient SQL as ground truth?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["ba614015-ae38-5939-8106-728d33b07d78"], "reference_pdf": ["b16e8b8f-0d45-58db-b7ec-72837add121d", "befe32c2-c0d6-520c-b7df-ddfcfeb79028", "a0ce147c-98bf-52ba-8365-84983999c80a", "6103a65c-dea4-59ae-bcc4-5f7420478289", "a87515b4-ac31-5ecb-a261-cc3c8d5f4c8b", "0b9362a1-e422-5331-a3ec-a8abc9c8c249", "8ff266a0-ac5b-543b-b908-bdea848acd2d", "79c6d4f0-99c6-5051-bc74-19bc136089f4", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "73172932-ae8b-5d7d-bee0-6bc34aea20e7", "d135e939-c86d-56a7-8840-c346de4706f9", "1d0dae01-2fe3-5971-86b2-965007cceb0c", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "45fbbb5f-4e5d-52b2-8956-84eedc7cba9a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that is in the third row of the table. What specific approach does the model proposed in the paper employ to minimize the SQL annotation error rate, and how does it ensure the selection of semantically equivalent and efficient SQL as ground truth?", "reference_answer": "The \\textsc{Bird} benchmark employs a double-blind annotation approach to minimize the SQL annotation error rate. This approach involves two independent SQL annotators generating SQLs for the same question without discussion. SQLs yielding identical results are collected, and those with discrepancies are reviewed by experts until a consensus is reached. This method dramatically reduces the SQL annotation error rate by ensuring a low probability for two skilled annotators to generate the same incorrect results when databases have large values. To ensure the selection of semantically equivalent and efficient SQL as ground truth, the more semantic-equivalent and efficient SQL selected by experts for each question is picked as ground truth SQL in \\textsc{Bird}. Additionally, external knowledge evidence sentences are recorded for each SQL if utilized, enhancing the model's comprehension of database values and promoting the generation of efficient SQL queries."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.18538/result_table.png"]}
{"uuid": "f1fc23f9-444f-59d6-ab3d-3a9e7871156c", "question": "Consider the paper that introduces the dataset that has the largest number of Queries|Aspects in the OABS category. What is the model's, proposed by the paper, average number of aspects per article, and what percentage of articles have less than 9 aspects?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["8c69a0d0-9b39-5c49-ab35-d6e2be640e67"], "reference_pdf": ["465bf5dc-d3c6-5cdb-a833-5a223ea9d0c4", "7c903f8a-6926-5c74-992d-a5f72888651d", "4cca10e7-d63c-561a-8e8a-00dc91d22abc", "02ac113f-2396-5fb2-bfd0-bc2f207f5aa5", "02ac9093-bf58-5560-8201-76013521e9e7", "56feac6c-0a5c-5288-a542-025bdf8c3060", "bbcbedee-3e7f-590c-b535-3bbc4a70bf8a", "49329a9c-736a-5aa7-a0e2-b91cf6e3b2c1", "6b9bbbdf-c1b6-5a98-8788-b7fa7d4cdd4f", "99c97405-c7d8-55c6-bf34-33a7683c61d0", "4fd71ee7-61e2-5a3f-8901-43462942712e", "612006a5-2d37-53ab-ac56-7de3ead0ace4", "3524af2f-8ff3-52a3-bc33-bdc29ff34c74", "1a2e47d7-a3b0-5724-8f1a-e269d06c2bcc", "f6e91a91-0b1e-5280-8522-a20492033f16", "d77ebf73-718c-584e-83ef-4b263f378f1c", "157308ae-6b7c-5d46-bc8f-e9aea528e034", "c1db49ca-79d7-5a72-9405-3964e2de0c5c", "251aa23c-e271-5ac1-8f70-da7ebf449029", "e5280e86-0b93-5183-b502-7316897c4e02", "a5e24ec8-9605-58e8-994a-32576d2b9cc6"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that has the largest number of Queries|Aspects in the OABS category. What is the model's, proposed by the paper, average number of aspects per article, and what percentage of articles have less than 9 aspects?", "reference_answer": "1.82 aspects per article and 99%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.04440/dataset_table.png"]}
{"uuid": "f39a4dac-a539-5203-94d0-08f60144fe5e", "question": "Consider the paper that introduces the dataset which has 1 SM task and 14 languages. What specific method was used to address the challenge of collecting tweets in those languages that share geographic locations but lack curated stopword lists, and how was this method validated?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset which has 1 SM task and 14 languages. What specific method was used to address the challenge of collecting tweets in those languages that share geographic locations but lack curated stopword lists, and how was this method validated?", "reference_answer": "To address the challenge of collecting tweets in languages that share geographic locations but have no curated stopword lists, a combination of location-based and vocabulary-based collection strategies was used. This included the creation of stopword lists for some languages by ranking words based on their frequency across different domains and using a word co-occurrence-based approach to extract stopwords. Native speakers verified the generated lists before use. This approach was validated through the successful collection and annotation of tweets in 14 African languages, as demonstrated by the creation of the AfriSenti datasets."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "f547c8df-eed3-5fe7-935c-a9833feff71e", "question": "Consider the paper that introduces the method which has a score of 61.2 in the BoolQ dataset with 32-shot prompting. What specific aspect of the task embeddings derived from the model proposed in the paper contributes to their effectiveness in capturing task relationships, as opposed to domain similarity?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which has a score of 61.2 in the BoolQ dataset with 32-shot prompting. What specific aspect of the task embeddings derived from the model proposed in the paper contributes to their effectiveness in capturing task relationships, as opposed to domain similarity?", "reference_answer": "Task embeddings capture task relationships more sensitively to the type of task than to domain similarity."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "f59ac087-d856-5500-8d04-9e847aa317aa", "question": "Consider the paper that introduces the model that exhibits the second best execution accuracy in direct prompting. What specific preprocessing steps were applied to the XML files during the data curation process for its base version?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["fa5fa5c5-1780-5e27-84e9-da46df259090"], "reference_pdf": ["6b887e82-ca3f-59e1-ae8a-f528919c1334", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "36158741-e64e-5148-9eb0-105a66c7f0d3", "b5ebcdd6-2a29-55fa-ad8f-1d52ede2025f", "b16e8b8f-0d45-58db-b7ec-72837add121d", "46074e2c-a8f2-5f8a-af58-207aa96a6480", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "ee36b0d3-9a2a-59fa-a9fe-c116b3edfb50", "8f709a51-f857-5683-8935-218a05ee1e15", "b9efb3d8-b346-518b-a6b9-d6fe8a8c9a20", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "a72dd3f5-dbd5-5512-a45a-9d31b8c6964b", "06d3aa01-a14c-5e73-af1f-5e05d049f777", "c292abb5-051b-54a6-966e-426024009c41", "33208c99-5812-536e-a710-c15a59707b74", "91295ee5-ecea-56df-8e38-5d3af693d9fb", "a341fbc5-db9c-5e4e-85e8-41ff9a683e3a", "cd4e4634-d8f7-5f30-9ed4-61e35cfbc617", "3131ef5f-37e6-5044-9136-be579ad82e5b", "09cd70b8-67ab-548a-ba13-90ea11ba2e24", "cfd90106-9c14-54c4-aa6c-58df4c94e301", "c70e3426-63f3-5420-87ad-25fbfb193761", "0d634a2b-3091-5566-b890-9e5e06d8d59e", "d38add76-d914-522b-9c38-1adf92508b32", "cdfa24a6-9314-5a71-8d3d-822ee4cf1595", "7908763f-3a9d-5ce5-af59-f68888750583", "ab6eacc9-9657-5b14-9c85-e0edeea4af11", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "b3cf3805-1c84-5852-874b-c43830dfbb3c", "649f6e13-91c8-5328-8ef3-cfa3d03f8618", "46a88ba5-c16e-5efd-913c-3de6e749f2a9", "ca6a2e66-beca-5605-b8e5-ce5e22df0fec", "94993d82-6d3b-5b04-b25f-13e33faf6822", "2f767215-ca92-5449-9a65-f9628c071a18", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "f539c3b0-32b8-5419-b22e-75fe5729c7c5", "07f09067-3b43-5c96-941d-de3a582e8770", "6d6f8a4b-0f39-5f6f-9513-678e6f490f84", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that exhibits the second best execution accuracy in direct prompting. What specific preprocessing steps were applied to the XML files during the data curation process for its base version?", "reference_answer": "Implemented a simple XML filter that checked for the presence of '<?xml version=' within the first 100 characters of the file."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11634/execution_accuracy_figure.png"]}
{"uuid": "f5e6ba58-5096-5d85-b201-f78fe2070ce5", "question": "Consider the paper that introduces the method in the figure that has a perplexity of approximately 30 and an average max toxicity of 0.2. What specific formatting guideline is provided by the model proposed in the paper for the width of the abstract text compared to the columns for the text in the body of the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["1641c55a-1178-5c41-9cf5-5453a9b4ef80"], "reference_pdf": ["ffbb6dd2-e4e9-5593-9a14-dff5ff793476", "eacab91e-f3fc-5b0b-a57a-6bab6fd45ec2", "34417770-67d7-5cab-b9d4-76999c97bc02", "8775e4a0-f937-5e22-ab4a-629dffe12d6b", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "7b87be86-9d46-51f9-90de-ec0d5fc14396", "e03c05c1-eaea-5ebf-b607-fe3ac23b8bf1", "29c01074-2d50-532e-b707-6e84ec72531e", "bb9a32dd-fb85-5cfe-851f-992d2001b4db", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "93091dfb-5e24-551a-9651-6c000af2f432", "ca5640af-3413-51d4-9850-faeeba815d6f", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "d33183f1-a1af-598c-9633-3bf42937ae3a", "82a80b14-aa33-57ed-b666-c182235bc860", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "3b6d7c62-8eef-546a-a95d-394cb5fa0139", "c253fb53-f760-508a-8c4c-8fab18ed2aa2", "03a7c389-4ec0-564b-b476-9ce9feffe418", "0178ef4d-109b-512b-8194-c5debb2014b1", "4f962bb9-bff2-534a-900e-75f56557f5d6", "1740ce5d-d35e-50c7-9e9b-6fe3f069651b", "077352df-0e26-5c93-a699-7c3e42da0cca", "fb93f23b-657e-55a4-95a0-7174820f65b4", "dd3f8d4e-2048-51d2-acf4-b48af1355488", "7622ac08-15d7-5102-89b2-6891803cd8af", "1398ab3c-cb2d-593e-9d68-02a0d484e643"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method in the figure that has a perplexity of approximately 30 and an average max toxicity of 0.2. What specific formatting guideline is provided by the model proposed in the paper for the width of the abstract text compared to the columns for the text in the body of the paper?", "reference_answer": "The width of the abstract text should be smaller than the width of the columns for the text in the body of the paper by 0.6 cm on each side."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.09520/comparison_figure.png"]}
{"uuid": "f645be69-cd03-5ddb-8f39-f29139f96eca", "question": "Consider the paper that introduces the method that has a score of 71.4 in the CB dataset with 4-shot prompting. What specific metric is used by the model proposed in the paper to compute the similarity between the average pooled representations of the prompt tokens when defining task similarity through prompts?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["898bc717-52e1-5411-8586-93195ba0d116"], "reference_pdf": ["9b1ddffa-e7a2-59f1-bd43-e64415b44bbd", "5205a403-7828-5133-965a-a28d9e64cc28", "595f30fd-057a-55de-a1e6-1cba7d3b904b", "4d2120b1-212d-52ad-a0e5-c56245349f00", "770222d1-8165-5bef-9d34-38f7f20a5c62", "b129fdb2-2a2e-54ca-94a6-eb3b5b61c25d", "de555f56-e912-58c2-9cd2-966bd3a9e1de", "b01da5d8-2db0-5d8c-b2f3-37ed254729fd", "62e25caa-070c-56c0-a5d5-c200c1413cc8", "37b080a5-6107-589f-9ec3-b436a3e37bb7", "7ee558ad-e050-510c-b0cf-0577d188521b", "7908763f-3a9d-5ce5-af59-f68888750583", "02cd2589-363c-520c-9f1b-f06d6809acc4", "452d4e28-7f06-559e-acaa-fd7cede347f4", "d33183f1-a1af-598c-9633-3bf42937ae3a", "0cf1659b-84ed-53b7-83e7-e6645287e66d", "61ec37f7-fdb8-55af-a3bf-3a8b14671a44", "64af0618-461c-5713-a0ba-5a179e12f739", "c36ce45b-f26e-5991-8a3e-209e395ab3fb", "f424edba-b48e-5654-bb56-533a4767fb27", "019f5dbe-dfb8-5e3d-a1c2-6c1f6b2fedda", "206d89fa-26e9-5109-8b5b-e1fa826a311e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "81c6be03-577c-51d5-8e65-f63b3e709112", "548c366c-3e29-5a90-ba32-da46177542d2", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "16c49bc2-7d77-5bd1-b2d1-f9f868189c37", "e756a768-abbe-52e1-8416-6c24deaa43ff", "6cb48d9e-f803-5274-8b12-b6ca17473e50", "7b79244f-3cea-5a12-a1bf-1e4609a1c0f2", "10394dc5-9259-54c9-8868-bf2692924ffa", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "26e45afd-1c91-5f0f-bb47-33707acec072", "23104b1a-a45b-50ef-9541-4627857e2b03", "ab8d017f-8645-5337-aa84-f52783391b99"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a score of 71.4 in the CB dataset with 4-shot prompting. What specific metric is used by the model proposed in the paper to compute the similarity between the average pooled representations of the prompt tokens when defining task similarity through prompts?", "reference_answer": "Cosine Similarity of Average Tokens"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11670/comparison_2_table.png"]}
{"uuid": "f7307ff6-166c-582c-a36b-e06538f04a51", "question": "Consider the paper that introduces the method shown in the first row of the table. Which specific mathematical reasoning capability does the TabMWP dataset aim to assess in machines, as highlighted by the challenges presented in its design?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["52401e06-7a75-5196-9a91-283debf280bd"], "reference_pdf": ["4ef8ff36-7d1b-5330-a3ba-dc447df54c31", "01bc60a1-bcb2-58ea-a5e4-8585440a10da", "440f88ab-2844-51e6-bf0e-3a73b407854d", "baab43b2-9ac7-5782-a48e-2fdfabda91dc", "f8035995-47e3-5210-81f7-1b74a2d93fc0", "2f304b1c-69d5-588d-8156-b92662ba2204", "410a8208-232c-5a5e-8125-b3148eafada2", "fc6bb8b7-c1c6-5462-aa43-cd6dc6d15f8d", "14b3abbe-d581-58e8-8d53-b52c2c64066c", "cc130a18-2c9b-5cdf-93d5-660e066195df", "2dfb09ca-13c5-58e9-b409-b50013714a75", "b32cc591-f1bb-558c-b4e4-d9d6d659c2c1", "78961296-27a4-563d-8392-419b42bf18aa", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "356f5944-26d4-5e48-adcf-22dcb69b9771", "97c33b3c-1e1d-5105-bde3-79855c80899a", "9634e5ed-b92f-5d25-97d8-de5a9146348e", "583e243a-4799-52af-9f47-e23e9a065a79", "143e602d-9fcb-5ed8-b7db-7a13bff72996", "a0276631-f7d8-5743-8ef1-1dd78aa0f71a", "e1e6c6cb-4b5f-55af-a140-4d8b8359b39b", "7ee7fec4-3acd-5e8b-99bb-023b305090f8", "6f4d0a2f-4457-55af-b519-da2a1df140da", "4705f7ff-28d4-5b84-aadf-0a911c97959c", "2b337d45-3a71-59e6-9706-d9ea917c8a9d", "7908763f-3a9d-5ce5-af59-f68888750583", "72fa6e51-23f1-5048-9e33-69914369efcf", "18bb551c-6c39-5d99-b143-34974536e02d", "c76b968a-995a-5109-a4eb-f329fa710f26", "c5c69dec-27a8-5494-9e24-84d14f5fa573", "43f38bc8-bf1f-51ce-9dc9-be9ae2ff4942", "3998efe3-6eb0-5c5b-9c68-1888031f2ad3", "677631bb-4fb7-5f2f-9b2f-9183754a6030"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method shown in the first row of the table. Which specific mathematical reasoning capability does the TabMWP dataset aim to assess in machines, as highlighted by the challenges presented in its design?", "reference_answer": "multi-hop mathematical reasoning over heterogeneous information"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06675/result_table.png"]}
{"uuid": "f8b60042-234c-544b-ac22-8b5f31cf0bf9", "question": "Consider the paper that introduces the benchmark that corresponds to the light green color in the figure. What is the average human-rater performance for the 'Temporal Sequences' task in the suite it belongs to?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["d57dbb00-d431-5f07-84bf-7ac4c95515b2"], "reference_pdf": ["81da51d9-10f0-55fa-a1a0-9c33f0f62d60", "97a1532b-9bde-55b3-815d-290e4190c11f", "67a68526-4d04-51a3-94a2-6fd77976a582", "6fb179b5-af16-5d8e-9b7f-531002a754ef", "33abd7ca-d89c-51a6-93ab-bb734ec9dfd9", "63377715-d4c6-5552-a521-71134d122d96", "e92e45f8-a691-5ecd-abee-67f6fb478fc2", "e53e07a1-6a43-5b5f-908e-3c19e2375eac", "3a46266d-7457-596f-9fe4-4415609ada7e", "36cc30bc-1b33-5196-939c-bb007346957e", "a76fdb50-d95e-5db2-83a6-ece16257796b", "ca8591e1-3c1d-559b-8241-d10d621689a3", "ff105ef4-7a03-5e2b-8ea8-2dd70b86766c", "63ac5232-d7e8-5f0e-ab4c-f2378c7c2a8b", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc", "381e26e9-8859-579a-894a-182173d840a6", "4ff07545-64af-5426-8c2e-5d296393c929", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "ad5ecb28-5270-5e7b-b161-6d994db6c2f7", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "916615ea-a2db-5994-815e-ff4c0b641987", "9fbb7b35-f1a6-5099-a379-29f450eb1ccb", "19d8d942-0454-5507-a8f2-bfcbb0fa0bcc", "1a81f6cf-3e46-5cdb-b9e3-04f72a3ffb0a", "96ce2b83-dafd-5418-9d75-d54158cf56ae", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "23ad3ca1-b89a-5ace-a9b9-940d351b46bc"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the benchmark that corresponds to the light green color in the figure. What is the average human-rater performance for the 'Temporal Sequences' task in the suite it belongs to?", "reference_answer": "90.8%"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05736/result_figure.png"]}
{"uuid": "f91884f4-74ae-5aa1-af12-be69c6665255", "question": "Consider the paper that introduces the dataset located in the top left of the figure. What specific linguistic phenomenon mentioned in the paper requires familiarity with social media to interpret correctly in the context of Chinese sentiment analysis, particularly when analyzing the SentiEval dataset?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["2b690d6e-331e-5655-8fe3-e0a99577b26d"], "reference_pdf": ["af424bb3-4227-5815-9e9b-ebbc9e9b961b", "00a5ff65-630e-5c56-be2b-6cdc1c6785fa", "d802270f-3cf5-5cfc-841c-86c7162ef46f", "a8ca16ce-2b4a-5ca6-8ae8-3fdf1ae98297", "58935b9e-55e8-5b65-9849-59af83aa7db4", "f5545f86-f052-5ba4-a7ac-60252dd219d1", "ea143f49-405f-55c1-b49b-3c092e20eb19", "3e1391d9-7d95-5db8-bff6-69ff8236f498", "0504eb73-304a-58fe-b1cb-9ec94e383a34", "34417770-67d7-5cab-b9d4-76999c97bc02", "9198c885-f142-5a1f-8f11-67dc2c6426c4", "7f978514-2342-57aa-a4ff-fd534c065de8", "003269db-f43b-57bc-a219-825c655fab01", "01c9329e-9789-52dc-9eed-c99a8ef88a5c", "38c42ad1-4e5f-5ebe-ae2d-683ef661bbfe", "7dc5b37c-ed28-507d-b05c-81a061ee2fcb", "0c6970d9-413b-50de-ad9c-d5d0c5c82569", "c094eec0-568e-572d-b67b-7054c21c9ae4", "473d3226-31b0-5da8-87e5-745966b86051", "80bd22e7-af3e-522e-a54f-c5e21a65fdfc", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "e3c55596-606e-5dbe-9ef3-ac06ef461af8", "f1a59d96-65d9-5a8a-a47e-747a32a51865", "1f1cc0ed-1a84-53af-98e3-d3c2a2d1f290", "eb4c8aef-aded-5cee-9cf3-805b485d85fd", "56edda55-3959-52aa-b229-9303f393bcaf", "27f6b85d-611b-50a8-9704-7e233716aa0d", "140dcda5-da3e-54a5-8ec3-3adb04d50900", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "5ec71e41-a031-502c-8098-58076c6ddbfb", "c20e9c12-7502-5cff-8f71-fd5857157068", "941ac574-4c1e-5b87-9a8d-b5fd7db093fc", "c9d562d0-09a2-5d71-a17f-25731003add5", "b585ca4a-eb1b-546d-a9e2-a5e682bd58c0", "6677d3c0-7aea-5795-a934-d93933e25157", "1784e68d-a499-59ab-a942-14c7a55861db", "7cf6b8e5-b9e9-5b76-ba8d-ba514e4e9d8d", "d0aa69e2-a929-5919-aff4-baaa66c19cd7", "e938b553-f1b6-5eaa-9abb-efe79edf89e5", "61e4ad30-ebe4-52e2-b1da-40a853022f68", "7908763f-3a9d-5ce5-af59-f68888750583", "d712b278-8121-521b-b7be-028c27148a47", "6024183f-3dca-53df-934d-62772213d7b3", "d8cece2f-f059-58ca-8e87-45d43c96d188", "d67339f8-e834-5f1e-8dec-a4967099e092", "dc85dba3-f10b-5d77-b4f6-7faa8471a774", "7b10bd29-bd5b-53ca-986e-719ca2e8fa6a", "dfa57c77-ef6d-504d-bf92-9778eb857419", "a5c8eac9-498e-5770-881e-f529a30a3c37", "d85b73dd-0a94-57cd-bbbf-6023240a2e3b", "91feff80-9b02-5b21-887c-06f5791a8d81", "908acaf9-025a-548a-bc7c-fcba8b7075ba", "ccf560db-a30b-552f-ab16-80026764a35e", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "afb3f87d-4b90-5da2-b7b8-a2bef519cf67", "6520c41e-2790-503e-8a34-3ad71c4624d3", "f9d26857-e887-5526-8b66-e0f9cecda38e", "ceaa70f6-a3c8-58ba-90f3-be193ac08d59", "2292ac5f-ddf9-5ed5-8009-b4f7a69a8ec9", "ae337723-451b-5c72-a65c-cf9969e7b19f", "f1726b79-7b39-5e5a-96f3-a4a0dfead588", "a15c6ae3-d802-5225-8256-e4ed086ba7ac", "9f14a945-a9c6-5677-8911-3d36cc56505f", "39c380e2-e65b-54e2-ad4e-b1cf5509e0d8", "809c6f68-1e37-541f-afd3-2a72fd4a06c4", "f71be6ff-bdd2-54b3-b19c-cce5f7c80fc7", "445e9197-1321-57c3-93bf-7084e795848d", "a664a316-f113-561d-be01-bf7870b1cc04", "d3ad5387-9dcd-5b57-a355-223a051c9569", "efbbb801-169a-5be8-b60f-f9f1201099e3", "db9fd2e3-0ef7-5878-aff1-f0ebe6320496", "6fae0d23-2a94-52ba-bc99-8fcef90e4d95", "40c7f29e-dc97-5443-a086-b3b0f20f5a57", "e9411300-bb50-5bb0-947a-bb61abad76a6", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset located in the top left of the figure. What specific linguistic phenomenon mentioned in the paper requires familiarity with social media to interpret correctly in the context of Chinese sentiment analysis, particularly when analyzing the SentiEval dataset?", "reference_answer": "Understanding complex linguistic nuances and cultural specificity"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.14557/comparison_figure.png"]}
{"uuid": "f9d3ac7b-20f9-5dcc-8d6a-e37ad55fabab", "question": "Consider the paper that introduces the method that demonstrates the second highest score in the TweetEval Irony dataset for both zero-shot and few-shot prompting. How does the model's, proposed by the paper, approach to handling the RefCOCOg task differ from traditional methods in terms of model architecture and learning objectives?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["2479f89b-b7c0-534f-b51d-d24093d3a1f9"], "reference_pdf": ["7aacee49-58db-593f-9a47-44846ba2ed23", "881f50d7-f0cf-59e7-8351-429ea3655e0b", "57c06ca1-608a-5816-86dd-0f35be577ce0", "1165b8f0-4261-5c50-9583-bfc199324e61", "1c848190-6829-5b07-a439-3452fd19617b", "ea8d0d91-a08c-547f-aa61-fc136ce41e58", "591f54ea-2f59-5cdb-8117-74bd1028e5d1", "e0c4b079-e17f-5d16-9fc3-e8774c9f400a", "71f0b9b0-e4fa-5ccc-a5e4-fc83695a9ed9", "003269db-f43b-57bc-a219-825c655fab01", "16e73621-a0c1-5f1d-ae72-fa60befecf05", "f992c4ad-ce9f-584d-b09e-80bcdf9589b2", "b31b84cd-d7c7-50d1-9dc2-cb340ea4d218", "3eb1e55f-5293-52ea-8b6f-1d2ff896bf3c", "a76fdb50-d95e-5db2-83a6-ece16257796b", "e0523cf0-8310-565e-9d91-c539c15adcb7", "be395337-c3e2-5e16-b2ef-1ed22e6736dd", "729f79df-1057-5418-89cd-592408770592", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "1e0413f9-466d-57a0-be12-cbfb9da4056a", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "8f02441e-aa43-5abf-bd9b-cfd760b7cc20", "e5c8fae9-734a-54d1-bde4-03ec07d10c86", "b5798106-2737-52fa-b1e5-010749d19c2c", "6677d3c0-7aea-5795-a934-d93933e25157", "02cf0294-1961-54c5-a745-0d99126e65d3", "c76b968a-995a-5109-a4eb-f329fa710f26", "de0470bf-d650-5f5c-9fb8-926b7ed2c806", "65c601c1-c571-5d9e-aa32-e37fcc3e0097", "445e9197-1321-57c3-93bf-7084e795848d", "da29dae2-1a88-5793-8149-81c0b63122ca", "02193a94-398e-57da-bb53-0c5800ca743a"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that demonstrates the second highest score in the TweetEval Irony dataset for both zero-shot and few-shot prompting. How does the model's, proposed by the paper, approach to handling the RefCOCOg task differ from traditional methods in terms of model architecture and learning objectives?", "reference_answer": "The unified framework's approach to handling the RefCOCOg task differs from traditional methods in that it uses a single architecture with the same language modeling objective for all tasks, including RefCOCOg. Traditional methods typically require designing task-specific architectures and objectives for each task, such as a multi-label classifier for visual question answering or a softmax classifier for referring expression comprehension. In contrast, the unified framework formulates tasks as multimodal conditional text generation, where models learn to generate labels in text based on visual and textual inputs, without the need for task-specific architectures or objectives."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15746/comparison_2_table.png"]}
{"uuid": "fa0d625f-e82c-5da6-9dc4-95bf7dcd291b", "question": "Consider the paper that introduces the method that scores a 70.1 in the 'Revised Persona' column. What is the implication of the model's performance on the CMUDoG dataset for future research directions in document-grounded conversation systems?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["26feec2d-e6df-532b-9f63-ab9b73e8266f"], "reference_pdf": ["8b28a50c-b93f-5426-adbf-c8a139d518de", "c02fd012-1287-5268-94e6-aaae4ee61dda", "686c19e6-39d7-5bb4-a324-ba2bd5c26db2", "c260bf67-2731-5445-96eb-94baa3e5f834", "51e05e32-8367-58b9-b753-6c6a6c1d665a", "ff0d0226-2dc4-5a18-9cc9-ec5826c16eb7", "60105831-0210-599b-a410-f12e2df3cffc", "08f4ba03-f60b-5eed-b60f-e94ba143379e", "0e0746e6-8044-5c49-b46e-0a66569438a8", "e2a2d7b1-a02c-58e5-8d14-272810335de1", "7908763f-3a9d-5ce5-af59-f68888750583", "c5833e1d-8813-56da-99d1-bf61d9ac33df", "5d474441-0098-5521-b6d2-4219837f18c9", "3134099b-d3ac-56d3-898d-c77c7a99370e", "311f9316-6c35-5c33-b61a-f25d90866412", "c76b968a-995a-5109-a4eb-f329fa710f26", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "da510970-00ea-5853-a68c-9741c0d1fd4d", "81de543a-91c2-5035-9617-724abb93a839", "08a1c735-eaca-5629-8347-bbbd2ed6a853", "206abdf4-f071-58ab-8bd6-206bb79786f1", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "d3344458-d106-52ed-be5c-505f8b07af06", "b4ce79f8-4a56-5bb4-b15c-13fee270a57d", "cbb28401-7af5-577d-b36c-a50a87e88b96", "27810986-0584-5a03-9944-a70637604b0f", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that scores a 70.1 in the 'Revised Persona' column. What is the implication of the model's performance on the CMUDoG dataset for future research directions in document-grounded conversation systems?", "reference_answer": "Exploring selection at the topic level."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06390/result_table.png"]}
{"uuid": "faa481c1-fb61-5d57-8add-320598a84c21", "question": "Consider the paper that introduces the method that exhibits the highest Accuracy@0.5 value on the RefCOCOg task. What is the role of the $\\tiny{<}obj\\tiny{>}$ token in the model's output sequence design proposed by the paper?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that exhibits the highest Accuracy@0.5 value on the RefCOCOg task. What is the role of the $\\tiny{<}obj\\tiny{>}$ token in the model's output sequence design proposed by the paper?", "reference_answer": "Indicates word-box alignments and simplifies sequence prediction by providing hints of text-box code-switching."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "faad8ad2-ebc8-58fe-9bd4-aae7da9d0aa7", "question": "Consider the paper that introduces the model that scores an 84.2 in the 'T10' column. What hyperparameter values were used for the FewRel dataset in the experiments?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["7dd2b865-9759-5cfe-8aff-d3f794fdb933"], "reference_pdf": ["b601ccd6-0578-593b-9413-871e5b7d6ada", "73ad76d7-eb4b-59a0-ae8f-d5df7afbe505", "bf28f877-f161-5569-a7ac-0ff9a8d9f89f", "2d8a2245-33f4-506c-9b85-aab7d7f6d8b2", "f9fb6227-8be1-5880-98b0-eb6df60c0250", "b8ae7f68-6c06-57fa-bb82-5fb88f4cc45d", "1a05c1a3-e926-53c4-86c5-70f51293c26b", "9d19a76a-1f8e-5170-b5d7-b2d07ad1c2ec", "50eba224-1c85-57a5-bb58-9d0fb0ddf191", "6986575a-2455-5144-b734-faf98ee0bc34", "f398b6e5-0ff2-59e4-9f26-eba5cea5b48c", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "99bca841-91b2-5a94-8f9e-562aa28e209f", "d709c093-593d-592f-991a-d60b4cb6008d", "5283b1ef-0255-5db6-aa92-1754b5f68317"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model that scores an 84.2 in the 'T10' column. What hyperparameter values were used for the FewRel dataset in the experiments?", "reference_answer": "$\\alpha=0.5$, $\\beta=0.5$, $\\tau_1=0.1$, $\\mu=0.5$, $\\omega=0.1$, $\\tau_2=0.5$, $\\gamma=1.25$, $\\lambda_1=0.5$, $\\lambda_2=1.1$."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.06547/result_1_table.png"]}
{"uuid": "fabc23a5-be8b-513b-b9e0-b3e789cdf38f", "question": "Consider the paper that introduces the method that has an accuracy of 78.1% on the VQA-v2 task. What specific improvement in CIDEr score does the model proposed in the paper contribute to image captioning through its text infilling pretraining task?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["0c01da61-e6d6-5664-a720-fe78fa8506f0"], "reference_pdf": ["2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "da9e1b4e-f0c6-5191-8a33-41b61efb4b0f"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has an accuracy of 78.1% on the VQA-v2 task. What specific improvement in CIDEr score does the model proposed in the paper contribute to image captioning through its text infilling pretraining task?", "reference_answer": "+0.8"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2311.04067/result_table.png"]}
{"uuid": "fac0e441-071d-5533-bea8-8ee09a26a7b8", "question": "Consider the paper that introduces the model in the table that corresponds to a 84.70% WInToRe. What is its inference time for feature extraction compared to VinVL and M2 Transformer?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["9906dc9c-eae7-5352-82ca-533b23d498a1"], "reference_pdf": ["f2c45532-0d1d-52f3-8293-a28562dca0c2", "46cca6ed-363d-5bcf-8b04-6e8f56b1debb", "a9e9314b-4cc2-58e5-bbbd-e0908b71d865", "120aa43e-5a6b-5fc6-9e11-fecd0d3ca36e", "200b3e0c-5509-5d2d-933d-f59e25c57c43", "411227b7-53f4-546d-9c14-70bf07f74473", "1b95bbb6-5c74-52f2-8c79-8fa03ff4879c", "cbb30373-01f6-5707-81b7-fd36a3e42c87", "d4223ac7-9d75-531d-9113-b52397da2e1e", "aa4f0205-fd37-5154-9b71-ce252dccab5c", "4a87a9d9-1977-5796-b15b-18eeb2537ea3", "884e57aa-78e0-5621-958c-8681a2d6f61f", "b95e3586-0087-5079-8c32-66506a0ba806", "c3e48be8-b991-5cfe-bd59-05d2496a094d", "ce1df36e-abc0-55b7-96a8-99f14f1fe8b1", "e4ad4c66-c12f-5367-a923-7342a3a48ac0", "19b4c2c4-42f6-595f-8a56-13b3d241ee6d", "d62a70d3-39eb-57b2-854c-06ae086c4b84", "eb335bea-aa4d-5fb1-9e60-189c2f979d4f", "45decdf4-f524-52d5-8385-3da8d839888b", "2a0adc2f-455b-5d5a-9cf1-ac09f4347ff9", "a039db49-aed3-57e6-8720-913aaac61942", "51e5bebd-9870-5529-875f-710339447ecb", "aa4925a8-1e46-5996-8654-b82cfa7820a5", "95c63efc-ff02-585d-bcdf-75e933c5816a", "9baa42c9-b79b-5654-85d3-860ee3241d5e", "c466be66-c99c-5dcd-90a5-5b86d4a6638a", "a229d47a-0069-5d45-8bac-7e5eb2e8b8d1", "0b363526-f924-5baa-be50-c665bd10cb5b", "fa4b52f4-0a73-5305-bf28-adee87c842ec", "72e031f9-130a-5dd0-9f2c-bb29e197a8c2", "14028d43-a37a-52d4-8869-f174ff05ca4c", "d88358e9-efe9-5844-8bfa-b1d3ed22ce82", "45b99aad-66f7-5bc9-a6ef-cc7eb8d66567", "ded8818d-5039-5cc2-b3c7-9f4908153210", "4b918831-da2b-5123-8351-ffdf3abde7c2", "04873797-c04f-5d4b-bab4-fcace1b87c1b", "4d4ba218-3d96-5deb-b3c1-90589dfbf6d3", "5da677b6-dec7-57c9-afb4-5c1af7801b8c", "82a80b14-aa33-57ed-b666-c182235bc860", "5a09a7b9-bceb-58cc-a560-2845b8774e26", "058b61e1-dbec-5ca7-9603-d53c1e14e733", "5fabde11-10a7-5fc8-a1b5-57a6237b5535", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "e41d952a-d067-52a4-9fea-12aa78420924", "3942a9be-4b4f-5453-ad09-9483e96f7599", "2318a9a9-d21c-563f-9414-102fe10fd204", "b82c062d-e25e-560b-9fe8-47a56901fc74", "1ee90f2d-74b4-5c24-ade4-7608f608d42b", "a02bef04-a577-5433-8a32-7d3786ccfd02", "345e1ebc-c05b-59ea-9619-557ba7bc6e3c", "f5a5accd-0b7a-52cc-9e74-388ad1a25efa", "0178ef4d-109b-512b-8194-c5debb2014b1", "0a58057a-a09f-5b93-9aeb-0243adcf3eef", "26e45afd-1c91-5f0f-bb47-33707acec072", "dd4cf2bd-a308-5ae4-8718-2eb04418d7e5", "5c347f12-43c5-57a5-832b-bcf310dfad98", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "1e6bbab0-102d-51b6-bd9c-79b6f266eb8a", "ef55b6d8-d37c-5a62-95ca-83bd707306cd", "c5227d39-0b3c-5458-a976-982cdd8d4015", "55fff8cb-7639-5bab-8c5c-ab352eb833ae", "1c5aa016-c6ba-5928-87b6-b71a0c952504", "ac1b0430-6781-5539-9d45-5067c0c6ff3e", "6ba85b19-07ef-56af-9cb7-726e2402e4f4"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the model in the table that corresponds to a 84.70% WInToRe. What is its inference time for feature extraction compared to VinVL and M2 Transformer?", "reference_answer": "31 ms"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2312.11523/comparison_table.png"]}
{"uuid": "fae3adb5-f84e-55e4-ad1b-7798642c33e4", "question": "Consider the paper that introduces the text-davinci-002 GPT-3.5 model within the CO\\textsubscript{3} framework using the dataset for the 'dialogue response' task. What specific hyperparameter settings were employed for generating conversations grounded in narrative?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["db2754aa-bf0b-52b1-a544-2cafb659b753"], "reference_pdf": ["c8717e4f-8ff0-5152-8082-266d0bb88071", "5f861444-411b-5c95-80cf-3aa93ff28763", "f7afa50e-c73f-5bef-9acb-4944c13f1533", "34417770-67d7-5cab-b9d4-76999c97bc02", "93f2b359-d6c0-5c0e-8b53-ad03af3ac946", "f92811a6-b9ce-519e-9346-f3b892d7f535", "47952b13-8f8a-5402-8c8a-17b461aaa1cc", "98971f11-6faa-5050-845f-caecdf06f97a", "41982a4d-b3c2-5e5f-bb78-4c0a480299c1", "da90e201-7d72-5390-82f0-8549c85e4fba", "6c5168e1-a3f3-5263-84b3-29de388a544b", "ec5ed5f8-d390-59f2-8299-03115ca2c742", "cb79f244-a7d6-5793-9199-512a482911f8", "c0bc2a7b-a0a6-5785-823a-a24f24ac099b", "8231e6be-dbce-5906-969a-b7fa846b672f", "c497371c-17dd-5bac-a8f4-a047d15a0ee7", "6b474476-57a6-5296-8664-c0cad7717810", "109d0033-172c-50fb-96ac-084259f65089", "f803a6a1-a7a5-5d45-a5ef-8aae55d2858e", "f1a88572-1160-54ad-922f-f66cc1c22315", "15d8d13b-7f13-54bf-87a6-f40d75167eb9", "808a8c71-5485-5683-88e6-b4616d8e7ead", "edfe70ca-6ad5-5b43-a1af-87d5886f44c3", "393e9431-63b0-589d-88bb-62335baaf8bc", "f6e91a91-0b1e-5280-8522-a20492033f16", "0b48d3a0-c352-5afd-8dc7-9c186316d538", "ebaab94f-c9fb-5186-951c-d7259a580fde", "a94d47ed-ede8-5a71-af1a-5ce44e897b38", "9ada7bff-c684-55ab-ae9b-04f836247ddc", "a5e24ec8-9605-58e8-994a-32576d2b9cc6", "003f56f8-651c-535b-8983-3f448ef1addd", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the text-davinci-002 GPT-3.5 model within the CO\\textsubscript{3} framework using the dataset for the 'dialogue response' task. What specific hyperparameter settings were employed for generating conversations grounded in narrative?", "reference_answer": "Temperature: 0.9, top-p: 0.95, frequency penalty: 1.0, presence penalty: 0.6, max tokens: 1024."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.07096/CFQ_table.png"]}
{"uuid": "fbda84bb-5c50-5525-9172-67bdd85c3fb4", "question": "Consider the paper that introduces the method that has a lower Hits@1 score than ReasoningLM but a higher Hits@1 score than NSM across all fine-tuning samples. What is the core component of the model proposed in the paper that enables the propagation of matching information along the directed edges on KGs?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["30ce5dc5-482b-5bd5-8255-1e74e83762a4"], "reference_pdf": ["3e6ebb91-fb32-5754-abed-0d8518e037a8", "6305afda-1839-57a8-9f4c-aaa788f95912", "113174b9-1f5c-59aa-972d-7c6eb43597a9", "338e177b-154c-5635-a216-408ed793b9c8", "a1ee6864-35ca-5ec6-b5a3-71e7013c7643", "d3d52a0d-373a-5de1-8a89-c8a5a57ec224", "6c13c345-6625-5459-ae26-1fccc31ca2d3", "8511a75d-b196-502c-87f3-3b8a5cdea12a", "3f302571-f9a6-5c1b-895d-9f0ea8865d1d", "7908763f-3a9d-5ce5-af59-f68888750583", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "782f319d-905f-57b4-9dde-03031c0c96a7", "9add874f-1824-5518-80da-9b2569fa1728", "63813a1d-48c7-5be9-b6d2-ba1e463de539", "d40a6590-2c99-555f-85be-4208a63bfe6c", "9abee888-fdb9-50bd-bb86-2e53a6052057", "ab8da4b2-8830-5dc2-b901-ca484702bbbe", "2f4062a4-bd8e-50d5-b536-f2f33bc077d0", "3996e0e9-1288-58e0-9a4a-3f7fddb32b48", "80609df9-a5bb-503c-b165-da3a39e2253b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that has a lower Hits@1 score than ReasoningLM but a higher Hits@1 score than NSM across all fine-tuning samples. What is the core component of the model proposed in the paper that enables the propagation of matching information along the directed edges on KGs?", "reference_answer": "matching information propagation module"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2401.00158/comparison_figure.png"]}
{"uuid": "fc23f10f-ce88-590e-b4e2-a81e7de84fb9", "question": "Consider the paper that introduces the method that achieves a relatively constant MRR score in the FB15k-237 dataset as entity code entropy increases. How is the initial representation for non-reserved entities generated in the model's entity-agnostic encoding process before being input into the Graph Neural Network (GNN)?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["676bc226-2e8f-5bd2-a094-a415ed954ed9"], "reference_pdf": ["d2b92dc2-2da1-558d-8bbc-1f6acb259372", "c36d6d6b-727a-5c59-b847-cccde8d7f6f8", "52e249a0-cbea-5812-8143-0bbf71491d92", "680db1c1-3dec-573f-84d9-c379bbbcffbb", "062f80f6-0783-5217-a26f-cd212334e3c9", "8b7e7134-0ddb-5c70-8ab0-a2d91332666e", "a9f84464-d2a7-5252-acb7-ec8494db2c6d", "42b36679-e0aa-50ec-9b1a-914e55e3427f", "36a99716-f24d-5d45-ac0d-5475d521f4c3", "26a28bd5-1116-5876-9b75-8b69894c3243", "e65d4a4c-2e1d-575c-9a5d-20b538cdd432", "4183f8eb-54fe-5977-9e59-c305ddc27209", "2ab48fef-09b1-5175-9b7c-a29783ecce26", "d69a7660-3938-561b-a88e-aaeb0d5e7fad", "6390e287-cf27-5025-bcb6-dee5300dc49b", "389f600b-9b7b-5c08-8318-d005562e2e27", "e90a11ab-8f5e-50b8-b3e8-084bd6844e1f", "04f6e1fb-2218-5cd1-91e8-f7e37567df77", "ddb1aaae-4a2c-57b7-8148-8d9e97d5d7ae", "0dd8b917-8e34-5406-bd69-fcd0838aa929", "9bed7533-e4f6-580b-9e8d-7c996dbbc493", "f66565d0-3473-5828-a075-94cad5400620", "c652713e-6d65-5914-85e4-1a80d45a015d", "16269c81-8856-5df6-a1ac-b1a54440ca6e", "a5a36de6-f56b-586f-ab8f-83c1bfa31d0d"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves a relatively constant MRR score in the FB15k-237 dataset as entity code entropy increases. How is the initial representation for non-reserved entities generated in the model's entity-agnostic encoding process before being input into the Graph Neural Network (GNN)?", "reference_answer": "For non-reserved entities, their initial representation before being input into the GNN is generated by combining the encoded connected relation information (\\(\\mathbf{h}_{e}^{\\rm c}\\)) and the encoded \\(k\\)-nearest reserved entity information (\\(\\mathbf{h}_{e}^{\\rm k}\\)) through a 2-layer MLP (\\(f_{m}\\)), as described in Equation (\\ref{eq:info-combine})."}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.15797/performance_comparison_figure.png"]}
{"uuid": "fd6765f7-0b78-502e-9275-3f37ee0b160f", "question": "Consider the paper that introduces the method which corresponds to the first row of the table. What specific improvement in accuracy percentage does the model proposed in the paper achieve over the state-of-the-art for 5-class sentiment classification in multimodal sentiment analysis?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["5e8f8496-8deb-510a-aeb9-49ffff159e23"], "reference_pdf": ["61bb0ab8-4419-5a2c-a8a1-6ec9c8512d8a", "3960e993-aece-5afc-a9d9-a232feae755a", "f33376c4-1446-5591-8cd8-edaa162293c6", "750c0d08-363e-59a3-8d37-6c5ad16551d8", "d625e278-c235-5992-bfb7-2e447d365a2e", "ee84be56-8306-5304-8a3a-3ad106e977f3", "94a3a713-4b94-5cba-a2ff-d1d0e1b04fb7", "6ea15eac-4060-5f1d-8629-76330e0b67c5", "39651ad0-168e-5246-98c3-2f973f1202c4", "ae7e311d-d5ed-5eec-a0c1-03cf2939de7f", "e4664f86-db28-5fec-a1de-52cf5cc3bc4a", "18ffe39d-717f-5eaa-b3d7-26da397a2650", "f0216761-d251-530a-8ee6-a5884b0d15d2", "9617d0cd-1ba2-55f5-ba67-079c53c46bba", "256dfb2a-1c40-5a19-9d6f-c00877580cc4", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method which corresponds to the first row of the table. What specific improvement in accuracy percentage does the model proposed in the paper achieve over the state-of-the-art for 5-class sentiment classification in multimodal sentiment analysis?", "reference_answer": "6.7"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05804/comparison_table.png"]}
{"uuid": "fea47045-7187-58b1-844a-6ac4ea939268", "question": "Consider the paper that introduces the dataset that corresponds to the last row of the table. Which specific linguistic phenomenon is used as an example in the paper to illustrate the challenge of detecting hate speech when comments use phrases that only make sense when read backwards?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "table", "text", "subjective"], "anchor_pdf": ["1788f4ae-0acc-52b5-be73-e172b198f535"], "reference_pdf": ["cc3e6e4a-1cd0-5e58-a2de-aea4e04f9fa8", "4e470d52-af5c-5fb4-8596-104107b9949a", "90f84f34-0fc3-5f12-80ee-eff109e02428", "46351f44-6981-5f11-8936-24b1d926681f", "69a73f12-18fe-5be6-b2f2-605926d56b88", "04235996-3396-5b9d-85ee-1f0262f8c751", "cfd9bcfc-924d-5175-96d2-c111a44925e3", "d39282a4-d3bb-51e7-8491-520b786fd079", "88eaf40c-dc71-5736-b1a5-7e39d2d01725", "7d0460c9-1ff3-5c75-b763-dfcc614e7946", "bc0adf93-62a6-5c6d-9cf9-32a404de12e3", "e0da4bd0-221a-5dc6-9f9f-f364385d2921", "ab336578-5d72-5504-96e1-f89d354c2515", "27248c8f-8afa-585c-8aba-7783c11d501c", "d133dc64-872a-5d68-aa1d-1c48c9ad1e65", "91b11d4c-44b0-54c6-83df-fa949b257373", "6afec1dc-863f-5f4d-b07b-42568d79c0a2", "29f9429b-0ff7-5e11-8fef-f6266228fa8a", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ccf560db-a30b-552f-ab16-80026764a35e", "e45897f5-4429-5750-a8fb-dcfa9a904b5f", "d4f09bf2-6feb-53d1-8ca6-a5413551966b", "40076536-9fb5-50c7-acb2-93db2c59e1d7", "0c2deafb-5ba6-5f61-93bf-cba4a976a858", "9e0baaab-f75d-5b52-b965-a5b427196392", "64ea97a6-b16c-52fe-ba4c-baad89c75ddf", "03e70d5c-ae9c-50f3-8d54-6e6fe067dd8d", "26e45afd-1c91-5f0f-bb47-33707acec072", "eb603d6c-2a60-504d-93ed-aef55ff4655b", "7f53ca74-d8c6-5880-9bc9-e35befaff0a3", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the dataset that corresponds to the last row of the table. Which specific linguistic phenomenon is used as an example in the paper to illustrate the challenge of detecting hate speech when comments use phrases that only make sense when read backwards?", "reference_answer": "Puns"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.11166/comparison_table.png"]}
{"uuid": "ff3a0b3b-8c25-56d6-a963-fa1a75a3e1d1", "question": "Consider the paper that introduces the method that achieves the highest score in the 'w/o p_out' setting. How does its performance in detecting out-of-distribution samples using ResNet on CIFAR-10, when SVHN is used as OOD, compare to the baseline and ODIN methods in terms of TNR at TPR 95%?", "answer_format": "You should answer the question in a short-answer form. Do not provide long answers.", "tags": ["multiple", "image", "text", "subjective"], "anchor_pdf": ["810b0721-c498-57eb-93f3-4687d2dc64f8"], "reference_pdf": ["96ffb0d8-e291-596b-8c52-bcb4f183ed44", "74bcffe4-c1bb-5022-8e6a-7a9fef895ed0", "b0a79d1a-de14-5e2c-a2f8-c8e66f707a89", "8f328ef8-5248-5492-b3c9-d115046efc43", "9523ad64-fad9-5352-bc32-ceb1a8f5adbc", "83cd0d28-4378-5b49-8949-01f5181b7b17", "1047803c-3229-546d-8a93-9027fcbe4df0", "8f13f0c9-2b92-5a09-8369-41969fc0924d", "e879e81b-c392-5e42-8658-34e328f1b1ca", "87a8fb3c-6f1d-53d7-95c5-baed9d1f223e", "82058002-7940-5f07-be28-abac6954e278", "f3dd87c3-4705-546b-ac6c-93d9d1692249", "78a2a197-944e-5f53-91c7-265b771d4c06", "de5ec475-b70f-5190-a798-98df54b25136", "d05f95b6-53e2-5fa5-a256-7c4c232feb64", "b3afe895-977b-58d5-89a8-69bf5f6d84a3", "d7e4e761-411b-5c7a-8d24-3a7b71ea2719", "37a5f603-9e5f-5fa5-bdfd-9dc0318ef668", "7c403e43-6318-5a9f-a3c8-40ff27f52369", "f554c584-7f48-587f-9f9b-4e4debbc5cad", "80686b1b-4ffa-54fb-a2fe-79152313a396", "8a533609-59b9-5837-a2c4-669dea41251a", "baa84a82-a8d5-5bc3-8896-82f9ef647504", "c811c5a5-c22a-5fd6-9f1c-1ffa1bde7c47", "65999ca9-2672-51e5-b596-2c9bb3cee2dd", "4a324a22-6bd2-5602-84bc-07231c819440", "ac1b0430-6781-5539-9d45-5067c0c6ff3e"], "conference": [], "reasoning_steps": [], "evaluator": {"eval_func": "eval_m3sciqa", "eval_kwargs": {"question": "Consider the paper that introduces the method that achieves the highest score in the 'w/o p_out' setting. How does its performance in detecting out-of-distribution samples using ResNet on CIFAR-10, when SVHN is used as OOD, compare to the baseline and ODIN methods in terms of TNR at TPR 95%?", "reference_answer": "96.42"}}, "state": {}, "annotator": "m3sciqa", "anchor_image": ["data/dataset/m3sciqa/images/2310.05083/comparison_figure.png"]}
